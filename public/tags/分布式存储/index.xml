<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fatedier blog </title>
    <link>http://blog.fatedier.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2016</rights>
    <updated>2016-05-25 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>部署openstack的对象存储服务swift</title>
          <link>http://blog.fatedier.com/2016/05/25/deploy-openstack-swift</link>
          <pubDate>Wed, 25 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/05/25/deploy-openstack-swift</guid>
          <description>

&lt;p&gt;OpenStack Swift 是一个开源项目，提供了弹性可伸缩、高可用的分布式对象存储服务，适合存储大规模非结构化数据。由于要开发自己的分布式存储应用，需要借鉴 swift 的一些架构，所以在自己的机器上搭建了一个集群环境用于测试。&lt;/p&gt;

&lt;h3 id=&#34;环境:15a147333eadc9d914016442056e059f&#34;&gt;环境&lt;/h3&gt;

&lt;p&gt;一台物理机上，开了三台虚拟机，操作系统是 Centos7&lt;/p&gt;

&lt;p&gt;ip 为 &lt;strong&gt;192.168.2.129, 192.168.2.130, 192.168.2.131&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之前安装过一次，当时是 2.4.0 版本，目前最新的是 2.7.0 版本，最新的版本由于我的机器上缺少某些动态库，所以还是选择了比较熟悉的 2.4.0 版本，基本上的步骤是一样的。&lt;/p&gt;

&lt;p&gt;后续的安装步骤需要在三台机器上全部执行一遍，下文中的 &lt;code&gt;user:user&lt;/code&gt; 根据需要修改为自己机器上的用户。&lt;/p&gt;

&lt;p&gt;整个步骤参考了官方的文档： &lt;a href=&#34;http://docs.openstack.org/developer/swift/development_saio.html&#34;&gt;http://docs.openstack.org/developer/swift/development_saio.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装各种依赖:15a147333eadc9d914016442056e059f&#34;&gt;安装各种依赖&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo yum install curl gcc memcached rsync sqlite xfsprogs git-core \
    libffi-devel xinetd liberasurecode-devel \
    python-setuptools \
    python-coverage python-devel python-nose \
    pyxattr python-eventlet \
    python-greenlet python-paste-deploy \
    python-netifaces python-pip python-dns \
    python-mock
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;创建磁盘设备:15a147333eadc9d914016442056e059f&#34;&gt;创建磁盘设备&lt;/h3&gt;

&lt;p&gt;由于 swift 需要使用 xfs 格式的磁盘，这里我们使用回环设备。&lt;/p&gt;

&lt;h4 id=&#34;创建一个用于回环设备的2gb大小的文件:15a147333eadc9d914016442056e059f&#34;&gt;创建一个用于回环设备的2GB大小的文件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir /srv
sudo truncate -s 1GB /srv/swift-disk
sudo mkfs.xfs /srv/swift-disk
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;修改-etc-fstab:15a147333eadc9d914016442056e059f&#34;&gt;修改 /etc/fstab&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/srv/swift-disk /srv/node/sdb1 xfs loop,noatime,nodiratime,nobarrier,logbufs=8 0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建挂载点并进行挂载:15a147333eadc9d914016442056e059f&#34;&gt;创建挂载点并进行挂载&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /srv/node/sdb1
sudo mount /srv/node/sdb1
sudo chown -R user:user /srv/node
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;下载安装-swift-和-swift-client:15a147333eadc9d914016442056e059f&#34;&gt;下载安装 swift 和 swift-client&lt;/h4&gt;

&lt;p&gt;从 git 下载这两个项目之后切换到 2.4.0 版本，安装 python 依赖以后使用 &lt;code&gt;python setup.py&lt;/code&gt; 安装。&lt;/p&gt;

&lt;p&gt;直接通过 yum 安装的 pip 可能版本不是最新的，需要升级，使用 &lt;code&gt;pip install --upgrade pip&lt;/code&gt; 升级。&lt;/p&gt;

&lt;h5 id=&#34;swift-client:15a147333eadc9d914016442056e059f&#34;&gt;swift-client&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/openstack/python-swiftclient.git
git checkout 2.4.0
cd ./python-swiftclient; sudo python setup.py develop; cd -
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;swift:15a147333eadc9d914016442056e059f&#34;&gt;swift&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/openstack/swift.git
git checkout 2.4.0
cd ./swift; sudo pip install -r requirements.txt; sudo python setup.py develop; cd -
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;配置-etc-rc-local:15a147333eadc9d914016442056e059f&#34;&gt;配置 /etc/rc.local&lt;/h5&gt;

&lt;p&gt;需要在每次开机时都创建一些需要的目录。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /var/run/swift
sudo chown user:user /var/run/swift
sudo mkdir -p /var/cache/swift
sudo chown user:user /var/cache/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置-rsync:15a147333eadc9d914016442056e059f&#34;&gt;配置 rsync&lt;/h3&gt;

&lt;h4 id=&#34;修改-etc-rsyncd-conf:15a147333eadc9d914016442056e059f&#34;&gt;修改 /etc/rsyncd.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# /etc/rsyncd: configuration file for rsync daemon mode
uid = root
gid = root
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
address = 0.0.0.0

[account]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/account.lock

[container]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/container.lock

[object]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/object.lock
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;启动-rsync-并设置开机启动:15a147333eadc9d914016442056e059f&#34;&gt;启动 rsync 并设置开机启动&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo chkconfig rsyncd on
sudo service rsyncd start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置rsyslog让每个程序输出独立的日志-可选:15a147333eadc9d914016442056e059f&#34;&gt;配置rsyslog让每个程序输出独立的日志（可选）&lt;/h3&gt;

&lt;p&gt;swift 默认将日志信息输出到文件 /var/log/syslog 中。如果要按照个人需求设置 rsyslog，生成另外单独的 swift日志文件，就需要另外配置。&lt;/p&gt;

&lt;h4 id=&#34;创建日志配置文件-etc-rsyslog-d-10-swift-conf:15a147333eadc9d914016442056e059f&#34;&gt;创建日志配置文件 /etc/rsyslog.d/10-swift.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Uncomment the following to have a log containing all logs together
#local1,local2,local3,local4,local5.*   /var/log/swift/all.log

# Uncomment the following to have hourly proxy logs for stats processing
$template HourlyProxyLog,&amp;quot;/var/log/swift/hourly/%$YEAR%%$MONTH%%$DAY%%$HOUR%&amp;quot;
#local1.*;local1.!notice ?HourlyProxyLog

local1.*;local1.!notice /var/log/swift/proxy.log
local1.notice           /var/log/swift/ proxy.error
local1.*                ~

local2.*;local2.!notice /var/log/swift/object.log
local2.notice           /var/log/swift/ object.error
local2.*                ~

local3.*;local3.!notice /var/log/swift/container.log
local3.notice           /var/log/swift/ container.error
local3.*                ~

local4.*;local4.!notice /var/log/swift/account.log
local4.notice           /var/log/swift/ account.error
local4.*                ~
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;编辑文件-etc-rsyslog-conf-更改参数-privdroptogroup-为-adm:15a147333eadc9d914016442056e059f&#34;&gt;编辑文件 /etc/rsyslog.conf，更改参数 $PrivDropToGroup 为 adm&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$PrivDropToGroup adm
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-var-log-swift-目录-用于存放独立日志:15a147333eadc9d914016442056e059f&#34;&gt;创建 /var/log/swift 目录，用于存放独立日志&lt;/h4&gt;

&lt;p&gt;此外，上面的 &lt;code&gt;10-swift.conf&lt;/code&gt; 文件中设置了输出 Swift Proxy Server 每小时的 stats 日志信息，于是也要创建 &lt;code&gt;/var/log/swift/hourly&lt;/code&gt; 目录。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /var/log/swift/hourly
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;更改-swift-独立日志目录的权限:15a147333eadc9d914016442056e059f&#34;&gt;更改 swift 独立日志目录的权限&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chown -R root.adm /var/log/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;重启-rsyslog-服务:15a147333eadc9d914016442056e059f&#34;&gt;重启 rsyslog 服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo service rsyslog restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动-memcached-并设置开机启动:15a147333eadc9d914016442056e059f&#34;&gt;启动 memcached 并设置开机启动&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo service memcached start
sudo chkconfig memcached on
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置swift相关的配置文件:15a147333eadc9d914016442056e059f&#34;&gt;配置swift相关的配置文件&lt;/h3&gt;

&lt;h4 id=&#34;创建存储-swift-配置文件的目录:15a147333eadc9d914016442056e059f&#34;&gt;创建存储 swift 配置文件的目录&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir /etc/swift
sudo chown -R user:user /etc/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-swift-配置文件-etc-swift-swift-conf:15a147333eadc9d914016442056e059f&#34;&gt;创建 swift 配置文件 /etc/swift/swift.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[swift-hash]

# random unique string that can never change (DO NOT LOSE)
swift_hash_path_suffix = jtangfs
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-account-服务-etc-swift-account-server-conf:15a147333eadc9d914016442056e059f&#34;&gt;配置 account 服务 /etc/swift/account-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6002
workers = 4
user = wcl
log_facility = LOG_LOCAL4

[pipeline:main]
pipeline = account-server

[app:account-server]
use = egg:swift#account

[account-replicator]
[account-auditor]
[account-reaper]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-container-服务-etc-swift-container-server-conf:15a147333eadc9d914016442056e059f&#34;&gt;配置 container 服务 /etc/swift/container-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6001
workers = 4
user = wcl
log_facility = LOG_LOCAL3

[pipeline:main]
pipeline = container-server

[app:container-server]
use = egg:swift#container

[container-replicator]

[container-updater]

[container-auditor]

[container-sync]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-object-服务-etc-swift-object-server-conf:15a147333eadc9d914016442056e059f&#34;&gt;配置 object 服务 /etc/swift/object-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6000
workers = 4
user = wcl
log_facility = LOG_LOCAL2

[pipeline:main]
pipeline = object-server

[app:object-server]
use = egg:swift#object

[object-replicator]

[object-updater]

[object-auditor]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-proxy-服务-etc-swift-proxy-server-conf:15a147333eadc9d914016442056e059f&#34;&gt;配置 proxy 服务 /etc/swift/proxy-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
bind_port = 8080
user = wcl
workers = 2
log_facility = LOG_LOCAL1

[pipeline:main]
pipeline = healthcheck cache tempauth proxy-logging proxy-server

[app:proxy-server]
use = egg:swift#proxy
allow_account_management = true
account_autocreate = true

[filter:tempauth]
use = egg:swift#tempauth
user_admin_admin = admin .admin .reseller_admin
user_test_tester = testing .admin
user_test2_tester2 = testing2 .admin
user_test_tester3 = testing3
reseller_prefix = AUTH
token_life = 86400
# account和token的命名前缀，注意此处不可以加&amp;quot;_&amp;quot;。
# 例如X-Storage-Ur可能l为http://127.0.0.1:8080/v1/AUTH_test
# 例如X-Auth-Token为AUTH_tk440e9bd9a9cb46d6be07a5b6a585f7d1# token的有效期，单位：秒。

[filter:healthcheck]
use = egg:swift#healthcheck

[filter:cache]
use = egg:swift#memcache

# 这里可以是多个memcache server，proxy会自动当作一个集群来使用# 例如 memcache_servers = 192.168.2.129:11211,192.168.2.130:11211,192.168.2.131

[filter:proxy-logging]
use = egg:swift#proxy_logging
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注：&lt;code&gt;user_admin_admin = admin .admin .reseller_admin&lt;/code&gt; 后面还可以增加一项 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt;，显示地指定 swift 为该用户提供的存储服务入口，admin 用户通过认证后，swift 会把 Token 和该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt;  返回给用户，此后 admin 用户可以使用该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 访问 swift 来请求存储服务。特别值得说明的是，如果在 Proxy Server 前面增加了负载均衡器（如 nginx），那么该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 应该指向负载均衡器，使得用户在通过认证后，向负载均衡器发起存储请求，再由负载均衡器将请求均衡地分发给 Proxy Server 集群。此时的 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 形如 &lt;code&gt;http://&amp;lt;LOAD_BALANCER_HOSTNAME&amp;gt;:&amp;lt;PORT&amp;gt;/v1/AUTH_admin&lt;/code&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建-ring-文件:15a147333eadc9d914016442056e059f&#34;&gt;创建 ring 文件&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;swift&lt;/strong&gt; 安装完成后会有一个 &lt;strong&gt;swift-ring-builder&lt;/strong&gt; 程序用于对 ring 的相关操作。&lt;/p&gt;

&lt;h4 id=&#34;生成-ring:15a147333eadc9d914016442056e059f&#34;&gt;生成 ring&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder create 18 3 1
swift-ring-builder container.builder create 18 3 1
swift-ring-builder object.builder create 18 3 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要事先创建好3个 ring，18 表示 partition 数为2的18次方，3表示 replication 数为3，1 表示分区数据的最短迁移间隔时间为1小时。（官网说明里如果移除设备的话不在这个限制内）&lt;/p&gt;

&lt;h3 id=&#34;向-ring-中加入设备:15a147333eadc9d914016442056e059f&#34;&gt;向 ring 中加入设备&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder add z1-192.168.2.129:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.129:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.129:6000/sdb1 100

swift-ring-builder account.builder add z2-192.168.2.130:6002/sdb1 100
swift-ring-builder container.builder add z2-192.168.2.130:6001/sdb1 100
swift-ring-builder object.builder add z2-192.168.2.130:6000/sdb1 100

swift-ring-builder account.builder add z2-192.168.2.131:6002/sdb1 100
swift-ring-builder container.builder add z2-192.168.2.131:6001/sdb1 100
swift-ring-builder object.builder add z2-192.168.2.131:6000/sdb1 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;z1&lt;/strong&gt; 和 &lt;strong&gt;z2&lt;/strong&gt; 表示 &lt;strong&gt;zone1&lt;/strong&gt; 和 &lt;strong&gt;zone2&lt;/strong&gt;（&lt;strong&gt;zone&lt;/strong&gt; 这个概念是虚拟的，可以将一个 &lt;strong&gt;device&lt;/strong&gt; 划定到一个 &lt;strong&gt;zone&lt;/strong&gt;，在分配 &lt;strong&gt;partition&lt;/strong&gt; 的时候会考虑到这个因素，尽量划分到不同的 &lt;strong&gt;zone&lt;/strong&gt; 中）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sdb1&lt;/strong&gt; 为 &lt;strong&gt;swift&lt;/strong&gt; 所使用的存储空间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;100&lt;/strong&gt; 代表设备的权重，也是在分配 &lt;strong&gt;partition&lt;/strong&gt; 的时候会考虑的因素。&lt;/p&gt;

&lt;h4 id=&#34;rebalance:15a147333eadc9d914016442056e059f&#34;&gt;rebalance&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder rebalance
swift-ring-builder container.builder rebalance
swift-ring-builder object.builder rebalance
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;将-ring-文件传输到其他机器的-etc-swift-目录下:15a147333eadc9d914016442056e059f&#34;&gt;将 ring 文件传输到其他机器的 /etc/swift 目录下&lt;/h4&gt;

&lt;p&gt;最终生成的 ring 文件以 &lt;code&gt;.gz&lt;/code&gt; 结尾。&lt;/p&gt;

&lt;h3 id=&#34;创建初始化-起停等脚本:15a147333eadc9d914016442056e059f&#34;&gt;创建初始化、起停等脚本&lt;/h3&gt;

&lt;p&gt;由于 swift 涉及的组件较多，起停都比较麻烦，所以最好先写好起停脚本。&lt;/p&gt;

&lt;h4 id=&#34;remake-rings-sh-脚本文件-用于完成-ring-的重新创建:15a147333eadc9d914016442056e059f&#34;&gt;remake_rings.sh 脚本文件，用于完成 ring 的重新创建&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
cd /etc/swift

rm -f *.builder *.ring.gz backups/*.builder backups/*.ring.gz

swift-ring-builder account.builder create 18 3 1
swift-ring-builder container.builder create 18 3 1
swift-ring-builder object.builder create 18 3 1

swift-ring-builder account.builder add z1-192.168.2.129:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.129:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.129:6000/sdb1 100

swift-ring-builder account.builder add z1-192.168.2.130:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.130:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.130:6000/sdb1 100

swift-ring-builder account.builder add z1-192.168.2.131:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.131:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.131:6000/sdb1 100

swift-ring-builder account.builder rebalance
swift-ring-builder container.builder rebalance
swift-ring-builder object.builder rebalance
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;reset-swift-sh-脚本文件-用于一键清空-swift-的对象数据和日志-完全重置:15a147333eadc9d914016442056e059f&#34;&gt;reset_swift.sh 脚本文件，用于一键清空 swift 的对象数据和日志，完全重置&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init all stop

find /var/log/swift -type f -exec rm -f {} \;

sudo umount /srv/node/sdb1
sudo mkfs.xfs -f -i size=1024 /srv/swift-disk
sudo mount /srv/node/sdb1

sudo chown wcl:wcl /srv/node/sdb1

sudo rm -f /var/log/debug /var/log/messages /var/log/rsyncd.log /var/log/syslog
sudo service rsyslog restart
sudo service rsyncd restart
sudo service memcached restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;start-main-sh-脚本文件-用于启动-swift-所有基础服务:15a147333eadc9d914016442056e059f&#34;&gt;start_main.sh 脚本文件，用于启动 swift 所有基础服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init main start
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-main-sh-脚本文件-用于关闭-swift-所有基础服务:15a147333eadc9d914016442056e059f&#34;&gt;stop_main.sh 脚本文件，用于关闭 swift 所有基础服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init main stop
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;start-all-sh-脚本文件:15a147333eadc9d914016442056e059f&#34;&gt;start_all.sh 脚本文件&lt;/h4&gt;

&lt;p&gt;一键启动 swift 的所有服务。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init proxy start
swift-init account-server start
swift-init account-replicator start
swift-init account-auditor start
swift-init container-server start
swift-init container-replicator start
swift-init container-updater start
swift-init container-auditor start
swift-init object-server start
swift-init object-replicator start
swift-init object-updater start
swift-init object-auditor start
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-all-sh-脚本文件:15a147333eadc9d914016442056e059f&#34;&gt;stop_all.sh 脚本文件&lt;/h4&gt;

&lt;p&gt;一键关闭 swift的所有服务。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init proxy stop
swift-init account-server stop
swift-init account-replicator stop
swift-init account-auditor stop
swift-init container-server stop
swift-init container-replicator stop
swift-init container-updater stop
swift-init container-auditor stop
swift-init object-server stop
swift-init object-replicator stop
swift-init object-updater stop
swift-init object-auditor stop
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;启动-swift-服务:15a147333eadc9d914016442056e059f&#34;&gt;启动 swift 服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./start_all.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;动态扩容:15a147333eadc9d914016442056e059f&#34;&gt;动态扩容&lt;/h3&gt;

&lt;p&gt;重新编写 &lt;strong&gt;remake_rings.sh&lt;/strong&gt; 脚本中的内容，加上需要添加的机器信息，重新生成 ring 文件。&lt;/p&gt;

&lt;p&gt;将新生成的 ring 文件放到每一个服务器的 &lt;code&gt;/etc/swift&lt;/code&gt; 目录下。&lt;/p&gt;

&lt;p&gt;swift 的各个组件程序会定期重新读取 rings 文件。&lt;/p&gt;

&lt;h3 id=&#34;一些需要注意的地方:15a147333eadc9d914016442056e059f&#34;&gt;一些需要注意的地方&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;服务器时间必须一致，不一致的话会出现问题。测试中有一台服务器比其他的慢了2小时，结果向这台 proxy  上传文件，返回成功，但是其实并没有上传成功，可能是由于时间原因，在其他机器看来这个文件已经被删除掉了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;restful-api-及测试:15a147333eadc9d914016442056e059f&#34;&gt;RESTful API 及测试&lt;/h3&gt;

&lt;p&gt;swift 可以通过 swift-proxy 提供的 RESTful API 来进行操作。&lt;/p&gt;

&lt;p&gt;另外一种方法就是使用 &lt;code&gt;swift&lt;/code&gt; 程序来进行增删查改的操作，可以实现和 RESTful API 相同的功能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;所有的操作都需要先获取一个 auth-token，之后的所有操作都需要在 header 中附加上 X-Auth-Token 字段的信息进行权限认证。有一定时效性，过期后需要再次获取。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;获取-x-storage-url-和-x-auth-token:15a147333eadc9d914016442056e059f&#34;&gt;获取 X-Storage-Url 和 X-Auth-Token&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/auth/v1.0 -v -H &#39;X-Storage-User: test:tester&#39; -H &#39;X-Storage-Pass: testing&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的用户和密码是在 &lt;code&gt;proxy-server.conf&lt;/code&gt; 中配置的。&lt;/p&gt;

&lt;p&gt;返回结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt; HTTP/1.1 200 OK
&amp;lt; X-Storage-Url: http://127.0.0.1:8080/v1/AUTH_test
&amp;lt; X-Auth-Token: AUTH_tk039a65cb62594b319faea9dc492039a2
&amp;lt; Content-Type: text/html; charset=UTF-8
&amp;lt; X-Storage-Token: AUTH_tk039a65cb62594b319faea9dc492039a2
&amp;lt; X-Trans-Id: tx7bcd450378d84b56b1482-005745b5c8
&amp;lt; Content-Length: 0
&amp;lt; Date: Wed, 25 May 2016 14:25:12 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看账户信息:15a147333eadc9d914016442056e059f&#34;&gt;查看账户信息&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/v1/AUTH_test -v -H &#39;X-Auth-Token: AUTH_tk039a65cb62594b319faea9dc492039a2&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt; HTTP/1.1 200 OK
&amp;lt; Content-Length: 5
&amp;lt; X-Account-Object-Count: 1
&amp;lt; X-Account-Storage-Policy-Policy-0-Bytes-Used: 4
&amp;lt; X-Account-Storage-Policy-Policy-0-Container-Count: 1
&amp;lt; X-Timestamp: 1464106581.68979
&amp;lt; X-Account-Storage-Policy-Policy-0-Object-Count: 1
&amp;lt; X-Account-Bytes-Used: 4
&amp;lt; X-Account-Container-Count: 1
&amp;lt; Content-Type: text/plain; charset=utf-8
&amp;lt; Accept-Ranges: bytes
&amp;lt; X-Trans-Id: tx59e9c2f1772349d684d04-005745b713
&amp;lt; Date: Wed, 25 May 2016 14:30:43 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-container:15a147333eadc9d914016442056e059f&#34;&gt;创建 container&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/v1/AUTH_test/default -X PUT -H &amp;quot;X-Auth_Token: AUTH_tk039a65cb62594b319faea9dc492039a2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 test 用户下创建了一个名为 default 的 container。&lt;/p&gt;

&lt;h4 id=&#34;restful-api-总结:15a147333eadc9d914016442056e059f&#34;&gt;RESTful API 总结&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;资源类型&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;URL&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;PUT&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;POST&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;DELETE&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;HEAD&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;账户&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取容器列表&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取账户元数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/container&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象列表&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;创建容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;更新容器元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;删除容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取容器元数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/container/object&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象内容和元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;创建、更新或拷贝对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;更新对象元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;删除对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象元数据&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;直接使用-swift-客户端程序进行操作:15a147333eadc9d914016442056e059f&#34;&gt;直接使用 swift 客户端程序进行操作&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;-A&lt;/strong&gt; 参数指定 url，&lt;strong&gt;-U&lt;/strong&gt; 参数指定用户，&lt;strong&gt;-K&lt;/strong&gt; 参数指定密码。&lt;/p&gt;

&lt;h5 id=&#34;查看指定账户的-swift-存储信息:15a147333eadc9d914016442056e059f&#34;&gt;查看指定账户的 swift 存储信息&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing stat
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;创建-container-1:15a147333eadc9d914016442056e059f&#34;&gt;创建 container&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing post default
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看-test-用户的-container-列表:15a147333eadc9d914016442056e059f&#34;&gt;查看 test 用户的 container 列表&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing list
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;上传object-文件-上传-test-cpp-文件到-default-容器中:15a147333eadc9d914016442056e059f&#34;&gt;上传Object（文件），上传 test.cpp 文件到 default 容器中&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing upload default ./dd.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看容器中的内容:15a147333eadc9d914016442056e059f&#34;&gt;查看容器中的内容&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing list default
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;下载object-文件:15a147333eadc9d914016442056e059f&#34;&gt;下载Object（文件）&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing download default dd.cpp
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>codis 2.x版本环境搭建与测试</title>
          <link>http://blog.fatedier.com/2015/10/07/installation-and-testing-of-codis-version-two</link>
          <pubDate>Wed, 07 Oct 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/10/07/installation-and-testing-of-codis-version-two</guid>
          <description>

&lt;p&gt;Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别（有一些命令不支持），上层应用可以像使用单机的 Redis 一样，Codis 底层会处理请求的转发。Codis 支持不停机进行数据迁移, 对于前面的客户端来说是透明的, 可以简单的认为后面连接的是一个内存无限大的 Redis 服务。&lt;/p&gt;

&lt;h3 id=&#34;安装并启动-zookeeper:57de784f564f909e53fd43ba72fc074a&#34;&gt;安装并启动 zookeeper&lt;/h3&gt;

&lt;p&gt;codis 2.x 版本重度依赖于 zookeeper。&lt;/p&gt;

&lt;p&gt;从官网下载 &lt;a href=&#34;http://zookeeper.apache.org/releases.html&#34;&gt;zookeeper&lt;/a&gt;，解压安装。&lt;/p&gt;

&lt;p&gt;使用默认配置启动 zookeeper &lt;code&gt;sh ./bin/zkServer.sh start&lt;/code&gt;，监听地址为 &lt;code&gt;2181&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;下载安装-codis:57de784f564f909e53fd43ba72fc074a&#34;&gt;下载安装 codis&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;go get -d github.com/CodisLabs/codis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;进入源码根目录 &lt;code&gt;cd $GOPATH/src/github.com/CodisLabs/codis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;执行安装脚本 &lt;code&gt;./bootstrap.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：这里第一步和第三步（会下载第三方库到本地）需要从 github copy 数据，鉴于网络环境的问题，时间会比较长。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之后生成的可执行文件都在 &lt;code&gt;codis/bin&lt;/code&gt; 文件夹下。&lt;/p&gt;

&lt;h3 id=&#34;部署-codis-server:57de784f564f909e53fd43ba72fc074a&#34;&gt;部署 codis-server&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;codis-server&lt;/strong&gt; 基于 &lt;strong&gt;redis 2.8.21&lt;/strong&gt; 稍微进行了一些修改以支持原子性的迁移数据，具体用法和 redis 一致。&lt;/p&gt;

&lt;p&gt;将 &lt;code&gt;bin&lt;/code&gt; 文件夹下的 codis-server 拷贝到集群中每个节点，和 redis-server 的启动命令一样，指定配置文件，启动。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这里要注意 redis.conf 配置中需要设置 maxmemory，不然无法自动按照负载均衡的方式分配 slot（可以手动分配），推荐单台机器部署多个 redis 实例。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-server ./redis_conf/redis_6400.conf&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;启动-dashboard:57de784f564f909e53fd43ba72fc074a&#34;&gt;启动 dashboard&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;dashboard&lt;/strong&gt; 既是 codis 集群的管理中心，又提供了一个人性化的 web 界面，方便查看统计信息以及对集群进行管理操作。&lt;/p&gt;

&lt;p&gt;启动 web 控制面板，注意这里要用到配置文件，不指定的话就是当前目录下的 config.ini，可以用 &lt;code&gt;-c&lt;/code&gt; 参数指定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nohup ./bin/codis-config -c ./config.ini dashboard --addr=:18087 &amp;amp;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;初始化-slot:57de784f564f909e53fd43ba72fc074a&#34;&gt;初始化 slot&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot init&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;该命令会在 zookeeper 上创建 slot 相关信息。&lt;/p&gt;

&lt;h3 id=&#34;添加-group:57de784f564f909e53fd43ba72fc074a&#34;&gt;添加 group&lt;/h3&gt;

&lt;p&gt;每个 &lt;strong&gt;group&lt;/strong&gt; 只能有一个 &lt;strong&gt;master&lt;/strong&gt; 和多个 &lt;strong&gt;slave&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;命令格式： &lt;code&gt;codis-config -c ./config.ini server add &amp;lt;group_id&amp;gt; &amp;lt;redis_addr&amp;gt; &amp;lt;role&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;例如向 group 1 和 group 2 中各加入两个 codis-server 实例，一主一从。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 1 localhost:6379 master&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 1 localhost:6380 slave&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 2 localhost:6381 master&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 2 localhost:6382 slave&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1 代表 group_id，必须为数字，且从 1 开始&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;分配-slot:57de784f564f909e53fd43ba72fc074a&#34;&gt;分配 slot&lt;/h3&gt;

&lt;h4 id=&#34;手动分配:57de784f564f909e53fd43ba72fc074a&#34;&gt;手动分配&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;codis-config -c ./config.ini slot range-set &amp;lt;slot_from&amp;gt; &amp;lt;slot_to&amp;gt; &amp;lt;group_id&amp;gt; &amp;lt;status&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;slot&lt;/strong&gt; 默认为 &lt;strong&gt;1024&lt;/strong&gt; 个，范围是 &lt;strong&gt;0 - 1023&lt;/strong&gt;，需要将这 1024 个 slot 分配到集群中不同的 group 中。&lt;/p&gt;

&lt;p&gt;例如将 1024 个 slot 平均分配到&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot range-set 0 511 1 online&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot range-set 512 1023 2 online&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;自动分配:57de784f564f909e53fd43ba72fc074a&#34;&gt;自动分配&lt;/h4&gt;

&lt;p&gt;在 dashboard 上可以自动分配 slot，会按照负载均衡的方式进行分配，不推荐使用，因为可能会造成大量数据的迁移。&lt;/p&gt;

&lt;p&gt;或者使用命令进行自动分配&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot rebalance&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;启动-codis-proxy:57de784f564f909e53fd43ba72fc074a&#34;&gt;启动 codis-proxy&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-proxy -c ./config.ini -L ./log/proxy.log --cpu=8 --addr=10.10.100.1:19000 --http-addr=10.10.100.1:11000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意：这里 &amp;ndash;addr 和 &amp;ndash;http-addr 不要填 0.0.0.0，要绑定一个具体的 ip，不然 zookeeper 中存的将是hostname，会导致 dashboard 无法连接。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;codis-proxy 是无状态的，可以部署多个，且用 go 编写，可以利用多核，建议 cpu 设置核心数的一半到2/3，19000 即为访问 redis 集群的端口，11000 为获取 proxy 相关状态的端口。&lt;/p&gt;

&lt;p&gt;之后使用 codis-config 将 codis-proxy 加入进来，也就是设置online（后来更新了一个版本，默认启动后即自动注册为online）&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bin/codis-config -c ./config.ini proxy online &amp;lt;proxy_name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;需要注意的是，启动 codis-proxy，会在 zookeeper 中注册一个 node，地址为 /zk/codis/db_test/fence，如果使用 kill -9 强行杀掉进程的话，这个会一直存在，需要手工删除。且 node 名称为 [hostname:port]，所以需要注意这个组合不能重复。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;主从切换:57de784f564f909e53fd43ba72fc074a&#34;&gt;主从切换&lt;/h3&gt;

&lt;p&gt;官方建议是手工操作，避免数据不一致的问题，但是没有自动容灾的话可用性太差。&lt;/p&gt;

&lt;p&gt;官方另外提供了一个工具，&lt;strong&gt;codis-ha&lt;/strong&gt;，这是一个通过 codis 开放的 api 实现自动切换主从的工具。该工具会在检测到 master 挂掉的时候将其下线并选择其中一个 slave 提升为 master 继续提供服务。&lt;/p&gt;

&lt;p&gt;这个工具不是很好用，如果 codis-ha 连接 dashboard 失败之后进程就会自动退出，需要手动重启或者使用 supervisor 拉起来。另外，当有机器被提升为 master 之后，其他 slave 的状态不会改变，还是从原 master 同步数据。原来的 master 重启之后处于 offline 状态，也需要手动加入 group 指定为 slave。也就是说有master 挂掉后，其余机器的状态需要手动修改。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-ha --codis-config=10.10.100.3:18087 --productName=common&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;10.10.100.14:18088&lt;/code&gt; 为 dashboard 所在机器的 ip 和端口。&lt;/p&gt;

&lt;h3 id=&#34;旧数据的迁移:57de784f564f909e53fd43ba72fc074a&#34;&gt;旧数据的迁移&lt;/h3&gt;

&lt;p&gt;官方提供了一个 &lt;strong&gt;redis-port&lt;/strong&gt; 工具可以将旧 redis 中的数据实时迁移到 codis 集群中，之后需要修改各服务配置文件，重启服务，指向 codis 集群即可。&lt;/p&gt;

&lt;h3 id=&#34;性能测试:57de784f564f909e53fd43ba72fc074a&#34;&gt;性能测试&lt;/h3&gt;

&lt;p&gt;测试环境： 24核 2.1GHz，4个redis实例&lt;/p&gt;

&lt;h4 id=&#34;不启用-pipeline:57de784f564f909e53fd43ba72fc074a&#34;&gt;不启用 pipeline&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;SET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;MSET&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;redis单机&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58997.05&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58651.02&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;33557.05&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis1核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;42973.79&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;33003.30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12295.58&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis4核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;44208.66&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;39936.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;21743.86&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;39478.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;23052.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;24679.17&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis12核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;28943.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;24224.81&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;21376.66&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核2proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62085.65&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;68964.40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;48298.74&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;pipeline-100:57de784f564f909e53fd43ba72fc074a&#34;&gt;pipeline = 100&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;SET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;MSET&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;redis单机&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;259067.36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;340136.06&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;40387.72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis1核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;158982.52&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;166112.95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15199.88&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis4核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;491159.12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;403551.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;40157.42&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;518134.72&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;537634.38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58156.44&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis12核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;520833.34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;500000.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;53418.80&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核2proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;529812.81&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;607041.47&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62872.28&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;通过测试可以看出，使用 codis 会在性能上比原来直接使用 redis 会有所下降，但是优势就在于可以通过横向扩展（加机器）的方式去提高 redis 的存储容量以及并发量。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Redis集群调研</title>
          <link>http://blog.fatedier.com/2015/09/15/redis-cluster-survey</link>
          <pubDate>Tue, 15 Sep 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/09/15/redis-cluster-survey</guid>
          <description>

&lt;p&gt;Redis作为一个使用场景很高的NoSQL数据库，支持了较为丰富的数据类型，相比于其他关系型数据库在性能方面优势明显。互联网公司通常更加倾向于将一些热点数据放入Redis中来承载高吞吐量的访问。&lt;/p&gt;

&lt;p&gt;单机Redis在普通的服务器上通常ops上限在5w左右，开启pipeline的情况下在20-30w左右。对于大多数中小公司来说，通常单机的Redis已经足够，最多根据不同业务分散到多台Redis。&lt;/p&gt;

&lt;h3 id=&#34;为什么需要集群:51fa3b005f880190963d473247382d62&#34;&gt;为什么需要集群&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Redis单线程特性，多请求顺序执行，单个耗时的操作会阻塞后续的操作&lt;/li&gt;
&lt;li&gt;单机内存有限&lt;/li&gt;
&lt;li&gt;某些特殊业务，带宽压力较大&lt;/li&gt;
&lt;li&gt;单点问题，缺乏高可用性&lt;/li&gt;
&lt;li&gt;不能动态扩容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Redis集群的目标就是为了实现高可用性，避免性能瓶颈，可动态扩容，易于做监控告警。&lt;/p&gt;

&lt;h3 id=&#34;三种主流的集群解决方案:51fa3b005f880190963d473247382d62&#34;&gt;三种主流的集群解决方案&lt;/h3&gt;

&lt;h4 id=&#34;客户端静态分片:51fa3b005f880190963d473247382d62&#34;&gt;客户端静态分片&lt;/h4&gt;

&lt;p&gt;通常需要 smart-client 支持，在业务程序端根据预先设置的路由规则进行分片，从而实现对多个redis实例的分布式访问。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-jedis.png&#34; alt=&#34;jedis&#34; /&gt;&lt;/p&gt;

&lt;p&gt;鉴于redis本身的高性能，并且有一些设计良好的第三方库，例如java开发者可以使用jedis，所以很多小公司使用此方案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt; 相比于使用代理，减少了一层网络传输的消耗，效率较高。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt; 当redis实例需要扩容或切换的情况下，需要修改业务端的程序，较为麻烦。并且需  要维护各个语言的客户端版本，如果要升级客户端成本也会比较高。出现故障时难以及时定位问题。（有些smart-client借助于zookeeper维护客户端访问redis实例的一致性）&lt;/p&gt;

&lt;h4 id=&#34;proxy分片:51fa3b005f880190963d473247382d62&#34;&gt;Proxy分片&lt;/h4&gt;

&lt;p&gt;通过统一的代理程序访问多个redis实例，比如业内曾广泛使用的 twemproxy 以及 豌豆荚开源的 codis。（twemproxy是twitter开源的一个redis和memcache代理服务器，只用于作为简单的代理中间件，目前twitter内部已经不再使用）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt; 业务程序端只需要使用普通的api去访问代理程序即可。各种组件分离，以后升级较为容易。也避免了客户端需要维持和每个redis实例的长连接导致连接数过多。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt; 增加了一层中间件，增加了网络和数据处理的消耗，性能下降。&lt;/p&gt;

&lt;h4 id=&#34;official-redis-cluster:51fa3b005f880190963d473247382d62&#34;&gt;Official Redis Cluster&lt;/h4&gt;

&lt;p&gt;Redis3.0之后的版本开始正式支持 redis cluster，核心目标是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;性能：&lt;/strong&gt;Redis作者比较看重性能，增加集群不能对性能有较大影响，所以Redis采用了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;水平扩展：&lt;/strong&gt;官方文档中称目标是能线性扩展到1000结点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可用性：&lt;/strong&gt;集群具有了以前Sentinel的监控和自动Failover能力。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;基于twemproxy的redis集群环境:51fa3b005f880190963d473247382d62&#34;&gt;基于twemproxy的redis集群环境&lt;/h3&gt;

&lt;h4 id=&#34;整体架构图:51fa3b005f880190963d473247382d62&#34;&gt;整体架构图&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-twemproxy-architecture.png&#34; alt=&#34;twemproxy_architecture&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;twemproxy的特点:51fa3b005f880190963d473247382d62&#34;&gt;twemproxy的特点&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;支持失败的节点自动摘除（仅作为缓存时）&lt;/li&gt;
&lt;li&gt;所有的key通过一致性哈希算法分布到集群中所有的redis实例中&lt;/li&gt;
&lt;li&gt;代理与每个redis实例维持长连接，减少客户端和redis实例的连接数&lt;/li&gt;
&lt;li&gt;代理是无状态的，可以任意部署多套，避免单点问题&lt;/li&gt;
&lt;li&gt;默认启用pipeline，连接复用，提高效率，性能损失在 10% - 20%&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;集群组件:51fa3b005f880190963d473247382d62&#34;&gt;集群组件&lt;/h4&gt;

&lt;p&gt;由于twemproxy本身只是简单的代理，所以需要依赖于一些其他的程序组件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redis Sentinel：&lt;/strong&gt; 管理主从备份，用于主从切换，当主服务器挂掉后，自动将从服务器提升为主服务器&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redis-Twemproxy Agent：&lt;/strong&gt; nodejs写的一个监控程序，用于监听 redis-sentinel 的 master 切换事件，并且及时更新twemproxy的配置文件后将其重新启动&lt;/p&gt;

&lt;h4 id=&#34;why-not-twemproxy:51fa3b005f880190963d473247382d62&#34;&gt;Why not Twemproxy&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;虽然使用 c 开发，性能损失较小，但同样是单线程。所以基本上twemproxy的数量需要和后端redis实例一样甚至更多才能充分发挥多实例的并发能力，造成运维困难。&lt;/li&gt;
&lt;li&gt;twemproxy更改配置文件需要重新启动，比较坑，需要修改代码使其支持动态加载。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无法动态扩容&lt;/strong&gt;，如果需要实现这个功能，要么自己写迁移脚本，手动迁移，比较繁琐，还会影响到当前服务的正常运行。或者二次开发，增加对zookeeper的依赖，将redis节点信息以及hash域相关的数据存储在zookeeper上，然后增加动态迁移数据的模块，可以在不影响现有服务运行的情况下完成增删实例。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;redis-cluster:51fa3b005f880190963d473247382d62&#34;&gt;Redis Cluster&lt;/h3&gt;

&lt;h4 id=&#34;数据分布-预分片:51fa3b005f880190963d473247382d62&#34;&gt;数据分布：预分片&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-redis-cluster-pre-sharding.png&#34; alt=&#34;redis-cluster-pre-sharding&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;预先分配好 16384 个slot&lt;/li&gt;
&lt;li&gt;slot 和 server 的映射关系存储每一个 server 的路由表中&lt;/li&gt;
&lt;li&gt;根据 CRC16(key) mod 16384 的值，决定将一个key放到哪一个slot中&lt;/li&gt;
&lt;li&gt;数据迁移时就是调整 slot 的分布&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;架构-去中心化:51fa3b005f880190963d473247382d62&#34;&gt;架构：去中心化&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-redis-cluster-architecture.png&#34; alt=&#34;redis-cluster-architecture&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无中心结构，每个节点都保存数据和整个集群的状态。&lt;/li&gt;
&lt;li&gt;采用 gossip 协议传播信息以及发现新节点（最终一致性）。

&lt;ul&gt;
&lt;li&gt;每个节点都和其他所有节点连接，并保持活跃。&lt;/li&gt;
&lt;li&gt;PING/PONG：心跳，附加上自己以及一些其他节点数据，每个节点每秒随机PING几个节点。会选择那些超过cluster-node-timeout一半的时间还未PING过或未收到PONG的节点。&lt;/li&gt;
&lt;li&gt;UPDATE消息：计数戳，如果收到server的计数为3，自己的为4，则发UPDATE更新对方路由表，反之更新自己的路由表，最终集群路由状态会和计数戳最大的实例一样。&lt;/li&gt;
&lt;li&gt;如果 cluster-node-timeout 设置较小，或者节点较多，数据传输量将比较可观。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Broadcast：有状态变动时先broadcast，后PING； 发布/订阅。&lt;/li&gt;
&lt;li&gt;Redis node 不作为client请求的代理（不转发请求），client根据node返回的错误信息重定向请求?（需要 smart-client 支持），所以client连接集群中任意一个节点都可以。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;可用性-master-slave:51fa3b005f880190963d473247382d62&#34;&gt;可用性：Master-Slave&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;每个Redis Node可以有一个或者多个Slave，当Master挂掉时，选举一个Slave形成新的Master。&lt;/li&gt;
&lt;li&gt;Master Slave 之间异步复制（可能会丢数据）。&lt;/li&gt;
&lt;li&gt;采用 gossip 协议探测其他节点存活状态，超过 cluster-node-timeout，标记为 PFAIL，PING中附加此数据。当 Node A发现半数以上master将失效节点标记为PFAIL，将其标记为FAIL，broadcast FAIL。&lt;/li&gt;
&lt;li&gt;各 slave 等待一个随机时间后 发起选举，向其他 master broadcast，半数以上同意则赢得选举否则发起下一次选举&lt;/li&gt;
&lt;li&gt;当 slave 成为 master，先broadcast，后持续PING，最终集群实例都获知此消息&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;存在的问题:51fa3b005f880190963d473247382d62&#34;&gt;存在的问题&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Gossip协议通信开销&lt;/li&gt;
&lt;li&gt;严重依赖于smart-client的成熟度

&lt;ul&gt;
&lt;li&gt;如果smart-client支持缓存slot路由，需要额外占用内存空间，为了效率需要建立和所有 redis server 的长连接（每一个使用该库的程序都需要建立这么多连接）。&lt;/li&gt;
&lt;li&gt;如果不支持缓存路由信息，会先访问任意一台 redis server，之后重定向到新的节点。&lt;/li&gt;
&lt;li&gt;需要更新当前所有的client。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;官方只提供了一个ruby程序 redis-trib 完成集群的所有操作，缺乏监控管理工具，很难清楚目前集群的状态&lt;/li&gt;
&lt;li&gt;数据迁移以Key为单位，速度较慢&lt;/li&gt;
&lt;li&gt;某些操作不支持，MultiOp和Pipeline都被限定在命令中的所有Key必须都在同一Slot内&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;codis:51fa3b005f880190963d473247382d62&#34;&gt;Codis&lt;/h3&gt;

&lt;h4 id=&#34;what-is-codis:51fa3b005f880190963d473247382d62&#34;&gt;What is Codis ？&lt;/h4&gt;

&lt;p&gt;Go语言开发的分布式 Redis 解决方案，对于上层的应用来说，访问 codis 和原生的 redis server 没有明显区别（不支持发布订阅等某些命令，支持 pipeline）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-codis-architecture.png&#34; alt=&#34;codis-architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Codis由四部分组成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Codis Proxy (codis-proxy)&lt;/li&gt;
&lt;li&gt;Codis Dashboard (codis-config)&lt;/li&gt;
&lt;li&gt;Codis Redis (codis-server)&lt;/li&gt;
&lt;li&gt;ZooKeeper/Etcd&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;codis-proxy 是客户端连接的 Redis 代理服务, codis-proxy 本身实现了 Redis 协议, 表现得和一个原生的 Redis 没什么区别 (就像 Twemproxy), 对于一个业务来说, 可以部署多个 codis-proxy, codis-proxy 本身是无状态的。&lt;/p&gt;

&lt;p&gt;codis-config 是 Codis 的管理工具, 支持包括, 添加/删除 Redis 节点, 添加/删除 Proxy 节点, 发起数据迁移等操作. codis-config 本身还自带了一个 http server, 会启动一个 dashboard, 用户可以直接在浏览器上观察 Codis 集群的运行状态。&lt;/p&gt;

&lt;p&gt;codis-server 是 Codis 项目维护的一个 Redis 分支, 基于 2.8.21 开发, 加入了 slot 的支持和原子的数据迁移指令. Codis 上层的 codis-proxy 和 codis-config 只能和这个版本的 Redis 交互才能正常运行。&lt;/p&gt;

&lt;p&gt;Codis 依赖 ZooKeeper 来存放数据路由表和 codis-proxy 节点的元信息, codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。&lt;/p&gt;

&lt;p&gt;Codis 支持按照 Namespace 区分不同的产品, 拥有不同的 product name 的产品, 各项配置都不会冲突。&lt;/p&gt;

&lt;h4 id=&#34;整体设计:51fa3b005f880190963d473247382d62&#34;&gt;整体设计&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;预分片，1024 slot， key =&amp;gt; crc32(key)%1024&lt;/li&gt;
&lt;li&gt;proxy无状态，便于负载均衡，启动时在 Zookeeper 上注册一个临时节点，方便做 HA&lt;/li&gt;
&lt;li&gt;Redis 只作为存储引擎&lt;/li&gt;
&lt;li&gt;Go语言开发，可以充分利用多核，不必像 twemproxy 一样部署很多套&lt;/li&gt;
&lt;li&gt;性能损失，在不开启pipeline的情况下会损失大概40%，通过加实例线性扩展&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    

  </channel>
</rss>
