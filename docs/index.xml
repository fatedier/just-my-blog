<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fatedier blog </title>
    <link>http://blog.fatedier.com/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2019</rights>
    <updated>2019-01-12 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>Service Mesh 探索之升级 HTTP/2 协议</title>
          <link>http://blog.fatedier.com/2019/01/12/service-mesh-explore-upgrade-http2/</link>
          <pubDate>Sat, 12 Jan 2019 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2019/01/12/service-mesh-explore-upgrade-http2/</guid>
          <description>&lt;p&gt;HTTP/2 是 HTTP/1.1 的升级，在请求方法、状态码乃至 URI 和绝大多数 HTTP 头部字段等方面保持高度兼容性，同时能够减少网络延迟和连接资源占用。Service Mesh 架构中，由于两个服务之间的通信由 proxy 介入，对于依靠 HTTP/1.1 通信的服务来说，可以无缝升级到 HTTP/2 协议。&lt;/p&gt;

&lt;h3 id=&#34;http-2-的优势&#34;&gt;HTTP/2 的优势&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;对 HTTP 头字段进行数据压缩(即 HPACK 算法)。&lt;/li&gt;
&lt;li&gt;HTTP/2 服务端推送(Server Push)。&lt;/li&gt;
&lt;li&gt;修复 HTTP/1.0 版本以来未修复的队头阻塞问题。&lt;/li&gt;
&lt;li&gt;对数据传输采用多路复用，让多个请求合并在同一 TCP 连接内。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于我们最主要的收益在于 TCP 连接的多路复用和头部字段压缩。&lt;/p&gt;

&lt;p&gt;TCP 连接的多路复用可以有效减少连接建立的延迟。在 HTTP/1.1 中我们也会复用空闲连接的方式来解决此问题，但是通常的实现方式是一个连接池，当空闲连接超过多长时间之后会被关闭，所以并没有完全解决这一问题。&lt;/p&gt;

&lt;p&gt;Header 字段压缩，对于内部服务来说可以有效减少请求和响应的数据大小。内部服务之间通常会在 Header 中附加较多的内容来表征一些类似标签格式的信息。经过测试，HTTP/2 使我们的内部服务在 Header 上的传输的数据量减少了 50% 以上。&lt;/p&gt;

&lt;h3 id=&#34;在同一个端口上同时支持-http-1-1-和-http-2&#34;&gt;在同一个端口上同时支持 HTTP/1.1 和 HTTP/2&lt;/h3&gt;

&lt;p&gt;HTTP/2 协议本身和 TLS 无关，但是通常浏览器 (Chrome 等) 都要求必须结合 TLS 来使用。&lt;/p&gt;

&lt;p&gt;h2c（HTTP/2 cleartext）是不带 TLS 的 HTTP/2。对于内部 API 服务来说，TLS 并非必须，反而会增加额外的资源开销。&lt;/p&gt;

&lt;p&gt;Go 的标准库已经支持了 h2，不支持 h2c，但是在 &lt;code&gt;golang.org/x/net/http2/h2c&lt;/code&gt; 中有对 h2c 的支持，算是半个标准库。&lt;/p&gt;

&lt;p&gt;由于 HTTP/2 和 HTTP/1.1 高度兼容，Golang 中我们需要提供的 &lt;code&gt;http.Handler&lt;/code&gt; 方法并没有什么变化，所以只需要替换 &lt;code&gt;Transport&lt;/code&gt; 就可以实现升级到 HTTP/2 这一能力。&lt;/p&gt;

&lt;h4 id=&#34;服务端&#34;&gt;服务端&lt;/h4&gt;

&lt;p&gt;示例程序:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;net/http&amp;quot;

    &amp;quot;golang.org/x/net/http2&amp;quot;
    &amp;quot;golang.org/x/net/http2/h2c&amp;quot;
)

func main() {
    mux := http.NewServeMux()
    mux.HandleFunc(&amp;quot;/&amp;quot;, func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintf(w, &amp;quot;You tell %s\n&amp;quot;, r.Proto)
    })
    h2s := &amp;amp;http2.Server{}
    h1s := &amp;amp;http.Server{Addr: &amp;quot;:9100&amp;quot;, Handler: h2c.NewHandler(mux, h2s)}

    log.Fatal(h1s.ListenAndServe())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;服务端会监听在 9100 端口，并且同时支持 HTTP/1.1 和 HTTP/2。&lt;/p&gt;

&lt;p&gt;通过 curl 用不同的协议访问的输出结果如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl http://127.0.0.1:9100
You tell HTTP/1.1

curl http://127.0.0.1:9100 --http2
You tell HTTP/2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之所以能够在同一个端口上同时支持这两个协议，是因为 &lt;code&gt;h2c.NewHandler&lt;/code&gt; 这个函数的封装。这个函数会在连接建立时先检测 &lt;code&gt;Request&lt;/code&gt; 的内容，h2c 要求连接以 &lt;code&gt;PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n&lt;/code&gt; 开头，如果匹配成功则交给 h2c 的 Handler 处理，否则交给 HTTP/1.1 的 Handler 处理。&lt;/p&gt;

&lt;p&gt;h2c 这部分的源码如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// ServeHTTP implement the h2c support that is enabled by h2c.GetH2CHandler.
func (s h2cHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // Handle h2c with prior knowledge (RFC 7540 Section 3.4)
    if r.Method == &amp;quot;PRI&amp;quot; &amp;amp;&amp;amp; len(r.Header) == 0 &amp;amp;&amp;amp; r.URL.Path == &amp;quot;*&amp;quot; &amp;amp;&amp;amp; r.Proto == &amp;quot;HTTP/2.0&amp;quot; {
        if http2VerboseLogs {
            log.Print(&amp;quot;h2c: attempting h2c with prior knowledge.&amp;quot;)
        }
        conn, err := initH2CWithPriorKnowledge(w)
        if err != nil {
            if http2VerboseLogs {
                log.Printf(&amp;quot;h2c: error h2c with prior knowledge: %v&amp;quot;, err)
            }
            return
        }
        defer conn.Close()

        s.s.ServeConn(conn, &amp;amp;http2.ServeConnOpts{Handler: s.Handler})
        return
    }
    // Handle Upgrade to h2c (RFC 7540 Section 3.2)
    if conn, err := h2cUpgrade(w, r); err == nil {
        defer conn.Close()

        s.s.ServeConn(conn, &amp;amp;http2.ServeConnOpts{Handler: s.Handler})
        return
    }

    s.Handler.ServeHTTP(w, r)
    return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;客户端&#34;&gt;客户端&lt;/h4&gt;

&lt;p&gt;由于我们的服务端同时支持 HTTP/1.1 和 HTTP/2，所以客户端可以通过任意的协议来通信，最好通过配置或环境变量的方式来决定是否启用升级 HTTP/2 的功能，后面会讲一下这个里面存在的坑。&lt;/p&gt;

&lt;p&gt;客户端的示例代码:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
    &amp;quot;crypto/tls&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;net&amp;quot;
    &amp;quot;net/http&amp;quot;

    &amp;quot;golang.org/x/net/http2&amp;quot;
)

func main() {
    client := http.Client{
        // Skip TLS dial
        Transport: &amp;amp;http2.Transport{
            AllowHTTP: true,
            DialTLS: func(network, addr string, cfg *tls.Config) (net.Conn, error) {
                return net.Dial(network, addr)
            },
        },
    }
    resp, err := client.Get(&amp;quot;http://127.0.0.1:9100&amp;quot;)
    if err != nil {
        log.Fatal(fmt.Errorf(&amp;quot;get response error: %v&amp;quot;, err))
    }
    fmt.Println(resp.StatusCode)
    fmt.Println(resp.Proto)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;http2.Transport 本身没有提供 &lt;code&gt;Dial&lt;/code&gt; 方法来不启用 TLS，但是由于 HTTP/2 和 TLS 无关，只需要将 &lt;code&gt;DialTLS&lt;/code&gt; 替换成我们自己方法，不建立 TLS 连接，对上层的 HTTP/2 的协议处理完全没有影响。&lt;/p&gt;

&lt;h3 id=&#34;遇到的问题&#34;&gt;遇到的问题&lt;/h3&gt;

&lt;p&gt;实际上线此功能后，运行了两天，出现了服务超时的问题，排查后看起来和 &lt;a href=&#34;https://github.com/golang/go/issues/28204&#34;&gt;https://github.com/golang/go/issues/28204&lt;/a&gt; 这个 issue 比较相似。&lt;/p&gt;

&lt;p&gt;目前 Golang 标准库(Go1.11)中对于 HTTP/2 的流量控制在某些特殊场景下存在 Bug，会导致 Flow Control 的写窗口一直为 0，且无法恢复。这就导致了请求超时，并且复用的 Stream 没有被正常关闭，如果持续请求，默认单个 TCP 连接中存在 100 个 Stream 时，会新建一个 TCP 连接，此时后续的请求会恢复正常，但是如果又出现了有问题的请求，会重复之前的错误。&lt;/p&gt;

&lt;p&gt;由于时间原因，并没有继续跟踪源码查看问题到底在哪，因为本地环境经过大量并发测试也并没有出现问题，说明应该是一个比较极端的 case 导致了这个错误。后续有精力时，可以考虑在线上开启流量复制的功能，将流量额外复制一份到单独版本的实例上，这个版本可以开启更多的 Debug 日志来辅助调试。&lt;/p&gt;

&lt;p&gt;线上暂时关闭了此功能，待问题确认修复后再通过环境变量控制开启。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>使用 telepresence 在 k8s 环境中实现快速开发</title>
          <link>http://blog.fatedier.com/2019/01/03/using-telepresence-for-quick-dev-in-k8s/</link>
          <pubDate>Thu, 03 Jan 2019 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2019/01/03/using-telepresence-for-quick-dev-in-k8s/</guid>
          <description>&lt;p&gt;随着容器化，微服务的概念逐渐成为主流，在日常的开发测试中，会遇到一些新的问题。例如如果服务跑在 istio 这样的 ServiceMesh 平台上，依赖于 k8s 的 sidecar 功能，在本地模拟这样的场景来调试和测试是比较复杂的。而 telepresence 帮助我们缓解了这样的问题。&lt;/p&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;p&gt;telepresence 的项目地址：&lt;a href=&#34;https://github.com/telepresenceio/telepresence&#34;&gt;https://github.com/telepresenceio/telepresence&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;OS X&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew cask install osxfuse
brew install datawire/blackbird/telepresence
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其他的系统环境安装参考 &lt;a href=&#34;https://www.telepresence.io/reference/install&#34;&gt;https://www.telepresence.io/reference/install&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;

&lt;p&gt;Telepresence 是用 python 编写的用于帮助我们在本地运行一个服务，同时能够访问到远端的 kubernetes 集群的服务。&lt;/p&gt;

&lt;p&gt;这样的话，我们不再需要每次修改代码后，重新编译，推送镜像，部署到 k8s 集群，然后调试，如果出现错误，再重复这样的步骤。并且由于服务是在本地运行，可以更方便地利用本地环境的一些调试工具来帮助我们排查分析问题。&lt;/p&gt;

&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;

&lt;p&gt;Telepresence 在远端 k8s 集群部署了一个和本地环境网络互通的 pod，可以选择 VPN 的方式。这个 pod 会将指定的网络流量，环境变量，磁盘等数据转发到本地的服务。且本地服务的 DNS 查询，网络流量，都可以被路由到远端的 k8s 集群。&lt;/p&gt;

&lt;h3 id=&#34;常用的功能&#34;&gt;常用的功能&lt;/h3&gt;

&lt;h4 id=&#34;新建一个-deployment-用于测试本地服务访问远端服务&#34;&gt;新建一个 Deployment 用于测试本地服务访问远端服务&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;telepresence --new-deployment myserver --run-shell --also-proxy 192.168.0.0/16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;telepresence 默认会使用当前的 kubectl 的 current context 来进行请求。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;ndash;new-deployment&lt;/strong&gt; 表示新创建一个名为 &lt;strong&gt;myserver&lt;/strong&gt; 的 deployment。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ndash;run-shell&lt;/strong&gt; 表示启动完成后进入一个 shell 命令行环境，可以继续执行自己需要的服务或命令。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ndash;also-proxy&lt;/strong&gt; 表示我们需要在本地通过 IP 的方式访问 192.168 网段的 k8s 服务。这个 IP 段是 k8s 上容器会被分配到的 IP 段。如果不设置这个参数，就只能通过 service 名来访问服务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动成功后，会进入到一个 shell 终端。在这个终端里运行的命令都能够访问到 k8s 集群里的服务。&lt;/p&gt;

&lt;p&gt;因为只打开了一个 shell 终端，如果需要同时调试多个服务就比较麻烦。最好能够借助于 &lt;strong&gt;tmux&lt;/strong&gt; 这样的工具来打开多个终端窗口。&lt;/p&gt;

&lt;h4 id=&#34;替换一个远端的-deployment-服务&#34;&gt;替换一个远端的 Deployment 服务&lt;/h4&gt;

&lt;p&gt;有时在远端 k8s 集群我们已经部署了一套完整的服务，但是其中某个服务可能有问题。我们希望能够将集群内的流量劫持到本地的进程，来进行调试，这样就可以快速修改代码，加日志，方便排查问题。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;telepresence --swap-deployment proxy:proxy --expose 9100:9100 --also-proxy 192.168.0.0/16
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;ndash;swap-deployment&lt;/strong&gt; 表示替换一个远端集群的 Deployment。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;proxy:proxy&lt;/strong&gt; 是要替换的 Deployment 中的指定容器的名字。如果要替换所有，可以不用加冒号。格式为 &lt;strong&gt;{Deployment}:{Container}&lt;/strong&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ndash;expose 9100:9100&lt;/strong&gt; 表示要将远端容器 9100 端口的流量转发到本地的 9100 端口，格式为 &lt;strong&gt;&amp;ndash;expose PORT[:REMOTE_PORT]&lt;/strong&gt; 。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动成功后，使用方式和 &lt;strong&gt;&amp;ndash;new-deployment&lt;/strong&gt; 一样，但是发往 proxy 这个服务的 9100 端口的流量会被路由到本地的 9100 端口的服务，此时只需要让本地调试的程序监听在 9100 端口，就可以实时接收 k8s 集群内部的流量，方便我们测试开发。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>kubernetes 中删除 pod 导致客户端连接不存在的 IP 超时问题</title>
          <link>http://blog.fatedier.com/2018/12/10/a-connect-timeout-problem-caused-by-k8s-pod-deleting/</link>
          <pubDate>Mon, 10 Dec 2018 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2018/12/10/a-connect-timeout-problem-caused-by-k8s-pod-deleting/</guid>
          <description>&lt;p&gt;在 k8s 平台测试自研 Service Mesh 方案时，发现更新服务时，会有少量请求耗时剧增。跟踪排查后确认是由于 Pod 被删除后，原先的 Pod 的 IP 不存在，客户端建立连接超时引起。&lt;/p&gt;

&lt;h3 id=&#34;现象&#34;&gt;现象&lt;/h3&gt;

&lt;p&gt;正常升级某个服务的 Deployment。&lt;/p&gt;

&lt;p&gt;升级策略，先起一个新实例，再停一个旧实例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;type: RollingUpdate
rollingUpdate:
  maxSurge: 1
  maxUnavailable: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实例停止前如果没有请求会立即退出，如果有请求则等待最多 60 秒，仍然没有结束时会被强制杀掉。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;terminationGracePeriodSeconds: 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;升级过程中，发现服务响应时间的 98 值增长很多，95 值没有太大变化，看起来有少量请求被升级操作影响到了。&lt;/p&gt;

&lt;h3 id=&#34;原因&#34;&gt;原因&lt;/h3&gt;

&lt;p&gt;排查后，确认部分请求变慢的原因是因为和后端实例建立连接超时，由于使用的是 Go 的 DefaultTransport，所以连接超时时间为 30s，部分请求在超时 30s 后才被重试，从而导致响应时间的 98 值变慢。&lt;/p&gt;

&lt;p&gt;为什么建立连接会超时？&lt;/p&gt;

&lt;p&gt;原来在升级实例的过程中，实例被杀掉，对应的容器的虚拟 IP 就不存在了，而客户端建立连接时发送的 SYNC 包收不到回应，会一直重发，直到超时。&lt;/p&gt;

&lt;p&gt;之所以客户端仍然会给该 IP 发送请求，是因为我们自研的 Service Mesh 方案的服务发现没有采用 k8s 默认的 DNS 轮询方式，而是自己开发的服务发现组件，为了能够更好地配合负载均衡的能力。网关是采用轮询的方式，每隔 10s 从 Discovery 组件同步一次数据，所以被杀掉的实例没有及时被同步到各网关。&lt;/p&gt;

&lt;h3 id=&#34;kubernetes-pod-停止流程&#34;&gt;kubernetes Pod 停止流程&lt;/h3&gt;

&lt;p&gt;为了更好解决问题，我们需要理解 k8s 中单个 Pod 停止的流程。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;用户发送请求删除 Pod，默认终止等待时间为 30s&lt;/li&gt;
&lt;li&gt;在 Pod 超过该等待时间后 API server 就会更新 Pod 的状态为 &lt;strong&gt;dead&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;在客户端命令行上显示 Pod 状态为 &lt;strong&gt;terminating&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;与步骤三同时，当 Kubelet 观察到一个 Pod 在步骤2被标记为 &lt;strong&gt;terminating&lt;/strong&gt;，开始终止工作

&lt;ol&gt;
&lt;li&gt;如果在pod中定义了 &lt;strong&gt;preStop hook&lt;/strong&gt;，在停止 pod 前会被调用。如果在等待期过后，&lt;strong&gt;preStop hook&lt;/strong&gt; 依然在运行，第二步会再增加2秒的等待期&lt;/li&gt;
&lt;li&gt;向 Pod 中的进程发送 &lt;strong&gt;SIGTERM&lt;/strong&gt; 信号&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;跟第三步同时，该 Pod 将从该 service 的地址列表中删除，不再是 replication controllers 中处于运行状态的实例之一。关闭的慢的 Pod 将不会再处理流量，因为负载均衡器（像是 service proxy）会将它们移除&lt;/li&gt;
&lt;li&gt;过了等待期后，将向 Pod 中依然运行的进程发送 SIGKILL 信号而杀掉进程&lt;/li&gt;
&lt;li&gt;Kublete 会在 API server 中通过将优雅周期设置为0（立即删除）来完成 Pod 的删除。Pod 将会从 API 中消失，并且在客户端也不可见&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;解决方案&#34;&gt;解决方案&lt;/h3&gt;

&lt;h4 id=&#34;优化超时时间&#34;&gt;优化超时时间&lt;/h4&gt;

&lt;p&gt;使用自定义的 Transport，内网的话超时时间可以减少为 1s，让请求尽快被重试，虽然不能解决问题，但是可以有效缓解问题。&lt;/p&gt;

&lt;h4 id=&#34;确保实例被服务发现摘除后再停止&#34;&gt;确保实例被服务发现摘除后再停止&lt;/h4&gt;

&lt;p&gt;思考了问题发生的原因，首先想到的就是能不能让实例先从服务发现中摘除，确认服务发现数据被同步到了各网关后，再杀实例。搜索了 k8s 的相关文档，发现通过 &lt;strong&gt;preStop&lt;/strong&gt; 的 hook 机制，可以实现该功能。&lt;/p&gt;

&lt;p&gt;示例配置如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      terminationGracePeriodSeconds: 90
      containers:
      - name: nginx
        image: my-nginx:xxx
        lifecycle:
          preStop:
            exec:
              command: [&amp;quot;/bin/sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;sleep 30&amp;quot;]
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重点就在于 &lt;strong&gt;lifecycle&lt;/strong&gt; 的配置。对应实例停止时，会先将该实例的服务发现地址从 &lt;strong&gt;service&lt;/strong&gt; 中移除，之后会调用我们给定的命令 &lt;code&gt;sleep 30&lt;/code&gt;，等待 30s 后，再给实例发送 SIGTERM 信号，如果实例超过 &lt;strong&gt;terminationGracePeriodSeconds&lt;/strong&gt; 配置的时间后，会再给实例发送 SIGKILL 信号，强行杀掉实例。&lt;/p&gt;

&lt;p&gt;我们服务发现数据同步间隔是 10s，留出 30s 的时间，所有网关的服务发现数据正常情况下已经全部同步完成，不会再有新的流量被路由到该实例上，也就不会出现新建连接超时的问题。&lt;/p&gt;

&lt;p&gt;需要注意的是，由于我们延迟了 30s 停止实例，所以保险起见 &lt;strong&gt;terminationGracePeriodSeconds&lt;/strong&gt; 也可以相应的增加 30s。&lt;/p&gt;

&lt;h3 id=&#34;猜想其他的解决方法&#34;&gt;猜想其他的解决方法&lt;/h3&gt;

&lt;h4 id=&#34;k8s-自身提供延迟停止实例的能力&#34;&gt;k8s 自身提供延迟停止实例的能力&lt;/h4&gt;

&lt;p&gt;如果 k8s 自身就能通过 Deployment 参数配置实现上文中我们通过 &lt;strong&gt;preStop&lt;/strong&gt; 实现的功能会更好一些，毕竟是一个比较取巧的方案，不一定完善。&lt;/p&gt;

&lt;h4 id=&#34;ip-被摘除后建立连接可以直接返回错误&#34;&gt;IP 被摘除后建立连接可以直接返回错误&lt;/h4&gt;

&lt;p&gt;涉及到 k8s 集群的网络解决方案，不一定所有的架构都能支持，需要进一步调研。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Service Mesh 探索之优先本地访问</title>
          <link>http://blog.fatedier.com/2018/12/01/service-mesh-explore-local-node-lb/</link>
          <pubDate>Sat, 01 Dec 2018 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2018/12/01/service-mesh-explore-local-node-lb/</guid>
          <description>&lt;p&gt;在设计 Service Mesh 架构方案时，考虑到有一些基础服务，访问频率高，流量大，如果在 kubernetes 平台上采用 DaemonSet 的部署方式，每一个机器部署一个实例，访问方能够优先访问同一个节点上的该服务，则可以极大地减少网络开销和延迟。&lt;/p&gt;

&lt;p&gt;目前开源的项目中还没有支持这一功能，所以我们需要实现自己的负载均衡策略来达到这一目的。&lt;/p&gt;

&lt;h3 id=&#34;discovery-组件&#34;&gt;discovery 组件&lt;/h3&gt;

&lt;p&gt;和 Istio 的 pilot 类似，一般 Service Mesh 平台中会有一个 discovery 组件，通过 discovery 组件，proxy 才能获得要访问的服务的所有节点信息，discovery 屏蔽了各个服务注册中心的细节。&lt;/p&gt;

&lt;p&gt;我们的 discovery 组件对外提供 GRPC 接口。有以下几个概念:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Zone: 区域，一个区域有多个集群，通常物理上不在一起，互相访问存在网络开销或不能直接访问。&lt;/li&gt;
&lt;li&gt;Cluster: 集群，一个集群是一组服务的集合，集群之间通常在一个区域的内部网络环境中。&lt;/li&gt;
&lt;li&gt;Service: 服务，一个服务对应 N 个实例。&lt;/li&gt;
&lt;li&gt;Instance: 实例，服务的最小实现单元。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里主要关心 Instance 这个结构，其 protobuf 定义如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message Instance {
    NetworkEndpoint endpoint = 1;
    Labels labels = 2;
}

message NetworkEndpoint {
    string address = 1;
    int64 port = 2;
    string port_name = 3;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 Labels 是一个 map 结构，每一个实例都会有一些标签，例如 &lt;code&gt;cluster=c1, zone=z1, node=n1&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;我们需要利用的就是 &lt;code&gt;node&lt;/code&gt; 这个标签，表示该实例所在的物理机器节点。这个标签可以为空，表示未知。&lt;/p&gt;

&lt;h3 id=&#34;kubernetes-中获取-node-信息&#34;&gt;kubernetes 中获取 Node 信息&lt;/h3&gt;

&lt;p&gt;在 kubernetes 中获取 NodeName 的简单代码示例:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;out := make([]*model.Instance, 0)
for _, item := range d.factory.Core().V1().Endpoints().Informer().GetStore().List() {
    ep := *item.(*corev1.Endpoints)
    
    for _, ss := range ep.Subsets {
        for _, ea := range ss.Addresses {
            for _, port := range ss.Ports {
                labels := make(model.Labels)
                labels[&amp;quot;namespace&amp;quot;] = ep.Namespace
                labels[&amp;quot;registry&amp;quot;] = string(registry.KubernetesRegistry)
                labels[&amp;quot;service&amp;quot;] = ep.Name
                labels[&amp;quot;cluster_id&amp;quot;] = d.clusterID
                if ea.NodeName != nil {
                    labels[&amp;quot;node&amp;quot;] = *ea.NodeName
                }

                out = append(out, &amp;amp;model.Instance{
                    Endpoint: &amp;amp;model.NetworkEndpoint{
                        Address:  ea.IP,
                        Port:     int(port.Port),
                        PortName: port.Name,
                    },
                    Labels: labels,
                })
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;k8s 的 Endpoint 信息中会附加上 NodeName，需要注意的是这个参数有可能不存在。&lt;/p&gt;

&lt;h3 id=&#34;proxy-组件&#34;&gt;proxy 组件&lt;/h3&gt;

&lt;p&gt;proxy 在启动时，会通过环境变量 &lt;code&gt;NODE_NAME&lt;/code&gt; 识别出自己所在的物理节点。&lt;/p&gt;

&lt;h4 id=&#34;部署在-k8s&#34;&gt;部署在 k8s&lt;/h4&gt;

&lt;p&gt;proxy 组件在 k8s 中是以 sidecar 的方式和服务的容器部署在同一个 pod 中，所以必然是在同一个物理机器上。我们通过修改 proxy 的 yaml 文件配置附加上 &lt;code&gt;NODE_NAME&lt;/code&gt; 这一环境变量。&lt;/p&gt;

&lt;p&gt;示例如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;env:
- name: NODE_NAME
  valueFrom:
    fieldRef:
      fieldPath: spec.nodeName
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;部署在物理机&#34;&gt;部署在物理机&lt;/h4&gt;

&lt;p&gt;通过启动 proxy 时主动指定 &lt;code&gt;NODE_NAME&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;env NODE_NAME=`hostname` ./proxy&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;负载均衡算法&#34;&gt;负载均衡算法&lt;/h3&gt;

&lt;p&gt;假设 A 服务希望通过 proxy 访问以 DaemonSet 方式部署的 B 服务。&lt;/p&gt;

&lt;p&gt;具体的步骤:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A 服务的 proxy 从环境变量中知道自身所在的 Node。&lt;/li&gt;
&lt;li&gt;从 discovery 中获取到 B 服务的所有 Instance 对应的 Node 信息。&lt;/li&gt;
&lt;li&gt;从 B 服务的所有 Instance 中选择具有相同 Node 的节点。&lt;/li&gt;
&lt;li&gt;优先访问该节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注意事项:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当 B 服务的本地节点出现故障时，需要依靠重试机制来保证可靠性。&lt;/li&gt;
&lt;li&gt;重试时会优先以轮询的方式重试具有相同 Node 的节点。&lt;/li&gt;
&lt;li&gt;如果相同 Node 的节点全部重试过一遍，则继续以轮询的方式重试剩余其他节点。&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
      
    
      
        <item>
          <title>Service Mesh 自研实践</title>
          <link>http://blog.fatedier.com/2018/10/15/self-designed-service-mesh/</link>
          <pubDate>Mon, 15 Oct 2018 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2018/10/15/self-designed-service-mesh/</guid>
          <description>&lt;p&gt;最近都在做自研 Service Mesh 方案的落地和后续迭代优化，目前稳定承接了旧系统的大部分流量，这里分享一下这套架构，以及过程中的思考和遇到的一些问题。&lt;/p&gt;

&lt;h3 id=&#34;service-mesh-现状&#34;&gt;Service Mesh 现状&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;服务网格（Service Mesh）是致力于解决服务间通讯的基础设施层。它负责在现代云原生应用程序的复杂服务拓扑来可靠地传递请求。实际上，Service Mesh 通常是通过一组轻量级网络代理（Sidecar proxy），与应用程序代码部署在一起来实现，而无需感知应用程序本身。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;微服务发展到一定阶段，Service Mesh 更像是借助于容器平台的兴起而对 API 网关的一种解耦和优化。&lt;/p&gt;

&lt;p&gt;目前看来最主要的开源解决方案是 Istio 和 Linkerd。前者甚至已经隐隐成为一种事实上的标准，是谈论 Service Mesh 绕不过去的一个项目，当你提及任何一个其他项目时，与 Istio 的对比可以检验一个项目的成熟度。&lt;/p&gt;

&lt;h3 id=&#34;为什么需要自研-service-mesh-方案&#34;&gt;为什么需要自研 Service Mesh 方案&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;在开始设计这套 Service Mesh 架构时，Istio 尚处于 0.X 的版本，没有达到一个生产级别的可用性，但是其所展现出的一些功能特性和理念还是很有吸引力。&lt;/li&gt;
&lt;li&gt;Istio 的 proxy 使用了 envoy，兼具丰富的功能和高性能。但是采用 C++ 开发，对于以 Golang 为主的开发团队来说，将我们需要的功能移植上去，且保证可靠性是有一定难度的。反过来看，用 Golang 实现一个 proxy，确是非常简单且可靠的，虽然在性能上做了一些取舍。&lt;/li&gt;
&lt;li&gt;公司内部本身已经有现成的网关组件以及丰富的 Golang 的 package，如果直接使用开源的方案，会放弃很多已有的功能，例如自定义的负载均衡策略。&lt;/li&gt;
&lt;li&gt;Istio 通过 iptables 进行流量劫持，大大降低了服务接入 Service Mesh 平台的难度，但是对于不需要劫持的流量却需要通过定义白名单的方式排除在外，不是很友好，且有额外不多的一些性能损耗。而通过环境变量或代码指定 proxy 的方式，有一定侵入性，但是几乎没什么难度，且可以根据用户需要自行管理。&lt;/li&gt;
&lt;li&gt;旧的服务迁移并非一件简单的事情，在这个过渡的过程中，需要考虑同时兼容多个多个平台和架构。Istio 虽然说是跨平台，但是实际上目前还是主要基于 kubernetes，对于运行在 kubernetes 之外的服务来说并不友好。自研的架构会针对这个问题做优化，帮助服务平滑迁移。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;核心功能&#34;&gt;核心功能&lt;/h3&gt;

&lt;h4 id=&#34;流量管理&#34;&gt;流量管理&lt;/h4&gt;

&lt;p&gt;流量管理是最核心的一部分内容，大部分功能是从原先的 API 网关中剥离出来抽象而成。&lt;/p&gt;

&lt;p&gt;提供了针对服务级别的断路器，超时，重试等功能，且支持复杂的规则配置，例如根据 HTTP Response Header 进行正则匹配来判断该请求是否需要重试。开发，运维可以根据需要动态调整集群中各个服务的参数配置。&lt;/p&gt;

&lt;p&gt;支持策略路由，例如将指定用户或按照百分比过滤的流量切到一个指定某个服务的指定版本的实例上，在灰度发布，A/B 测试等场景下可以提供帮助。&lt;/p&gt;

&lt;h4 id=&#34;安全性&#34;&gt;安全性&lt;/h4&gt;

&lt;p&gt;支持服务级别的访问控制，目前没有支持 TLS 和身份验证，因为当前只考虑内部的服务，没有这个需求。&lt;/p&gt;

&lt;h4 id=&#34;负载均衡&#34;&gt;负载均衡&lt;/h4&gt;

&lt;p&gt;支持轮询，最小连接数，优先本地节点和 Remote API 等负载均衡算法。通过规则配置，实现错误检测并自动摘除后端故障节点。&lt;/p&gt;

&lt;p&gt;对某些均衡性要求较高的服务，支持 Remote API，利用远端全局视角来做负载均衡，避免由于 proxy 较多而导致负载均衡的能力下降。&lt;/p&gt;

&lt;h4 id=&#34;多种接入方式&#34;&gt;多种接入方式&lt;/h4&gt;

&lt;p&gt;由于新的架构中所有服务的入流量和出流量都需要经过 proxy 中转才能使用其中的能力，目前支持两种方式来实现这个需求，服务可以选择其中任意一种方式来接入到这个平台。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;支持 HTTP_PROXY 这种主动指定代理的方式，A 服务访问 B 服务时，主动向 proxy 发送请求，由 proxy 转发给 B 服务。这种方式的优点是一次转发，性能消耗小，且对外的请求是否需要经过 proxy 可以根据服务需要来指定，灵活性更高。缺点是服务需要感知 proxy 的存在并做针对的设置。&lt;/li&gt;
&lt;li&gt;流量劫持的方式，通过 iptables 等方式将指定出口的流量劫持到 proxy 中。优缺点和第一种代理的方式正好相反。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;多协议支持&#34;&gt;多协议支持&lt;/h4&gt;

&lt;p&gt;支持 HTTP, HTTP2, grpc 等 rpc 协议，可扩展。&lt;/p&gt;

&lt;h4 id=&#34;统一的监控及日志&#34;&gt;统一的监控及日志&lt;/h4&gt;

&lt;p&gt;对于服务调用之间的响应时间，请求数，状态码等会由 proxy 对外提供统一的监控数据 (通过 prometheus 采集和 grafana 展示) 和审计日志。&lt;/p&gt;

&lt;h4 id=&#34;跨区域访问&#34;&gt;跨区域访问&lt;/h4&gt;

&lt;p&gt;对于不在一个机房的多个 k8s 集群，能够共享服务发现数据，实现跨区域访问服务的功能。&lt;/p&gt;

&lt;p&gt;在某个机房出现故障或资源不足问题时，多机房的集群可以互为灾备。&lt;/p&gt;

&lt;h4 id=&#34;多平台-架构支持&#34;&gt;多平台，架构支持&lt;/h4&gt;

&lt;p&gt;架构上尽量的抽象，屏蔽底层平台的细节，能够通过扩展的方式方便地支持在 k8s, mesos 或是在物理机上部署的服务。&lt;/p&gt;

&lt;h3 id=&#34;架构&#34;&gt;架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2018/2018-10-15-self-designed-service-mesh-architecture.jpg&#34; alt=&#34;architecture&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;discovery&#34;&gt;discovery&lt;/h4&gt;

&lt;p&gt;discovery 为平台提供服务发现的能力，通过抽象，支持同时对接多种后端数据源，例如 k8s, consul, config 等。&lt;/p&gt;

&lt;p&gt;discovery 屏蔽了后端各个数据源的细节，对外提供统一的 GRPC 服务发现接口，将服务发现的数据传播到 proxy 中。&lt;/p&gt;

&lt;h4 id=&#34;commander&#34;&gt;commander&lt;/h4&gt;

&lt;p&gt;平台中的所有功能都依赖于配置来管理，commander 提供了对这些配置的抽象。开发，运维通过 commander 提供的统一接口来管理集群的流量及行为。&lt;/p&gt;

&lt;p&gt;这些配置可能来自于 k8s CRD，静态配置文件，远端 API。commander 会将这些配置发送给所有的 proxy。&lt;/p&gt;

&lt;h4 id=&#34;proxy&#34;&gt;proxy&lt;/h4&gt;

&lt;p&gt;在 k8s 中，proxy 会以 sidecar 的方式和每一个服务部署在一起，负责代理服务的出入流量。通过 discovery 获取服务发现数据源，从 commander 获取策略配置，来实现管理服务调用的能力。&lt;/p&gt;

&lt;p&gt;和 Istio 不同的是，绝大多数核心能力在这个组件中实现，而不是额外的 mixer 组件。&lt;/p&gt;

&lt;h4 id=&#34;global-lb&#34;&gt;global-lb&lt;/h4&gt;

&lt;p&gt;global-lb 提供统一视角负载均衡的功能。&lt;/p&gt;

&lt;p&gt;由于新架构的变更，每一个服务实例都会有一个与之对应的 proxy。而每一个 proxy 的负载均衡都使用的是自身视角的数据，均衡性会大打折扣。在某些对均衡性需求较高的场景下， proxy 可以借助于 global-lb 来实现统一视角的负载均衡。&lt;/p&gt;

&lt;h4 id=&#34;zone-agent&#34;&gt;zone-agent&lt;/h4&gt;

&lt;p&gt;跨集群服务代理组件。&lt;/p&gt;

&lt;p&gt;在跨区域服务访问中，由于 k8s 集群之间的服务不能直接通信，A 集群的服务访问 B 集群的服务，需要经过 zone-agent 代理。zone-agent 作为一个反向代理会通过 ingress 的方式暴露给集群外部的服务。&lt;/p&gt;

&lt;h3 id=&#34;一些思考&#34;&gt;一些思考&lt;/h3&gt;

&lt;h4 id=&#34;mixer-组件&#34;&gt;Mixer 组件&lt;/h4&gt;

&lt;p&gt;Istio 一个很好的抽象就是独立出了 Mixer 组件，也就是 Service Mesh 中的控制面。为 Mixer 开发一些 Adapter 就可以很方便的在这套架构上扩展新的功能，例如 QPS 限制，监控，日志收集等。&lt;/p&gt;

&lt;p&gt;但是对于我们目前而言，每一个请求都需要经过 Mixer 组件，存在一定的性能和可靠性的问题。我觉得这是一个过于超前的设计，在目前的架构上可能并不是最合适的解决方案。虽然可以在 proxy 中通过缓存来缓解压力，但是目前看来也不够完善，不能解决所有问题，且还存在着一些隐患，例如缓存的内存占用问题，在量级小的时候不明显，后期上量之后可能才会暴露。&lt;/p&gt;

&lt;p&gt;我们将 Mixer 中的大部分功能都合并到了 proxy 中，虽然 proxy 因此变得复杂，但是带来的收益确实实实在在的。减少了一次额外的链路访问，降低延迟。Mixer 虽然可以水平扩展，但是通常和 proxy 的数量比起来还是较少，监控和日志的量级，如果都放在 Mixer 上去做，未必可靠，加上我们已有的监控和日志收集的体系，proxy 可以很方便的接入，所以这套架构中没有了类似 Mixer 的组件。&lt;/p&gt;

&lt;h4 id=&#34;流量劫持&#34;&gt;流量劫持&lt;/h4&gt;

&lt;p&gt;Istio 的一个理念就是让平台上的服务对这套架构完全没有感知，可以不需要任何改动的情况下从旧的平台架构中迁移过来。&lt;/p&gt;

&lt;p&gt;我个人认为这并不是一个需要十分在意的点。服务感知 proxy 的存在，收益远大于成本。当前 Istio 通过 iptables 流量劫持的方式，虽然服务几乎不需要改动，但是非常暴力，如果有额外的数据库或者不需要经过代理的集群外部的服务，都需要通过白名单的方式不去劫持这部分流量，不友好。&lt;/p&gt;

&lt;p&gt;目前的架构中同时支持流量劫持和 HTTP_PROXY，并且 HTTP_PROXY 是推荐的使用姿势，适配起来几乎没有难度。只有在服务自身难以通过修改代码来使用代理的时候才会采用流量劫持的方式，且这一方式和 Istio 也存在一些差异，后面会专门写一篇文章讲下这个方案。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>烟然</title>
          <link>http://blog.fatedier.com/2018/09/01/yan-ran/</link>
          <pubDate>Sat, 01 Sep 2018 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2018/09/01/yan-ran/</guid>
          <description>&lt;p&gt;通关仙剑四后的随笔，作于 2008 年。&lt;/p&gt;

&lt;h3 id=&#34;一&#34;&gt;一&lt;/h3&gt;

&lt;p&gt;风雨尘世百年。&lt;/p&gt;

&lt;p&gt;青峦峰上，依旧是云雾缥缈，绿阴苍郁，大树，木屋，瀑布，流水，世间竟还有这般洗尽人世浮华之所。&lt;/p&gt;

&lt;p&gt;云踪深处，她来了，与他相见，纵是百年烟云浮过，天依旧湛蓝。紫辰叠雪，蓝衣飘飘，素带轻浮，四目而对，眸中的便是整个世界的依托。这一刻，唯有定格永恒，方能诉尽千言万语。&lt;/p&gt;

&lt;p&gt;“……无所谓好或不好，人生一场虚空大梦，韶华白首，不过转瞬。唯有天道恒在，往复循环，不曾更改……”&lt;/p&gt;

&lt;p&gt;真的？这真的是我说的吗？&lt;/p&gt;

&lt;p&gt;我，真的好傻。竟以为能窥透这世间万物。&lt;/p&gt;

&lt;p&gt;白衣青领，白发垂肩，巨大的剑匣中却没有剑的依托，是愁，是化作了酒的愁。漫天飞洒，丝丝如绵。&lt;/p&gt;

&lt;p&gt;是的，人们都叫我 “酒剑仙”。&lt;/p&gt;

&lt;h3 id=&#34;二&#34;&gt;二&lt;/h3&gt;

&lt;p&gt;既然天道昭昭，又为什么要让我忆起了前世？爱！亦或是恨！天道究竟是什么？&lt;/p&gt;

&lt;p&gt;前世的我叫做玄风，她叫做烟然。我们曾经相守在一起，我是人，她不是，她是妖。我是昆仑琼华派的弟子，以剑术见长，颇得掌门厚爱，在这一辈弟子中也颇有威望。&lt;/p&gt;

&lt;p&gt;纳万里之天河，吞千丈之连峰，是为昆仑。以气御剑，驰骋于云端，冯虚御风，娱游于天际，是为琼华。&lt;/p&gt;

&lt;p&gt;她是妖，竟是凤凰花修炼而成。烟然就和我一起在后山修炼，清净，很少有人，相依相守，光阴对于我们总是连绵漫长而又弹指一挥间。我们再不管外人，只知道今朝。&lt;/p&gt;

&lt;p&gt;我以为世界就是这样美好！我对烟然说总有一天我们会修炼成仙。她只是笑，却不回答。我知道这是一条两个异族生灵唯一可以殊途同归的道路，那么无论怎样艰难不可思议我们也要全力以赴。相爱，自然便会愿望长相厮守，我们有什么选择呢？&lt;/p&gt;

&lt;p&gt;那个时候的我真傻。&lt;/p&gt;

&lt;p&gt;她何尝不是呢？&lt;/p&gt;

&lt;p&gt;她是妖，竟敢上昆仑，入太一仙径，进琼华。&lt;/p&gt;

&lt;p&gt;初次见她是在昆仑半山腰。她衣着鲜红如血，发如青丝，眼如秋痕，两手叉腰，细看来，原来是被附近的两个强盗拦住了。&lt;/p&gt;

&lt;p&gt;“此山是我开，此树是我栽，要从此路过，留下买路财。”那一胖一瘦两个强盗模样确实有点可笑。&lt;/p&gt;

&lt;p&gt;她娇笑着，手指轻触着脸颊，道：“呵，连妖你们也敢打劫？”语气竟蕴含着几分俏皮与调笑。&lt;/p&gt;

&lt;p&gt;两个强盗这才反应过来原来是妖，却是不信，妖又岂会敢上琼华？自投罗网？可如此正好，他们顿时满脸正气，好不“正义”，拔出腰间的佩剑向她冲去。在他们看来，“妖”便是连他们也不如的生灵了。&lt;/p&gt;

&lt;p&gt;我既为琼华子弟，视除魔卫道为己任，早已御剑而待，在她将要出剑之前，我必决不留情。本应是英雄救美的好戏却成了正与邪的交锋。&lt;/p&gt;

&lt;p&gt;多么可笑！多么荒唐！我被骗了，师父师叔们教我的道义，妖，除之。不问是谁伤了谁，是谁要伤谁，是谁先伤谁，只须牢记，妖，除之。&lt;/p&gt;

&lt;p&gt;非我族类，其心必异。&lt;/p&gt;

&lt;p&gt;可是那时的我奉为真理。而她，却躲开了。在太一仙径的尽头处冲着两个强盗拌了个鬼脸，然后又微笑着看了看山峰之上御剑而待的我，最终身影消失在林中。&lt;/p&gt;

&lt;p&gt;“那个女妖竟然真敢上昆仑琼华，必然死路一条，怨不得别人。”&lt;/p&gt;

&lt;p&gt;“管那么多干嘛，我们都已经两天没饭吃了。”&lt;/p&gt;

&lt;p&gt;“恩。她竟然敢笑我们，哼！我不过看她是女的才手下留情而已。”&lt;/p&gt;

&lt;p&gt;我真想大笑一场，这就是我所追求的天道？人不屑于强盗，强盗不屑于妖，互相残杀，互相屠戮，是谁的过错呢？&lt;/p&gt;

&lt;h3 id=&#34;三&#34;&gt;三&lt;/h3&gt;

&lt;p&gt;烟然真的有点傻，她竟然去找明道掌门加入琼华派，一处修仙，一处成妖，她竟自信得可以。&lt;/p&gt;

&lt;p&gt;他们对她怒目而视，四下弟子皆蠢蠢欲动。&lt;/p&gt;

&lt;p&gt;她，依然笑着，等待着答复。&lt;/p&gt;

&lt;p&gt;我……说什么好呢？我也傻傻地去求掌门收留她。真可笑，在众师兄弟眼里，一个修仙之人岂能替妖求情。我不知道她怎么还能泰然自若地站在那里，她难道不知道这么多人一人一剑足以将她粉身碎骨，支离破碎。那一刻，我们在她面前仿佛是从未有过的渺小。天哪！她是妖！我是人！&lt;/p&gt;

&lt;p&gt;更可笑的是，明道掌门答应了。真的答应了。世界果真这么美好，他命我和烟然一起去后山修炼，还传授我们成仙得道的心法口诀。我和烟然在众人疑惑的眼神中去了后山，那里有醉花阴，那个凤凰花盛开的地方。&lt;/p&gt;

&lt;p&gt;凤凰花，红得似火，在朝霞余晖的映衬下，片片如玉，那么美好，那么柔弱。&lt;/p&gt;

&lt;p&gt;我们都被骗了。&lt;/p&gt;

&lt;p&gt;我对她说：“你若是喜欢，日后我们每天在此赏花。”她只是笑，并不答话，脸上尽是幸福。我也曾埋怨过她竟敢独自上山来。烟然莞尔一笑：“这样不是很好么？我遇到了你。”她总是那么开朗，乐观，在她的世界里仿佛没有忧愁，一朵凤凰花便可以让她乐上一整天。&lt;/p&gt;

&lt;p&gt;我唯一有一件至今都很后悔的事，那就是不该相信烟然的话。&lt;/p&gt;

&lt;p&gt;烟然说人与妖应该相互信任，既然只要足够的坚定和努力，那么无论多么卑微的生灵到头来也可以成仙，也就是说众生平等。她说世上总还有一句话叫做“天道昭昭”，一心向善行为坦荡总不会有错。我问她那我除妖斩魔是对是错，她板起脸来将我训斥了一番。&lt;/p&gt;

&lt;p&gt;我真的不应该相信她，相信一个傻傻的妖的话。&lt;/p&gt;

&lt;p&gt;我被骗了，她亦如此。&lt;/p&gt;

&lt;p&gt;我们真的好傻。&lt;/p&gt;

&lt;p&gt;那天我找遍了醉花阴却不见了烟然，往常此时她都会等着我陪她一同赏花，那她永远也忘不了的凤凰花，她总对我说：“玄风，做一朵花真好！好想和你一起长伴这醉花阴。”&lt;/p&gt;

&lt;h3 id=&#34;四&#34;&gt;四&lt;/h3&gt;

&lt;p&gt;我们却无福等到那个时候了。&lt;/p&gt;

&lt;p&gt;卷云台上，我找到了烟然。&lt;/p&gt;

&lt;p&gt;一男一女，两名气势不凡的琼华剑士在高台上相对而立，台下有无数佩剑者修行者在翘首注视着他们的一举一动。剑士出剑舞动，两道强大的剑气合并一处，直冲天际，竟将天空撕裂出一个大窟窿。无数妖兽从天而降，与台下的佩剑者们展开一场惨烈无比的厮杀。&lt;/p&gt;

&lt;p&gt;我认识，那两把剑正是羲和与望舒，他们不是说有这两把剑就可以使琼华飞升仙界的吗？那又为什么要如此大肆屠杀呢？我不解。我看着烟然，她挥舞着手中的烟然剑，凡被她的凤凰花粉触及者皆就地而眠，她的目光中泣着一千万种震惊。&lt;/p&gt;

&lt;p&gt;“妖物，我收你如我门下，今日竟助纣为虐！”明道掌门见众多弟子在她四周躺倒，厉声喝道。&lt;/p&gt;

&lt;p&gt;她笑了笑，不过笑得好苦，好无奈。我太了解她了，即使如此，她也不愿伤人性命，她只是希望不要再相互残杀，可这，真的好难。&lt;/p&gt;

&lt;p&gt;她终究比我聪明些，望着遍地尸海：“为什么？为什么要如此？只因为我是妖么？你以我之妖力引导网缚我妖界众生，只欲成全你飞升之梦。你当日收我入琼华就因如此！”&lt;/p&gt;

&lt;p&gt;我们都被骗了？&lt;/p&gt;

&lt;p&gt;还是只有我一个人被骗了？&lt;/p&gt;

&lt;p&gt;不管怎样，我是相信烟然的。&lt;/p&gt;

&lt;p&gt;她被骗的好惨，有什么办法？到现在我才明白，无所谓什么天道，力量才是这个世界上唯一的美德，只是，我又能做什么？&lt;/p&gt;

&lt;p&gt;这个世界不可理喻！&lt;/p&gt;

&lt;p&gt;……我难以忘记，那一天，烟然死掉了，她死掉了，我的世界灰飞烟灭。鲜血浸透了她全身，缓缓滴落入土，她的身体渐凉，她的眼睛没有闭上，她望着我，凄然一笑。&lt;/p&gt;

&lt;p&gt;我抬头，周身的血液瞬间凝固，呆呆地望着那朵艳红的凤凰花。&lt;/p&gt;

&lt;p&gt;—— “玄风，做一朵花真好！好想和你一起长伴这醉花阴。”&lt;/p&gt;

&lt;p&gt;烟然，我被你骗了。&lt;/p&gt;

&lt;p&gt;昆仑，琼华，飞升，除魔卫道……烟然的微笑依稀尚在，然后，整整一个世界在我眼前破裂。笑，节制不住，冲破喉咙撕碎心胸。向善？坦荡？连生途也不可保证，那便是笑话一场。看着眼前的同门，尸横遍野。烟然有什么错？人类门派妄图飞升仙界，关妖界何干？他们有什么错？一己私欲，一不小心妖界便成了阻碍，需要扫平，天经地义，成王败寇的游戏，这一次，我输了。&lt;/p&gt;

&lt;h3 id=&#34;五&#34;&gt;五&lt;/h3&gt;

&lt;p&gt;在这个世上，很多人都知道蜀山上的那座锁妖塔，那段不朽的传说。而在昆仑半山腰处，，那个叫做里昆仑的地方却是鲜有人知。&lt;/p&gt;

&lt;p&gt;我醒了过来，很庆幸烟然已经死了，这样也好，她虽是妖，恐怕也没有见过这样恶心的世界。恶心，只有这两个字了。到处是猩红，到处是腐烂，到处是厮杀和惨叫。在这里，所有的生灵都在问一个问题：为什么？&lt;/p&gt;

&lt;p&gt;为什么要在这里？&lt;/p&gt;

&lt;p&gt;废话，因为你是妖。&lt;/p&gt;

&lt;p&gt;是的，没错，我是妖了，顿悟魔道而成了妖。&lt;/p&gt;

&lt;p&gt;我不明白现在的我和以前的玄风有什么不同，不过是外表无尽的扭曲，身上散发着腐臭的气息。&lt;/p&gt;

&lt;p&gt;在这里的妖没有什么信念，只有屠杀，否则还能干什么？所幸我还有活着的理由，我要出去！我不想死，我要出去！我不管为什么，我要逃出这昆仑山下的黑暗，我要报仇。太痛了，真的，这不能没有代价。如果世间原本不公，那么尽量活着吧。只要活下去，至少还有自己可以指望。天道昭昭，总有一天我要亲自去书写它。&lt;/p&gt;

&lt;p&gt;我与他们疯狂厮杀。&lt;/p&gt;

&lt;p&gt;在求生与杀生的过程中我发现，心中只有一个字，那便是“恨”，摧肝裂肺。原来世间最浓烈的毒不过“恨”字而已，我心中的，便是极致。也罢，我已不是那个信奉天道的执剑少年了，要在这种地方活下去并不容易，我需要它。&lt;/p&gt;

&lt;p&gt;在这样的过程中，他们渐渐知道怕我，远离我，他们管我叫赤焰王，这取代了我最初的名字。我想也好，玄风已经在那一天跟着烟然一起死掉了，活下来的只是一只心中的恨化作了盛怒狂火的妖。他的心中，恨化作了火。&lt;/p&gt;

&lt;p&gt;有一次我坐在一个呆子的对面，我们毫无意义地彼此看着。那个呆子满眼尽是茫然，他问我：“我是该先迈右脚呢，还是先迈左脚呢？”见我久久不答，他说：“啊，这个问题好难，而且妙在永远没有答案。你不如和我一起想想吧，这样时间也能过得快些，心里被它填满，你也好过一些。&lt;/p&gt;

&lt;p&gt;……我不，我不要。我的心是用来恨的，不是用来麻木的。&lt;/p&gt;

&lt;p&gt;沉思鬼不看我，继续说：“迈哪一条腿好呢？都对，又都不对，怎么选择？我要先把这个问题解决了，再想其他的。到底迈哪一条呢……”&lt;/p&gt;

&lt;p&gt;我起身离去，决定以后再也不要见到他。这只妖怪让我迷惑，他总有一天会让我忘记了复仇，安心跟他思考左右腿的问题。&lt;/p&gt;

&lt;p&gt;这太幸福了，我消受不起！&lt;/p&gt;

&lt;h3 id=&#34;六-永远没有结局的终章&#34;&gt;六 (永远没有结局的终章)&lt;/h3&gt;

&lt;p&gt;我记得我曾经说过，力量是这个世界唯一的美德，我再一次用我的生命鉴证了这一切，这个不可理喻的世界似乎让我有点明白了。&lt;/p&gt;

&lt;p&gt;她叫做蛛儿，别人都叫她毒娘子，几乎没有人听过她说话，看过她那双眼睛的人都永远的消失了。我却知道，她和我一样，心中的恨都化作了毒，到了极致的毒，还有什么可以抵挡？她更可笑，是一只爱上了神兽的妖，结果后来蜀山筑塔需要雷灵珠，似乎神兽需要五百年可以孕育一颗，接下来的我不知道了，或许我也不想知道，当她的毒液浸入我全身，我竟感到一丝快感，一种解脱的快感。&lt;/p&gt;

&lt;p&gt;一滴晶莹的泪珠滚落在我脸上，我们都明白我们都被骗了，但是，我们又到底明白了些什么？&lt;/p&gt;

&lt;p&gt;就这样吧，也好。我不用再日夜煎熬地屠杀了。这里流传着一句话“杀满一千只妖便可以出去了。”没有人知道是真是假，但杀戮从没有停止过，如果连这唯一的信念也被抹去，那活着与死了又有什么区别？&lt;/p&gt;

&lt;p&gt;渐渐地我感觉到冥冥之中似乎有一只手想要将我的灵魂抽离身体，我突然发现就这样睡下去似乎真的是一件很幸福的事，但身体的本能使我不自觉的反抗起来，有一些控制不住的情感在灵魂深处猛烈地冲击。&lt;/p&gt;

&lt;p&gt;撕心裂肺的疼痛从没有停止过，我却仿佛回到了醉花阴，很真实，因为我看到了烟然，还是那红衣如血，巧笑嫣然。疼痛感逐渐消失，我沉浸在一片温暖之中，缓缓地伸出手去想要抓住些什么，然后意识逐渐模糊于一片凤凰花中。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>记一次mesos集群停容器时间过长的问题排查</title>
          <link>http://blog.fatedier.com/2017/07/16/record-problem-resolve-for-docker-stop-slow/</link>
          <pubDate>Sun, 16 Jul 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2017/07/16/record-problem-resolve-for-docker-stop-slow/</guid>
          <description>&lt;p&gt;公司 mesos 集群某个 app 已经有数千的实例数，每次做滚动升级时，由于总资源不足，需要分批操作，每次起一批新版本实例，再停一批旧版本实例。目前停容器的策略是，先从服务发现中摘除需要停掉的节点，等待 60 秒后再停止容器，释放资源，但是实际上每次从发送停止容器的请求到容器资源被实际释放需要长达 6 分钟，导致滚动升级耗时过长。经过排查，最终确认问题出在我们使用 docker 的方式上，这里记录下分析和解决问题的过程。&lt;/p&gt;

&lt;h3 id=&#34;集群环境&#34;&gt;集群环境&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;ubuntu 14.04&lt;/li&gt;
&lt;li&gt;mesos 1.0.1&lt;/li&gt;
&lt;li&gt;docker 1.12.1&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;现象&#34;&gt;现象&lt;/h3&gt;

&lt;p&gt;从发送停止容器请求给 mesos 调度器到实际资源被释放，耗时超过 6 分钟。登录机器手动调用 &lt;code&gt;docker stop&lt;/code&gt; 停止容器只需 10 秒。&lt;/p&gt;

&lt;h3 id=&#34;排查问题&#34;&gt;排查问题&lt;/h3&gt;

&lt;p&gt;停止一个容器的请求，经过的步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;client 发送停止容器请求给 scheduler。&lt;/li&gt;
&lt;li&gt;scheduler 和 mesos-master 交互，请求停止对应的 TASK。&lt;/li&gt;
&lt;li&gt;mesos-master 发送请求给对应机器的 mesos-agent 要求停止这个容器。&lt;/li&gt;
&lt;li&gt;mesos-agent 发送 &lt;code&gt;TASK_KILL&lt;/code&gt; 消息给对应的 executor（这里用的是 mesos-docker-executor）。&lt;/li&gt;
&lt;li&gt;mesos-docker-executor 收到 &lt;code&gt;TASK_KILL&lt;/code&gt; 消息，调用 docker stop 停止容器，确认容器被停止后，发送确认消息给 mesos-agent。&lt;/li&gt;
&lt;li&gt;mesos-docker-executor 退出。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中步骤二 scheduler 和 mesos-master 的交互会延迟 60s，是为了让容器平滑的关闭，处理完已经接收到的请求。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;初步推测可能是 mesos-agent 或者 mesos-docker-executor 组件哪里出现了问题。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;检查是否是-mesos-agent-或-executor-的问题&#34;&gt;检查是否是 mesos-agent 或 executor 的问题&lt;/h4&gt;

&lt;p&gt;登录要停止的容器的机器，通过 &lt;code&gt;docker ps&lt;/code&gt; 查看对应容器的 name，这里假设是 &lt;code&gt;mesos-5ff75923-a2fd-4959-bb3b-4b128e43e9eb-S353.d008ad6c-37be-4cc5-ae40-3ba6a7ebca20&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;ps -ef|grep mesos-5ff75923-a2fd-4959-bb3b-4b128e43e9eb-S353.d008ad6c-37be-4cc5-ae40-3ba6a7ebca20&lt;/code&gt; 获取这个容器对应的 mesos-docker-executor 的 pid，这里假设是 &lt;code&gt;24235&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;ss -antp|grep 24235|grep LIS&lt;/code&gt; 查看这个进程目前监听的端口，mesos-agent 会通过这个端口和 mesos-docker-executor 通信，我们需要使用 &lt;strong&gt;tcpdump&lt;/strong&gt; 抓包跟踪这两个组件之间的通信，这里假设端口为 &lt;code&gt;20017&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;抓包命令 &lt;code&gt;tcpdump -i any -ASnn port 20017&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;00:39:22.202763 IP 192.168.76.53.21877 &amp;gt; 192.168.76.53.20017: Flags [P.], seq 3399346312:3399346653, ack 3564212561, win 342, length 341
E..}..@.@.&amp;lt;...L5..L5UuN1.....q.QP..V.+..POST /executor(1)/mesos.internal.KillTaskMessage HTTP/1.1
User-Agent: libprocess/slave(1)@192.168.76.53:5051
Libprocess-From: slave(1)@192.168.76.53:5051
Connection: Keep-Alive
Host:
Transfer-Encoding: chunked

6f
+
)5ff75923-a2fd-4959-bb3b-4b128e43e9eb-0000.@
&amp;gt;image.cb5aeece-697b-11e7-ad61-6c92bf2f06d8.1500136612181605046
0

00:44:22.516118 IP 192.168.76.53.21877 &amp;gt; 192.168.76.53.20017: Flags [P.], seq 3399346994:3399347417, ack 3564212561, win 342, length 423
E.....@.@.&amp;lt;...L5..L5UuN1...2.q.QP..V.}..POST /executor(1)/mesos.internal.StatusUpdateAcknowledgementMessage HTTP/1.1
User-Agent: libprocess/slave(1)@192.168.76.53:5051
Libprocess-From: slave(1)@192.168.76.53:5051
Connection: Keep-Alive
Host:
Transfer-Encoding: chunked

ae

+
)5ff75923-a2fd-4959-bb3b-4b128e43e9eb-S353.+
)5ff75923-a2fd-4959-bb3b-4b128e43e9eb-0000.@
&amp;gt;image.cb5aeece-697b-11e7-ad61-6c92bf2f06d8.1500136612181605046&amp;quot;..!....Hn.&#39;.j&amp;amp;.6.
0


00:44:22.516137 IP 192.168.76.53.20017 &amp;gt; 192.168.76.53.21877: Flags [.], ack 3399347417, win 2523, length 0
E..(..@.@.u...L5..L5N1Uu.q.Q....P.      .....
00:44:23.486916 IP 192.168.76.53.20017 &amp;gt; 192.168.76.53.21877: Flags [F.], seq 3564212561, ack 3399347417, win 2523, length 0
E..(..@.@.u...L5..L5N1Uu.q.Q....P.      .....
00:44:23.487507 IP 192.168.76.53.21877 &amp;gt; 192.168.76.53.20017: Flags [F.], seq 3399347417, ack 3564212562, win 342, length 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看 meso-agent 日志如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-mesos-agent-log.png&#34; alt=&#34;mesos-agent-log&#34; /&gt;&lt;/p&gt;

&lt;p&gt;确认 mesos-agent 在 &lt;strong&gt;00:39:22&lt;/strong&gt; 给 mesos-docker-executor 发送了 kill task 的消息，但是 mesos-docker-executor 在 &lt;strong&gt;00:44:22&lt;/strong&gt; 时才回复消息确认实例被停止了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明问题出在 mesos-docker-executor。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;分析-mesos-docker-executor-源码&#34;&gt;分析 mesos-docker-executor 源码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-mesos-docker-executor.png&#34; alt=&#34;mesos-docker-executor&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出，这里有一个很关键的 &lt;code&gt;gracePeriod&lt;/code&gt; 变量，如果停止任务的请求中有设置 &lt;code&gt;killPolicy&lt;/code&gt; 则此值为 &lt;code&gt;killPolicy&lt;/code&gt; 中的值，否则使用默认值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-executor-shutdown-code.png&#34; alt=&#34;shutdown-code&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这个值在 mesos-agent 启动的时候通过 &lt;code&gt;--executor_shutdown_grace_period&lt;/code&gt; 传进去，实际环境中我们配置的是 5 分钟。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-docker-stop-code.png&#34; alt=&#34;docker-stop-code&#34; /&gt;&lt;/p&gt;

&lt;p&gt;mesos-docker-executor 会根据 &lt;code&gt;gracePeriod&lt;/code&gt; 的值调用 &lt;code&gt;docker stop -t&lt;/code&gt; 来停止容器。&lt;/p&gt;

&lt;h4 id=&#34;docker-问题排查&#34;&gt;docker 问题排查&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;docker stop&lt;/code&gt; 停止一个容器会先发送 &lt;strong&gt;SIGTERM&lt;/strong&gt; 信号给容器，如果在 &lt;code&gt;-t&lt;/code&gt; 指定的时间仍然没有结束，则发送 &lt;strong&gt;SIGKILL&lt;/strong&gt; 信号强行杀掉。所以问题就是为什么我们的容器收到 &lt;strong&gt;SIGTERM&lt;/strong&gt; 信号后没有退出。&lt;/p&gt;

&lt;p&gt;使用 &lt;code&gt;docker exec -ti {container_name} bash&lt;/code&gt; 登录容器，查看容器内进程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 00:04 ?        00:00:00 /bin/sh /root/start.sh
root         8     1 99 00:04 ?        01:25:14 /root/dora-image -f /root/doraimage.conf
root      1111     0  2 01:23 ?        00:00:00 bash
root      1216  1111  0 01:23 ?        00:00:00 ps -ef
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;手动向 PID 为 1 的进程发送 SIGTERM 信号，结果无响应，到这一步已经定位到问题所在了。&lt;/p&gt;

&lt;p&gt;通过 Google 搜索后了解到原因。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;如果 pid 为 1 的进程，无法向其子进程传递信号，可能导致容器发送 SIGTERM 信号之后，父进程等待子进程退出。此时，如果父进程不能将信号传递到子进程，则整个容器就将无法正常退出，除非向父进程发送 SIGKILL 信号，使其强行退出。&lt;/p&gt;

&lt;p&gt;考虑如下进程树：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;bash（PID 1）

&lt;ul&gt;
&lt;li&gt;app（PID2）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;bash 进程在接受到 SIGTERM 信号的时候，不会向 app 进程传递这个信号，这会导致 app 进程仍然不会退出。对于传统 Linux 系统（bash 进程 PID 不为 1），在 bash进程退出之后，app进程的父进程会被 init 进程（PID 为 1）接管，成为其父进程。但是在容器环境中，这样的行为会使 app 进程失去父进程，因此 bash 进程不会退出。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;解决方案&#34;&gt;解决方案&lt;/h3&gt;

&lt;p&gt;最后找到了一个解决 init 问题的项目 &lt;a href=&#34;https://github.com/krallin/tini&#34;&gt;tini&lt;/a&gt;。而对于我们遇到的问题，目前想到的解决方案有三个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;docker 1.13 及以后的版本已经解决了 init 问题，就是内置了 &lt;strong&gt;tini&lt;/strong&gt;，使 &lt;strong&gt;tini&lt;/strong&gt; 作为 PID  为 1 的进程启动。&lt;/li&gt;
&lt;li&gt;升级 docker 版本难度较大，既然明确了新版本 docker 是如何解决问题的，我们就直接使用 &lt;strong&gt;tini&lt;/strong&gt; 作为 init 进程即可。&lt;/li&gt;
&lt;li&gt;修改 mesos-agent 的启动参数，将 &lt;code&gt;executor_shutdown_grace_period&lt;/code&gt; 设置的短一些，但是这样会影响到其他正常的容器。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;经过考虑，采用方案二较为简单和稳妥。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;对于 mesos 和 docker 的使用姿势还不熟悉，并且这两个项目的生态系统也并不成熟，导致在实际使用的过程中容易遇到各种各样的问题。通过日志，抓包，源码分析等手段相结合，就能够快速地定位到问题，再通过搜索引擎和官方文档资料等来解决问题。如果是一些社区当前还没有解决的问题，可能需要自己修改源码来 fix。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>为 mtcp 项目添加 udp 支持</title>
          <link>http://blog.fatedier.com/2017/03/03/support-udp-in-mtcp/</link>
          <pubDate>Fri, 03 Mar 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2017/03/03/support-udp-in-mtcp/</guid>
          <description>&lt;p&gt;mtcp 是一个用户态的 tcp 协议栈，结合 dpdk 可以实现高性能的收发包。mtcp 不支持 udp 协议，想要在 bind 里利用 mtcp 进行加速，需要改动源码以提供支持。&lt;/p&gt;

&lt;h3 id=&#34;大致思路&#34;&gt;大致思路&lt;/h3&gt;

&lt;p&gt;mtcp 项目地址：&lt;a href=&#34;https://github.com/mtcp-stack/mtcp&#34;&gt;https://github.com/mtcp-stack/mtcp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我们需要实现和 udp 数据收发相关的函数，提供给其他程序使用的 SDK。各个所需函数的实现方式如下。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mtcp_socket()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;创建 socket 对象，对象池数组，分配一个与其他 socket 对象不冲突的 id(fd)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mtcp_bind()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;将绑定的本地 IP 地址和端口等数据写入 socket 对象，将此 socket 对象的地址放入一个存放正在监听中的 socket 对象的 hashmap。&lt;/p&gt;

&lt;p&gt;需要创建一个 hashmap，存放所有处于监听状态的 socket 对象，key 是本地 IP，Port。&lt;/p&gt;

&lt;h3 id=&#34;udp-数据包的接收&#34;&gt;UDP 数据包的接收&lt;/h3&gt;

&lt;p&gt;解析到 以太网帧 -&amp;gt; ip -&amp;gt; udp&lt;/p&gt;

&lt;p&gt;解析出目的 ip，port，检查 hashmap 中是否有正处于监听状态的 socket 对象，如果没有，丢弃，否则加入到该 socket 对象的读缓冲区（这里需要一个队列）。&lt;/p&gt;

&lt;p&gt;调用 pthread_cond_singal 唤醒处于 recvfrom 的线程，或者是 epoll 队列中有该socket 的可读事件监听，pthread_cond_singal 唤醒 mtcp_epoll_wait 线程。&lt;/p&gt;

&lt;h4 id=&#34;mtcp-recvfrom&#34;&gt;mtcp_recvfrom()&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;不使用 epoll，阻塞：使用 pthread_cond_wait 等待主线程轮询网卡数据包，有此socket 的 udp 包的时候会被唤醒，从读缓冲区中取出内容返回。&lt;/li&gt;
&lt;li&gt;不使用 epoll，非阻塞：直接查询监听中socket-hashmap的此socket的读缓冲区，取出内容并返回。&lt;/li&gt;
&lt;li&gt;使用 epoll（非阻塞）：将此 socket 的可读事件加入监听，epoll_wait 被唤醒，检查到可读事件，非阻塞模式读缓冲区内容。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;mtcp-sendto&#34;&gt;mtcp_sendto()&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;不使用 epoll，阻塞：如果此 socket 的写缓冲区未满，直接写入并返回，如果已满（需要等到有空间后被唤醒，考虑 socket 对象需要加一个 send_wait_list，统一触发）&lt;/li&gt;
&lt;li&gt;不使用 epoll，非阻塞：已满就返回错误。&lt;/li&gt;
&lt;li&gt;使用 epoll（非阻塞）：将可写事件加入 epoll 事件队列，当 socket 可写时写入缓冲区。
（如果原来写缓冲区是空的，现在有内容了，加入到一个全局的 send_list 队列中）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果此 socket 的 udp_stream 为 NULL，说明是一个客户端的 socket，创建一个新的udp_stream，分配一个随机的 udp 端口，加入到正在监听中的 socket 对象的 hashmap。&lt;/p&gt;

&lt;h3 id=&#34;udp-数据包发送&#34;&gt;udp 数据包发送&lt;/h3&gt;

&lt;p&gt;这里需要一开始创建一个全局的 udp_sender 对象，有一个 send_list 队列，存放需要发送数据的所有的 socket 对象。&lt;/p&gt;

&lt;p&gt;轮询这些 socket 对象，构造数据包，udp -&amp;gt; ip -&amp;gt; 以太网帧，调用 dpdk 发送包的接口。&lt;/p&gt;

&lt;h3 id=&#34;主线程循环&#34;&gt;主线程循环&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;udp 数据包的接收&lt;/li&gt;
&lt;li&gt;udp 数据包发送&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
      
    
      
        <item>
          <title>减小 golang 编译出程序的体积</title>
          <link>http://blog.fatedier.com/2017/02/04/reduce-golang-program-size/</link>
          <pubDate>Sat, 04 Feb 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2017/02/04/reduce-golang-program-size/</guid>
          <description>&lt;p&gt;Go 语言的优势是可以很方便地编译出跨平台的应用程序，而不需要为每一个平台做代码适配，也不像 JAVA 一样需要预先安装 JDK 环境。相应的问题就是 go 编译出的程序体积较大，和 c/c++ 不同，它将大多数依赖都以静态编译的方式编译进了程序中。&lt;/p&gt;

&lt;h3 id=&#34;ldflags&#34;&gt;-ldflags&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;go build&lt;/code&gt; 编译程序时可以通过 &lt;code&gt;-ldflags&lt;/code&gt; 来指定编译参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-s&lt;/strong&gt; 的作用是去掉符号信息。
&lt;strong&gt;-w&lt;/strong&gt; 的作用是去掉调试信息。&lt;/p&gt;

&lt;p&gt;测试加与不加 &lt;code&gt;-ldflags&lt;/code&gt; 编译出的应用大小。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go build -o tmp/frpc ./cmd/frpc
-rwxr-xr-x  1 fate  staff  12056092 Dec 10 15:49 frpc

go build -ldflags &amp;quot;-s -w&amp;quot; -o tmp/frpc2 ./cmd/frpc
-rwxr-xr-x  1 fate  staff   8353308 Dec 10 15:49 frpc2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;减小了接近 4MB 的体积。&lt;/p&gt;

&lt;h3 id=&#34;upx-压缩&#34;&gt;UPX 压缩&lt;/h3&gt;

&lt;p&gt;在某些设备上动辄接近 10MB 的程序大小还是比较大的，这个时候可以采用 UPX 来进一步压缩。好处是占用磁盘空间小了，坏处是程序启动时会先进行一æ­¥解压缩，将代码还原到内存中，也就是说占用的内存大小并不会减少，当然，对于现代设备来说，启动的耗时几乎可以忽略。&lt;/p&gt;

&lt;p&gt;通过各系统的包管理工具一般可以自动安装 UPX。
例如 Centos 上 epel 库 &lt;code&gt;yum install -y upx&lt;/code&gt;。
macos 上通过 brew 安装 &lt;code&gt;brew install upx&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;压缩命令
&lt;code&gt;upx -9 -o ./frpc2_upx ./frpc2&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-o&lt;/strong&gt; 指定压缩后的文件名。
&lt;strong&gt;-9&lt;/strong&gt; 指定压缩级别，1-9。&lt;/p&gt;

&lt;p&gt;压缩后的文件体积&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-rwxr-xr-x  1 fate  staff   2998928 Dec 10 15:49 frpc2_upx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到缩小了接近 5MB，效果显著。&lt;/p&gt;

&lt;p&gt;需要注意的是，UPX 可能并不能正确的压缩所有平台的程序，压缩完成后最好自行在对应平台运行测试一下。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang 交叉编译</title>
          <link>http://blog.fatedier.com/2017/01/01/golang-cross-compile/</link>
          <pubDate>Sun, 01 Jan 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2017/01/01/golang-cross-compile/</guid>
          <description>&lt;p&gt;golang 相比 c/c++ 的优势之一是更容易编写出跨平台的应用，而不需要为各个平台编写适配代码。和 JAVA 相比，对系统环境要求较低，不需要预先安装 JDK 等适配环境。&lt;/p&gt;

&lt;h3 id=&#34;go-build&#34;&gt;go build&lt;/h3&gt;

&lt;p&gt;这里以 &lt;a href=&#34;https://github.com/fatedier/frp&#34;&gt;frp&lt;/a&gt; 项目的跨平台编译脚本作为示例&lt;/p&gt;

&lt;p&gt;编译 linux/amd64 版本的应用：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags &amp;quot;-s -w&amp;quot; -o frpc_linux_amd64 ./cmd/frpc&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;编译 windows/amd64 版本的应用：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build -ldflags &amp;quot;-s -w&amp;quot; -o ./frpc_windows_amd64.exe ./cmd/frpc&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在 linux 上编译出 windows 的 exe 文件后，可以直接拷贝到 windows 机器上运行。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GOOS&lt;/strong&gt; 表明目标平台的操作系统。
&lt;strong&gt;GOARCH&lt;/strong&gt; 表明目标平台的架构，通常 386 表示 32位系统，amd64 表示 64位系统。
可以通过 &lt;code&gt;go tool dist list&lt;/code&gt; 查看支持的操作系统和对应的平台。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-s -w&lt;/strong&gt; 是为了去掉编译时的符号信息和调试信息，缩小编译出的程序文件大小，非必需。
&lt;strong&gt;CGO_ENABLED=0&lt;/strong&gt; 可以禁用 cgo 编译，跨平台兼容性会更好。&lt;/p&gt;

&lt;h3 id=&#34;限定代码只在某个特定平台上编译&#34;&gt;限定代码只在某个特定平台上编译&lt;/h3&gt;

&lt;p&gt;有时候我们仍然希望为不同平台的应用编写特殊的代码，通过给 Go 文件加上 &lt;code&gt;// +build&lt;/code&gt; 注释可以实现。&lt;/p&gt;

&lt;p&gt;例如 Go 文件开头存在如下注释&lt;/p&gt;

&lt;p&gt;&lt;code&gt;// +build linux,386 darwin,!cgo&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;说明该文件仅在 linux/386 或者 darwin(No cgo) 的环境下被编译。
在其他环境下该文件不会被编译。&lt;/p&gt;

&lt;p&gt;通过这个方法，我们可以为不同平台编写同一份代码的不同实现。&lt;/p&gt;

&lt;h3 id=&#34;额外注意事项&#34;&gt;额外注意事项&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;推荐在 linux/amd64 上进行交叉编译，其他平台可能会出现一些意外情况，具体不明确。&lt;/li&gt;
&lt;li&gt;使用 cgo 时交叉编译可能失败，编写跨平台应用最好禁用 cgo。&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
      
    
      
        <item>
          <title>旅行、编程与写作</title>
          <link>http://blog.fatedier.com/2016/10/22/travel-coding-and-writing/</link>
          <pubDate>Sat, 22 Oct 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/10/22/travel-coding-and-writing/</guid>
          <description>&lt;p&gt;前段时间的精力主要放在了找工作上，压力也比较大，阅读和写博客的计划都有所耽误。后来难得利用换工作的间歇期去了云南的大理、丽江、香格里拉旅行，还看了《黑客与画家》这本书，对于工作、生活、理想的一些看法与感悟有了些许改变。&lt;/p&gt;

&lt;p&gt;我目前最大的三个爱好：旅行、编程与写作，热衷程度由高到低。&lt;/p&gt;

&lt;p&gt;但理想很丰满，现实很骨感。作为一个程序员，很难说到底有多少时间是在工作与学习，然而就算如此学到的也只是沧海一粟，这仿佛是一个永无止境的过程，需要持续不断地投入精力，但也让人乐此不疲。与之相应的是，业余生活成了一件一成不变、可有可无的事情。偶尔有那么一些小石子会在平静的湖泊中溅起涟漪，但转瞬便恢复了之前的平静。&lt;/p&gt;

&lt;p&gt;在上海呆了近两年，这座繁华而又空洞的大城市，我依旧觉得无法全身心地融入其中。依稀能够回忆起没来上海工作前，去外滩游玩，眺望东方明珠，怀揣着梦想与激情，畅想未来。今天呢？我甚至不能在脑海中描绘出这里的行道树是什么样子，入眼都是高楼大厦，遮天蔽日，耳边始终回响着地铁呼啸着驶过的声音，行色匆匆的人们吵杂地交谈着，西装革履的白领们低头玩着手机。日复一日，年复一年。&lt;/p&gt;

&lt;p&gt;「你将来是要在上海定居吗？」朋友问我。我被这个问题难住了，我并不是一个喜欢安分的人，但这个问题仍然让我对未来的不确定性充满了疑惑与迷惘。我开始思考一些关于编程之外的事情。&lt;/p&gt;

&lt;h3 id=&#34;关于黑客&#34;&gt;关于黑客&lt;/h3&gt;

&lt;p&gt;在外人看来对程序员的定位就是码农，书呆子，聪明人。&lt;/p&gt;

&lt;p&gt;我个人觉得我也许可以做个「黑客」与「艺术家」。&lt;/p&gt;

&lt;p&gt;就如同《黑客与画家》的作者 Paul Graham 所说的那样，在所有的行业中，他认为黑客与画家最相像。而我觉得黑客与作家亦然。当我学习写作时，我需要阅读大量的名著，摘抄那些优美的句子，揣摩作者是如何遣词造句，最终在不断的实践中形成自己的风格，如果把这些作品按照时间顺序排列，就会很容易发现这个循序渐进的过程。&lt;/p&gt;

&lt;p&gt;「那么，黑客是如何学习编程的呢？」注意这里我没有再用「程序员」这个词，因为显然「程序员 ≠ 艺术家」。在我看来，黑客是创作者，是艺术家，他们执着于用自己的能力创造出吸引他人的作品，并不循规蹈矩，发自内心地热爱着创作的过程。而程序员只是一份工作，你需要有一技之长用来养家糊口。程序员通常在大学课堂与培训机构里学习编程，而黑客通过研究优秀的项目与实践来学习。&lt;/p&gt;

&lt;p&gt;「喂，书呆子！」这样的问候早已习以为常。&lt;/p&gt;

&lt;p&gt;如果你想要清晰地思考，就必须远离人群。但是走得越远，你的处境就会越困难，受到的阻力也会越大，因为你没有迎合社会习俗，而是一步步地与它背道而驰。黑客往往就处于这样的境地之中。好消息是，在这个人人都该学点编程的时代，就连美国总统奥巴马也表示，「编程教学如同识字一样，应成为基础教育的一部分」。也许有一天，黑客会像伟大的画家、作家、音乐家一样备受推崇、流芳后世，而不仅仅局限于一小部分群体之中。毕竟，黑客很酷，不是吗？&lt;/p&gt;

&lt;h3 id=&#34;旅行&#34;&gt;旅行&lt;/h3&gt;

&lt;p&gt;旅行被我放在了第一位，也许真的是因为不容易得到的东西才懂得珍惜。&lt;/p&gt;

&lt;p&gt;就和大多数人的抱怨一样，在有时间的时候没钱，有钱的时候又忙于工作而没有时间。小时候总是喜欢对自己说，「嘿，以后赚到钱了就去环游世界吧。」长大了才意识到先不谈能去到多远的地方欣赏风景，首先得在当前的环境下站稳脚跟，而这已属不易。&lt;/p&gt;

&lt;p&gt;我喜欢爬山，喜欢慢慢地走着，一步一个脚印，欣赏沿途的风景。&lt;/p&gt;

&lt;p&gt;就如同喜欢编程一样，我很享受这种可以通过自己一步步的努力，最终获得想要的成果的感觉。而是否能够到达山顶反而不是那么重要了。&lt;/p&gt;

&lt;p&gt;能够心无旁骛地放飞自我，享受时光流逝，真的是一件很幸福的事。&lt;/p&gt;

&lt;h3 id=&#34;编程&#34;&gt;编程&lt;/h3&gt;

&lt;p&gt;看完《黑客与画家》之后，我做的第一件事就是去学习作者十分推崇的 Lisp 语言。&lt;/p&gt;

&lt;p&gt;这大概是我第三次尝试去学习这门语言了，很遗憾最终依然以失败告终。在掌握了基本的语法之后，我仍然无法说服自己去用这门语言开发一个有实际意义的项目。或许已经过了那种充满猎奇心理的年纪？又或者说是因为功利心太强了吧。现在在选择是否尝试做一些事情时，必然会权衡利弊得失，再也不像从前那样全凭兴趣，任性而为。&lt;/p&gt;

&lt;p&gt;这一年来主要的开发语言从 C/C++ 换成了 Go。得益于其开发的高效率，可以把更多的精力花在系统整体的架构、设计上，能够快速实现自己的一些想法并且兼顾性能。&lt;/p&gt;

&lt;p&gt;程序员可以从开源项目上学到很多东西，这已经成为我提升自身能力的重要方法。今年主要看了 Codis 和 InfluxDB 的源码，也研究了一些其他分布式存储项目的架构设计。fstor 是我规划中要开发的一个分布式对象存储应用，目前还在设计研究阶段，相关的知识积累还不够，但我就是喜欢给自己定下一些中长期的目标，稍稍超出自己的能力范围，然后享受为之奋斗的过程。&lt;/p&gt;

&lt;p&gt;此外，我开发的 frp 这个用于内网穿透的小工具在 Github 上也有了 2000+ 的 star，这其中收获的成就感真的无法用言语来形容，大概只有程序员能理解了吧。这个项目的初衷仅仅是为了我更方便地在任何地方连接到公司内网的台式机，开源之后，有其他人会报告 bug 以及提新的需求，这让我重新站在不同使用者的角度去思考问题，不断地完善这个项目。如果以后有机会创业，我想这样的经历将会对我起到非常大的帮助。&lt;/p&gt;

&lt;h3 id=&#34;写作&#34;&gt;写作&lt;/h3&gt;

&lt;p&gt;我仍然记得高中的时候，做完作业，偷偷拿出一本褶皱的笔记本，开始将自己幻想中的世界一笔一划地记录下来，旁边放着英语或者数学的教科书，以备随时将写小说的笔记本遮住，仿佛这真的是一件多么见不得人的事，可以和背着父母偷玩掌上游戏机相媲美。&lt;/p&gt;

&lt;p&gt;如果你曾经做过类似的事情，那么这真的值得让人羡慕。你会惊奇地发现，曾经的你竟然如此充满想象力，海阔天空，飞鸟游鱼，应有尽有。而现在，取代它们的是居高不下的房价，堪忧的食品卫生，不健全的医疗制度。生活在这样的环境中，又何来想象力之说呢？&lt;/p&gt;

&lt;p&gt;写作上，我现在更多的是将平时的学习笔记整理成博客，今年由于增加了读书计划，也会写一些读书笔记以及生活感悟。当然，我最喜欢的文体还是小说，经常会有零碎的念头从我脑海中闪过，但是缺乏精力与时间，很难抓住这些小灵感。小说是用一个个生动的故事，去表达作者的世界观与价值观，让每个读者都能用自己的方式去感悟，她不像议论文那么义正言辞，也不像散文那么阳春白雪，每个人都能从中搜寻到与自己生活相关的蛛丝马迹。如果未来有机会，我或许会「重操旧业」也未可知。&lt;/p&gt;

&lt;h3 id=&#34;梦想&#34;&gt;梦想&lt;/h3&gt;

&lt;p&gt;有的人的梦想比较容易实现，有的人的梦想很难。&lt;/p&gt;

&lt;p&gt;我的梦想是和自己喜欢的人一起，在环球旅行的途中，在每个风景优美的地方，敲着代码，做自己喜欢的项目，赚到足够旅行的开销，然后用文字记录下每一天。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>InfluxDB详解之TSM存储引擎解析（二）</title>
          <link>http://blog.fatedier.com/2016/08/15/detailed-in-influxdb-tsm-storage-engine-two/</link>
          <pubDate>Mon, 15 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/08/15/detailed-in-influxdb-tsm-storage-engine-two/</guid>
          <description>&lt;p&gt;上一篇文章主要介绍了 TSM 存储引擎一些相关的概念、组件以及数据存储的目录结构，文件组成结构等内容。这一篇将会尽量从 InfluxDB 源码的角度，深入讲解数据插入、查询、合并等操作的具体流程以及内部数据结构的设计。&lt;/p&gt;

&lt;p&gt;上一篇文章传送门： &lt;a href=&#34;http://blog.fatedier.com/2016/08/05/detailed-in-influxdb-tsm-storage-engine-one/&#34;&gt;『InfluxDB详解之TSM存储引擎解析（一）』&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;主要数据结构&#34;&gt;主要数据结构&lt;/h3&gt;

&lt;p&gt;InfluxDB 中的数据结构主要分为以下几个层次：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;tsdb.Store
    -- map[string]*tsdb.DatabaseIndex
        -- map[string]*tsdb.Measurement
        -- map[string]*tsdb.Series
    -- map[uint64]*tsdb.Shard
        -- Engine // 抽象接口，可插拔设计，目前是 tsm1 存储引擎
            -- tsm1.WAL
            -- tsm1.Cache
            -- tsm1.Compactor
            -- tsm1.FileStore
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;store&#34;&gt;Store&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Store struct {
    path string         // 数据库文件在磁盘上的存储路径

    // 数据库索引文件，key 为数据库名
    databaseIndexes map[string]*DatabaseIndex

    // 所有 shards 的索引，key 为其 shard ID
    shards map[uint64]*Shard
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Store 是存储结构中最顶层的抽象结构体，主要包含了 InfluxDB 中所有数据库的 &lt;strong&gt;索引&lt;/strong&gt; 和 &lt;strong&gt;实际存储数据的 Shard 对象&lt;/strong&gt;。InfluxDB 中的其他服务都需要通过 Store 对象对底层数据进行操作。&lt;/p&gt;

&lt;h4 id=&#34;shard&#34;&gt;Shard&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Shard struct {
    index   *DatabaseIndex      // 所在数据库的索引对象
    path    string              // shard 在磁盘上的路径
    walPath string              // 对应的 wal 文件所在目录
    id      uint64              // shard ID，就是在磁盘上的文件名
    database        string      // 所在数据库名
    retentionPolicy string      // 对应存储策略名
    engine  Engine              // 存储引擎
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每一个 Shard 对象都有一个单独的底层数据存储引擎，engine 负责和底层的文件数据打交道。Shard 还保存了一个指向所在数据库索引的指针，便于快速检索到该 Shard 中的元数据信息。&lt;/p&gt;

&lt;h4 id=&#34;engine&#34;&gt;Engine&lt;/h4&gt;

&lt;p&gt;Engine 是一个抽象接口，对于 InfluxDB 来说，可以很方便地替换掉底层的存储引擎。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Engine interface {
    LoadMetadataIndex(shardID uint64, index *DatabaseIndex) error

    Backup(w io.Writer, basePath string, since time.Time) error
    Restore(r io.Reader, basePath string) error

    CreateIterator(opt influxql.IteratorOptions) (influxql.Iterator, error)
    WritePoints(points []models.Point) error
    ContainsSeries(keys []string) (map[string]bool, error)
    DeleteSeries(keys []string) error
    DeleteSeriesRange(keys []string, min, max int64) error
    DeleteMeasurement(name string, seriesKeys []string) error
    SeriesCount() (n int, err error)
    MeasurementFields(measurement string) *MeasurementFields
    CreateSnapshot() (string, error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;目前 tsm1 存储引擎中 Engine 的结构：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Engine struct {
    path      string
    index             *tsdb.DatabaseIndex                 // 数据库索引信息，目前没和存储引擎放在一起，看起来后续会更改设计作为存储引擎的一部分
    measurementFields map[string]*tsdb.MeasurementFields  // 所有 measurement 对应的 fields 对象
    WAL            *WAL                 // WAL 文件对象
    Cache          *Cache               // WAL 文件在内存中的缓存
    Compactor      *Compactor           // 压缩合并管理对象
    CompactionPlan CompactionPlanner
    FileStore      *FileStore           // 数据文件对象
    MaxPointsPerBlock int               // 每个 block 中最多存储的 Points 数量

    // Cache 超过指定大小后内容会被写入一个新的 TSM 文件
    CacheFlushMemorySizeThreshold uint64

    // Cache 超过多长时间后还没有数据写入，会将内容写入新的 TSM 文件
    CacheFlushWriteColdDuration time.Duration
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Engine 负责维护和管理 &lt;strong&gt;Cache, FileStore, WAL&lt;/strong&gt; 等对象。当用户进行插入或查询操作时，Engine 都会对这些对象进行相应的操作，而这些对上层用户和服务来说是透明的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;从代码中的注释来看，在后续的版本中会把 tsdb.DatabaseIndex 移到 Engine 这一层，由存储引擎自己维护，降低代码的耦合程度。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;数据写入&#34;&gt;数据写入&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_usage,host=server01 value=0.64 1434055562000000000&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;通过-httpd-插入数据&#34;&gt;通过 httpd 插入数据&lt;/h4&gt;

&lt;p&gt;通常我们通过 HTTP 的接口写入一条或同时写入多条数据。在 InfluxDB 启动时会启动一个  httpd 服务，代码在 &lt;code&gt;services/httpd&lt;/code&gt; 包中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (h *Handler) serveWrite(w http.ResponseWriter, r *http.Request, user *meta.UserInfo) {
    ...
    err := h.PointsWriter.WritePoints(database, r.URL.Query().Get(&amp;quot;rp&amp;quot;), consistency, points)
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;httpd 服务解析出要插入的所有 Points，以及数据库，存储策略等内容，之后调用 PointsWriter 的 WritePoints 方法插入数据。&lt;/p&gt;

&lt;h4 id=&#34;pointswriter&#34;&gt;PointsWriter&lt;/h4&gt;

&lt;p&gt;PointsWriter 的结构在 &lt;code&gt;coordinator&lt;/code&gt; 包定义中，所有对数据的操作实际上都是通过这个对象来进行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (w *PointsWriter) WritePoints(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, points []models.Point) error {
    ...
    // 将要写入的 Points 按照时间划分到要写入的 shard，返回一个 Point 和 shard 之间的映射关系
    shardMappings, err := w.MapShards(&amp;amp;WritePointsRequest{Database: database, RetentionPolicy: retentionPolicy, Points: points})
    ...
    
    // 每一个 shard 都有一个独立的协程负责写入，只要有一个出错，就立即返回错误信息
    ch := make(chan error, len(shardMappings.Points))
    for shardID, points := range shardMappings.Points {
        go func(shard *meta.ShardInfo, database, retentionPolicy string, points []models.Point) {
            ch &amp;lt;- w.writeToShard(shard, database, retentionPolicy, points)
        }(shardMappings.Shards[shardID], database, retentionPolicy, points)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;WritePoints&lt;/code&gt; 函数会&lt;strong&gt;根据 Point 的时间戳判断出其属于哪一个 Shard&lt;/strong&gt;，之后调用 &lt;code&gt;writeToShard&lt;/code&gt; 函数批量将 Points 分别写入到不同的 Shard 中。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;writeToShard&lt;/code&gt; 函数中，实际上是调用了 &lt;code&gt;TSDBStore&lt;/code&gt; 的 &lt;code&gt;WriteToShard&lt;/code&gt;。这里的 &lt;code&gt;TSDBStore&lt;/code&gt; 就是前文中提到的 &lt;code&gt;Store&lt;/code&gt; 对象，是一个负责数据存储的顶层的抽象数据结构。而在 &lt;code&gt;Store&lt;/code&gt; 对象中存储了所有 Shard 的管理对象，数据将会交由指定的 Shard 去处理。Shard 会继续调用底层 tsm1 引擎的 engine 对象来真正意义上的写入数据。代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// PointsWirte.writeToShard -&amp;gt; TSDBStore.WriteToShard
func (w *PointsWriter) writeToShard(shard *meta.ShardInfo, database, retentionPolicy string, points []models.Point) error {
    ...
    err := w.TSDBStore.WriteToShard(shard.ID, points)
    ...
}

// TSDBStore.WriteToShard -&amp;gt; shard.WritePoints
func (s *Store) WriteToShard(shardID uint64, points []models.Point) error {
    ...
    sh, ok := s.shards[shardID]
    if !ok {
        return ErrShardNotFound
    }
    return sh.WritePoints(points)
}

// shard.WritePoints -&amp;gt; engine.WritePoints
func (s *Shard) WritePoints(points []models.Point) error {
    ...
    err := s.engine.WritePoints(points)
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;engine-实际写入数据&#34;&gt;Engine 实际写入数据&lt;/h4&gt;

&lt;p&gt;从下面的代码中可以看出，写入操作实际上就是将 value 写入 Cache 和 WAL 中，Cache 中主要是一个 Map 的结构，根据 key 缓存不同时间戳的 value，而 WAL 文件中的数据就是内存中数据的一个持久化的存储文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (e *Engine) WritePoints(points []models.Point) error {
    values := map[string][]Value{}
    for _, p := range points {
        // 一条插入语句中一个 series 对应的多个 value 会被拆分出来，形成多条数据
        for k, v := range p.Fields() {
            // 这里的 key 是 seriesKey + 分隔符 + filedName
            key := string(p.Key()) + keyFieldSeparator + k
            values[key] = append(values[key], NewValue(p.Time().UnixNano(), v))
        }    
    }    
    e.mu.RLock()
    defer e.mu.RUnlock()

    // 向 cache 中写入 value 数据，如果超过了内存阀值上限，返回错误
    err := e.Cache.WriteMulti(values)
    if err != nil {
        return err
    }    

    // 将数据写入 wal 文件中
    _, err = e.WAL.WritePoints(values)
    return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;数据删除&#34;&gt;数据删除&lt;/h3&gt;

&lt;p&gt;InfluxDB 支持对数据的删除操作，和其他 LSM Tree 类似的数据库一样，都是采用了标记要删除的键的方式来进行操作，等到需要进行压缩合并时，再真正意义上地删除这些数据。&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;data&lt;/code&gt; 中和 tsm file 同一级的目录下，会存在一些以 &lt;code&gt;.tombstone&lt;/code&gt; 文件，其中就记录了哪些 key 在哪一个时间段内的数据需要删除。&lt;/p&gt;

&lt;p&gt;有两种情况需要用到这些文件，一种是在查询时，对于查询结果，需要和 &lt;code&gt;.tombstone&lt;/code&gt; 文件中的内容进行比对，把不符合条件的 value 剔除。另外就是在 &lt;code&gt;Compactor&lt;/code&gt; 进行压缩合并多个 tsm file 时，这些被删除的数据将不会被转存到新的 tsm file 中，从而达到删除数据，释放磁盘空间的目的。&lt;/p&gt;

&lt;h3 id=&#34;数据查询与索引结构&#34;&gt;数据查询与索引结构&lt;/h3&gt;

&lt;p&gt;由于 LSM Tree 的原理就是通过将大量的随机写转换为顺序写，从而极大地提升了数据写入的性能，与此同时牺牲了部分读的性能。TSM 存储引擎是基于 LSM Tree 开发的，所以情况类似。通常设计数据库时会采用索引文件的方式（例如 LevelDB 中的 Mainfest 文件） 或者 Bloom filter 来对 LSM Tree 这样的数据结构的读取操作进行优化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;InfluxDB 中采用索引的方式进行优化，主要存在两种类型的索引。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;元数据索引&#34;&gt;元数据索引&lt;/h4&gt;

&lt;p&gt;一个数据库的元数据索引通过 &lt;strong&gt;DatabaseIndex&lt;/strong&gt; 这个结构体来存储，在数据库启动时，会进行初始化，从所有 shard 下的 tsm file 中加载 index 数据，获取其中所有 &lt;strong&gt;Measurement&lt;/strong&gt; 以及 &lt;strong&gt;Series&lt;/strong&gt; 的信息并缓存到内存中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type DatabaseIndex struct {
    measurements map[string]*Measurement // 该数据库下所有 Measurement 对象
    series       map[string]*Series      // 所有 Series 对象，SeriesKey = measurement + tags
    name string // 数据库名
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个结构体中最主要存放的就是该数据下所有 &lt;code&gt;Measurement&lt;/code&gt; 和 &lt;code&gt;Series&lt;/code&gt; 的内容，其数据结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Measurement struct {
    Name       string `json:&amp;quot;name,omitempty&amp;quot;`
    fieldNames map[string]struct{}      // 此 measurement 中的所有 filedNames

    // 内存中的索引信息
    // id 以及其对应的 series 信息，主要是为了在 seriesByTagKeyValue 中存储Id节约内存
    seriesByID          map[uint64]*Series              // lookup table for series by their id

    // 根据 tagk 和 tagv 的双重索引，保存排好序的 SeriesID 数组
    // 这个 map 用于在查询操作时，可以根据 tags 来快速过滤出要查询的所有 SeriesID，之后根据 SeriesKey 以及时间范围从文件中读取相应内容
    seriesByTagKeyValue map[string]map[string]SeriesIDs // map from tag key to value to sorted set of series ids

    // 此 measurement 中所有 series 的 id，按照 id 排序
    seriesIDs           SeriesIDs                       // sorted list of series IDs in this measurement
}

type Series struct {
    Key         string              // series key
    Tags        map[string]string   // tags
    id          uint64              // id
    measurement *Measurement        // 所属 measurement
    // 在哪些 shard 中存在
    shardIDs    map[uint64]bool // shards that have this series defined
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;元数据查询&#34;&gt;元数据查询&lt;/h4&gt;

&lt;p&gt;InfluxDB 支持一些特殊的查询语句（支持正则表达式匹配），可以查询一些 measurement 以及 tags 相关的数据，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SHOW MEASUREMENTS
SHOW TAG KEYS FROM &amp;quot;measurement_name&amp;quot;
SHOW TAG VALUES FROM &amp;quot;measurement_name&amp;quot; WITH KEY = &amp;quot;tag_key&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如我们需要查询 &lt;code&gt;cpu_usage&lt;/code&gt; 这个 measurement 上传数据的机器有哪些，一个可能的查询语句为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SHOW TAG VALUES FROM &amp;quot;cpu_usage&amp;quot; WITH KEY = &amp;quot;host&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;首先根据 measurement 可以在 &lt;code&gt;DatabaseIndex.measurements&lt;/code&gt; 中拿到 &lt;code&gt;cpu_usage&lt;/code&gt; 所对应的 &lt;code&gt;Measurement&lt;/code&gt; 对象。&lt;/li&gt;
&lt;li&gt;通过 &lt;code&gt;Measurement.seriesByTagKeyValue&lt;/code&gt; 获取 &lt;code&gt;tagk=host&lt;/code&gt; 所对应的以 &lt;code&gt;tagv&lt;/code&gt; 为键的 map 对象。&lt;/li&gt;
&lt;li&gt;遍历这个 map 对象，所有的 key 则为我们需要获取的数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;普通数据查询的定位&#34;&gt;普通数据查询的定位&lt;/h4&gt;

&lt;p&gt;对于普通的数据查询语句，则可以通过上述的元数据索引快速定位到要查询的数据所包含的所有 &lt;strong&gt;seriesKey，fieldName 和时间范围&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;举个例子，假设查询语句为获取 &lt;code&gt;server01&lt;/code&gt; 这台机器上 &lt;code&gt;cpu_usage&lt;/code&gt; 指标最近一小时的数据：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;`SELECT value FROM &amp;quot;cpu_usage&amp;quot; WHERE host=&#39;server01&#39; AND time &amp;gt; now() - 1h`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先根据 &lt;code&gt;measurement=cpu_usage&lt;/code&gt; 从 &lt;code&gt;DatabaseIndex.measurements&lt;/code&gt; 中获取到 &lt;code&gt;cpu_usage&lt;/code&gt; 对应的 &lt;code&gt;Measurement&lt;/code&gt; 对象。&lt;/p&gt;

&lt;p&gt;之后通过 &lt;code&gt;DatabaseIndex.measurements[&amp;quot;cpu_usage&amp;quot;].seriesByTagKeyValue[&amp;quot;host&amp;quot;][&amp;quot;server01&amp;quot;]&lt;/code&gt; 获取到所有匹配的 &lt;code&gt;series&lt;/code&gt; 的 ID值，再通过 &lt;code&gt;Measurement.seriesByID&lt;/code&gt; 这个 map 对象根据 &lt;code&gt;series ID&lt;/code&gt; 获取它们的实际对象。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意这里虽然只指定了 &lt;code&gt;host=server01&lt;/code&gt;，但不代表 &lt;code&gt;cpu_usage&lt;/code&gt; 下只有这一个 &lt;code&gt;series&lt;/code&gt;，可能还有其他的 tags 例如 &lt;code&gt;user=1&lt;/code&gt; 以及 &lt;code&gt;user=2&lt;/code&gt;，这样获取到的 &lt;code&gt;series ID&lt;/code&gt; 实际上有两个，获取数据时需要获取所有 &lt;code&gt;series&lt;/code&gt; 下的数据。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;Series&lt;/code&gt; 结构体中的 &lt;code&gt;shardIDs&lt;/code&gt; 这个 map 变量存放了哪些 shard 中存在这个 series 的数据。而 &lt;code&gt;Measurement.fieldNames&lt;/code&gt; 这个 map 可以帮助过滤掉 fieldName 不存在的情况。&lt;/p&gt;

&lt;p&gt;至此，我们在 o(1) 的时间复杂度内，获取到了所有符合要求的 series key、这些 series key 所存在的 shardID，要查询数据的时间范围，之后我们就可以创建数据迭代器从不同的 shard 中获取每一个 series key 在指定时间范围内的数据。后续的查询则和 tsm file 中的 Index 的在内存中的缓存相关。&lt;/p&gt;

&lt;h4 id=&#34;tsm-file-索引&#34;&gt;TSM File 索引&lt;/h4&gt;

&lt;p&gt;上一篇文章中讲过了对于 tsm file 中的 Index 部分会在内存中做间接索引，从而可以实现快速检索的目的。这里看一下具体的数据结构：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type indirectIndex struct {
    b []byte                // 下层详细索引的字节流
    offsets []int32         // 偏移量数组，记录了一个 key 在 b 中的偏移量
    minKey, maxKey string   
    minTime, maxTime int64  // 此文件中的最小时间和最大时间，根据这个可以快速判断要查询的数据在此文件中是否存在，是否有必要读取这个文件
    tombstones map[string][]TimeRange   // 用于记录哪些 key 在指定范围内的数据是已经被删除的
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;b&lt;/code&gt; 直接对应着 tsm file 中的 Index 部分，通过对 offsets 进行二分查找，可以获取到指定 key 的所有 block 的索引信息，之后根据 offset 和 size 信息可以取出一个指定的 block 中的所有数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type indexEntries struct {
    Type    byte 
    entries []IndexEntry
}

type IndexEntry struct {
    // 一个 block 中的 point 都在这个最小和最大的时间范围内
    MinTime, MaxTime int64

    // block 在 tsm 文件中偏移量
    Offset int64

    // block 的具体大小
    Size uint32
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上一节中说明了通过元数据索引可以获取到所有 &lt;strong&gt;符合要求的 series key，它们对应的 shardID，时间范围&lt;/strong&gt;。通过 tsm file 索引，我们就可以根据 series key 和 时间范围快速定位到数据在 tsm file 中的位置。&lt;/p&gt;

&lt;h4 id=&#34;从-tsm-file-中读取数据&#34;&gt;从 tsm file 中读取数据&lt;/h4&gt;

&lt;p&gt;InfluxDB 中的所有数据读取操作都通过 &lt;strong&gt;Iterator&lt;/strong&gt; 来完成。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Iterator&lt;/strong&gt; 是一个抽象概念，并且支持嵌套，一个 Iterator 可以从底层的其他 Iterator 中获取数据并进行处理，之后再将结果传递给上层的 Iterator。&lt;/p&gt;

&lt;p&gt;这部分的代码逻辑比较复杂，这里不展开说明。实际上 &lt;strong&gt;Iterator&lt;/strong&gt; 底层最主要的就是通过 &lt;code&gt;cursor&lt;/code&gt; 来获取数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type cursor interface {
    next() (t int64, v interface{})
}

type floatCursor interface {
    cursor
    nextFloat() (t int64, v float64)
}

// 底层主要是 KeyCursor，每次读取一个 block 的数据
type floatAscendingCursor struct {
    // 内存中的 value 对象
    cache struct {
        values Values
        pos    int
    }

    tsm struct {
        tdec      TimeDecoder   // 时间序列化对象
        vdec      FloatDecoder  // value 序列化对象
        buf       []FloatValue
        values    []FloatValue  // 从 tsm 文件中读取到的 FloatValue 的缓存
        pos       int
        keyCursor *KeyCursor
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;cursor&lt;/strong&gt; 提供了一个 &lt;code&gt;next()&lt;/code&gt; 方法用于获取一个 value 值。每一种数据类型都有一个自己的 &lt;code&gt;cursor&lt;/code&gt; 实现。&lt;/p&gt;

&lt;p&gt;底层实现都是 &lt;strong&gt;KeyCursor&lt;/strong&gt;，&lt;strong&gt;KeyCursor&lt;/strong&gt; 会缓存每个 Block 的数据，通过 &lt;code&gt;Next()&lt;/code&gt; 函数依次返回，当一个 Block 中的内容读完后再通过 &lt;code&gt;ReadBlock()&lt;/code&gt; 函数读取下一个 Block 中的内容。&lt;/p&gt;

&lt;h3 id=&#34;数据压缩与合并&#34;&gt;数据压缩与合并&lt;/h3&gt;

&lt;p&gt;主要涉及到两个结构体：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Compactor struct {
    Dir  string
    Size int
    FileStore interface {
        NextGeneration() int
    }
}

type CompactionPlanner interface {
    Plan(lastWrite time.Time) []CompactionGroup
    PlanLevel(level int) []CompactionGroup
    PlanOptimize() []CompactionGroup
}

// 默认的压缩合并计划
type DefaultPlanner struct {
    FileStore interface {
        Stats() []FileStat
        LastModified() time.Time
        BlockCount(path string, idx int) int
    }

    // 如果一个 shard 对应的 wal 文件超过指定时间一直没有数据写入
    // 存储引擎将会将此 shard 中的 tsm 文件进行一次全量压缩合并
    CompactFullWriteColdDuration time.Duration

    // 如果为 true，表示此 shard 中的 tsm 文件要么只有一个，要么已经处于单个文件最大值
    lastPlanCompactedFull bool

    // lastPlanCheck is the last time Plan was called
    lastPlanCheck time.Time
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 InfluxDB 创建一个 Shard 对应的底层的存储引擎时，会启用一些协程，每隔 1s 检查是否有需要压缩合并的任务，如果有就去执行相应的操作，部分代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (e *Engine) SetCompactionsEnabled(enabled bool) {
    if enabled {
        ...
        e.done = make(chan struct{})
        // 启用压缩合并功能
        e.Compactor.Open()

        // 启用另外的协程去定期检测是否需要进行压缩合并
        e.wg.Add(5)
        // 将 cache 中的内容刷新到磁盘上的新的 tsm 文件中
        go e.compactCache()
        // 下面是定期合并不同 level 的 tsm 文件
        go e.compactTSMFull()
        go e.compactTSMLevel(true, 1)
        go e.compactTSMLevel(true, 2)
        go e.compactTSMLevel(false, 3)
    }
    ...
}

func (e *Engine) compactCache() {
    defer e.wg.Done()
    // 每秒钟检查一次
    for {
        select {
        case &amp;lt;-e.done:
            return

        default:
            // 更新缓存据上一次快照时间的间隔时间
            e.Cache.UpdateAge()
            if e.ShouldCompactCache(e.WAL.LastWriteTime()) {
                start := time.Now()
                err := e.WriteSnapshot()
                ...
            }
        }
        time.Sleep(time.Second)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;compactCache()&lt;/code&gt; 函数负责定期检测 Cache 中的容量是否达到阀值，如果超过阀值会将 Cache 中的内容做一个快照，之后写入到一个新的 tsm file 中。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;compactTSMLevel()&lt;/code&gt; 函数则负责对 tsm file 文件进行合并，每一个协程负责不同级别的文件，多个文件合并后，生成的新的文件级别会是旧文件中级别最高的那个文件加1。合并过程中，会在同一目录下创建以 &lt;code&gt;.tmp&lt;/code&gt; 结尾的临时文件存储合并后的数据，当合并操作完成后，会进行替换操作，删除已经被合并完成的文件。&lt;code&gt;.tombstone&lt;/code&gt; 文件在合并时也会被利用以过滤无效数据。&lt;/p&gt;

&lt;h3 id=&#34;一些问题&#34;&gt;一些问题&lt;/h3&gt;

&lt;h4 id=&#34;go-不支持泛型&#34;&gt;Go 不支持泛型&lt;/h4&gt;

&lt;p&gt;由于 go 不支持泛型，所以 InfluxDB 中很多代码需要兼容各种类型，例如 float,int,string 等都是通过模版文件来 generate 源文件的方式来生成的。&lt;/p&gt;

&lt;p&gt;这样导致代码可读性比较差，并且有大段大段的重复内容。如果使用 interface 的话，势必效率会下降很多。&lt;/p&gt;

&lt;p&gt;对比一下 C++ 的 STL 库，go 在这方面的支持还不是很好，标准库里的 list, heap 等容器包还是用的 interface 的方式，自己要开发一个通用的算法或者容器时也不方便，还是希望之后能支持泛型这样的功能。&lt;/p&gt;

&lt;h4 id=&#34;多个-wal-文件同时写入&#34;&gt;多个 WAL 文件同时写入&lt;/h4&gt;

&lt;p&gt;由于每一个 shard 都有一个独立的 wal 文件，如果使用者创建了多个数据库、存储策略并且数据没有按照时间顺序插入，就会造成写入性能的下降。官方文档中有说之后会采用一个总的 WAL 文件来解决这个问题，不过可能会带来一些其他方面的问题。&lt;/p&gt;

&lt;h4 id=&#34;索引数据对内存的占用&#34;&gt;索引数据对内存的占用&lt;/h4&gt;

&lt;p&gt;InfluxDB 中对于所有 measument 以及 series 的元数据都是缓存在内存中，特别是 tsm file 的 Index 部分的数据，随着保留的数据越来越多，这部分的内存占用也会逐渐增加。&lt;/p&gt;

&lt;p&gt;官方设计文档里也提到了一些方案缓解这类问题，例如采用 LRU 策略，或是采用和 OpenTSDB 中类似的对 key 进行压缩的方法。还有一个方案是将索引数据放到另外一个数据库例如 BoltDB 中进行存储。&lt;/p&gt;

&lt;p&gt;综合来说，InfluxDB 在性能和资源占用等方面都表现得很优秀，1.0.0 版本的稳定性也很高，我在测试环境中使用的一个月中没有出现过异常状况。可能目前最重要的问题就是不支持集群，对数据量有要求的公司需要自己进行二次开发。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>go 程序中获取虚拟块设备的读写速度</title>
          <link>http://blog.fatedier.com/2016/08/08/get-wr-speed-of-virtual-block-device-in-golang/</link>
          <pubDate>Mon, 08 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/08/08/get-wr-speed-of-virtual-block-device-in-golang/</guid>
          <description>&lt;p&gt;最近在写程序时需要在 centos5 系统上获取 device mapper 中的虚拟块设备的读写信息。在这个过程中发现由于
go 跨平台的特性，有一些 api 是无法拿到特定平台上的一些特殊信息的，或者是需要一些小技巧来实现。&lt;/p&gt;

&lt;h3 id=&#34;获取磁盘读写速度&#34;&gt;获取磁盘读写速度&lt;/h3&gt;

&lt;p&gt;正常情况下 linux 上通过 &lt;code&gt;/proc/diskstats&lt;/code&gt; 这个文件来获取磁盘设备的读写信息，这个文件的内容可以通过 &lt;code&gt;cat /proc/diskstats&lt;/code&gt; 获取，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;   1    0 ram0 0 0 0 0 0 0 0 0 0 0 0
   1    1 ram1 0 0 0 0 0 0 0 0 0 0 0
   1    2 ram2 0 0 0 0 0 0 0 0 0 0 0
   1    3 ram3 0 0 0 0 0 0 0 0 0 0 0
   1    4 ram4 0 0 0 0 0 0 0 0 0 0 0
   1    5 ram5 0 0 0 0 0 0 0 0 0 0 0
   1    6 ram6 0 0 0 0 0 0 0 0 0 0 0
   1    7 ram7 0 0 0 0 0 0 0 0 0 0 0
   1    8 ram8 0 0 0 0 0 0 0 0 0 0 0
   1    9 ram9 0 0 0 0 0 0 0 0 0 0 0
   1   10 ram10 0 0 0 0 0 0 0 0 0 0 0
   1   11 ram11 0 0 0 0 0 0 0 0 0 0 0
   1   12 ram12 0 0 0 0 0 0 0 0 0 0 0
   1   13 ram13 0 0 0 0 0 0 0 0 0 0 0
   1   14 ram14 0 0 0 0 0 0 0 0 0 0 0
   1   15 ram15 0 0 0 0 0 0 0 0 0 0 0
   8    0 sda 29130 11247 905939 500914 155932 727767 7071070 2191673 0 552400 2692588
   8    1 sda1 84 1040 2264 450 31 12 86 382 0 809 832
   8    2 sda2 29026 10190 903379 500111 155901 727755 7070984 2191291 0 551590 2691403
 253    0 dm-0 38942 0 902058 758838 883873 0 7070984 30357342 0 551667 31116195
 253    1 dm-1 142 0 1136 502 0 0 0 0 0 84 502
  22    0 hdc 0 0 0 0 0 0 0 0 0 0 0
   2    0 fd0 0 0 0 0 0 0 0 0 0 0 0
   9    0 md0 0 0 0 0 0 0 0 0 0 0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一列和第二列是设备号，第三列是设备名称，第六列是读取的 sectors 数，第十列是写入的 sectors 数。&lt;/p&gt;

&lt;p&gt;和计算 cpu 使用率类似，我们需要读取两次该文件，将两次读取到的值相减以后除以间隔时间来计算读写速度。&lt;/p&gt;

&lt;h3 id=&#34;虚拟块设备的区别&#34;&gt;虚拟块设备的区别&lt;/h3&gt;

&lt;p&gt;通过 &lt;code&gt;df -h&lt;/code&gt; 可以看到其中 &lt;code&gt;/dev/mapper/VolGroup00-LogVol00&lt;/code&gt; 就是一个虚拟块设备：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup00-LogVol00
                       18G  1.9G   15G  12% /
/dev/sda1              99M   13M   81M  14% /boot
tmpfs                 499M     0  499M   0% /dev/shm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是获取读写信息时拿到的对应设备名并不是这个，实际上应该是 &lt;code&gt;dm-0&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;所以我们需要通过设备号来获取他们的对应关系。&lt;/p&gt;

&lt;h4 id=&#34;获取设备号&#34;&gt;获取设备号&lt;/h4&gt;

&lt;p&gt;在 centos5 上比较特殊，没法使用 &lt;code&gt;lsblk&lt;/code&gt; 获取设备号，所以需要用其他的方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls -lh /dev/mapper/

total 0
crw------- 1 root root  10, 60 Jul 11 22:18 control
brw-rw---- 1 root disk 253,  0 Jul 11 22:19 VolGroup00-LogVol00
brw-rw---- 1 root disk 253,  1 Jul 11 22:18 VolGroup00-LogVol01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出 &lt;code&gt;VolGroup00-LogVol00&lt;/code&gt; 的设备号为 &lt;code&gt;253,0&lt;/code&gt;，既然 &lt;code&gt;ls -lh&lt;/code&gt; 可以显示设备号信息，说明这个信息是可以通过 &lt;code&gt;stat&lt;/code&gt; 获取到的。&lt;/p&gt;

&lt;h4 id=&#34;go-中获取文件信息&#34;&gt;go 中获取文件信息&lt;/h4&gt;

&lt;p&gt;go 中文件的信息接口如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type FileInfo interface {
    Name() string           // 文件的名字（不含扩展名）
    Size() int64            // 普通文件返回值表示其大小；其他文件的返回值含义各系统不同
    Mode() FileMode         // 文件的模式位
    ModTime() time.Time     // 文件的修改时间
    IsDir() bool            // 等价于
    Mode().IsDir()Sys() interface{} // 底层数据来源（可以返回nil）
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于 go 语言需要考虑跨平台的特性，正常情况下只能拿到这些通用的信息。而如果要在 linux 下获取设备号，关键就在于那个 &lt;code&gt;Sys()&lt;/code&gt; 函数所返回的 &lt;code&gt;Interface{}&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在 linux 平台上，其对应的是一个 &lt;code&gt;Stat_t&lt;/code&gt; 结构体：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Stat_t struct {
    Dev       uint64
    X__pad1   uint16
    Pad_cgo_0 [2]byte
    X__st_ino uint32
    Mode      uint32
    Nlink     uint32
    Uid       uint32
    Gid       uint32
    Rdev      uint64
    X__pad2   uint16
    Pad_cgo_1 [2]byte
    Size      int64
    Blksize   int32
    Blocks    int64
    Atim      Timespec
    Mtim      Timespec
    Ctim      Timespec
    Ino       uint64
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;需要注意这个结构体在不同平台上的定义是不同的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;其中的 &lt;code&gt;Rdev&lt;/code&gt; 就是设备号的值，例如查看上文中的设备文件设备号返回结果是 &lt;code&gt;64768&lt;/code&gt;，转换成 &lt;code&gt;ls -lh&lt;/code&gt; 中显示的格式就是 &lt;code&gt;253,0&lt;/code&gt;，转换成 16 进制是 &lt;code&gt;FD00&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;下面是示例代码片段，需要注意的是这段代码可能并不能在除 linux 之外的其他平台运行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;dev, err := os.Stat(&amp;quot;/dev/mapper/VolGroup00-LogVol00&amp;quot;)
if err != nil {
    os.Exit(1)
}
sys, ok := dev.Sys().(*syscall.Stat_t)
if !ok {
    os.Exit(1)
}
major := sys.Rdev / 256
minor := sys.Rdev % 256
devNumStr := fmt.Sprintf(&amp;quot;%d:%d&amp;quot;, major, minor)
fmt.Printf(&amp;quot;get dev mapper [%s] [%s]&amp;quot;, dev.Name, devNumStr)
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>InfluxDB详解之TSM存储引擎解析（一）</title>
          <link>http://blog.fatedier.com/2016/08/05/detailed-in-influxdb-tsm-storage-engine-one/</link>
          <pubDate>Fri, 05 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/08/05/detailed-in-influxdb-tsm-storage-engine-one/</guid>
          <description>&lt;p&gt;InfluxDB 项目更新比较快，google 了一下网上的一些文档基本上都是简单介绍了一下，而且很多都已经过时了，比如其中使用的 TSM 存储引擎，甚至官方文档上的内容都不是最新的。在源码里的 README 中有最新的设计实现的一些概要说明。&lt;/p&gt;

&lt;p&gt;我认为像这样的针对特殊场景进行优化的数据库会是今后数据库领域发展的主流，这里针对 InfluxDB 1.0.0 版本的源码深入研究一下 TSM 引擎的实现原理。TSM 存储引擎解决了 InfluxDB 之前使用的 LevelDB 和 BoltDB 时遇到的一些问题。&lt;/p&gt;

&lt;p&gt;因为 TSM 是根据 LSM Tree 针对时间序列数据优化而来，所以总体架构设计上相差并不是很大，LSM Tree 的概念可以参考 &lt;a href=&#34;http://blog.fatedier.com/2016/06/15/learn-lsm-tree/&#34;&gt;『LSM Tree 学习笔记』&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;p&gt;首先需要简单了解 InfluxDB 的总体的架构以及一些关键概念，有一个总的思路，知道这个数据库是为了存储什么样的数据，解决哪些问题而诞生的，便于后面理解 TSM 存储引擎的详细的结构。可以简单看一下我之前的文章，&lt;a href=&#34;http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb/&#34;&gt;『时间序列数据库调研之InfluxDB』&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;数据格式&#34;&gt;数据格式&lt;/h4&gt;

&lt;p&gt;在 InfluxDB 中，我们可以粗略的将要存入的一条数据看作&lt;strong&gt;一个虚拟的 key 和其对应的 value(field value)&lt;/strong&gt;，格式如下：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cpu_usage,host=server01,region=us-west value=0.64 1434055562000000000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;虚拟的 key 包括以下几个部分： database, retention policy, measurement, tag sets, field name, timestamp。&lt;/strong&gt; database 和 retention policy 在上面的数据中并没有体现，通常在插入数据时在 http 请求的相应字段中指定。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;database&lt;/strong&gt;: 数据库名，在 InfluxDB 中可以创建多个数据库，不同数据库中的数据文件是隔离存放的，存放在磁盘上的不同目录。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;retention policy&lt;/strong&gt;: 存储策略，用于设置数据保留的时间，每个数据库刚开始会自动创建一个默认的存储策略 autogen，数据保留时间为永久，之后用户可以自己设置，例如保留最近2小时的数据。插入和查询数据时如果不指定存储策略，则使用默认存储策略，且默认存储策略可以修改。InfluxDB 会定期清除过期的数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;measurement&lt;/strong&gt;: 测量指标名，例如 cpu_usage 表示 cpu 的使用率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tag sets&lt;/strong&gt;: tags 在 InfluxDB 中会按照字典序排序，不管是 tagk 还是 tagv，只要不一致就分别属于两个 key，例如 &lt;code&gt;host=server01,region=us-west&lt;/code&gt; 和 &lt;code&gt;host=server02,region=us-west&lt;/code&gt; 就是两个不同的 tag set。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;field name&lt;/strong&gt;: 例如上面数据中的 &lt;code&gt;value&lt;/code&gt; 就是 fieldName，InfluxDB 中支持一条数据中插入多个 fieldName，这其实是一个语法上的优化，在实际的底层存储中，是当作多条数据来存储。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;timestamp&lt;/strong&gt;: 每一条数据都需要指定一个时间戳，在 TSM 存储引擎中会特殊对待，以为了优化后续的查询操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;point&#34;&gt;Point&lt;/h4&gt;

&lt;p&gt;InfluxDB 中单条插入语句的数据结构，&lt;code&gt;series + timestamp&lt;/code&gt; 可以用于区别一个 point，也就是说一个 point 可以有多个 field name 和 field value。&lt;/p&gt;

&lt;h4 id=&#34;series&#34;&gt;Series&lt;/h4&gt;

&lt;p&gt;series 相当于是 InfluxDB 中一些数据的集合，在同一个 database 中，retention policy、measurement、tag sets 完全相同的数据同属于一个 series，同一个 series 的数据在物理上会按照时间顺序排列存储在一起。&lt;/p&gt;

&lt;p&gt;series 的 key 为 &lt;code&gt;measurement + 所有 tags 的序列化字符串&lt;/code&gt;，这个 key 在之后会经常用到。&lt;/p&gt;

&lt;p&gt;代码中的结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Series struct {
    mu          sync.RWMutex
    Key         string              // series key
    Tags        map[string]string   // tags
    id          uint64              // id
    measurement *Measurement        // measurement
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;shard&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;shard 在 InfluxDB 中是一个比较重要的概念，它和 retention policy 相关联。每一个存储策略下会存在许多 shard，每一个 shard 存储一个指定时间段内的数据，并且不重复，例如 7点-8点 的数据落入 shard0 中，8点-9点的数据则落入 shard1 中。每一个 shard 都对应一个底层的 tsm 存储引擎，有独立的 cache、wal、tsm file。&lt;/p&gt;

&lt;p&gt;创建数据库时会自动创建一个默认存储策略，永久保存数据，对应的在此存储策略下的 shard 所保存的数据的时间段为 7 天，计算的函数如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func shardGroupDuration(d time.Duration) time.Duration {
    if d &amp;gt;= 180*24*time.Hour || d == 0 { // 6 months or 0
        return 7 * 24 * time.Hour
    } else if d &amp;gt;= 2*24*time.Hour { // 2 days
        return 1 * 24 * time.Hour
    }
    return 1 * time.Hour
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果创建一个新的 retention policy 设置数据的保留时间为 1 天，则单个 shard 所存储数据的时间间隔为 1 小时，超过1个小时的数据会被存放到下一个 shard 中。&lt;/p&gt;

&lt;h3 id=&#34;组件&#34;&gt;组件&lt;/h3&gt;

&lt;p&gt;TSM 存储引擎主要由几个部分组成： &lt;strong&gt;cache、wal、tsm file、compactor&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-architecture.png&#34; alt=&#34;tsm-architecture&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;shard-1&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;shard 并不能算是其中的一个组件，因为这是在 tsm 存储引擎之上的一个概念。在 InfluxDB 中按照数据的时间戳所在的范围，会去创建不同的 shard，每一个 shard 都有自己的 cache、wal、tsm file 以及 compactor，这样做的目的就是为了可以通过时间来快速定位到要查询数据的相关资源，加速查询的过程，并且也让之后的批量删除数据的操作变得非常简单且高效。&lt;/p&gt;

&lt;p&gt;在 LSM Tree 中删除数据是通过给指定 key 插入一个删除标记的方式，数据并不立即删除，需要等之后对文件进行压缩合并时才会真正地将数据删除，所以删除大量数据在 LSM Tree 中是一个非常低效的操作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;而在 InfluxDB 中，通过 retention policy 设置数据的保留时间，当检测到一个 shard 中的数据过期后，只需要将这个 shard 的资源释放，相关文件删除即可，这样的做法使得删除过期数据变得非常高效。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;cache&#34;&gt;Cache&lt;/h4&gt;

&lt;p&gt;cache 相当于是 LSM Tree 中的 memtable，在内存中是一个简单的 map 结构，这里的 key 为 &lt;code&gt;seriesKey + 分隔符 + filedName&lt;/code&gt;，目前代码中的分隔符为 &lt;code&gt;#!~#&lt;/code&gt;，entry 相当于是一个按照时间排序的存放实际值的数组，具体结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Cache struct {
    commit  sync.Mutex
    mu      sync.RWMutex
    store   map[string]*entry
    size    uint64              // 当前使用内存的大小
    maxSize uint64              // 缓存最大值

    // snapshots are the cache objects that are currently being written to tsm files
    // they&#39;re kept in memory while flushing so they can be queried along with the cache.
    // they are read only and should never be modified
    // memtable 快照，用于写入 tsm 文件，只读
    snapshot     *Cache
    snapshotSize uint64
    snapshotting bool

    // This number is the number of pending or failed WriteSnaphot attempts since the last successful one.
    snapshotAttempts int

    stats        *CacheStatistics
    lastSnapshot time.Time
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;插入数据时，实际上是同时往 cache 与 wal 中写入数据，可以认为 cache 是 wal 文件中的数据在内存中的缓存。当 InfluxDB 启动时，会遍历所有的 wal 文件，重新构造 cache，这样即使系统出现故障，也不会导致数据的丢失。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cache 中的数据并不是无限增长的，有一个 maxSize 参数用于控制当 cache 中的数据占用多少内存后就会将数据写入 tsm 文件。&lt;/strong&gt;如果不配置的话，默认上限为 25MB，每当 cache 中的数据达到阀值后，会将当前的 cache 进行一次快照，之后清空当前 cache 中的内容，再创建一个新的 wal 文件用于写入，剩下的 wal 文件最后会被删除，快照中的数据会经过排序写入一个新的 tsm 文件中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;目前的 cache 的设计有一个问题&lt;/strong&gt;，当一个快照正在被写入一个新的 tsm 文件时，当前的 cache 由于大量数据写入，又达到了阀值，此时前一次快照还没有完全写入磁盘，InfluxDB 的做法是让后续的写入操作失败，用户需要自己处理，等待恢复后继续写入数据。&lt;/p&gt;

&lt;h4 id=&#34;wal&#34;&gt;WAL&lt;/h4&gt;

&lt;p&gt;wal 文件的内容与内存中的 cache 相同，其作用就是为了持久化数据，当系统崩溃后可以通过 wal 文件恢复还没有写入到 tsm 文件中的数据。&lt;/p&gt;

&lt;p&gt;由于数据是被顺序插入到 wal 文件中，所以写入效率非常高。但是如果写入的数据没有按照时间顺序排列，而是以杂乱无章的方式写入，数据将会根据时间路由到不同的 shard 中，每一个 shard 都有自己的 wal 文件，这样就不再是完全的顺序写入，对性能会有一定影响。看到官方社区有说后续会进行优化，只使用一个 wal 文件，而不是为每一个 shard 创建 wal 文件。&lt;/p&gt;

&lt;p&gt;wal 单个文件达到一定大小后会进行分片，创建一个新的 wal 分片文件用于写入数据。&lt;/p&gt;

&lt;h4 id=&#34;tsm-file&#34;&gt;TSM file&lt;/h4&gt;

&lt;p&gt;单个 tsm file 大小最大为 2GB，用于存放数据。&lt;/p&gt;

&lt;p&gt;TSM file 使用了自己设计的格式，对查询性能以及压缩方面进行了很多优化，在后面的章节会具体说明其文件结构。&lt;/p&gt;

&lt;h4 id=&#34;compactor&#34;&gt;Compactor&lt;/h4&gt;

&lt;p&gt;compactor 组件在后台持续运行，每隔 1 秒会检查一次是否有需要压缩合并的数据。&lt;/p&gt;

&lt;p&gt;主要进行两种操作，一种是 cache 中的数据大小达到阀值后，进行快照，之后转存到一个新的 tsm 文件中。&lt;/p&gt;

&lt;p&gt;另外一种就是合并当前的 tsm 文件，将多个小的 tsm 文件合并成一个，使每一个文件尽量达到单个文件的最大大小，减少文件的数量，并且一些数据的删除操作也是在这个时候完成。&lt;/p&gt;

&lt;h3 id=&#34;目录与文件结构&#34;&gt;目录与文件结构&lt;/h3&gt;

&lt;p&gt;InfluxDB 的数据存储主要有三个目录。&lt;/p&gt;

&lt;p&gt;默认情况下是 &lt;strong&gt;meta&lt;/strong&gt;, &lt;strong&gt;wal&lt;/strong&gt; 以及 &lt;strong&gt;data&lt;/strong&gt; 三个目录。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;meta&lt;/strong&gt; 用于存储数据库的一些元数据，&lt;strong&gt;meta&lt;/strong&gt; 目录下有一个 &lt;code&gt;meta.db&lt;/code&gt; 文件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;wal&lt;/strong&gt; 目录存放预写日志文件，以 &lt;code&gt;.wal&lt;/code&gt; 结尾。&lt;strong&gt;data&lt;/strong&gt; 目录存放实际存储的数据文件，以 &lt;code&gt;.tsm&lt;/code&gt; 结尾。这两个目录下的结构是相似的，其基本结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# wal 目录结构
-- wal
   -- mydb
      -- autogen
         -- 1
            -- _00001.wal
         -- 2
            -- _00035.wal
      -- 2hours
         -- 1
            -- _00001.wal

# data 目录结构
-- data
   -- mydb
      -- autogen
         -- 1
            -- 000000001-000000003.tsm
         -- 2
            -- 000000001-000000001.tsm
      -- 2hours
         -- 1
            -- 000000002-000000002.tsm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;strong&gt;mydb&lt;/strong&gt; 是数据库名称，&lt;strong&gt;autogen&lt;/strong&gt; 和 &lt;strong&gt;2hours&lt;/strong&gt; 是存储策略名称，再下一层目录中的以数字命名的目录是 shard 的 ID 值，比如 &lt;strong&gt;autogen&lt;/strong&gt; 存储策略下有两个 shard，ID 分别为 1 和 2，shard 存储了某一个时间段范围内的数据。再下一级的目录则为具体的文件，分别是 &lt;code&gt;.wal&lt;/code&gt; 和 &lt;code&gt;.tsm&lt;/code&gt; 结尾的文件。&lt;/p&gt;

&lt;h4 id=&#34;wal-文件&#34;&gt;WAL 文件&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-wal-entry.png&#34; alt=&#34;wal-entry&#34; /&gt;&lt;/p&gt;

&lt;p&gt;wal 文件中的一条数据，对应的是一个 key(measument + tags + fieldName) 下的所有 value 数据，按照时间排序。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type (1 byte)&lt;/strong&gt;: 表示这个条目中 value 的类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key Len (2 bytes)&lt;/strong&gt;: 指定下面一个字段 key 的长度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key (N bytes)&lt;/strong&gt;: 这里的 key 为 measument + tags + fieldName。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Count (4 bytes)&lt;/strong&gt;: 后面紧跟着的是同一个 key 下数据的个数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Time (8 bytes)&lt;/strong&gt;: 单个 value 的时间戳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value (N bytes)&lt;/strong&gt;: value 的具体内容，其中 float64, int64, boolean 都是固定的字节数存储比较简单，通过 Type 字段知道这里 value 的字节数。string 类型比较特殊，对于 string 来说，N bytes 的 Value 部分，前面 4 字节用于存储 string 的长度，剩下的部分才是 string 的实际内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;tsm-文件&#34;&gt;TSM 文件&lt;/h4&gt;

&lt;p&gt;单个 tsm 文件的主要格式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file.png&#34; alt=&#34;tsm-file&#34; /&gt;&lt;/p&gt;

&lt;p&gt;主要分为四个部分： &lt;strong&gt;Header, Blocks, Index, Footer&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;其中 &lt;strong&gt;Index&lt;/strong&gt; 部分的内容会被缓存在内存中，下面详细说明一下每一个部分的数据结构。&lt;/p&gt;

&lt;h5 id=&#34;header&#34;&gt;Header&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-header.png&#34; alt=&#34;tsm-file-header&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MagicNumber  (4 bytes)&lt;/strong&gt;: 用于区分是哪一个存储引擎，目前使用的 tsm1 引擎，MagicNumber 为 &lt;code&gt;0x16D116D1&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Version (1 byte)&lt;/strong&gt;: 目前是 tsm1 引擎，此值固定为 &lt;code&gt;1&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;blocks&#34;&gt;Blocks&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-blocks.png&#34; alt=&#34;tsm-file-blocks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Blocks 内部是一些连续的 Block，block 是 InfluxDB 中的最小读取对象，每次读取操作都会读取一个 block。每一个 Block 分为 CRC32 值和 Data 两部分，CRC32 值用于校验 Data 的内容是否有问题。Data 的长度记录在之后的 Index 部分中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data 中的内容根据数据类型的不同，在 InfluxDB 中会采用不同的压缩方式&lt;/strong&gt;，float 值采用了 Gorilla float compression，而 timestamp 因为是一个递增的序列，所以实际上压缩时只需要记录时间的偏移量信息。string 类型的 value 采用了 snappy 算法进行压缩。&lt;/p&gt;

&lt;p&gt;Data 的数据解压后的格式为 8 字节的时间戳以及紧跟着的 value，value 根据类型的不同，会占用不同大小的空间，其中 string 为不定长，会在数据开始处存放长度，这一点和 WAL 文件中的格式相同。&lt;/p&gt;

&lt;h5 id=&#34;index&#34;&gt;Index&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-index.png&#34; alt=&#34;tsm-file-index&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Index 存放的是前面 Blocks 里内容的索引。索引条目的顺序是先按照 key 的字典序排序，再按照 time 排序。InfluxDB 在做查询操作时，可以根据 Index 的信息快速定位到 tsm file 中要查询的 block 的位置。&lt;/p&gt;

&lt;p&gt;这张图只展示了其中一部分，用结构体来表示的话类似下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type BlockIndex struct {
    MinTime     int64
    MaxTime     int64
    Offset      int64
    Size        uint32
}

type KeyIndex struct {
    KeyLen      uint16
    Key         string
    Type        byte
    Count       uint32
    Blocks      []*BlockIndex
}

type Index []*KeyIndex
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Key Len (2 bytes)&lt;/strong&gt;: 下面一个字段 key 的长度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key (N bytes)&lt;/strong&gt;: 这里的 key 指的是 seriesKey + 分隔符 + fieldName。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type (1 bytes)&lt;/strong&gt;: fieldName 所对应的 fieldValue 的类型，也就是 Block 中 Data 内的数据的类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Count (2 bytes)&lt;/strong&gt;: 后面紧跟着的 Blocks 索引的个数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;后面四个部分是 block 的索引信息，根据 Count 中的个数会重复出现，每个 block 索引固定为 28 字节，按照时间排序。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Min Time (8 bytes)&lt;/strong&gt;: block 中 value 的最小时间戳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Time (8 bytes)&lt;/strong&gt;: block 中 value 的最大时间戳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Offset (8 bytes)&lt;/strong&gt;: block 在整个 tsm file 中的偏移量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Size (4 bytes)&lt;/strong&gt;: block 的大小。根据 Offset + Size 字段就可以快速读取出一个 block 中的内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;间接索引&#34;&gt;间接索引&lt;/h5&gt;

&lt;p&gt;间接索引只存在于内存中，是为了可以快速定位到一个 key 在详细索引信息中的位置而创建的，可以被用于二分查找来实现快速检索。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-index-simple.png&#34; alt=&#34;tsm-file-index-simple&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-sub-index.png&#34; alt=&#34;tsm-file-sub-index&#34; /&gt;&lt;/p&gt;

&lt;p&gt;offsets 是一个数组，其中存储的值为每一个 key 在 Index 表中的位置，由于 key 的长度固定为 2字节，所以根据这个位置就可以找到该位置上对应的 key 的内容。&lt;/p&gt;

&lt;p&gt;当指定一个要查询的 key 时，就可以通过二分查找，定位到其在 Index 表中的位置，再根据要查询的数据的时间进行定位，由于 KeyIndex  中的 BlockIndex 结构是定长的，所以也可以进行一次二分查找，找到要查询的数据所在的 BlockIndex 的内容，之后根据偏移量以及 block 长度就可以从 tsm 文件中快速读取出一个 block 的内容。&lt;/p&gt;

&lt;h5 id=&#34;footer&#34;&gt;Footer&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-footer.png&#34; alt=&#34;tsm-file-footer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;tsm file 的最后8字节的内容存放了 Index 部分的起始位置在 tsm file 中的偏移量，方便将索引信息加载到内存中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于内容较多，具体的写入与查询操作的流程，以及部分代码的详解会在下一篇文章中介绍。&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang 中使用 statik 将静态资源编译进二进制文件中</title>
          <link>http://blog.fatedier.com/2016/08/01/compile-assets-into-binary-file-with-statik-in-golang/</link>
          <pubDate>Mon, 01 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/08/01/compile-assets-into-binary-file-with-statik-in-golang/</guid>
          <description>&lt;p&gt;现在的很多程序都会提供一个 Dashboard 类似的页面用于查看程序状态并进行一些管理的功能，通常都不会很复杂，但是其中用到的图片和网页的一些静态资源，如果需要用户额外存放在一个目录，也不是很方便，如果能打包进程序发布的二进制文件中，用户下载以后可以直接使用，就方便很多。&lt;/p&gt;

&lt;p&gt;最近在阅读 InfluxDB 的源码，发现里面提供了一个 admin 管理的页面，可以通过浏览器来执行一些命令以及查看程序运行的信息。但是我运行的时候只运行了一个 influxd 的二进制文件，并没有看到 css, html 等文件。&lt;/p&gt;

&lt;p&gt;原来 InfluxDB 中使用了 statik 这个工具将静态资源都编译进了二进制文件中，这样用户只需要运行这个程序即可，而不需要管静态资源文件存放的位置。&lt;/p&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;p&gt;先下载并安装 statik 这个工具&lt;/p&gt;

&lt;p&gt;&lt;code&gt;go get -d github.com/rakyll/statik&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;go install github.com/rakyll/statik&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注意将 &lt;code&gt;$GOPATH/bin&lt;/code&gt; 加入到 PATH 环境变量中。&lt;/p&gt;

&lt;h3 id=&#34;创建测试项目&#34;&gt;创建测试项目&lt;/h3&gt;

&lt;p&gt;创建一个测试用的 golang 项目，这里假设目录为 &lt;code&gt;$GOPATH/src/test/testStatikFS&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;创建一个 assets 目录用于放静态资源文件。包括 &lt;code&gt;./assets/a&lt;/code&gt; 和 &lt;code&gt;./assets/tmp/b&lt;/code&gt; 两个文件，文件内容分别为 &lt;code&gt;aaa&lt;/code&gt; 和 &lt;code&gt;bbb&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;创建 main.go 文件，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//go:generate statik -src=./assets
//go:generate go fmt statik/statik.go

package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
    &amp;quot;os&amp;quot;

    _ &amp;quot;test/testStatikFS/statik&amp;quot;
    &amp;quot;github.com/rakyll/statik/fs&amp;quot;
)

// Before buildling, run go generate.
func main() {
    statikFS, err := fs.New()
    if err != nil {
        fmt.Printf(&amp;quot;err: %v\n&amp;quot;, err)
        os.Exit(1)
    }   

    file, err := statikFS.Open(&amp;quot;/tmp/b&amp;quot;)
    if err != nil {
        fmt.Printf(&amp;quot;err: %v\n&amp;quot;, err)
        os.Exit(1)
    }   
    content, err := ioutil.ReadAll(file)
    if err != nil { 
        fmt.Printf(&amp;quot;err: %v\n&amp;quot;, err)
        os.Exit(1)
    }   
    fmt.Printf(&amp;quot;content: %s\n&amp;quot;, content)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意文件最开始的两行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//go:generate statik -src=./assets
//go:generate go fmt statik/statik.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个注释是告诉 &lt;code&gt;go generate&lt;/code&gt; 需要执行的命令，之后就可以通过 &lt;code&gt;go generate&lt;/code&gt; 生成我们需要的 go 文件。&lt;/p&gt;

&lt;p&gt;这段代码的功能就是从 &lt;strong&gt;statikFS&lt;/strong&gt; 提供的文件系统接口中获取 &lt;code&gt;/tmp/b&lt;/code&gt; 这个文件的内容并输出，可以看到操作起来和操作普通文件的方法基本一致。&lt;/p&gt;

&lt;h3 id=&#34;将静态资源打包成-go-文件&#34;&gt;将静态资源打包成 go 文件&lt;/h3&gt;

&lt;p&gt;执行 &lt;code&gt;go generate&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在项目目录下执行这个命令会生成一个 &lt;strong&gt;statik&lt;/strong&gt; 目录，里面存放的是自动生成的 go 文件，将所有 &lt;code&gt;./assets&lt;/code&gt; 下的文件变成了一个压缩后的字符串放在了这个文件中，并且在程序启动时会解析这个字符串，构造一个 &lt;strong&gt;http.FileSystem&lt;/strong&gt; 对象，之后就可以使用对文件系统类似的操作来获取文件内容。&lt;/p&gt;

&lt;h3 id=&#34;编译&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;go build -o test ./main.go&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在 main.go 中我们 import 了两个包&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;_ &amp;quot;test/testStatikFS/statik&amp;quot;
&amp;quot;github.com/rakyll/statik/fs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个就是 &lt;code&gt;go generate&lt;/code&gt; 自动生成的目录，其中只有一个 &lt;code&gt;init()&lt;/code&gt; 函数，初始化相关的资源，我们不需要调用这个包里面的函数，只执行 &lt;code&gt;init()&lt;/code&gt; 函数，所以在包名前加上 &lt;code&gt;_&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;运行&#34;&gt;运行&lt;/h3&gt;

&lt;p&gt;运行编译后的文件： &lt;code&gt;./test&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;输出了文件 &lt;code&gt;./assets/tmp/b&lt;/code&gt; 中的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;content: bbb
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;文件系统接口&#34;&gt;文件系统接口&lt;/h3&gt;

&lt;p&gt;由于 statik 实现了标准库中的 http.FileSystem 接口，所以也可以直接使用 http 包提供静态资源的访问服务，关键部分代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
  &amp;quot;github.com/rakyll/statik/fs&amp;quot;

    _ &amp;quot;./statik&amp;quot; // TODO: Replace with the absolute import path
)

// ...

statikFS, _ := fs.New()
http.ListenAndServe(&amp;quot;:8080&amp;quot;, http.FileServer(statikFS))
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>使用gvm在不同go版本之间切换</title>
          <link>http://blog.fatedier.com/2016/07/25/use-different-go-version-by-gvm/</link>
          <pubDate>Mon, 25 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/25/use-different-go-version-by-gvm/</guid>
          <description>&lt;p&gt;Centos7上通过 yum 从 epel 仓库里直接安装的 go 版本还是 1.4.2，从源码编译安装最新的 go 版本比较麻烦，而且开发中有时需要调试在不同编译环境下可能存在的问题，不能忽略使用最新版本是存在某些 bug 的可能性。&lt;/p&gt;

&lt;p&gt;Go 的更新速度比较快，2015年8月发布 1.5 版本，2016年2月发布 1.6 版本，2016年8月即将发布 1.7 版本，在性能以及GC方便都在不断优化，及时更新到新版本的 go 很有优势。&lt;/p&gt;

&lt;h3 id=&#34;go-版本切换的问题&#34;&gt;Go 版本切换的问题&lt;/h3&gt;

&lt;p&gt;二进制文件的管理比较简单，通过链接使用不同版本的程序即可，实际上主要是一些环境变量和标准库的设置问题，环境变量主要是 &lt;code&gt;GOPATH&lt;/code&gt; 以及 &lt;code&gt;GOROOT&lt;/code&gt;，标准库的话需要在切换 go 版本时也能跟着切换。&lt;strong&gt;gvm&lt;/strong&gt; 实际上就是帮助完成这些配置工作。&lt;/p&gt;

&lt;h3 id=&#34;安装-gvm&#34;&gt;安装 gvm&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;gvm&lt;/strong&gt; 的项目地址：&lt;a href=&#34;https://github.com/moovweb/gvm&#34;&gt;https://github.com/moovweb/gvm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装命令：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bash &amp;lt;&amp;lt; (curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果你使用的是 &lt;code&gt;zsh&lt;/code&gt; 的话将前面的 &lt;code&gt;bash&lt;/code&gt; 改为 &lt;code&gt;zsh&lt;/code&gt; 即可，这条命令主要是下载 &lt;strong&gt;gvm&lt;/strong&gt; 相关的文件，创建所需目录，并且在 &lt;code&gt;.bashrc&lt;/code&gt; 或者 &lt;code&gt;.zshrc&lt;/code&gt; 中加入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[[ -s &amp;quot;/home/wcl/.gvm/scripts/gvm&amp;quot; ]] &amp;amp;&amp;amp; source &amp;quot;/home/wcl/.gvm/scripts/gvm&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;使每次登录 shell 时都可以生效。&lt;/p&gt;

&lt;h3 id=&#34;安装指定-go-版本&#34;&gt;安装指定 go 版本&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;gvm install go1.6.3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;需要注意这里实际上是先执行&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git clone https://go.googlesource.com/go $GVM_ROOT/archive/go&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个网站在墙外。&lt;/p&gt;

&lt;p&gt;我们可以通过配置使 git 可以通过 http 代理访问，修改 &lt;code&gt;.gitconfig&lt;/code&gt; 文件，加上 http 代理服务器的地址：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[http]
        proxy = http://[proxydomain]:[port]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下载成功后，有可能提示编译失败，因为 go1.6.3 需要依赖于 go1.4 来编译，需要设置 &lt;code&gt;GOROOT_BOOTSTRAP&lt;/code&gt; 变量。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;go env&lt;/code&gt; 查看 &lt;code&gt;GOROOT&lt;/code&gt; 的路径，通常 &lt;code&gt;GOROOT_BOOTSTRAP&lt;/code&gt; 就设置成 &lt;code&gt;GOROOT&lt;/code&gt;，centos7 下需要注意 /usr/lib/golang/bin 下并没有 &lt;code&gt;go&lt;/code&gt; 的二进制文件，通过 cp 命令复制一个过去。&lt;/p&gt;

&lt;p&gt;之后再次执行 &lt;code&gt;gvm install go1.6.3&lt;/code&gt; 即可安装完成。&lt;/p&gt;

&lt;h3 id=&#34;修改配置信息方便使用&#34;&gt;修改配置信息方便使用&lt;/h3&gt;

&lt;p&gt;最初测试时发现每次切换 go 版本后都会被修改 &lt;code&gt;GOPATH&lt;/code&gt; 变量，而实际上我并不需要这个功能，只是希望用新版本来编译已有的项目，所以我们需要把 &lt;code&gt;~/.gvm/environments&lt;/code&gt; 文件夹下所有 &lt;code&gt;GOPATH&lt;/code&gt; 的设置全部删除。&lt;/p&gt;

&lt;p&gt;另外还需要将 &lt;code&gt;~/.zshrc&lt;/code&gt; 或者 &lt;code&gt;~/.bashrc&lt;/code&gt; 中的&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[[ -s &amp;quot;~/.gvm/scripts/gvm&amp;quot; ]] &amp;amp;&amp;amp; source &amp;quot;~/.gvm/scripts/gvm&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;移到设置 &lt;code&gt;GOPATH&lt;/code&gt; 变量之前，避免登录 shell 之后被修改 &lt;code&gt;GOPATH&lt;/code&gt; 变量。&lt;/p&gt;

&lt;h3 id=&#34;使用&#34;&gt;使用&lt;/h3&gt;

&lt;h4 id=&#34;切换到安装好的指定-go-版本&#34;&gt;切换到安装好的指定 go 版本&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm use go1.6.3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;go version&lt;/code&gt; 可以看到已经是新版本的二进制文件，通过 &lt;code&gt;go env&lt;/code&gt; 可以查看 &lt;code&gt;GOROOT&lt;/code&gt; 信息，例如我的就是 &lt;code&gt;~/.gvm/gos/go1.6.3&lt;/code&gt;，这样编译项目时就会在这个目录下找标准库中的文件。&lt;/p&gt;

&lt;h4 id=&#34;切换到原来的系统版本&#34;&gt;切换到原来的系统版本&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm use system&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查看当前已经安装的所有版本&#34;&gt;查看当前已经安装的所有版本&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm list&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gvm gos (installed)

=&amp;gt; go1.6.3
   system
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;设置某个版本为默认&#34;&gt;设置某个版本为默认&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm use go1.6.3 --default&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这样设置后，再登录 shell 就默认使用 &lt;code&gt;go1.6.3&lt;/code&gt; 的版本，而不是系统原来的版本了。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>linux下查看指定进程的所有连接信息</title>
          <link>http://blog.fatedier.com/2016/07/18/stat-all-connection-info-of-special-process-in-linux/</link>
          <pubDate>Mon, 18 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/18/stat-all-connection-info-of-special-process-in-linux/</guid>
          <description>&lt;p&gt;定位某个进程的网络故障时经常需要用到的一个功能就是查找所有连接的信息。通常查找某个端口的连接信息使用 ss 或者 netstat 可以轻松拿到，如果是主动与别的机器建立的连接信息则可以通过 lsof 命令来获得。&lt;/p&gt;

&lt;p&gt;例如我想要查看进程 &lt;code&gt;frps&lt;/code&gt; 当前的所有连接信息，先获得进程的 pid：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ps -ef|grep frps&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wcl       4721     1  0 10:27 ?        00:00:01 ./frps
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到进程 pid 为 &lt;strong&gt;4721&lt;/strong&gt;，之后通过 lsof 命令查看所有 TCP 连接信息：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lsof -p 4721 -nP | grep TCP&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;显示结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;frps    4721  wcl    4u     IPv6 117051764      0t0     TCP *:7000 (LISTEN)
frps    4721  wcl    6u     IPv6 117051765      0t0     TCP *:7003 (LISTEN)
frps    4721  wcl    7u     IPv6 117092563      0t0     TCP 139.129.11.120:7000-&amp;gt;116.231.70.223:61545 (ESTABLISHED)
frps    4721  wcl    8u     IPv6 117092565      0t0     TCP *:6000 (LISTEN)
frps    4721  wcl    9u     IPv6 117334426      0t0     TCP 139.129.11.120:7000-&amp;gt;116.237.93.230:64898 (ESTABLISHED)
frps    4721  wcl   10u     IPv6 117053538      0t0     TCP 139.129.11.120:7000-&amp;gt;115.231.20.123:41297 (ESTABLISHED)
frps    4721  wcl   11u     IPv6 117053540      0t0     TCP *:6005 (LISTEN)
frps    4721  wcl   12u     IPv6 117334428      0t0     TCP *:6004 (LISTEN)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从 &lt;strong&gt;lsof&lt;/strong&gt; 的输出结果中可以清楚的看到 &lt;strong&gt;frps&lt;/strong&gt; 进程监听了 5 个端口，并且在 7000 端口上建立了 3 个连接，连接两端的 ip 信息也都可以查到。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;lsof&lt;/strong&gt; 的 &lt;strong&gt;-nP&lt;/strong&gt; 参数用于将 ip 地址和端口号显示为正常的数值类型，否则可能会用别名表示。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>从0到1：遥远的理想国</title>
          <link>http://blog.fatedier.com/2016/07/10/from-zero-to-one-just-a-dream/</link>
          <pubDate>Sun, 10 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/10/from-zero-to-one-just-a-dream/</guid>
          <description>&lt;p&gt;已经记不清自己到底有多久没有认真读过一本非技术类的书籍了，大量的时间被花在职业相关的学习中，宅属性与日俱增。长此以往，渐渐发现个人的主观思想愈加匮乏，对事物的思考与理解能力逐渐下降，这真是一件令人细思极恐之事。&lt;/p&gt;

&lt;p&gt;为了缓解我对于现状的焦虑，计划利用空闲时间多读一些非技术类书籍，并且能够养成阅读的习惯。当然，读书笔记必不可少，我并不打算按照固有的模式根据一本书的框架进行简单介绍，而是侧重于自身对于书中观点的理解与感悟，希望之后再次翻阅时也能对自己有所启发。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;我抽空利用睡前的零星时间读了这本听其名就令人肃然起敬的书 &amp;ndash;著名的 PayPal 黑帮老大 Peter Thiel 的《从0到1：开启商业与未来的秘密》。英文原名是 Zero To One，有时被翻译为「从无到有」，这里我觉得直译为「从0到1」更加贴切而富有想象力。&lt;/p&gt;

&lt;p&gt;Peter Thiel 的团队在硅谷以「PayPal 黑帮」著称。在将 PayPal 以15亿美元卖给了 eBay 公司之后，埃隆·马斯克创立了太空探索技术公司，并与别人合办了特斯拉汽车公司；里德·霍夫曼与别人共同创立了领英公司；陈士骏、查德·赫尔利和贾维德·卡里姆共同创办了 YouTube 视频网站；杰里米·斯托普尔曼和拉塞尔·西蒙斯成立了 Yelp 点评网站，每一个都闻名世界，令人景仰。&lt;/p&gt;

&lt;p&gt;一开始我很好奇这样的作者会如何阐述关于创业的理论，能给出怎样的启示与指导。&lt;strong&gt;通读完此书后，总体上来说是略微有些失望的，然而细想之，根本原因是我原本抱有了过分的期望。「当你歌唱时，饥饿的人是用他的肚子在听」，又或者我就是那个饥饿的人。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;垄断与竞争&#34;&gt;垄断与竞争&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;We wanted flying cars, instead we got 140 characters.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Peter Thiel 批评一些其他的硅谷投资者为了谋求短期快速地利润，只敢投资轻量资本的创业，导致人类几十年以来在比特层面进步很大（互联网），但在原子层面进步很小（尖端科技）。&lt;/p&gt;

&lt;p&gt;这个观点我不是非常赞成，感觉 twitter 是躺着中枪，默哀一秒&amp;hellip;&lt;strong&gt;也许这样的企业确实没有对人类造成天翻地覆的改变，但其存在依然是极有意义的，不能因此就极端地否定其中的一些价值。并不是每个人都有能力创办像 Google、苹果这样的企业。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;本书的前半部分都被用来阐述 Peter Thiel 的这个观点：&lt;strong&gt;规避竞争，打造垄断企业。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;作者认为，创新可以造就垄断企业，而垄断企业推动社会进步的同时摄取大量利润。与之相反的是处于完全竞争中的企业，其产品价格由市场决定，没有定价能力，参与竞争会吞噬掉企业利润，从长远来看，无法将利润投入到新的产品技术研发中，从而进入恶性循环。&lt;/p&gt;

&lt;p&gt;垄断企业的特征：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;专利技术&lt;/li&gt;
&lt;li&gt;网络效应&lt;/li&gt;
&lt;li&gt;规模经济&lt;/li&gt;
&lt;li&gt;品牌优势&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;曾经由乔布斯领导的苹果公司是其中的代表，我们可以很清楚地看到，iphone 手机的设计、生产和营销给苹果公司带来了巨额的垄断利润，苹果公司的现金流储备甚至比一些国家都多。凭借其 ios 系统，在移动计算领域推翻了微软长达数十年的操作系统的霸主地位。想想当初 iphone 4S 发布的年代，市场上鲜有竞品可以与之相提并论。&lt;/p&gt;

&lt;p&gt;与此同时，苹果公司的产品拥有极为吸引人的外观，时尚简约的设计，精心控制的用户体验，优质产品该有的价格，这些都使苹果打造出了属于自己的品牌。&lt;/p&gt;

&lt;p&gt;另一个例子是 Google。&lt;/p&gt;

&lt;p&gt;Google 在 21 世纪初所向披靡，其搜索算法，效果比其他的搜索引擎都好，超短的页面加载时间和超精确地查询增加了核心搜索产品的稳健性和防御力。在技术领域，即使在今天，也通常认为 Google 的技术水平领先于世界先进水平 5 年以上。&lt;/p&gt;

&lt;p&gt;Google 在 2003-2006 年间先后发表了大数据领域著名的三大论文，从论文中可以看出，当时 GFS、BigTable、MapReduce 已然在 Google 内部被稳定使用两年以上。作为其仿制品的 Hadoop，是一个简化实现版本，在 2006 年被雅虎用于研究环境，在国内被广泛使用可能在 2010 年前后。&lt;/p&gt;

&lt;p&gt;2009 年，Google 公布了其最新的 Spanner（全球化分布式数据库）计划，并于 2012 年公布了关于 Spanner 的详细论文。这一数据库既具有 NoSQL 数据库的扩展性，又具有关系数据库的功能。CockroachDB 和 TiDB 作为 Spanner 的追随者在 2015 年启动项目，预计于 2017 年能够发布正式版本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在国内，大多数行业则是另外一番光景。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;滴滴与快的之间的竞争，持续的补贴大战，最终导致二者合二为一；各家外卖平台的烧钱之路仍在继续，小公司无力匹敌，早早倒闭；手机行业华为、小米、魅族、乐视、360，无数品牌之间的竞争日趋白热化，却只能在价格，广告宣传上大做文章；百度这样的公司也为了利益而放弃了「不作恶」的信条。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创新造就垄断企业，然而创新并不是没有代价的，相反，付出很多，且未必能够成功。&lt;/strong&gt;作者的观点在我看来更像是在教化大众，推崇一种理想的境界，却离一般人有些遥远。当然，这本书中的内容原本就是 Peter Thiel 在斯坦福大学的一门「初创企业」课的教学内容，根本不是面向我这样的普通受众。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我们都知道创新所带来的垄断优势非常巨大&lt;/strong&gt;，仿佛火箭发射的助推器，能够支撑企业迅速发展。然而这里又缺少了限定词，那就是天时、地利、人和。想象一下如果小米创办之初就立志于开发下一代的移动终端，今天我们还能看到这个品牌吗？&lt;/p&gt;

&lt;h3 id=&#34;微创新与从1到n&#34;&gt;微创新与从1到N&lt;/h3&gt;

&lt;p&gt;对于大多数人来说，从0到1也许根本就是一件无法完成的事，有时不如尝试着从1到N。&lt;/p&gt;

&lt;p&gt;现在这个时代，大多数人可能对明星的生活趣闻亦或是绯闻报道更感兴趣，街头巷尾的八卦新闻也大多诸如此类，“强东哥和奶茶妹不得不说的故事”，“马云这么有钱，为什么不整容？”。人心浮躁，创业者同样如此，盲目跟风，追热点，讲故事，拉投资，做实事者甚少，君不见每年倒闭的初创公司数不胜数，前几月刚刚倒闭的美味七七实数典型。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;虽然在书中 Peter Thiel 非常详尽地阐述了忽视创新所带来的危害，但从我个人的角度来看，微创新也许更适合于大多数人。&lt;/strong&gt;小米的成功或许值得我们思考与借鉴。&lt;/p&gt;

&lt;p&gt;2011年，有人对我说，看，有一部新手机发布了，还不错哦。那天，QQ右下角弹出了一条新闻，关于一部新手机。小米手机，这个名字听着就很土啊，我心想，据说是为发烧友定制的，和我没多大关系。小米从一个小众的市场开始起步。&lt;/p&gt;

&lt;p&gt;直到2013年，我入手了一部小米手机3，在当时顶级的配置，流畅的操作体验，精美的系统，各项人性化的功能，极高的可玩性，可以说超越了同时期绝大多数其他安卓 ROM。MIUI 也许在当时是小米唯一可以算作是创新的一个点。&lt;/p&gt;

&lt;p&gt;2016年，在大多数人早已换上 iphone 6s 半年后，我的米3换成了米5。已经乏善可陈的 MIUI，普通的旗舰级配置，毫无新意的「黑科技」，这仅仅是一部勉强及格的产品。&lt;/p&gt;

&lt;p&gt;为什么这样的情况下我还会选择小米手机？这是一个被大多数人忽视或者被简单归结于钱上的问题，事实远没有这么简单。我现在拥有的小米系列产品如下：小米手机3、小米手机5、小米手环2、小米路由器、小米空气净化器、小米体重秤、小米插线板、小米随身WIFI、小米耳机、小米移动电源。没错，小米已经成为或者快要成为一个新时代的百货商店，手机仅仅是一个载体，通过 MIUI 将其中大部分设备更好地串联在一起，我已经有了一定的使用习惯，很难再转向另一个生态系统。就好比使用 iphone，macbook，ipad 三件套的人也很难再脱离苹果的掌控。&lt;/p&gt;

&lt;p&gt;路由器成了这个生态系统的核心，手机是控制终端，手环是身份识别设备。当我回家时，小米空气净化器自动打开，当我进入睡眠时，手环可以感知到，并将空气净化器调整为静音模式，早上出门时自动关闭；MIUI 对手环进行了很多适配，可以用于解锁手机屏幕，快捷支付等场景；白天出门后，远程操控小米路由器下载电视剧和电影；通过手机操作插线板，定时开关一些电气设备；小米随身 WIFI 和云服务相结合，相当于一个「移动U盘」；手环和体重秤让我这个懒于锻炼的人逐渐开始了训练计划。小米并不是在这各个产品领域中做的最好的，但它是将这些产品与自己的生态系统结合的最好的一家。&lt;strong&gt;我的生活在被一点点改变，并且期待着下一个可以被改进的设备。虽然没有10年前微软的概念宣传片里的智慧家庭那么震撼人心，但我仍然感受到了这微小进步中所带来的喜悦。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在那个 BAT 独领风骚，垄断社交、电商、搜索，覆盖各个行业领域的情况下，小米在风口飞了起来。从0到1并不是企业追求成功地唯一途径，理想中万众创新，开创美好新世界的理想国也许并不存在，或者只是很遥远。我们更应该不断地尝试从1到N，提高用户体验，扩大市场占有率，然后你才有资本去说从0到1这种话。毕竟不是每一家公司都能像苹果一样创造出颠覆整个行业的产品，而雷军总结小米成功的七字诀：专注、极致、口碑、快，机会不等人，也许对于初创公司来说更加合适。&lt;/p&gt;

&lt;h3 id=&#34;关于创业的一些问题&#34;&gt;关于创业的一些问题&lt;/h3&gt;

&lt;p&gt;这本书的后半部分揭示了一些创业过程中的问题，作者结合了美国这些年信息科技领域的发展趋势以及在 PayPal 和之后投资领域的一些实际经验，分享自己对于未来，对于创业的独到见解。&lt;/p&gt;

&lt;h4 id=&#34;10倍的改进&#34;&gt;10倍的改进&lt;/h4&gt;

&lt;p&gt;你的产品和技术是否能够领先竞争者10倍以上？即使你已经做出了2倍于竞争对手的产品，人们通常认为只是有了一些改进而根本不会买账，特别是在一个已经很拥挤的市场。&lt;/p&gt;

&lt;p&gt;一个很好地例子就是 iphone 与安卓手机。即使将来安卓手机超越 iphone，拥有更好的性能、流畅度、可玩性、开放性与工艺设计，正在使用的 iphone 的那些用户也并不会考虑。除非你做出了10倍的改进，也就相当于是开发出了下一个具有跨时代意义的产品，否则很难改变用户固有的习惯。&lt;/p&gt;

&lt;h4 id=&#34;打造企业文化&#34;&gt;打造企业文化&lt;/h4&gt;

&lt;p&gt;我对企业文化方面认知度最高的当属 facebook，大学时就非常向往 facebook 的黑客文化，它通过大胆地创新试验与敏捷的速度来赢得竞争。&lt;/p&gt;

&lt;p&gt;Facebook 采用扁平化的管理方式，公司的高管层人数很少，基本是中层与基层为主，没有人拥有独立办公室，如果你愿意可以找任何人聊你的想法，即使是 CEO Mark Zuckerberg 也同样在开放的环境中办公。充分信任员工并给予权力是对他们最大的驱动力。&lt;/p&gt;

&lt;h4 id=&#34;关于员工&#34;&gt;关于员工&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;在一开始创业时，首先要做的至关重要的决定是&amp;ndash;和谁一起做。&lt;/strong&gt;技术能力和才华固然重要，但互相之间的了解程度与默契程度也同样重要，此外，是否有共同的信念与目标将是决定未来能否成功地关键。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创业公司不要打福利待遇之战。&lt;/strong&gt;你应该清楚为什么别人要放弃去大公司获取高薪与威望的机会，而选择你的公司。告知员工为何而战，和谁并肩而战才能让员工全力以赴。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;任何用现金支付的薪资都关乎现在，而非着眼未来。&lt;/strong&gt;初创公司不需要支付高薪，因为它们能提供更好地待遇：公司的部分所有权。股票是报酬的一种形式，它能有效引到人们在未来创造价值。&lt;/p&gt;

&lt;h4 id=&#34;从小市场里起步并占据垄断地位&#34;&gt;从小市场里起步并占据垄断地位&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;每个初创公司都应该在非常小的市场内起步，之后逐步扩大规模。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;亚马逊以图书作为起步，之后扩展到其他垂直市场，并且从最相近的光盘，影像和软件市场开始，然后继续增加品类直到成为世界级的“综合商店”，现在亚马逊的云服务 AWS 占据了大部分企业级用户市场，甚至帮助亚马逊实现了盈利。&lt;/p&gt;

&lt;p&gt;即使做不到颠覆式地创新，我们也可以在一个小的市场内，针对一部分受众群体将产品做到极致。很多人忽视了循序渐进的重要性，马佳佳、余佳文、王凯歆这些近几年较为有名的90后创业者，因为现代互联网媒体的快速发展而过早地暴露在大众的聚光灯下，投资人钞票一挥，数千万的融资额仿佛不费吹灰之力。「明年拿1亿分员工！」「超级课程表是全国最大的大学生泡妞平台！」这样的言辞不绝于耳。喧嚣渐息后，他们未来的道路是否依然顺风顺水，拭目以待。&lt;/p&gt;

&lt;h4 id=&#34;重视销售与市场营销&#34;&gt;重视销售与市场营销&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;尽管销售无处不在，多数人还是低估了其重要性，尤其是技术精英。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我作为一个专心于技术领域的工作者，此前一直对销售与市场营销方面的人员不屑一顾。「只要我们的产品足够出色，就能够吸引到足够多得用户，他们会帮助我们宣传，有需求的用户自然会被吸引。」这样的想法一直持续到我工作两年后，事实是，不管是此前火热的房地产企业，教育培训机构，还是如今被互联网深度渗透的各类O2O公司，可以说我们的世界正是由销售所驱动的。&lt;/p&gt;

&lt;p&gt;前段时间看到知乎上有人提问在 Github 上维护一个 1000 star 以上的大型开源项目是一种什么样的体验，大多数的答题人分享了他们的项目经历，其中不容忽视的就是前期的推广与宣传。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;当时也算是抱着『搞个大新闻』的念想小小策划了一下，同时在 HackerNews、Reddit、EchoJS 等地方发了帖子，还给 DailyJS、JavaScript Weekly 等媒体发了自荐。发布后幸运地在 HN 首页呆了一段时间，第一周后拿到了 615 个 star。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;上面这段话是前端领域有名的开源项目 Vue.js 的作者所分享，我相信有很多做技术的同学觉得自己的项目技术含金量相当高，甚至连说明文档也不愿意多写，「你如果感兴趣，自己看源码呗。」大多数项目被埋没在作者技术精英式的思维之下。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最好的产品未必会常常获胜。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;结语&#34;&gt;结语&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;一个人的价值不在于他成就了什么，而在于他想成就什么。&lt;/strong&gt;虽然从0到1在我看来更像是一种期望，是一种理想，但是人终归是要有理想的，只是每个人对于实现理想的途径的理解会有所不同。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-07-10-from-zero-to-one-just-a-dream-book-pic.png&#34; alt=&#34;book-pic&#34; /&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>InfluxDB 与 OpenTSDB 对比测试</title>
          <link>http://blog.fatedier.com/2016/07/06/test-influxdb-and-opentsdb/</link>
          <pubDate>Wed, 06 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/06/test-influxdb-and-opentsdb/</guid>
          <description>&lt;p&gt;通过调研，在时间序列数据库的选择上，从社区活跃度，易用程度，综合性能上来看比较合适的就是 OpenTSDB 和 InfluxDB，所以对这两个数据库进行了一个简单测试。&lt;/p&gt;

&lt;h3 id=&#34;时间序列数据库热度排名&#34;&gt;时间序列数据库热度排名&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-07-06-test-influxdb-and-opentsdb-db-rank.png&#34; alt=&#34;db-rank&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;测试环境&#34;&gt;测试环境&lt;/h3&gt;

&lt;p&gt;青云 centos7&lt;/p&gt;

&lt;p&gt;4 cpu，8GB RAM&lt;/p&gt;

&lt;h3 id=&#34;测试样本&#34;&gt;测试样本&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;metric&lt;/strong&gt; 从 cpu_load1 - cpu_load10 共10个。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tags&lt;/strong&gt; 只有一个，host_id 为 1-100。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;time&lt;/strong&gt; 为 1467000000 - 1467010000，各维度每秒生成1条数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;value&lt;/strong&gt; 取值为 0.1-0.9。&lt;/p&gt;

&lt;p&gt;合计数据量为 10 * 100 * 10000 = 1000w。&lt;/p&gt;

&lt;h3 id=&#34;查询测试用例&#34;&gt;查询测试用例&lt;/h3&gt;

&lt;h4 id=&#34;查询1-单条查询&#34;&gt;查询1：单条查询&lt;/h4&gt;

&lt;p&gt;指定 metricName 以及 host_id，对 time 在 1467000000 和 1467005000 内的数据按照每3分钟的粒度进行聚合计算平均值。&lt;/p&gt;

&lt;p&gt;例如 InfluxDB 中的查询语句&lt;/p&gt;

&lt;p&gt;&lt;code&gt;select mean(value) from cpu_load1 where host_id = &#39;1&#39; and time &amp;gt; 1467000000000000000 and time &amp;lt; 1467005000000000000 group by time(3m)&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查询2-批量10条不同-metricname-查询&#34;&gt;查询2：批量10条不同 metricName 查询&lt;/h4&gt;

&lt;p&gt;单条查询的基础上修改成不同的 metricName&lt;/p&gt;

&lt;h3 id=&#34;influxdb&#34;&gt;InfluxDB&lt;/h3&gt;

&lt;p&gt;并发数 50 通过 http 写入，每次 100 条数据&lt;/p&gt;

&lt;h4 id=&#34;资源占用&#34;&gt;资源占用&lt;/h4&gt;

&lt;p&gt;cpu 使用率维持在 100% 左右，耗时 1m58s，约 84746/s&lt;/p&gt;

&lt;p&gt;磁盘占用 70MB&lt;/p&gt;

&lt;h4 id=&#34;查询1&#34;&gt;查询1&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num1: 0.010s&lt;/li&gt;
&lt;li&gt;Num2: 0.010s&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;查询2&#34;&gt;查询2&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num 1: 0.029s&lt;/li&gt;
&lt;li&gt;Num 2: 0.021s&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;opentsdb&#34;&gt;OpenTSDB&lt;/h3&gt;

&lt;p&gt;并发数 50 通过http写入，每次 100 条数据&lt;/p&gt;

&lt;h4 id=&#34;资源占用-1&#34;&gt;资源占用&lt;/h4&gt;

&lt;p&gt;cpu 开始时跑满，之后在250%左右 耗时 2m16s，约 73529/s&lt;/p&gt;

&lt;p&gt;磁盘占用 1.6GB，由于是简单部署，这里 HBase 没有启用 lzo 压缩，据说压缩之后只需要占用原来 &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; 的空间，也就是 320MB。&lt;/p&gt;

&lt;h4 id=&#34;查询1-1&#34;&gt;查询1&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num 1: 0.285s&lt;/li&gt;
&lt;li&gt;Num 2: 0.039s&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;查询2-1&#34;&gt;查询2&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num 1: 0.111s&lt;/li&gt;
&lt;li&gt;Num 2: 0.040s&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;一开始是准备在本地的一个2核2GB的虚拟机里进行测试，InfluxDB 虽然比较慢，但是测试完成，而 OpenTSDB 测试过程中，要么 zookeeper 出现故障，要么 Hbase 异常退出，要么无法正常写入数据，始终无法完成测试。更换成配置更高的青云服务器后，两者都能正常完成测试。&lt;/p&gt;

&lt;p&gt;在单机部署上，InfluxDB 非常简单，一两分钟就可以成功运行，而 OpenTSDB 需要搭建 Hbase，创建 TSD 用到的数据表，配置 JAVA 环境等，相对来说更加复杂。&lt;/p&gt;

&lt;p&gt;资源占用方面，InfluxDB 都要占据优势，cpu 消耗更小，磁盘占用更是小的惊人。&lt;/p&gt;

&lt;p&gt;查询速度，由于测试样本数据量还不够大，速度都非常快，可以看到 InfluxDB 的查询在 10ms 这个数量级，而 OpenTSDB 则慢了接近 10 倍，第二次查询时，由于缓存的原因，OpenTSDB 的查询速度也相当快。&lt;/p&gt;

&lt;p&gt;集群方面，目前 InfluxDB 还没有比较好的解决方案，而 OpenTSDB 基于 HBase，这一套集群方案已经被很多大公司采用，稳定运行。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>时间序列数据库调研之InfluxDB</title>
          <link>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb/</link>
          <pubDate>Tue, 05 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb/</guid>
          <description>&lt;p&gt;基于 Go 语言开发，社区非常活跃，项目更新速度很快，日新月异，关注度高。&lt;/p&gt;

&lt;h3 id=&#34;测试版本&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;1.0.0_beta2-1&lt;/p&gt;

&lt;h3 id=&#34;安装部署&#34;&gt;安装部署&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo yum localinstall influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;配置文件路径为 &lt;code&gt;/etc/influxdb/influxdb.conf&lt;/code&gt;，修改后启动服务&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo service influxdb start&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;特点&#34;&gt;特点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可以设置metric的保存时间。&lt;/li&gt;
&lt;li&gt;支持通过条件过滤以及正则表达式删除数据。&lt;/li&gt;
&lt;li&gt;支持类似 sql 的语法。&lt;/li&gt;
&lt;li&gt;可以设置数据在集群中的副本数。&lt;/li&gt;
&lt;li&gt;支持定期采样数据，写入另外的measurement，方便分粒度存储数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式-line-protocol&#34;&gt;数据格式 Line Protocol&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;measurement[,tag_key1=tag_value1...] field_key=field_value[,field_key2=field_value2] [timestamp]

cpu_load,host_id=1 value=0.1 1434055562000000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比于 JSON 格式，无需序列化，更加高效。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;measurement: metric name，例如 cpu_load。&lt;/li&gt;
&lt;li&gt;field-key, field-value: 通常用来存储数据，类似 opentsdb 中的 value=0.6，但是支持各种类型，数据存储时不会进行索引，每条数据必须拥有一个 field-key，如果使用 field-key 进行过滤，需要遍历一遍所有数据。&lt;/li&gt;
&lt;li&gt;tags-key, tags-value: 和 field-key 类似，但是会进行索引，方便查询时用于过滤条件。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;series&#34;&gt;Series&lt;/h4&gt;

&lt;p&gt;measurement, tag set, retention policy 相同的数据集合算做一个 series。&lt;/p&gt;

&lt;p&gt;假设 cpu_load 有两个 tags，host_id 和 name，host_id 的数量为 100，name 的数量为 200，则 series 基数为 100 * 200 = 20000。&lt;/p&gt;

&lt;h4 id=&#34;数据存储&#34;&gt;数据存储&lt;/h4&gt;

&lt;p&gt;measurements, tag keys, field keys，tag values 全局存一份。&lt;/p&gt;

&lt;p&gt;field values 和 timestamps 每条数据存一份。&lt;/p&gt;

&lt;h4 id=&#34;retention-policy&#34;&gt;Retention Policy&lt;/h4&gt;

&lt;p&gt;保留策略包括设置数据保存的时间以及在集群中的副本个数。&lt;/p&gt;

&lt;p&gt;默认的 RP 为 &lt;strong&gt;default&lt;/strong&gt;，保存时间不限制，副本个数为 1，默认 RP 是可以修改的，并且我们可以创建新的 RP。&lt;/p&gt;

&lt;h4 id=&#34;continuous-query&#34;&gt;Continuous Query&lt;/h4&gt;

&lt;p&gt;CQ 是预先配置好的一些查询命令，&lt;strong&gt;SELECT&lt;/strong&gt; 语句必须包含 &lt;strong&gt;GROUP BY time()&lt;/strong&gt;，influxdb 会定期自动执行这些命令并将查询结果写入指定的另外的 measurement 中。&lt;/p&gt;

&lt;p&gt;利用这个特性并结合 RP 我们可以方便地保存不同粒度的数据，根据数据粒度的不同设置不同的保存时间，这样不仅节约了存储空间，而且加速了时间间隔较长的数据查询效率，避免查询时再进行聚合计算。&lt;/p&gt;

&lt;h4 id=&#34;shard&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;Shard 这个概念并不对普通用户开放，实际上是 InfluxDB 将连续一段时间内的数据作为一个 shard 存储，根据数据保存策略来决定，通常是保存1天或者7天的数据。例如如果保存策略 RP 是无限制的话，shard 将会保存7天的数据。这样方便之后的删除操作，直接关闭下层对应的一个数据库即可。&lt;/p&gt;

&lt;h3 id=&#34;存储引擎&#34;&gt;存储引擎&lt;/h3&gt;

&lt;p&gt;从 LevelDB（LSM Tree），到 BoltDB（mmap B+树），现在是自己实现的 TSM Tree 的算法，类似 LSM Tree，针对 InfluxDB 的使用做了特殊优化。&lt;/p&gt;

&lt;h4 id=&#34;leveldb&#34;&gt;LevelDB&lt;/h4&gt;

&lt;p&gt;LevelDB 底层使用了 LSM Tree 作为数据结构，用于存储大量的 key 值有序的 K-V 数据，鉴于时序数据的特点，只要将时间戳放入 key 中，就可以非常快速的遍历指定时间范围内的数据。LSM Tree 将大量随机写变成顺序写，所以拥有很高的写吞吐量，并且 LevelDB 内置了压缩功能。&lt;/p&gt;

&lt;p&gt;数据操作被先顺序写入 WAL 日志中，成功之后写入内存中的 MemTable，当 MemTable 中的数据量达到一定阀值后，会转换为 Immutable MemTable，只读，之后写入 SSTable。SSTable 是磁盘上只读的用于存储有序键值对的文件，并且会持续进行合并，生成新的 SSTable。在 LevelDB 中是分了不同层级的 SSTable 用于存储数据。&lt;/p&gt;

&lt;p&gt;LevelDB 不支持热备份，它的变种 RocksDB 和 HyperLevelDB 实现了这个功能。&lt;/p&gt;

&lt;p&gt;最严重的问题是由于 InfluxDB 通过 shard 来组织数据，每一个 shard 对应的就是一个 LevelDB 数据库，而由于 LevelDB 的底层存储是大量 SSTable 文件，所以当用户需要存储长时间的数据，例如几个月或者一年的时候，会产生大量的 shard，从而消耗大量文件描述符，将系统资源耗尽。&lt;/p&gt;

&lt;h4 id=&#34;boltdb&#34;&gt;BoltDB&lt;/h4&gt;

&lt;p&gt;之后 InfluxDB 采用了 BoltDB 作为数据存储引擎。BoltDB 是基于 LMDB 使用 Go 语言开发的数据库。同 LevelDB 类似的是，都可以用于存储 key 有序的 K-V 数据。&lt;/p&gt;

&lt;p&gt;虽然采用 BoltDB 的写效率有所下降，但是考虑到用于生产环境需要更高的稳定性，BoltDB 是一个合适的选择，而且 BoltDB 使用纯 Go 编写，更易于跨平台编译部署。&lt;/p&gt;

&lt;p&gt;最重要的是 BoltDB 的一个数据库存储只使用一个单独的文件。Bolt 还解决了热备的问题，很容易将一个 shard 从一台机器转移到另外一台。&lt;/p&gt;

&lt;p&gt;但是当数据库容量达到数GB级别时，同时往大量 series 中写入数据，相当于是大量随机写，会造成 IOPS 上升。&lt;/p&gt;

&lt;h4 id=&#34;tsm-tree&#34;&gt;TSM Tree&lt;/h4&gt;

&lt;p&gt;TSM Tree 是 InfluxDB 根据实际需求在 LSM Tree 的基础上稍作修改优化而来。&lt;/p&gt;

&lt;h5 id=&#34;wal&#34;&gt;WAL&lt;/h5&gt;

&lt;p&gt;每一个 shard 对应底层的一个数据库。每一个数据库有自己的 WAL 文件，压缩后的元数据文件，索引文件。&lt;/p&gt;

&lt;p&gt;WAL 文件名类似 &lt;code&gt;_000001.wal&lt;/code&gt;，数字递增，每达到 2MB 时，会关闭此文件并创建新的文件，有一个写锁用于处理多协程并发写入的问题。&lt;/p&gt;

&lt;p&gt;可以指定将 WAL 从内存刷新到磁盘上的时间，例如30s，这样会提高写入性能，同时有可能会丢失这30s内的数据。&lt;/p&gt;

&lt;p&gt;每一个 WAL 中的条目遵循 TLV 的格式，1字节用于表示类型（points，new fields，new series，delete），4字节表示 block 的长度，后面则是具体压缩后的 block 内容。WAL 文件中得内容在内存中会进行缓存，并且不会压缩，每一个 point 的 key 为 measurement, tagset 以及 unique field，每一个 field 按照自己的时间顺序排列。&lt;/p&gt;

&lt;p&gt;查询操作将会去 WAL 以及索引中查询，WAL 在内存中缓存有一个读写锁进行控制。删除操作会将缓存中的key删除，同时在 WAL 文件中进行记录并且在内存的索引中进行删除标记。&lt;/p&gt;

&lt;h5 id=&#34;data-files-sstables&#34;&gt;Data Files(SSTables)&lt;/h5&gt;

&lt;p&gt;这部分 InfluxDB 自己定义了特定的数据结构，将时间戳编码到了 DataFiles 中，进行了相对于时间序列数据的优化。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;通过 HTTP 访问 influxdb。&lt;/p&gt;

&lt;p&gt;语法上是一种类似于 SQL 的命令，官方称为 InfluxQL。&lt;/p&gt;

&lt;h4 id=&#34;创建数据库&#34;&gt;创建数据库&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -POST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;cpu_load_short 是 measurement，host 和 region 是 tags-key，value 是 field-key。&lt;/p&gt;

&lt;p&gt;多条数据时，用换行区分每条数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server02 value=0.67
cpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257
cpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;读取数据&#34;&gt;读取数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -GET &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时查询多条数据时，以分号分隔&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -G &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;;SELECT count(value) FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 &lt;code&gt;--data-urlencode &amp;quot;epoch=s&amp;quot;&lt;/code&gt; 会使返回的时间戳为 unix 时间戳格式。&lt;/p&gt;

&lt;h4 id=&#34;创建-rp&#34;&gt;创建 RP&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE RETENTION POLICY two_hours ON food_data DURATION 2h REPLICATION 1 DEFAULT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里将 &lt;strong&gt;two_hours&lt;/strong&gt; 设置成了默认保存策略，存入 food_data 中的数据如果没有明确指定 RP 将会默认采用此策略，数据保存时间为 2 小时，副本数为 1。&lt;/p&gt;

&lt;h4 id=&#34;创建-cq&#34;&gt;创建 CQ&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE CONTINUOUS QUERY cq_5m ON food_data BEGIN SELECT mean(website) AS mean_website,mean(phone) AS mean_phone INTO food_data.&amp;quot;default&amp;quot;.downsampled_orders FROM orders GROUP BY time(5m) END
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里创建了一个 CQ，每个5分钟将 two_hours.orders 中的数据计算5分钟的平均值后存入 default.downsampled_orders 中，default 这个 RP 中的数据是永久保存的。&lt;/p&gt;

&lt;h4 id=&#34;where&#34;&gt;WHERE&lt;/h4&gt;

&lt;p&gt;查询时指定查询的限制条件，例如查询最近1小时内 host_id=1 的机器的 cpu 数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT value FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;group-by&#34;&gt;GROUP BY&lt;/h4&gt;

&lt;p&gt;类似于 SQL 中的语法，可以对细粒度数据进行聚合计算，例如查询最近1小时内 host_id=1 的机器的 cpu 的数据，并且采样为每5分钟的平均值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT mean(value) FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1 GROUP BY time(5m)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;官方推荐硬件配置&#34;&gt;官方推荐硬件配置&lt;/h3&gt;

&lt;h4 id=&#34;单节点&#34;&gt;单节点&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Load&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Writes per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Queries per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Unique series&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Low&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Moderate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;High&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Probably infeasible&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 500 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 10 million&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;Low: CPU 2-4, RAM 2-4GB, IOPS 500&lt;/li&gt;
&lt;li&gt;Moderate: CPU 4-6, RAM 8-32GB, IOPS 500-1000&lt;/li&gt;
&lt;li&gt;High: CPU CPU 8+, RAM 32GB+, IOPS 1000+&lt;/li&gt;
&lt;li&gt;Probably infeasible: 可能单机无法支持，需要集群环境&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;集群&#34;&gt;集群&lt;/h4&gt;

&lt;p&gt;InfluxDB 从 0.12 版本开始将不再开源其 cluster 源码，而是被用做提供商业服务。&lt;/p&gt;

&lt;p&gt;如果考虑到以后的扩展，需要自己在前端做代理分片或者类似的开发工作。&lt;/p&gt;

&lt;p&gt;已知七牛是采用了 InfluxDB 作为时间序列数据的存储，自研了调度器以及高可用模块，具有横向扩展的能力。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;目前最火热的时间序列数据库项目，社区开发活跃，迭代更新较快，存储引擎经常变化，网上的一些资料都比较过时，例如最新的 TSM 存储引擎只能看到官方的文档简介，还没有详细的原理说明的文章。&lt;/p&gt;

&lt;p&gt;就单机来说，在磁盘占用、cpu使用率、读写速度方面都让人眼前一亮。如果数据量级不是非常大的情况下，单节点的 InfluxDB 就可以承载数十万每秒的写入，是一个比较合适的选择。&lt;/p&gt;

&lt;p&gt;另一方面，从 0.12 版本开始不再开源其集群代码（虽然之前的集群部分就比较烂），如果考虑到之后进行扩展的话，需要进行二次开发。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>时间序列数据库调研之OpenTSDB</title>
          <link>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb/</link>
          <pubDate>Mon, 04 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb/</guid>
          <description>&lt;p&gt;Java 项目，基于 HBase（2.3版本貌似开始支持 Google BigTable 和 Cassandra） 的一个时间序列数据库，被广泛应用于监控系统中。很多大公司都在使用，社区较为活跃。&lt;/p&gt;

&lt;h3 id=&#34;测试版本&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;hbase-1.1.5&lt;/p&gt;

&lt;p&gt;opentsdb-2.2.0&lt;/p&gt;

&lt;h3 id=&#34;单机部署&#34;&gt;单机部署&lt;/h3&gt;

&lt;p&gt;单机部署可以参考我之前的一篇文章，集群部署比较复杂，这里仅使用单机进行测试。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/&#34;&gt;OpenTSDB部署与使用&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式&#34;&gt;数据格式&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;metric: 一个可测量的单位的标称。&lt;/li&gt;
&lt;li&gt;tags: 对 metric 的具体描述。&lt;/li&gt;
&lt;li&gt;timestamp: 时间戳。&lt;/li&gt;
&lt;li&gt;value: metric 的实际测量值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;uid&#34;&gt;UID&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，每一个 metric、tagk 或者 tagv 在创建的时候被分配一个唯一标识叫做 UID。在后续的实际存储中，实际上存储的是 UID，而不是它们原本的字符串，UID 占 3个字节（也可以修改源码改为4字节），这样可以节省存储空间。&lt;/p&gt;

&lt;h4 id=&#34;tsuid&#34;&gt;TSUID&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;metric_UID&amp;gt;&amp;lt;timestamp&amp;gt;&amp;lt;tagk1_UID&amp;gt;&amp;lt;tagv1_UID&amp;gt;[...&amp;lt;tagkN_UID&amp;gt;&amp;lt;tagvN_UID&amp;gt;]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;写入 HBase 时的 row key 格式，其中的 metric、tagk 和 tagv 都被转换成了 UID。&lt;/p&gt;

&lt;h4 id=&#34;data-table-schema&#34;&gt;Data Table Schema&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-data-table-schema.png&#34; alt=&#34;data-table-schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RowKey&lt;/strong&gt; 就是上述的 TSUID，除了时间戳占 4 byte，其余 UID 占 3 byte。&lt;/p&gt;

&lt;p&gt;时间戳的部分只保留到了小时粒度，具体相对于小时的偏移量被存储在了 &lt;strong&gt;列族 t&lt;/strong&gt; 中。这样就减小了 HBase 中的存储行数。也就是说对于同一个小时的 metric + tags 相同的数据都会存放在一个 row 下面，这样的设计提高了 row 的检索速度。&lt;/p&gt;

&lt;p&gt;这样的 RowKey 设计使得 metric + tags 相同的数据都会连续存放，且 metric 相同的数据也会连续存放，底层 HBase 中会放在同一 Region 中，在做 Scan 的时候可以快速读取到大片数据，加速查询的过程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;value&lt;/strong&gt; 使用 8 bytes 存储，既可以存储 long,也可以存储 double。&lt;/p&gt;

&lt;h4 id=&#34;compaction&#34;&gt;Compaction&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，会将多列合并到一列之中以减少磁盘占用空间，这个过程会在 TSD 写数据或者查询过程中不定期的发生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-compaction.png&#34; alt=&#34;compaction&#34; /&gt;&lt;/p&gt;

&lt;p&gt;例如图中，将列 1890 和 列 1892 合并到了一起。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;OpenTSDB 同样提供了一套基于 HTTP 的 API 接口。&lt;/p&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/put&#34;&gt;http://localhost:4242/api/put&lt;/a&gt;, POST&lt;/p&gt;

&lt;p&gt;内容为 JSON 格式，支持同时插入多条数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 18,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web01&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 9,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web02&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查询数据&#34;&gt;查询数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/query&#34;&gt;http://localhost:4242/api/query&lt;/a&gt;, POST&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1463452826,
    &amp;quot;end&amp;quot;: 1463453026,
    &amp;quot;globalAnnotations&amp;quot;: true,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;avg&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.disk.usage&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.load&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;start&lt;/strong&gt; 和 &lt;strong&gt;end&lt;/strong&gt; 指定了查询的时间范围。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tags&lt;/strong&gt; 指定了过滤条件，2.2 版本中将不被推荐，取而代之的是 filters 参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;downsample&lt;/strong&gt; 聚合计算，例如上面是对每隔60s的数据计算一次平均值。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;OpenTSDB 在存储时间序列数据这一领域拥有很大的优势，被大多数公司所采用，网上的相关文档也比较全面。&lt;/p&gt;

&lt;p&gt;底层存储依托于 HBase，采用特殊设计过的数据存储格式，提供了非常快的查询速度，在此基础之上也更容易横向扩展。&lt;/p&gt;

&lt;p&gt;但是，相对于 InfluxDB 这种即使是新手也可以在两分钟内部署运行完成，OpenTSDB 的部署和运维显然要麻烦很多，由于底层依赖于 HBase，想要大规模运行起来，需要相当专业、细心的运维工作。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>kubernetes 初探及部署实践</title>
          <link>http://blog.fatedier.com/2016/06/24/demystifying-kubernetes-and-deployment/</link>
          <pubDate>Fri, 24 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/06/24/demystifying-kubernetes-and-deployment/</guid>
          <description>&lt;p&gt;Kubernetes 是 Google 开源的容器集群管理系统，作为 Go 语言开发的热门项目之一，它提供了应用部署、维护、 扩展机制等功能，利用 Kubernetes 能够方便地管理跨机器运行的容器化应用，目前主要是针对 Docker 的管理。&lt;/p&gt;

&lt;h3 id=&#34;主要概念&#34;&gt;主要概念&lt;/h3&gt;

&lt;h4 id=&#34;pod&#34;&gt;Pod&lt;/h4&gt;

&lt;p&gt;在 Kubernetes 中是最基本的调度单元，可以包含多个相关的容器，属于同一个 pod 的容器会被运行在同一个机器上，看作一个统一的管理单元。例如我们的一个应用由 nginx、web网站、数据库三部分组成，每一部分都运行在一个单独的容器中，那么我们可以将这三个容器创建成一个 pod。&lt;/p&gt;

&lt;h4 id=&#34;service&#34;&gt;Service&lt;/h4&gt;

&lt;p&gt;Service 是 pod 的路由代理抽象，主要是为了解决 pod 的服务发现问题。因为当有机器出现故障导致容器异常退出时，这个 pod 可能就会被 kubernetes 分配到另外一个正常且资源足够的机器上，此时 IP 地址以及端口都有可能发生变化，所以我们并不能通过 host 的真实 IP 地址和端口来访问。Service 的引入正是为了解决这样的问题，通过 service 这层代理我们就可以访问到 pod 中的容器，目前的版本是通过 iptables 来实现的。&lt;/p&gt;

&lt;h4 id=&#34;replicationcontroller&#34;&gt;ReplicationController&lt;/h4&gt;

&lt;p&gt;ReplicationController 的概念比较简单，从名字就可以看出是用于管理 pod 的多副本运行的。它用于确保 kubernetes 集群中指定的 pod 始终会有指定数量的副本在运行。如果检测到有容器异常退出，replicationController 会立即重新启动新的容器，并且通过 replicationController 我们还可以动态地调整 pod 的副本数量。&lt;/p&gt;

&lt;h4 id=&#34;label&#34;&gt;Label&lt;/h4&gt;

&lt;p&gt;Label 是用于将上述几个概念关联起来的一些 k-v 值。例如我们创建了一个 pod 并且设置了 label 为 &lt;code&gt;app=nginx&lt;/code&gt;，同样在创建 service 和 replicationController 时也设置相同的 label，这样通过 label 的 selector 机制就可以将创建好的 service 和 replicationController 作用在之前创建的 pod 上。&lt;/p&gt;

&lt;h3 id=&#34;主要组件&#34;&gt;主要组件&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-06-24-demystifying-kubernetes-and-deployment-k8s-overview.png&#34; alt=&#34;k8s-overview&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes 集群中主要存在两种类型的节点，分别是 master 节点，以及 minion 节点。&lt;/p&gt;

&lt;p&gt;Minion 节点是实际运行 Docker 容器的节点，负责和节点上运行的 Docker 进行交互，并且提供了代理功能。&lt;/p&gt;

&lt;p&gt;Master 节点负责对外提供一系列管理集群的 API 接口，并且通过和 Minion 节点交互来实现对集群的操作管理。&lt;/p&gt;

&lt;h4 id=&#34;apiserver&#34;&gt;apiserver&lt;/h4&gt;

&lt;p&gt;用户和 kubernetes 集群交互的入口，封装了核心对象的增删改查操作，提供了 RESTFul 风格的 API 接口，通过 etcd 来实现持久化并维护对象的一致性。&lt;/p&gt;

&lt;h4 id=&#34;scheduler&#34;&gt;scheduler&lt;/h4&gt;

&lt;p&gt;负责集群资源的调度和管理，例如当有 pod 异常退出需要重新分配机器时，scheduler 通过一定的调度算法从而找到最合适的节点。&lt;/p&gt;

&lt;h4 id=&#34;controller-manager&#34;&gt;controller-manager&lt;/h4&gt;

&lt;p&gt;主要是用于保证 replicationController 定义的复制数量和实际运行的 pod 数量一致，另外还保证了从 service 到 pod 的映射关系总是最新的。&lt;/p&gt;

&lt;h4 id=&#34;kubelet&#34;&gt;kubelet&lt;/h4&gt;

&lt;p&gt;运行在 minion 节点，负责和节点上的 Docker 交互，例如启停容器，监控运行状态等。&lt;/p&gt;

&lt;h4 id=&#34;proxy&#34;&gt;proxy&lt;/h4&gt;

&lt;p&gt;运行在 minion 节点，负责为 pod 提供代理功能，会定期从 etcd 获取 service 信息，并根据 service 信息通过修改 iptables 来实现流量转发（最初的版本是直接通过程序提供转发功能，效率较低。），将流量转发到要访问的 pod 所在的节点上去。&lt;/p&gt;

&lt;h3 id=&#34;部署实践&#34;&gt;部署实践&lt;/h3&gt;

&lt;p&gt;Kubernetes 的部署十分简单，先从 Github 上下载编译好的二进制文件（我自己尝试编译耗时太久，遂作罢），这里强调简单的原因是因为每个组件并不需要配置文件，而是直接通过启动参数来设置。相比于很多 Java 项目一系列的环境设置，组件搭建，k8s 还是比较友好的。下面主要说一下各个组件常用的启动参数的设置。&lt;/p&gt;

&lt;h4 id=&#34;etcd&#34;&gt;etcd&lt;/h4&gt;

&lt;p&gt;安装并启动 etcd 集群，这里以一台作为示例，比较简单，不具体说明，假设访问地址为 &lt;code&gt;192.168.2.129:2379&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;flannel&#34;&gt;flannel&lt;/h4&gt;

&lt;p&gt;Flannel 是 CoreOS 团队针对 Kubernetes 设计的一个覆盖网络（Overlay Network）工具，需要另外下载部署。我们知道当我们启动 Docker 后会有一个用于和容器进行交互的 IP 地址，如果不去管理的话可能这个 IP 地址在各个机器上是一样的，并且仅限于在本机上进行通信，无法访问到其他机器上的 Docker 容器。&lt;/p&gt;

&lt;p&gt;Flannel 的目的就是为集群中的所有节点重新规划 IP 地址的使用规则，从而使得不同节点上的容器能够获得同属一个内网且不重复的 IP 地址，并让属于不同节点上的容器能够直接通过内网 IP 通信。&lt;/p&gt;

&lt;p&gt;具体实现原理可以参考： &lt;a href=&#34;http://www.open-open.com/news/view/1aa473a&#34;&gt;http://www.open-open.com/news/view/1aa473a&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&#34;安装-flannel&#34;&gt;安装 flannel&lt;/h5&gt;

&lt;p&gt;在 etcd 中创建 flannel 需要用到的键，假设我们 Minion 中 flannel 所使用的子网范围为&lt;code&gt;172.17.1.0~172.17.254.0&lt;/code&gt;（每一个Minion节点都有一个独立的flannel子网）。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;etcdctl mk /coreos.com/network/config &#39;{&amp;quot;Network&amp;quot;:&amp;quot;172.17.0.0/16&amp;quot;, &amp;quot;SubnetMin&amp;quot;: &amp;quot;172.17.1.0&amp;quot;, &amp;quot;SubnetMax&amp;quot;: &amp;quot;172.17.254.0&amp;quot;}&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;启动参数&#34;&gt;启动参数&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;flanneld -etcd-endpoints=http://192.168.2.129:2379 -etcd-prefix=/coreos.com/network --log_dir=./ --logtostderr=false&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-etcd-endpoints: etcd 集群的地址
-etcd-prefix: etcd 中存储 flannel 信息的前缀
--log_dir: 设置日志文件存储目录
--logtostderr: 设置错误信息是否存储到标准输出中
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;修改-docker0-网卡的-ip-地址&#34;&gt;修改 docker0 网卡的 IP 地址&lt;/h5&gt;

&lt;p&gt;默认情况下启动 docker 后会有一个 docker0 的虚拟网卡，每一台机器的 docker0 网卡对应的 ip 地址都是相同的。&lt;/p&gt;

&lt;p&gt;修改启动 docker 的参数，centos7 下可以修改 &lt;code&gt;/usr/lib/systemd/system/docker.service&lt;/code&gt; 文件。&lt;/p&gt;

&lt;p&gt;增加 &lt;code&gt;EnvironmentFile=-/run/flannel/subnet.env&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ExecStart&lt;/code&gt; 增加两个参数 &lt;code&gt;--bip=${FLANNEL_SUBNET}  --mtu=${FLANNEL_MTU}&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;FLANNEL_SUBNET&lt;/code&gt; 和 &lt;code&gt;FLANNEL_MTU&lt;/code&gt; 这两个变量就是从 &lt;code&gt;/run/flannel/subnet.env&lt;/code&gt; 文件中读取，记录了 flannel 在这台机器上被分配到的一个网段。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;systemctl daemon-reload&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;systemctl start docker.service&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后通过 &lt;code&gt;ifconfig&lt;/code&gt; 可以看到 docker0 的网卡 ip 已经变成了 flannel 的网段。&lt;/p&gt;

&lt;h4 id=&#34;kube-apiserver&#34;&gt;kube-apiserver&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-apiserver --logtostderr=false --log-dir=./ --v=0 --etcd-servers=http://192.168.2.129:2379 --address=0.0.0.0 --port=8080 --kubelet-port=10250 --allow-privileged=true --service-cluster-ip-range=10.254.0.0/16&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-scheduler&#34;&gt;kube-scheduler&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-scheduler --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-controller-manager&#34;&gt;kube-controller-manager&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-controller-manager --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kubelet-1&#34;&gt;kubelet &lt;/h4&gt;

&lt;p&gt;部署在 Minion 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubelet --logtostderr=false --log-dir=./ --v=0 --api-servers=http://192.168.2.129:8080 --address=0.0.0.0 --port=10250 --allow-privileged=true&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-proxy&#34;&gt;kube-proxy&lt;/h4&gt;

&lt;p&gt;部署在 Minion 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-proxy --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;遇到的问题&#34;&gt;遇到的问题&lt;/h3&gt;

&lt;p&gt;通过上面的步骤，k8s 集群就差不多搭建成功了，但是仍然遇到了一些问题，有的甚至目前还没有找到解决方案，直接导致了我丧失了将 k8s 用于实际开发环境的动力。&lt;/p&gt;

&lt;h4 id=&#34;pause-镜像&#34;&gt;pause 镜像&lt;/h4&gt;

&lt;p&gt;在每个 Minion 节点上的 Docker 需要安装  gcr.io/google_containers/pause 镜像，这个镜像是在 kubernetes 集群启动用户配置的容器时需要用到。&lt;/p&gt;

&lt;p&gt;本来启动容器后会直接从 google 官方源下载，因为墙的原因，在国内无法下载成功，这里可以先从 dockerhub 上下载，&lt;code&gt;sudo docker pull kubernetes/pause&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;之后再打上 tag，&lt;code&gt;sudo docker tag kubernetes/pause gcr.io/google_containers/pause:2.0&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;我装的 &lt;code&gt;kubernetes 1.2.3&lt;/code&gt; 版本对应的 tag 是 &lt;code&gt;pause:2.0&lt;/code&gt;，如果不知道版本，可以尝试运行一个 pod ，之后通过查看错误信息得到。&lt;/p&gt;

&lt;p&gt;后来查看文档发现也可以通过在 kubelet 的启动参数中设置这个镜像的地址，不过还没有测试过。&lt;/p&gt;

&lt;h4 id=&#34;搭建私有-docker-镜像仓库&#34;&gt;搭建私有 docker 镜像仓库&lt;/h4&gt;

&lt;p&gt;为了便于使用，最好自己搭建内网环境的私有镜像仓库，因为 k8s 中每一台机器上的 docker 都需要 pull 镜像到本地，如果从外网环境拉镜像的话效率较低，而且以后更新镜像等操作将变的非常不方便。&lt;/p&gt;

&lt;p&gt;具体的步骤可以参考我之前的一篇文章， &lt;a href=&#34;http://blog.fatedier.com/2016/05/16/install-private-docker-registry/&#34;&gt;『搭建私有docker仓库』&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;service-访问问题&#34;&gt;service 访问问题&lt;/h4&gt;

&lt;p&gt;测试时可以在一台机器上的容器内部通过 service 提供的内网 IP 地址访问到运行在另外一台机器上的容器。但是必须是在容器内部才行，如果直接在这个机器上通过 telnet 或者 curl 访问，则无法正确地根据这个内网 IP 转发到对应节点的容器中。&lt;/p&gt;

&lt;p&gt;因为是通过 iptables 来进行转发，我查看了 iptables 的规则，并没有发现问题，后来通过抓包发现这个包的目的 IP 地址被替换成功了，但是源地址并没有被正确替换，导致对方节点无法正确回复。这个问题我还没有发现具体的原因，目前不能在容器外部通过 service 提供的 IP 地址来访问容器，导致很多应用没有了实际部署的意义，后面有时间还是要研究下。&lt;/p&gt;

&lt;h4 id=&#34;文件存储&#34;&gt;文件存储&lt;/h4&gt;

&lt;p&gt;由于 pod 可能会被在任意一台机器上重新启动，所以并不能简单的像运行单机 Docker 那样将容器内部的目录映射到宿主机的指定目录上，否则将会丢失文件。所以通常我们需要使用类似 NFS、ceph、glusterFS 这样的分布式存储系统来为 k8s 集群提供后端的统一存储。这样一来，无疑就增加了部署的难度，比如要搭建一个靠谱的 ceph 集群，无疑是需要有比较靠谱的运维团队的。&lt;/p&gt;

&lt;h3 id=&#34;测试-nginx-容器&#34;&gt;测试 nginx 容器&lt;/h3&gt;

&lt;h4 id=&#34;创建并启动-replicationcontroller&#34;&gt;创建并启动 replicationController&lt;/h4&gt;

&lt;p&gt;创建配置文件 &lt;code&gt;nginx-rc.yaml&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1 
kind: ReplicationController 
metadata: 
  name: nginx-controller 
spec: 
  replicas: 2 
  selector: 
    name: nginx 
  template: 
    metadata: 
      labels: 
        name: nginx 
    spec: 
      containers: 
        - name: nginx
          image: nginx
          ports: 
            - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里定义了一个 nginx pod 的复制器，复制份数为2。&lt;/p&gt;

&lt;p&gt;执行下面的操作创建nginx pod复制器：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 create -f nginx-rc.yaml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看创建 pod 的状态：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 get pods&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;创建并启动-service&#34;&gt;创建并启动 service&lt;/h4&gt;

&lt;p&gt;Service 的 type 有 ClusterIP 和 NodePort 之分，缺省是 ClusterIP，这种类型的 Service 只能在集群内部访问，而 NodePort 可以在集群外部访问，但是它的原理就是在所有节点上都绑定这个端口，之后将所有的流量转发到正确的节点上。&lt;/p&gt;

&lt;p&gt;创建配置文件 &lt;code&gt;nginx-service-clusterip.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1 
kind: Service 
metadata: 
  name: nginx-service-clusterip 
spec: 
  ports: 
    - port: 8001 
      targetPort: 80 
      protocol: TCP 
  selector: 
    name: nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行下面的命令创建 service：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 create -f ./nginx-service-clusterip.yaml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看 service 提供的 IP 地址和端口：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 get service&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后就可以通过 curl 来验证是否能够成功访问到之前部署的 nginx 容器，由于启用了 service，会自动帮我们进行负载均衡，流量会被分发到后端的多个 pod 中。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>LSM Tree 学习笔记</title>
          <link>http://blog.fatedier.com/2016/06/15/learn-lsm-tree/</link>
          <pubDate>Wed, 15 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/06/15/learn-lsm-tree/</guid>
          <description>&lt;p&gt;最近发现很多数据库都使用了 LSM Tree 的存储模型，包括 LevelDB，HBase，Google BigTable，Cassandra，InfluxDB 等。之前还没有留意这么设计的原因，最近调研时间序列数据库的时候才发现这样设计的优势所在，所以重新又复习了一遍 LSM Tree 的原理。&lt;/p&gt;

&lt;h3 id=&#34;特点&#34;&gt;特点&lt;/h3&gt;

&lt;p&gt;总的来说就是通过将大量的随机写转换为顺序写，从而极大地提升了数据写入的性能，虽然与此同时牺牲了部分读的性能。&lt;/p&gt;

&lt;p&gt;只适合存储 key 值有序且写入大于读取的数据，或者读取操作通常是 key 值连续的数据。&lt;/p&gt;

&lt;h3 id=&#34;存储模型&#34;&gt;存储模型&lt;/h3&gt;

&lt;h4 id=&#34;wal&#34;&gt;WAL&lt;/h4&gt;

&lt;p&gt;在设计数据库的时候经常被使用，当插入一条数据时，数据先顺序写入 WAL 文件中，之后插入到内存中的 MemTable 中。这样就保证了数据的持久化，不会丢失数据，并且都是顺序写，速度很快。当程序挂掉重启时，可以从 WAL 文件中重新恢复内存中的 MemTable。&lt;/p&gt;

&lt;h4 id=&#34;memtable&#34;&gt;MemTable&lt;/h4&gt;

&lt;p&gt;MemTable 对应的就是 WAL 文件，是该文件内容在内存中的存储结构，通常用 SkipList 来实现。MemTable 提供了 k-v 数据的写入、删除以及读取的操作接口。其内部将 k-v 对按照 key 值有序存储，这样方便之后快速序列化到 SSTable 文件中，仍然保持数据的有序性。&lt;/p&gt;

&lt;h4 id=&#34;immutable-memtable&#34;&gt;Immutable Memtable&lt;/h4&gt;

&lt;p&gt;顾名思义，Immutable Memtable 就是在内存中只读的 MemTable，由于内存是有限的，通常我们会设置一个阀值，当 MemTable 占用的内存达到阀值后就自动转换为 Immutable Memtable，Immutable Memtable 和 MemTable 的区别就是它是只读的，系统此时会生成新的 MemTable 供写操作继续写入。&lt;/p&gt;

&lt;p&gt;之所以要使用 Immutable Memtable，就是为了避免将 MemTable 中的内容序列化到磁盘中时会阻塞写操作。&lt;/p&gt;

&lt;h4 id=&#34;sstable&#34;&gt;SSTable&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-06-15-learn-lsm-tree-sstable.png&#34; alt=&#34;sstable&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SSTable 就是 MemTable 中的数据在磁盘上的有序存储，其内部数据是根据 key 从小到大排列的。通常为了加快查找的速度，需要在 SSTable 中加入数据索引，可以快读定位到指定的 k-v 数据。&lt;/p&gt;

&lt;p&gt;SSTable 通常采用的分级的结构，例如 LevelDB 中就是如此。MemTable 中的数据达到指定阀值后会在 Level 0 层创建一个新的 SSTable。当某个 Level 下的文件数超过一定值后，就会将这个 Level 下的一个 SSTable 文件和更高一级的 SSTable 文件合并，由于 SSTable 中的 k-v 数据都是有序的，相当于是一个多路归并排序，所以合并操作相当快速，最终生成一个新的 SSTable 文件，将旧的文件删除，这样就完成了一次合并过程。&lt;/p&gt;

&lt;h3 id=&#34;常用操作的实现&#34;&gt;常用操作的实现&lt;/h3&gt;

&lt;h4 id=&#34;写入&#34;&gt;写入&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-06-15-learn-lsm-tree-write.png&#34; alt=&#34;write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在 LSM Tree 中，写入操作是相当快速的，只需要在 WAL 文件中顺序写入当次操作的内容，成功之后将该 k-v 数据写入 MemTable 中即可。尽管做了一次磁盘 IO，但是由于是顺序追加写入操作，效率相对来说很高，并不会导致写入速度的降低。数据写入 MemTable 中其实就是往 SkipList 中插入一条数据，过程也相当简单快速。&lt;/p&gt;

&lt;h4 id=&#34;更新&#34;&gt;更新&lt;/h4&gt;

&lt;p&gt;更新操作其实并不真正存在，和写入一个 k-v 数据没有什么不同，只是在读取的时候，会从 Level0 层的 SSTable 文件开始查找数据，数据在低层的 SSTable 文件中必然比高层的文件中要新，所以总能读取到最新的那条数据。也就是说此时在整个 LSM Tree 中可能会同时存在多个 key 值相同的数据，只有在之后合并 SSTable 文件的时候，才会将旧的值删除。&lt;/p&gt;

&lt;h4 id=&#34;删除&#34;&gt;删除&lt;/h4&gt;

&lt;p&gt;删除一条记录的操作比较特殊，并不立即将数据从文件中删除，而是记录下对这个 key 的删除操作标记，同插入操作相同，插入操作插入的是 k-v 值，而删除操作插入的是 k-del 标记，只有当合并 SSTable 文件时才会真正的删除。&lt;/p&gt;

&lt;h4 id=&#34;compaction&#34;&gt;Compaction&lt;/h4&gt;

&lt;p&gt;当数据不断从  Immutable Memtable 序列化到磁盘上的 SSTable 文件中时，SSTable 文件的数量就不断增加，而且其中可能有很多更新和删除操作并不立即对文件进行操作，而只是存储一个操作记录，这就造成了整个 LSM Tree 中可能有大量相同 key 值的数据，占据了磁盘空间。&lt;/p&gt;

&lt;p&gt;为了节省磁盘空间占用，控制 SSTable 文件数量，需要将多个 SSTable 文件进行合并，生成一个新的 SSTable 文件。比如说有 5 个 10 行的 SSTable 文件要合并成 1 个 50 行的 SSTable 文件，但是其中可能有 key 值重复的数据，我们只需要保留其中最新的一条即可，这个时候新生成的 SSTable 可能只有 40 行记录。&lt;/p&gt;

&lt;p&gt;通常在使用过程中我们采用分级合并的方法，其特点如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每一层都包含大量 SSTable 文件，key 值范围不重复，这样查询操作只需要查询这一层的一个文件即可。(第一层比较特殊，key 值可能落在多个文件中，并不适用于此特性）&lt;/li&gt;
&lt;li&gt;当一层的文件达到指定数量后，其中的一个文件会被合并进入上一层的文件中。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;读取&#34;&gt;读取&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-06-15-learn-lsm-tree-read.png&#34; alt=&#34;read&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LSM Tree 的读取效率并不高，当需要读取指定 key 的数据时，先在内存中的 MemTable 和 Immutable MemTable 中查找，如果没有找到，则继续从 Level 0 层开始，找不到就从更高层的 SSTable 文件中查找，如果查找失败，说明整个 LSM Tree 中都不存在这个 key 的数据。如果中间在任何一个地方找到这个 key 的数据，那么按照这个路径找到的数据都是最新的。&lt;/p&gt;

&lt;p&gt;在每一层的 SSTable 文件的 key 值范围是不重复的，所以只需要查找其中一个 SSTable 文件即可确定指定 key 的数据是否存在于这一层中。Level 0 层比较特殊，因为数据是 Immutable MemTable 直接写入此层的，所以 Level 0 层的 SSTable 文件的 key 值范围可能存在重复，查找数据时有可能需要查找多个文件。&lt;/p&gt;

&lt;h4 id=&#34;优化读取&#34;&gt;优化读取&lt;/h4&gt;

&lt;p&gt;因为这样的读取效率非常差，通常会进行一些优化，例如 LevelDB 中的 Mainfest 文件，这个文件记录了 SSTable 文件的一些关键信息，例如 Level 层数，文件名，最小 key 值，最大 key 值等，这个文件通常不会太大，可以放入内存中，可以帮助快速定位到要查询的 SSTable 文件，避免频繁读取。&lt;/p&gt;

&lt;p&gt;另外一个经常使用的方法是布隆解析器(Bloom filter)，布隆解析器是一个使用内存判断文件是否包含一个关键字的有效方法。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;LSM Tree 的思想非常实用，将随机写转换为顺序写来大幅提高写入操作的性能，但是牺牲了部分读的性能。&lt;/p&gt;

&lt;p&gt;由于时间序列数据库的特性，运用 LSM Tree 的算法非常合适。持续写入数据量大，数据和时间相关，编码到 key 值中很容易使 key 值有序。读取操作相对来说较少，而且通常不是读取单个 key 的值，而是一段时间范围内的数据，这样就把 LSM Tree 读取性能差的劣势缩小了，反而由于数据在 SSTable 中是按照 key 值顺序排列，读取大块连续的数据时效率也很高。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>部署openstack的对象存储服务swift</title>
          <link>http://blog.fatedier.com/2016/05/25/deploy-openstack-swift/</link>
          <pubDate>Wed, 25 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/05/25/deploy-openstack-swift/</guid>
          <description>&lt;p&gt;OpenStack Swift 是一个开源项目，提供了弹性可伸缩、高可用的分布式对象存储服务，适合存储大规模非结构化数据。由于要开发自己的分布式存储应用，需要借鉴 swift 的一些架构，所以在自己的机器上搭建了一个集群环境用于测试。&lt;/p&gt;

&lt;h3 id=&#34;环境&#34;&gt;环境&lt;/h3&gt;

&lt;p&gt;一台物理机上，开了三台虚拟机，操作系统是 Centos7&lt;/p&gt;

&lt;p&gt;ip 为 &lt;strong&gt;192.168.2.129, 192.168.2.130, 192.168.2.131&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之前安装过一次，当时是 2.4.0 版本，目前最新的是 2.7.0 版本，最新的版本由于我的机器上缺少某些动态库，所以还是选择了比较熟悉的 2.4.0 版本，基本上的步骤是一样的。&lt;/p&gt;

&lt;p&gt;后续的安装步骤需要在三台机器上全部执行一遍，下文中的 &lt;code&gt;user:user&lt;/code&gt; 根据需要修改为自己机器上的用户。&lt;/p&gt;

&lt;p&gt;整个步骤参考了官方的文档： &lt;a href=&#34;http://docs.openstack.org/developer/swift/development_saio.html&#34;&gt;http://docs.openstack.org/developer/swift/development_saio.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装各种依赖&#34;&gt;安装各种依赖&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo yum install curl gcc memcached rsync sqlite xfsprogs git-core \
    libffi-devel xinetd liberasurecode-devel \
    python-setuptools \
    python-coverage python-devel python-nose \
    pyxattr python-eventlet \
    python-greenlet python-paste-deploy \
    python-netifaces python-pip python-dns \
    python-mock
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;创建磁盘设备&#34;&gt;创建磁盘设备&lt;/h3&gt;

&lt;p&gt;由于 swift 需要使用 xfs 格式的磁盘，这里我们使用回环设备。&lt;/p&gt;

&lt;h4 id=&#34;创建一个用于回环设备的2gb大小的文件&#34;&gt;创建一个用于回环设备的2GB大小的文件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir /srv
sudo truncate -s 1GB /srv/swift-disk
sudo mkfs.xfs /srv/swift-disk
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;修改-etc-fstab&#34;&gt;修改 /etc/fstab&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/srv/swift-disk /srv/node/sdb1 xfs loop,noatime,nodiratime,nobarrier,logbufs=8 0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建挂载点并进行挂载&#34;&gt;创建挂载点并进行挂载&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /srv/node/sdb1
sudo mount /srv/node/sdb1
sudo chown -R user:user /srv/node
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;下载安装-swift-和-swift-client&#34;&gt;下载安装 swift 和 swift-client&lt;/h4&gt;

&lt;p&gt;从 git 下载这两个项目之后切换到 2.4.0 版本，安装 python 依赖以后使用 &lt;code&gt;python setup.py&lt;/code&gt; 安装。&lt;/p&gt;

&lt;p&gt;直接通过 yum 安装的 pip 可能版本不是最新的，需要升级，使用 &lt;code&gt;pip install --upgrade pip&lt;/code&gt; 升级。&lt;/p&gt;

&lt;h5 id=&#34;swift-client&#34;&gt;swift-client&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/openstack/python-swiftclient.git
git checkout 2.4.0
cd ./python-swiftclient; sudo python setup.py develop; cd -
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;swift&#34;&gt;swift&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/openstack/swift.git
git checkout 2.4.0
cd ./swift; sudo pip install -r requirements.txt; sudo python setup.py develop; cd -
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;配置-etc-rc-local&#34;&gt;配置 /etc/rc.local&lt;/h5&gt;

&lt;p&gt;需要在每次开机时都创建一些需要的目录。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /var/run/swift
sudo chown user:user /var/run/swift
sudo mkdir -p /var/cache/swift
sudo chown user:user /var/cache/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置-rsync&#34;&gt;配置 rsync&lt;/h3&gt;

&lt;h4 id=&#34;修改-etc-rsyncd-conf&#34;&gt;修改 /etc/rsyncd.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# /etc/rsyncd: configuration file for rsync daemon mode
uid = user
gid = user
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
address = 0.0.0.0

[account]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/account.lock

[container]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/container.lock

[object]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/object.lock
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;启动-rsync-并设置开机启动&#34;&gt;启动 rsync 并设置开机启动&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo chkconfig rsyncd on
sudo service rsyncd start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置rsyslog让每个程序输出独立的日志-可选&#34;&gt;配置rsyslog让每个程序输出独立的日志（可选）&lt;/h3&gt;

&lt;p&gt;swift 默认将日志信息输出到文件 /var/log/syslog 中。如果要按照个人需求设置 rsyslog，生成另外单独的 swift日志文件，就需要另外配置。&lt;/p&gt;

&lt;h4 id=&#34;创建日志配置文件-etc-rsyslog-d-10-swift-conf&#34;&gt;创建日志配置文件 /etc/rsyslog.d/10-swift.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Uncomment the following to have a log containing all logs together
#local1,local2,local3,local4,local5.*   /var/log/swift/all.log

# Uncomment the following to have hourly proxy logs for stats processing
$template HourlyProxyLog,&amp;quot;/var/log/swift/hourly/%$YEAR%%$MONTH%%$DAY%%$HOUR%&amp;quot;
#local1.*;local1.!notice ?HourlyProxyLog

local1.*;local1.!notice /var/log/swift/proxy.log
local1.notice           /var/log/swift/ proxy.error
local1.*                ~

local2.*;local2.!notice /var/log/swift/object.log
local2.notice           /var/log/swift/ object.error
local2.*                ~

local3.*;local3.!notice /var/log/swift/container.log
local3.notice           /var/log/swift/ container.error
local3.*                ~

local4.*;local4.!notice /var/log/swift/account.log
local4.notice           /var/log/swift/ account.error
local4.*                ~
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;编辑文件-etc-rsyslog-conf-更改参数-privdroptogroup-为-adm&#34;&gt;编辑文件 /etc/rsyslog.conf，更改参数 $PrivDropToGroup 为 adm&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$PrivDropToGroup adm
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-var-log-swift-目录-用于存放独立日志&#34;&gt;创建 /var/log/swift 目录，用于存放独立日志&lt;/h4&gt;

&lt;p&gt;此外，上面的 &lt;code&gt;10-swift.conf&lt;/code&gt; 文件中设置了输出 Swift Proxy Server 每小时的 stats 日志信息，于是也要创建 &lt;code&gt;/var/log/swift/hourly&lt;/code&gt; 目录。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /var/log/swift/hourly
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;更改-swift-独立日志目录的权限&#34;&gt;更改 swift 独立日志目录的权限&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chown -R root.adm /var/log/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;重启-rsyslog-服务&#34;&gt;重启 rsyslog 服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo service rsyslog restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动-memcached-并设置开机启动&#34;&gt;启动 memcached 并设置开机启动&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo service memcached start
sudo chkconfig memcached on
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置swift相关的配置文件&#34;&gt;配置swift相关的配置文件&lt;/h3&gt;

&lt;h4 id=&#34;创建存储-swift-配置文件的目录&#34;&gt;创建存储 swift 配置文件的目录&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir /etc/swift
sudo chown -R user:user /etc/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-swift-配置文件-etc-swift-swift-conf&#34;&gt;创建 swift 配置文件 /etc/swift/swift.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[swift-hash]

# random unique string that can never change (DO NOT LOSE)
swift_hash_path_suffix = jtangfs
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-account-服务-etc-swift-account-server-conf&#34;&gt;配置 account 服务 /etc/swift/account-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6002
workers = 4
user = wcl
log_facility = LOG_LOCAL4

[pipeline:main]
pipeline = account-server

[app:account-server]
use = egg:swift#account

[account-replicator]
[account-auditor]
[account-reaper]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-container-服务-etc-swift-container-server-conf&#34;&gt;配置 container 服务 /etc/swift/container-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6001
workers = 4
user = wcl
log_facility = LOG_LOCAL3

[pipeline:main]
pipeline = container-server

[app:container-server]
use = egg:swift#container

[container-replicator]

[container-updater]

[container-auditor]

[container-sync]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-object-服务-etc-swift-object-server-conf&#34;&gt;配置 object 服务 /etc/swift/object-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6000
workers = 4
user = wcl
log_facility = LOG_LOCAL2

[pipeline:main]
pipeline = object-server

[app:object-server]
use = egg:swift#object

[object-replicator]

[object-updater]

[object-auditor]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-proxy-服务-etc-swift-proxy-server-conf&#34;&gt;配置 proxy 服务 /etc/swift/proxy-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
bind_port = 8080
user = wcl
workers = 2
log_facility = LOG_LOCAL1

[pipeline:main]
pipeline = healthcheck cache tempauth proxy-logging proxy-server

[app:proxy-server]
use = egg:swift#proxy
allow_account_management = true
account_autocreate = true

[filter:tempauth]
use = egg:swift#tempauth
user_admin_admin = admin .admin .reseller_admin
user_test_tester = testing .admin
user_test2_tester2 = testing2 .admin
user_test_tester3 = testing3
reseller_prefix = AUTH
token_life = 86400
# account和token的命名前缀，注意此处不可以加&amp;quot;_&amp;quot;。
# 例如X-Storage-Ur可能l为http://127.0.0.1:8080/v1/AUTH_test
# 例如X-Auth-Token为AUTH_tk440e9bd9a9cb46d6be07a5b6a585f7d1# token的有效期，单位：秒。

[filter:healthcheck]
use = egg:swift#healthcheck

[filter:cache]
use = egg:swift#memcache

# 这里可以是多个memcache server，proxy会自动当作一个集群来使用# 例如 memcache_servers = 192.168.2.129:11211,192.168.2.130:11211,192.168.2.131

[filter:proxy-logging]
use = egg:swift#proxy_logging
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注：&lt;code&gt;user_admin_admin = admin .admin .reseller_admin&lt;/code&gt; 后面还可以增加一项 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt;，显示地指定 swift 为该用户提供的存储服务入口，admin 用户通过认证后，swift 会把 Token 和该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt;  返回给用户，此后 admin 用户可以使用该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 访问 swift 来请求存储服务。特别值得说明的是，如果在 Proxy Server 前面增加了负载均衡器（如 nginx），那么该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 应该指向负载均衡器，使得用户在通过认证后，向负载均衡器发起存储请求，再由负载均衡器将请求均衡地分发给 Proxy Server 集群。此时的 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 形如 &lt;code&gt;http://&amp;lt;LOAD_BALANCER_HOSTNAME&amp;gt;:&amp;lt;PORT&amp;gt;/v1/AUTH_admin&lt;/code&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建-ring-文件&#34;&gt;创建 ring 文件&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;swift&lt;/strong&gt; 安装完成后会有一个 &lt;strong&gt;swift-ring-builder&lt;/strong&gt; 程序用于对 ring 的相关操作。&lt;/p&gt;

&lt;h4 id=&#34;生成-ring&#34;&gt;生成 ring&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder create 18 3 1
swift-ring-builder container.builder create 18 3 1
swift-ring-builder object.builder create 18 3 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要事先创建好3个 ring，18 表示 partition 数为2的18次方，3表示 replication 数为3，1 表示分区数据的最短迁移间隔时间为1小时。（官网说明里如果移除设备的话不在这个限制内）&lt;/p&gt;

&lt;h3 id=&#34;向-ring-中加入设备&#34;&gt;向 ring 中加入设备&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder add z1-192.168.2.129:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.129:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.129:6000/sdb1 100

swift-ring-builder account.builder add z2-192.168.2.130:6002/sdb1 100
swift-ring-builder container.builder add z2-192.168.2.130:6001/sdb1 100
swift-ring-builder object.builder add z2-192.168.2.130:6000/sdb1 100

swift-ring-builder account.builder add z2-192.168.2.131:6002/sdb1 100
swift-ring-builder container.builder add z2-192.168.2.131:6001/sdb1 100
swift-ring-builder object.builder add z2-192.168.2.131:6000/sdb1 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;z1&lt;/strong&gt; 和 &lt;strong&gt;z2&lt;/strong&gt; 表示 &lt;strong&gt;zone1&lt;/strong&gt; 和 &lt;strong&gt;zone2&lt;/strong&gt;（&lt;strong&gt;zone&lt;/strong&gt; 这个概念是虚拟的，可以将一个 &lt;strong&gt;device&lt;/strong&gt; 划定到一个 &lt;strong&gt;zone&lt;/strong&gt;，在分配 &lt;strong&gt;partition&lt;/strong&gt; 的时候会考虑到这个因素，尽量划分到不同的 &lt;strong&gt;zone&lt;/strong&gt; 中）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sdb1&lt;/strong&gt; 为 &lt;strong&gt;swift&lt;/strong&gt; 所使用的存储空间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;100&lt;/strong&gt; 代表设备的权重，也是在分配 &lt;strong&gt;partition&lt;/strong&gt; 的时候会考虑的因素。&lt;/p&gt;

&lt;h4 id=&#34;rebalance&#34;&gt;rebalance&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder rebalance
swift-ring-builder container.builder rebalance
swift-ring-builder object.builder rebalance
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;将-ring-文件传输到其他机器的-etc-swift-目录下&#34;&gt;将 ring 文件传输到其他机器的 /etc/swift 目录下&lt;/h4&gt;

&lt;p&gt;最终生成的 ring 文件以 &lt;code&gt;.gz&lt;/code&gt; 结尾。&lt;/p&gt;

&lt;h3 id=&#34;创建初始化-起停等脚本&#34;&gt;创建初始化、起停等脚本&lt;/h3&gt;

&lt;p&gt;由于 swift 涉及的组件较多，起停都比较麻烦，所以最好先写好起停脚本。&lt;/p&gt;

&lt;h4 id=&#34;remake-rings-sh-脚本文件-用于完成-ring-的重新创建&#34;&gt;remake_rings.sh 脚本文件，用于完成 ring 的重新创建&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
cd /etc/swift

rm -f *.builder *.ring.gz backups/*.builder backups/*.ring.gz

swift-ring-builder account.builder create 18 3 1
swift-ring-builder container.builder create 18 3 1
swift-ring-builder object.builder create 18 3 1

swift-ring-builder account.builder add z1-192.168.2.129:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.129:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.129:6000/sdb1 100

swift-ring-builder account.builder add z1-192.168.2.130:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.130:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.130:6000/sdb1 100

swift-ring-builder account.builder add z1-192.168.2.131:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.131:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.131:6000/sdb1 100

swift-ring-builder account.builder rebalance
swift-ring-builder container.builder rebalance
swift-ring-builder object.builder rebalance
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;reset-swift-sh-脚本文件-用于一键清空-swift-的对象数据和日志-完全重置&#34;&gt;reset_swift.sh 脚本文件，用于一键清空 swift 的对象数据和日志，完全重置&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init all stop

find /var/log/swift -type f -exec rm -f {} \;

sudo umount /srv/node/sdb1
sudo mkfs.xfs -f -i size=1024 /srv/swift-disk
sudo mount /srv/node/sdb1

sudo chown wcl:wcl /srv/node/sdb1

sudo rm -f /var/log/debug /var/log/messages /var/log/rsyncd.log /var/log/syslog
sudo service rsyslog restart
sudo service rsyncd restart
sudo service memcached restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;start-main-sh-脚本文件-用于启动-swift-所有基础服务&#34;&gt;start_main.sh 脚本文件，用于启动 swift 所有基础服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init main start
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-main-sh-脚本文件-用于关闭-swift-所有基础服务&#34;&gt;stop_main.sh 脚本文件，用于关闭 swift 所有基础服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init main stop
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;start-all-sh-脚本文件&#34;&gt;start_all.sh 脚本文件&lt;/h4&gt;

&lt;p&gt;一键启动 swift 的所有服务。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init proxy start
swift-init account-server start
swift-init account-replicator start
swift-init account-auditor start
swift-init container-server start
swift-init container-replicator start
swift-init container-updater start
swift-init container-auditor start
swift-init object-server start
swift-init object-replicator start
swift-init object-updater start
swift-init object-auditor start
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-all-sh-脚本文件&#34;&gt;stop_all.sh 脚本文件&lt;/h4&gt;

&lt;p&gt;一键关闭 swift的所有服务。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init proxy stop
swift-init account-server stop
swift-init account-replicator stop
swift-init account-auditor stop
swift-init container-server stop
swift-init container-replicator stop
swift-init container-updater stop
swift-init container-auditor stop
swift-init object-server stop
swift-init object-replicator stop
swift-init object-updater stop
swift-init object-auditor stop
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;启动-swift-服务&#34;&gt;启动 swift 服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./start_all.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;动态扩容&#34;&gt;动态扩容&lt;/h3&gt;

&lt;p&gt;重新编写 &lt;strong&gt;remake_rings.sh&lt;/strong&gt; 脚本中的内容，加上需要添加的机器信息，重新生成 ring 文件。&lt;/p&gt;

&lt;p&gt;将新生成的 ring 文件放到每一个服务器的 &lt;code&gt;/etc/swift&lt;/code&gt; 目录下。&lt;/p&gt;

&lt;p&gt;swift 的各个组件程序会定期重新读取 rings 文件。&lt;/p&gt;

&lt;h3 id=&#34;一些需要注意的地方&#34;&gt;一些需要注意的地方&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;服务器时间必须一致，不一致的话会出现问题。测试中有一台服务器比其他的慢了2小时，结果向这台 proxy  上传文件，返回成功，但是其实并没有上传成功，可能是由于时间原因，在其他机器看来这个文件已经被删除掉了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;restful-api-及测试&#34;&gt;RESTful API 及测试&lt;/h3&gt;

&lt;p&gt;swift 可以通过 swift-proxy 提供的 RESTful API 来进行操作。&lt;/p&gt;

&lt;p&gt;另外一种方法就是使用 &lt;code&gt;swift&lt;/code&gt; 程序来进行增删查改的操作，可以实现和 RESTful API 相同的功能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;所有的操作都需要先获取一个 auth-token，之后的所有操作都需要在 header 中附加上 X-Auth-Token 字段的信息进行权限认证。有一定时效性，过期后需要再次获取。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;获取-x-storage-url-和-x-auth-token&#34;&gt;获取 X-Storage-Url 和 X-Auth-Token&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/auth/v1.0 -v -H &#39;X-Storage-User: test:tester&#39; -H &#39;X-Storage-Pass: testing&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的用户和密码是在 &lt;code&gt;proxy-server.conf&lt;/code&gt; 中配置的。&lt;/p&gt;

&lt;p&gt;返回结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt; HTTP/1.1 200 OK
&amp;lt; X-Storage-Url: http://127.0.0.1:8080/v1/AUTH_test
&amp;lt; X-Auth-Token: AUTH_tk039a65cb62594b319faea9dc492039a2
&amp;lt; Content-Type: text/html; charset=UTF-8
&amp;lt; X-Storage-Token: AUTH_tk039a65cb62594b319faea9dc492039a2
&amp;lt; X-Trans-Id: tx7bcd450378d84b56b1482-005745b5c8
&amp;lt; Content-Length: 0
&amp;lt; Date: Wed, 25 May 2016 14:25:12 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看账户信息&#34;&gt;查看账户信息&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/v1/AUTH_test -v -H &#39;X-Auth-Token: AUTH_tk039a65cb62594b319faea9dc492039a2&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt; HTTP/1.1 200 OK
&amp;lt; Content-Length: 5
&amp;lt; X-Account-Object-Count: 1
&amp;lt; X-Account-Storage-Policy-Policy-0-Bytes-Used: 4
&amp;lt; X-Account-Storage-Policy-Policy-0-Container-Count: 1
&amp;lt; X-Timestamp: 1464106581.68979
&amp;lt; X-Account-Storage-Policy-Policy-0-Object-Count: 1
&amp;lt; X-Account-Bytes-Used: 4
&amp;lt; X-Account-Container-Count: 1
&amp;lt; Content-Type: text/plain; charset=utf-8
&amp;lt; Accept-Ranges: bytes
&amp;lt; X-Trans-Id: tx59e9c2f1772349d684d04-005745b713
&amp;lt; Date: Wed, 25 May 2016 14:30:43 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-container&#34;&gt;创建 container&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/v1/AUTH_test/default -X PUT -H &amp;quot;X-Auth_Token: AUTH_tk039a65cb62594b319faea9dc492039a2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 test 用户下创建了一个名为 default 的 container。&lt;/p&gt;

&lt;h4 id=&#34;restful-api-总结&#34;&gt;RESTful API 总结&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;资源类型&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;URL&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;PUT&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;POST&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;DELETE&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;HEAD&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;账户&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取容器列表&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取账户元数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/container&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象列表&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;创建容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;更新容器元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;删除容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取容器元数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/container/object&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象内容和元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;创建、更新或拷贝对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;更新对象元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;删除对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象元数据&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;直接使用-swift-客户端程序进行操作&#34;&gt;直接使用 swift 客户端程序进行操作&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;-A&lt;/strong&gt; 参数指定 url，&lt;strong&gt;-U&lt;/strong&gt; 参数指定用户，&lt;strong&gt;-K&lt;/strong&gt; 参数指定密码。&lt;/p&gt;

&lt;h5 id=&#34;查看指定账户的-swift-存储信息&#34;&gt;查看指定账户的 swift 存储信息&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing stat
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;创建-container-1&#34;&gt;创建 container&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing post default
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看-test-用户的-container-列表&#34;&gt;查看 test 用户的 container 列表&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing list
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;上传object-文件-上传-test-cpp-文件到-default-容器中&#34;&gt;上传Object（文件），上传 test.cpp 文件到 default 容器中&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing upload default ./dd.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看容器中的内容&#34;&gt;查看容器中的内容&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing list default
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;下载object-文件&#34;&gt;下载Object（文件）&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing download default dd.cpp
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>搭建私有docker仓库</title>
          <link>http://blog.fatedier.com/2016/05/16/install-private-docker-registry/</link>
          <pubDate>Mon, 16 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/05/16/install-private-docker-registry/</guid>
          <description>&lt;p&gt;docker 使用起来确实非常方便，易于部署，但是在国内如果要从 DockerHub 上下载镜像实在是一件非常吃力的事，而且公司内部环境使用或者搭建类似 kubernetes 集群的话就需要搭建一个私有的 docker 镜像仓库，方便在集群上快速部署 docker 服务。&lt;/p&gt;

&lt;h3 id=&#34;registry-镜像下载&#34;&gt;registry 镜像下载&lt;/h3&gt;

&lt;p&gt;直接下载官方提供的 docker 镜像&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker pull registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里有一点需要注意的比较坑的是官方的 &lt;code&gt;latest&lt;/code&gt; 的镜像指向的是 &lt;code&gt;0.9.1&lt;/code&gt; 版本，使用 python 开发的，已经被废弃了，新版本采用 go 开发，效率和安全方面都提升很多，所以需要手动指定最新的版本。&lt;/p&gt;

&lt;h3 id=&#34;启动-registry-容器&#34;&gt;启动 registry 容器&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker run -d --name registry -p 5000:5000 -v /opt/registry:/var/lib/registry registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;由于需要做目录映射，如果你的机器上开启了 &lt;strong&gt;SELINUX&lt;/strong&gt;，则使用如下命令：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker run -d --name registry -p 5000:5000 -v /opt/registry:/var/lib/registry:Z registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;否则在 docker 容器中可能没有操作此目录的权限，也可以临时关闭 &lt;strong&gt;SELINUX&lt;/strong&gt;，执行 &lt;code&gt;setenforce 0&lt;/code&gt;，永久关闭的话需要修改配置文件 &lt;code&gt;/etc/selinux/config&lt;/code&gt;，将 &lt;code&gt;SELINUX=enforcing&lt;/code&gt; 改为&lt;code&gt;SELINUX=disabled&lt;/code&gt;，并且重启系统。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-p 5000:5000&lt;/strong&gt;： 对外暴露 5000 端口用于提供服务&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-v  /opt/registry:/var/lib/registry&lt;/strong&gt;： 将宿主机的 &lt;code&gt;/opt/registry&lt;/code&gt; 目录映射到容器内的 &lt;code&gt;/var/lib/registry&lt;/code&gt;，这个目录用来存储 docker 的镜像文件，为了持久化存储，不然容器关闭后这些镜像文件会丢失。&lt;/p&gt;

&lt;p&gt;这里根据 registry 镜像的不同版本，存储镜像文件的目录可能并不是 &lt;code&gt;/var/lib/registry&lt;/code&gt;，&lt;code&gt;2.4&lt;/code&gt; 版本是 &lt;code&gt;/var/lib/registry&lt;/code&gt;，如果是其他版本可以查看具体的 Dockerfile 来确认。&lt;/p&gt;

&lt;h3 id=&#34;上传下载镜像&#34;&gt;上传下载镜像&lt;/h3&gt;

&lt;p&gt;由于 docker 的安全策略限制，如果要从私有的仓库上传下载镜像需要修改 docker 的启动参数，把我们自己搭建的 registry 的 ip 地址或者域名添加进来。&lt;/p&gt;

&lt;p&gt;centos7 上的配置文件位置为 &lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;设置 &lt;code&gt;INSECURE_REGISTRY=&#39;--insecure-registry 192.168.2.129:5000&#39;&lt;/code&gt;，重启 docker 服务，以后要和这个 registry 交互的机器都需要执行上述步骤。&lt;/p&gt;

&lt;p&gt;另外一个方法就是自己签一组证书，把 &lt;code&gt;ca.crt&lt;/code&gt; 拷贝到 &lt;code&gt;/etc/docker/certs.d/192.168.2.199:5000/ca.crt&lt;/code&gt; 就可以了，这样就不需要重启 docker 服务，这个方法目前还没试过，之后可以尝试一下。&lt;/p&gt;

&lt;h4 id=&#34;上传镜像&#34;&gt;上传镜像&lt;/h4&gt;

&lt;p&gt;给要上传的镜像打上 tag，修改前缀为我们的 registry 的 ip 和 port&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker tag centos 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker push 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;可以看到上传的镜像已经被存储在 /opt/registry 上了&lt;/p&gt;

&lt;h4 id=&#34;下载镜像&#34;&gt;下载镜像&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;docker pull 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;直接从内网环境下载镜像的速度相当快。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;Registry 的 API 也更新到了 V2 版本，可以通过 HTTP API 对私有仓库进行一些管理操作。具体的说明可以参考 github 上的项目文档 &lt;a href=&#34;https://github.com/docker/distribution。&#34;&gt;https://github.com/docker/distribution。&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>go程序中dns解析无法使用所有域名服务器</title>
          <link>http://blog.fatedier.com/2016/04/27/go-program-does-not-use-all-nameservers-for-dns-lookups/</link>
          <pubDate>Wed, 27 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/04/27/go-program-does-not-use-all-nameservers-for-dns-lookups/</guid>
          <description>&lt;p&gt;最近线上服务经常会出现异常，从错误日志来看是因为域名解析失败导致的，我们在 /etc/resolv.conf 中配置了多个域名服务器，第一个是内网的，用于解析内网域名，如果是外网域名，则会通过其他的域名服务器进行解析，按道理来说应该不会有问题，但是最近却频繁发生这样的故障，为了彻底解决问题，特意研究了一下 golang 中进行 dns 查询的源码并最终解决了此问题。&lt;/p&gt;

&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;

&lt;h4 id=&#34;nameserver-配置&#34;&gt;nameserver 配置&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;/etc/resolv.conf&lt;/code&gt; 中配置了多个 nameserver&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nameserver 10.10.100.3
nameserver 114.114.114.114
nameserver 8.8.8.8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;10.10.100.3&lt;/code&gt; 用于解析内网域名，外网域名通过 &lt;code&gt;114.114.114.114&lt;/code&gt; 或者 &lt;code&gt;8.8.8.8&lt;/code&gt; 来解析。&lt;/p&gt;

&lt;h4 id=&#34;测试代码&#34;&gt;测试代码&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
    &amp;quot;net&amp;quot;
    &amp;quot;fmt&amp;quot;
)

func main() {
    hostname := &amp;quot;www.baidu.com&amp;quot;
    addrs, err := net.LookupHost(hostname)
    if err != nil {
        fmt.Printf(&amp;quot;lookup host error: %v\n&amp;quot;, err)
    } else {
        fmt.Printf(&amp;quot;addrs: %v&amp;quot;, addrs)
    }   
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;结果&#34;&gt;结果&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lookup host error: lookup www.baidu.com on 10.10.100.3:53: no such host
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 go1.5 版本进行编译，发现程序并没有按照预想的过程来解析，通过 &lt;code&gt;10.10.100.3&lt;/code&gt; 无法解析后就直接返回了错误信息。&lt;/p&gt;

&lt;p&gt;而使用 go1.4 版本编译运行后，确得到了正确的结果。&lt;/p&gt;

&lt;h3 id=&#34;调试标准库的方法&#34;&gt;调试标准库的方法&lt;/h3&gt;

&lt;p&gt;调试 golang 的标准库非常简单，先找到标准库源码的存放位置，然后将要修改的文件备份一份，之后直接在其中添加输出语句，大部分可以 &lt;code&gt;import &amp;quot;fmt&amp;quot;&lt;/code&gt; 后使用 &lt;code&gt;fmt.Printf&lt;/code&gt; 函数进行输出，有的包中需要使用其他方式，避免循环引用，这里不详述，因为我们要改的 &lt;code&gt;net&lt;/code&gt; 包并不涉及这个问题，注意调试完之后将标准库的文件恢复。&lt;/p&gt;

&lt;h4 id=&#34;查找标准库所在的目录&#34;&gt;查找标准库所在的目录&lt;/h4&gt;

&lt;p&gt;执行 &lt;code&gt;go env&lt;/code&gt; 查看 go 的环境变量如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GOARCH=&amp;quot;amd64&amp;quot;
GOBIN=&amp;quot;&amp;quot;GOCHAR=&amp;quot;6&amp;quot;GOEXE=&amp;quot;&amp;quot;GOHOSTARCH=&amp;quot;amd64&amp;quot;GOHOSTOS=&amp;quot;linux&amp;quot;GOOS=&amp;quot;linux&amp;quot;
GOPATH=&amp;quot;/home/wcl/go_projects&amp;quot;
GORACE=&amp;quot;&amp;quot;
GOROOT=&amp;quot;/usr/lib/golang&amp;quot;
GOTOOLDIR=&amp;quot;/usr/lib/golang/pkg/tool/linux_amd64&amp;quot;
CC=&amp;quot;gcc&amp;quot;
GOGCCFLAGS=&amp;quot;-fPIC -m64 -pthread -fmessage-length=0&amp;quot;
CXX=&amp;quot;g++&amp;quot;
CGO_ENABLED=&amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;GOROOT&lt;/strong&gt; 的值即是标准库所在的目录，&lt;code&gt;net&lt;/code&gt; 包的具体路径为 &lt;code&gt;/usr/lib/golang/src/net&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;go-1-4-与-1-5-版本中-dns-查询逻辑的不同&#34;&gt;go 1.4 与 1.5 版本中 dns 查询逻辑的不同&lt;/h3&gt;

&lt;p&gt;因为最近很多程序都是使用 &lt;strong&gt;go1.5&lt;/strong&gt; 版本进行编译的，所以理所当然查看了两个版本这部分源码的区别，还真的有所改变。&lt;/p&gt;

&lt;p&gt;标准库对外暴露的 dns 查询函数是 &lt;code&gt;func LookupHost(host string) (addrs []string, err error)&lt;/code&gt; &lt;strong&gt;(net/lookup.go)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个函数会调用实际处理函数 &lt;code&gt;lookupHost&lt;/code&gt; &lt;strong&gt;(net/lookup_unix.go)&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;cgo-与纯-go-实现的-dns-查询&#34;&gt;cgo 与纯 go 实现的 dns 查询&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;go1.4 版本源码&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;func lookupHost(host string) (addrs []string, err error) {
    addrs, err, ok := cgoLookupHost(host)
    if !ok {
        addrs, err = goLookupHost(host)
    }
    return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;go1.5 版本源码&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;func lookupHost(host string) (addrs []string, err error) {
    order := systemConf().hostLookupOrder(host)
    if order == hostLookupCgo {
        if addrs, err, ok := cgoLookupHost(host); ok {
            return addrs, err
        }
        // cgo not available (or netgo); fall back to Go&#39;s DNS resolver
        order = hostLookupFilesDNS
    }
    return goLookupHostOrder(host, order)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;可以明显的看到 1.4 的源码中默认使用 cgo 的方式进行 dns 查询&lt;/strong&gt;（这个函数最终会创建一个线程调用c的 getaddrinfo 函数来获取 dns 查询结果），如果查询失败则会再使用纯 go 实现的查询方式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;而在 1.5 的源码中，这一点有所改变，cgo 的方式不再是默认值，而是根据 &lt;code&gt;systemConf().hostLookupOrder(host)&lt;/code&gt; 的返回值来判断具体使用哪种方式&lt;/strong&gt;。这个函数定义在 &lt;strong&gt;net/conf.go&lt;/strong&gt; 中，稍微看了一下， 除非通过编译标志强制使用 cgo 方式或者在某些特定的系统上会使用 cgo 方式，其他时候都使用纯 go 实现的查询方式。&lt;/p&gt;

&lt;p&gt;cgo 的方式没有问题，看起来程序会并发地向 &lt;code&gt;/etc/resolv.conf&lt;/code&gt; 中所有配置的域名服务器发送 dns 解析请求，然后将最先成功响应的结果返回。&lt;/p&gt;

&lt;h4 id=&#34;纯-go-实现的-dns-查询分析&#34;&gt;纯 go 实现的 dns 查询分析&lt;/h4&gt;

&lt;p&gt;问题就出在纯 go 实现的查询上，主要看一下 go1.5 的实现。&lt;/p&gt;

&lt;p&gt;函数调用逻辑如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;LookupHost (net/lookup.go)
    lookupHost  (net/lookup_unix.go)
        goLookupHostOrder  (net/dnsclient_unix.go)
            goLookupIPOrder  (net/dnsclient_unix.go)
                tryOneName   (net/dnsclient_unix.go)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;大部分实现代码在 &lt;code&gt;net/dnsclient_unix.go&lt;/code&gt; 这个文件中。&lt;/p&gt;

&lt;p&gt;重点看一下 &lt;code&gt;tryOneName&lt;/code&gt; 这个函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;func tryOneName(cfg *dnsConfig, name string, qtype uint16) (string, []dnsRR, error) {
    if len(cfg.servers) == 0 {
        return &amp;quot;&amp;quot;, nil, &amp;amp;DNSError{Err: &amp;quot;no DNS servers&amp;quot;, Name: name}
    }
    if len(name) &amp;gt;= 256 {
        return &amp;quot;&amp;quot;, nil, &amp;amp;DNSError{Err: &amp;quot;DNS name too long&amp;quot;, Name: name}
    }
    timeout := time.Duration(cfg.timeout) * time.Second
    var lastErr error
    for i := 0; i &amp;lt; cfg.attempts; i++ {
        for _, server := range cfg.servers {
            server = JoinHostPort(server, &amp;quot;53&amp;quot;)
            msg, err := exchange(server, name, qtype, timeout)
            if err != nil {
                lastErr = &amp;amp;DNSError{
                    Err:    err.Error(),
                    Name:   name,
                    Server: server,
                }
                if nerr, ok := err.(Error); ok &amp;amp;&amp;amp; nerr.Timeout() {
                    lastErr.(*DNSError).IsTimeout = true
                }
                continue
            }
            cname, rrs, err := answer(name, server, msg, qtype)
            if err == nil || msg.rcode == dnsRcodeSuccess || msg.rcode == dnsRcodeNameError &amp;amp;&amp;amp; msg.recursion_available {
                return cname, rrs, err
            }
            lastErr = err
        }
    }
    return &amp;quot;&amp;quot;, nil, lastErr
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一层 for 循环是尝试的次数，第二层 for 循环是遍历 &lt;code&gt;/etc/resolv.conf&lt;/code&gt; 中配置的所有域名服务器，&lt;code&gt;exchange&lt;/code&gt; 函数是发送 dns 查询请求并将响应结果解析到 &lt;code&gt;msg&lt;/code&gt; 变量中返回，初看到这里，觉得实现是没问题的，顺序向每一个域名服务器发送 dns 查询请求，如果成功就返回，如果失败就尝试下一个。&lt;/p&gt;

&lt;p&gt;问题出现在判断是否成功的那一行代码 &lt;code&gt;if err == nil || msg.rcode == dnsRcodeSuccess || msg.rcode == dnsRcodeNameError &amp;amp;&amp;amp; msg.recursion_available&lt;/code&gt;，这里的意思是如果 dns 查询成功，或者出错了但是对方支持递归查询的话，就直接返回，不继续请求下一个域名服务器。如果对方支持递归查询但是仍然没有查到的话，说明上级服务器也没有这个域名的记录，没有必要继续往下查。（这个逻辑在 go1.6 版本中被修改了，出错了以后不再判断是否支持递归查询，仍然尝试向下一个域名服务器发送请求）&lt;/p&gt;

&lt;p&gt;&lt;code&gt;msg.rcode&lt;/code&gt; 这个值很重要，是问题的关键。&lt;/p&gt;

&lt;h3 id=&#34;dns-查询协议格式&#34;&gt;dns 查询协议格式&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-04-27-go-program-does-not-use-all-nameservers-for-dns-lookups-dns-query-package.png&#34; alt=&#34;dns-query-package&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们只需要关注首部的12字节。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ID:占16位，2个字节。此报文的编号，由客户端指定。DNS回复时带上此标识，以指示处理的对应请应请求。&lt;/li&gt;
&lt;li&gt;QR:占1位，1/8字节。0代表查询，1代表DNS回复&lt;/li&gt;
&lt;li&gt;Opcode:占4位，1/2字节。指示查询种类：0:标准查询；1:反向查询；2:服务器状态查询；3-15:未使用。&lt;/li&gt;
&lt;li&gt;AA:占1位，1/8字节。是否权威回复。&lt;/li&gt;
&lt;li&gt;TC:占1位，1/8字节。因为一个UDP报文为512字节，所以该位指示是否截掉超过的部分。&lt;/li&gt;
&lt;li&gt;RD:占1位，1/8字节。此位在查询中指定，回复时相同。设置为1指示服务器进行递归查询。&lt;/li&gt;
&lt;li&gt;RA:占1位，1/8字节。由DNS回复返回指定，说明DNS服务器是否支持递归查询。&lt;/li&gt;
&lt;li&gt;Z:占3位，3/8字节。保留字段，必须设置为0。&lt;/li&gt;
&lt;li&gt;RCODE:占4位，1/2字节。由回复时指定的返回码：0:无差错；1:格式错；2:DNS出错；3:域名不存在；4:DNS不支持这类查询；5:DNS拒绝查询；6-15:保留字段。　&lt;/li&gt;
&lt;li&gt;QDCOUNT:占16位，2字节。一个无符号数指示查询记录的个数。&lt;/li&gt;
&lt;li&gt;ANCOUNT:占16位，2字节。一个无符号数指明回复记录的个数。&lt;/li&gt;
&lt;li&gt;NSCOUNT:占16位，2字节。一个无符号数指明权威记录的个数。&lt;/li&gt;
&lt;li&gt;ARCOUNT:占16位，2字节。一个无符号数指明格外记录的个数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中 &lt;strong&gt;RCODE&lt;/strong&gt; 是回复时用于判断查询结果是否成功的，对应前面的 &lt;code&gt;msg.rcode&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;bind-的-dns-回复问题&#34;&gt;bind 的 dns 回复问题&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;10.10.100.3&lt;/code&gt; 上是使用 &lt;strong&gt;bind&lt;/strong&gt; 搭建的本地域名服务器。&lt;/p&gt;

&lt;p&gt;使用 &lt;code&gt;dig @10.10.100.3 www.baidu.com&lt;/code&gt; 命令查看解析结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.8.2rc1-RedHat-9.8.2-0.23.rc1.el6_5.1 &amp;lt;&amp;lt;&amp;gt;&amp;gt; @10.10.100.3 www.baidu.com ;
(1 server found) 
;; global options: +cmd 
;; Got answer: 
;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 55909 
;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 13, ADDITIONAL: 0 
;; WARNING: recursion requested but not available 

;; QUESTION SECTION: 
;www.baidu.com.         IN  A 

;; AUTHORITY SECTION: 
.           518400  IN  NS  H.ROOT-SERVERS.NET.  
.           518400  IN  NS  K.ROOT-SERVERS.NET.  
.           518400  IN  NS  C.ROOT-SERVERS.NET.  
.           518400  IN  NS  A.ROOT-SERVERS.NET.  
.           518400  IN  NS  B.ROOT-SERVERS.NET.  
.           518400  IN  NS  F.ROOT-SERVERS.NET.  
.           518400  IN  NS  L.ROOT-SERVERS.NET.  
.           518400  IN  NS  D.ROOT-SERVERS.NET.  
.           518400  IN  NS  I.ROOT-SERVERS.NET.  
.           518400  IN  NS  E.ROOT-SERVERS.NET.  
.           518400  IN  NS  G.ROOT-SERVERS.NET.  
.           518400  IN  NS  M.ROOT-SERVERS.NET.  
.           518400  IN  NS  J.ROOT-SERVERS.NET.  

;; Query time: 1 msec 
;; SERVER: 10.10.100.3#53(10.10.100.3) 
;; WHEN: Wed Apr 27 17:35:15 2016 
;; MSG SIZE  rcvd: 242 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;bind&lt;/strong&gt; 并没有返回 &lt;code&gt;www.baidu.com&lt;/code&gt; 的 A 记录，而是返回了13个根域名服务器的地址，并且 &lt;strong&gt;status&lt;/strong&gt; 的状态是 &lt;strong&gt;NOERROR&lt;/strong&gt;（这个值就是前述的 &lt;strong&gt;RCODE&lt;/strong&gt;，这里返回0表示没有错误)，问题就在这里，没有查到 A 记录还返回 &lt;code&gt;RCODE=0&lt;/code&gt;，回顾一下上面 go 代码中的判断条件&lt;/p&gt;

&lt;p&gt;&lt;code&gt;if err == nil || msg.rcode == dnsRcodeSuccess || msg.rcode == dnsRcodeNameError &amp;amp;&amp;amp; msg.recursion_available&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果返回的 &lt;strong&gt;RCODE&lt;/strong&gt; 值为 0，则直接退出，不继续尝试后面的域名服务器，从而导致了域名解析失败。&lt;/p&gt;

&lt;h3 id=&#34;解决方案&#34;&gt;解决方案&lt;/h3&gt;

&lt;h4 id=&#34;仍然使用-go1-4-版本进行编译&#34;&gt;仍然使用 go1.4 版本进行编译&lt;/h4&gt;

&lt;p&gt;不推荐这么做，毕竟升级后在 gc 以及很多其他方面都有优化。&lt;/p&gt;

&lt;h4 id=&#34;使用-go1-5-及以上版本编译但是通过环境变量强制使用-cgo-的-dns-查询方式&#34;&gt;使用 go1.5 及以上版本编译但是通过环境变量强制使用 cgo 的 dns 查询方式&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;export GODEBUG=netdns=cgo go build&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;使用 cgo 的方式会在每一次调用时创建一个线程，在并发量较大时可能会对系统资源造成一定影响。而且需要每一个使用 go 编写的程序编译时都加上此标志，较为繁琐。&lt;/p&gt;

&lt;h4 id=&#34;修改-bind-的配置文件&#34;&gt;修改 bind 的配置文件&lt;/h4&gt;

&lt;p&gt;在 &lt;strong&gt;bind&lt;/strong&gt; 中彻底关闭对递归查询的支持也可以解决此问题，但是由于对 &lt;strong&gt;bind&lt;/strong&gt; 不是很熟悉，具体是什么原因导致没有查到 &lt;strong&gt;A 记录&lt;/strong&gt;但仍然返回 &lt;strong&gt;NOERROR&lt;/strong&gt; 不是很清楚，猜测可能和递归转发的查询方式有关，有可能 &lt;strong&gt;bind&lt;/strong&gt; 认为返回了根域名服务器的地址，&lt;strong&gt;client&lt;/strong&gt; 可以去这些地址上查，所以该次请求并不算做出错。&lt;/p&gt;

&lt;p&gt;修改配置文件加上以下内容以后，再次查询时会返回 &lt;strong&gt;RCODE=5&lt;/strong&gt;，拒绝递归查询，这样可以达到我们的目的，查询非内网域名时通过其他域名服务器查询&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;recursion no;
allow-query-cache { none; };
allow-recursion { none; };
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;更新&#34;&gt;更新&lt;/h4&gt;

&lt;p&gt;发现在 go1.7 版本中对这个问题做了修复，使用纯 go 实现的 dns 解析方式也已经运行正常。具体信息可以参考 &lt;a href=&#34;https://github.com/golang/go/issues/15434&#34;&gt;issue 15434&lt;/a&gt;。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>利用docker搭建gitlab及持续集成模块</title>
          <link>http://blog.fatedier.com/2016/04/05/install-gitlab-supporting-ci-with-docker/</link>
          <pubDate>Tue, 05 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/04/05/install-gitlab-supporting-ci-with-docker/</guid>
          <description>&lt;p&gt;版本控制的重要性应该是毋庸置疑了，git 作为现在最流行的版本控制工具，各种规模的公司都在用。通常开源项目都会放在 github 上，基础功能是免费的，私有项目收费。对于一个小团队来说，gitlab 就是另外一个替代品，可以用来搭建自己私有的git服务器。&lt;/p&gt;

&lt;h3 id=&#34;为什么需要版本控制和持续继承&#34;&gt;为什么需要版本控制和持续继承？&lt;/h3&gt;

&lt;p&gt;经常听到很多程序员说自己没有时间写测试用例，但其实很多人的时间都花在了手动测试，修复bug，调试程序上。如果写好测试用例，每次提交代码后都自动进行编译，然后将测试用例全部跑一遍，如果测试失败能够获取到足够的反馈信息，这样避免了重复构建测试环境，手动运行测试用例等低效率的工作，而这就是持续集成的好处。&lt;/p&gt;

&lt;h3 id=&#34;准备工作&#34;&gt;准备工作&lt;/h3&gt;

&lt;h4 id=&#34;docker-环境&#34;&gt;docker 环境&lt;/h4&gt;

&lt;p&gt;安装 &lt;code&gt;docker&lt;/code&gt; 环境，&lt;code&gt;centos&lt;/code&gt; 的话可以使用 &lt;code&gt;sudo yum install -y docker&lt;/code&gt; 直接安装&lt;/p&gt;

&lt;p&gt;之后启动 &lt;code&gt;docker&lt;/code&gt;，&lt;code&gt;sudo service docker start&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;docker-镜像加速&#34;&gt;docker 镜像加速&lt;/h4&gt;

&lt;p&gt;由于国内的网络环境过于恶劣，多次尝试从 &lt;a href=&#34;https://gitlab.com/&#34;&gt;gitlab&lt;/a&gt; 官网下载源码安装包未果，之后发现  gitlab 还提供 docker 镜像，这样不仅部署方便，利用国内一些云服务商提供的镜像加速功能，可以加速 docker 镜像的下载。&lt;/p&gt;

&lt;p&gt;推荐 daocloud 的镜像加速服务，&lt;a href=&#34;https://dashboard.daocloud.io/mirror&#34;&gt;https://dashboard.daocloud.io/mirror&lt;/a&gt;，安装之后，使用 &lt;code&gt;dao pull&lt;/code&gt; 替代 &lt;code&gt;docker pull&lt;/code&gt; 即可。&lt;/p&gt;

&lt;h4 id=&#34;下载相关docker镜像&#34;&gt;下载相关docker镜像&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;gitlab/gitlab-ce:latest （gitlab 的 docker镜像）&lt;/li&gt;
&lt;li&gt;gitlab/gitlab-runner:latest （用于持续集成，构建测试环境）&lt;/li&gt;
&lt;li&gt;golang:1.5 （golang基础环境，用于编译代码，运行测试用例）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;启动-gitlab&#34;&gt;启动 gitlab&lt;/h3&gt;

&lt;p&gt;具体的官方说明文档：&lt;a href=&#34;http://doc.gitlab.com/omnibus/docker/README.html&#34;&gt;http://doc.gitlab.com/omnibus/docker/README.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;启动 &lt;code&gt;gitlab&lt;/code&gt; 就是启动相应的 &lt;code&gt;docker&lt;/code&gt; 镜像，设置好相关配置参数，命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --detach \
    --hostname x.x.x.x \
    --publish 7000:443 --publish 80:80 --publish 7002:22 \
    --name gitlab \
    --restart always \
    --volume /srv/gitlab/config:/etc/gitlab \
    --volume /srv/gitlab/logs:/var/log/gitlab \
    --volume /srv/gitlab/data:/var/opt/gitlab \
    gitlab/gitlab-ce:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你的机器开启了 &lt;code&gt;SELINUX&lt;/code&gt;，需要使用如下的命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --detach \
    --hostname x.x.x.x \
    --publish 7000:443 --publish 80:80 --publish 7002:22 \
    --name gitlab \
    --restart always \
    --volume /srv/gitlab/config:/etc/gitlab:Z \
    --volume /srv/gitlab/logs:/var/log/gitlab:Z \
    --volume /srv/gitlab/data:/var/opt/gitlab:Z \
    gitlab/gitlab-ce:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;hostname&lt;/code&gt; 可以是gitlab服务器的ip，也可以是绑定的域名，80端口需要映射到宿主机的80端口，因为之后 &lt;code&gt;github-ci-runner&lt;/code&gt; 会从这个端口下载测试源码。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/srv/gitlab&lt;/code&gt; 是用于持久化 docker 容器中产生的数据，例如 &lt;strong&gt;redis&lt;/strong&gt;，&lt;strong&gt;postgresql&lt;/strong&gt; 等等，gitlab 的docker 镜像中已经内置了这些服务。&lt;/p&gt;

&lt;p&gt;启动成功后，可以通过浏览器访问80端口来使用 gitlab 了，可能是由于我的测试服务器配置较低，等待约2分钟后才能访问。&lt;/p&gt;

&lt;p&gt;初始帐号和密码为 &lt;code&gt;root&lt;/code&gt;  &lt;code&gt;5iveL!fe&lt;/code&gt;，第一次登录成功后需要修改密码。&lt;/p&gt;

&lt;p&gt;gitlab 的具体使用文档比较多，这里就不详细介绍了。&lt;/p&gt;

&lt;h3 id=&#34;创建测试项目&#34;&gt;创建测试项目&lt;/h3&gt;

&lt;p&gt;简单创建一个 &lt;code&gt;test&lt;/code&gt; 项目，先不要提交到 gitlab 仓库。&lt;/p&gt;

&lt;p&gt;包含一个 &lt;code&gt;a.go&lt;/code&gt; 文件，文件内容如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import fmt 

func main() {
    fmt.Printf(&amp;quot;aaa\n&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;可以看到 import 包名没有加双引号，显然编译时就会出错。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;添加-gitlab-ci-yml-文件&#34;&gt;添加 .gitlab-ci.yml 文件&lt;/h4&gt;

&lt;p&gt;配置文件详细内容请参考 &lt;a href=&#34;http://doc.gitlab.com/ce/ci/yaml/README.html&#34;&gt;http://doc.gitlab.com/ce/ci/yaml/README.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里简单写一下，仅仅用于测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;image: golang:1.5

job1:
    script:
        - go build a.go
        - ./a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;image&lt;/code&gt; 表示使用 &lt;code&gt;golang:1.5&lt;/code&gt; 的 docker 镜像来部署编译和测试代码，我们之前已经下好了。&lt;/p&gt;

&lt;p&gt;测试命令有两条，&lt;code&gt;go build a.go&lt;/code&gt; 编译源码， &lt;code&gt;./a&lt;/code&gt; 执行编译后的程序。&lt;/p&gt;

&lt;h3 id=&#34;获取-runner-registration-token&#34;&gt;获取 Runner registration token&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-registration-token.png&#34; alt=&#34;registration-token&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;gitlab&lt;/code&gt; 的管理员配置界面，左边有一个 &lt;code&gt;Runners&lt;/code&gt;，点进去之后可以看到有一个 &lt;code&gt;Registration token&lt;/code&gt;，这个是用于之后创建的 &lt;code&gt;runner&lt;/code&gt; 服务与 &lt;code&gt;gitlab&lt;/code&gt; 通信的时候认证使用。&lt;/p&gt;

&lt;p&gt;例如图中的 &lt;code&gt;Registration token&lt;/code&gt; 为 &lt;code&gt;XKZmVj9t8j4xj1e5k34N&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;启动-runner&#34;&gt;启动 Runner&lt;/h3&gt;

&lt;p&gt;Runner 官方详细说明文档： &lt;a href=&#34;https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/install/docker.md&#34;&gt;https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/install/docker.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Runner&lt;/code&gt;其实就是用于编译和管理测试环境的服务，当 &lt;code&gt;gitlab&lt;/code&gt; 上的项目有 &lt;code&gt;commit&lt;/code&gt; 或 &lt;code&gt;merge&lt;/code&gt; 的时候，&lt;code&gt;Runner&lt;/code&gt; 可以 hook 到相关信息，然后从 &lt;code&gt;gitlab&lt;/code&gt; 上拉取代码，利用 &lt;code&gt;docker&lt;/code&gt; 创建一个新的测试环境，之后执行 &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; 文件中预先配置好的命令。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --name gitlab-runner --restart always \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v /srv/gitlab-runner/config:/etc/gitlab-runner \
      gitlab/gitlab-runner:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你的机器开启了 SELINUX，需要使用如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --name gitlab-runner --restart always \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v /srv/gitlab-runner/config:/etc/gitlab-runner:Z \
      gitlab/gitlab-runner:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;关联-gitlab&#34;&gt;关联 gitlab&lt;/h4&gt;

&lt;p&gt;启动成功后的 &lt;code&gt;Runner&lt;/code&gt; 需要在 &lt;code&gt;gitlab&lt;/code&gt; 上注册，通过在 &lt;code&gt;Runner&lt;/code&gt; 上执行注册命令，会调用 &lt;code&gt;gitlab&lt;/code&gt; 的相关接口注册。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -it gitlab-runner gitlab-runner register

Please enter the gitlab-ci coordinator URL (e.g. [https://gitlab.com/ci](https://gitlab.com/ci) )
[https://gitlab.com/ci](https://gitlab.com/ci)（这里的gitlab.com替换成之前启动gitlab时填写的 hostname）

Please enter the gitlab-ci token for this runner
xxx（填写获取到的 runner registration token）

Please enter the gitlab-ci description for this runner
my
INFO[0034] fcf5c619 Registering runner... succeeded

Please enter the executor: shell, docker, docker-ssh, ssh?
docker

Please enter the Docker image (eg. ruby:2.1):
golang:1.5
INFO[0037] Runner registered successfully. Feel free to start it, but if it&#39;s
running already the config should be automatically reloaded!
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试&#34;&gt;测试&lt;/h3&gt;

&lt;p&gt;利用 &lt;code&gt;docker&lt;/code&gt; 来搭建这套环境还是非常简单的。&lt;/p&gt;

&lt;p&gt;接着提交我们之前创建的两个文件，&lt;code&gt;a.go&lt;/code&gt; 和 &lt;code&gt;.gitlab-ci.yml&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;访问 &lt;code&gt;gitlab&lt;/code&gt; 查看 &lt;code&gt;build&lt;/code&gt; 的结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-commit.png&#34; alt=&#34;test-commit&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到提交记录右边有一个红叉，表示测试未通过，点击红叉，可以看到测试的摘要信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-info.png&#34; alt=&#34;test-info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;继续点 红色的 &lt;code&gt;failed&lt;/code&gt; 按钮就可以看到详细的测试信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-deatil.png&#34; alt=&#34;test-deatil&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从 &lt;code&gt;Runner&lt;/code&gt; 测试过程的输出信息可以看出来，&lt;code&gt;Runner&lt;/code&gt; 先 &lt;code&gt;pull&lt;/code&gt; 我们指定的 &lt;code&gt;docker&lt;/code&gt; 镜像，这里是 &lt;code&gt;golang:1.5&lt;/code&gt;，之后 &lt;code&gt;git clone&lt;/code&gt; 代码到测试环境，然后开始执行测试命令，在执行 &lt;code&gt;go build a.go&lt;/code&gt; 的时候出现了错误，并且显示了错误信息。&lt;/p&gt;

&lt;p&gt;将错误的代码修改后再次提交&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
)

func main() {
    fmt.Printf(&amp;quot;aaa\n&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到能够通过测试了，执行程序后的输出 &lt;code&gt;aaa&lt;/code&gt; 也能够看到。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-commit-all.png&#34; alt=&#34;test-commit-all&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-succ-detail.png&#34; alt=&#34;test-succ-detail&#34; /&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>简记用sed对文件执行批量替换字符串的方法</title>
          <link>http://blog.fatedier.com/2016/03/25/using-sed-to-batch-replace-strings-in-files/</link>
          <pubDate>Fri, 25 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/03/25/using-sed-to-batch-replace-strings-in-files/</guid>
          <description>&lt;p&gt;每次要进行一些批量的文本处理，例如 sed, awk 处理数据或者涉及到正则表达式的时候，都需要临时去再查一遍资料，看一下怎么用。这里简要记录一下对大量文件进行正则匹配后批量替换文本的方法，方便以后要用的时候回顾一下。&lt;/p&gt;

&lt;p&gt;因为 blog 的图片迁到了七牛云上（提供CDN加速服务），原来的图片链接必然要替换成七牛云提供的二级域名，在 markdown 文件中有很多图片的标签，也不可能一个一个手动改，最好是能一个命令下去直接全部修改完毕并且以后也可以很轻松地改成其他域名。&lt;/p&gt;

&lt;p&gt;执行的命令如下：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sed -i &amp;quot;s?](.*|pic|?](http://xxx.clouddn.com|pic|?g&amp;quot; `grep &amp;quot;|pic|&amp;quot; -rl ./`&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：本文中所有的 &lt;code&gt;|pic|&lt;/code&gt; 其实是 &lt;code&gt;/pic/&lt;/code&gt;，这样是为了避免被误替换。也可以通过 &lt;code&gt;grep -v&lt;/code&gt; 来手动指定不替换的文件。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;markdown 中的图片标签一般的格式是 &lt;code&gt;![label](http://www.xxx.com/a.jpg)&lt;/code&gt;，我的图片链接则是都会有一个 &lt;code&gt;pic&lt;/code&gt; 的目录前缀。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;grep&#34;&gt;grep&lt;/h4&gt;

&lt;p&gt;先看后面，&lt;code&gt;grep &amp;quot;|pic|&amp;quot; -rl ./&lt;/code&gt; 用于递归查找所有含有 &lt;code&gt;|pic|&lt;/code&gt; 这个字符串的文件所在路径的路径名，按行显示。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-r&lt;/code&gt; 参数表示会对目录进行递归查找。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-l&lt;/code&gt; 参数会输出匹配的文件名&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;sed&#34;&gt;sed&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;sed&lt;/strong&gt; 和 &lt;strong&gt;awk&lt;/strong&gt; 都是文本处理的利器。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sed&lt;/code&gt; 进行文本替换的常用的格式是 &lt;code&gt;sed &amp;quot;s/aa/bb/g&amp;quot; ./testfile&lt;/code&gt;，表示将文件中所有的 &lt;strong&gt;aa&lt;/strong&gt; 替换成 &lt;strong&gt;bb&lt;/strong&gt;， 最后的 &lt;code&gt;g&lt;/code&gt; 表示作用域是全局。&lt;/p&gt;

&lt;p&gt;这里分隔符用的 &lt;code&gt;/&lt;/code&gt;，也可以换成其他符号，比如上面我用的是 &lt;code&gt;?&lt;/code&gt;，只要保证这三个地方的符号一致并且没有歧义即可。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;](.*|pic|&lt;/code&gt; 是一个正则匹配， &lt;code&gt;.&lt;/code&gt; 表示匹配任意一个字符，&lt;code&gt;*&lt;/code&gt; 表示匹配0个或多个前面的字符，这里两个合起来就是匹配任意字符串。完整的意思就是匹配以 &lt;code&gt;](&lt;/code&gt; 开头，以 &lt;code&gt;|pic|&lt;/code&gt; 结尾的任意字符串。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;](http://xxx.clouddn.com|pic|&lt;/code&gt; 是替换后的字符串。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-i&lt;/code&gt; 表示将替换后的结果写入文件中，而不是直接输出。&lt;/p&gt;

&lt;h4 id=&#34;查看修改结果&#34;&gt;查看修改结果&lt;/h4&gt;

&lt;p&gt;一开始不确定修改是否正确最好不要给予使用 &lt;code&gt;-i&lt;/code&gt; 参数将修改后的结果写入文件，可以将上面的命令换成如下的内容来检查是否替换正确：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sed -n &amp;quot;s?](.*|pic|?](http://xxx.clouddn.com|pic|?gp&amp;quot; `grep &amp;quot;|pic|&amp;quot; -rl ./`&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-n&lt;/code&gt; 表示静默模式，如果有输出内容的话，不会输出整个文件的内容，而仅仅是匹配的内容。&lt;/p&gt;

&lt;p&gt;后面的 &lt;code&gt;gp&lt;/code&gt;，&lt;code&gt;g&lt;/code&gt; 前面说过是表示作用域是全局，&lt;code&gt;p&lt;/code&gt; 表示会输出匹配的内容。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>OpenTSDB部署与使用</title>
          <link>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/</link>
          <pubDate>Sat, 12 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/</guid>
          <description>&lt;p&gt;OpenTSDB 是基于 HBase 存储时间序列数据的一个开源数据库，对于存储监控系统采集的数据来说非常合适，不仅在写入查询上有很高的效率，而且节省存储空间。&lt;/p&gt;

&lt;h3 id=&#34;安装-hbase&#34;&gt;安装 HBase&lt;/h3&gt;

&lt;p&gt;因为 OpenTSDB 的后端存储使用的是 HBase，所以我们需要先安装 HBase。&lt;/p&gt;

&lt;p&gt;参考文档： &lt;a href=&#34;https://hbase.apache.org/book.html#quickstart&#34;&gt;Quick Start - Standalone HBase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里简单搭建了一个&lt;strong&gt;单机&lt;/strong&gt;的 HBase 环境：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;安装 JDK 环境，centos 上可以直接通过 yum 安装。&lt;/li&gt;
&lt;li&gt;下载 HBase，&lt;a href=&#34;http://apache.fayea.com/hbase/stable&#34;&gt;http://apache.fayea.com/hbase/stable&lt;/a&gt;，这里我们选择下载 stable 的 1.1.3 版本，文件名为 &lt;code&gt;hbase-1.1.3-bin.tar.gz&lt;/code&gt;，解压到任意目录。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-env.sh&lt;/code&gt; ，设置  &lt;code&gt;JAVA_HOME=/usr&lt;/code&gt;，这个是 &lt;code&gt;/bin/java&lt;/code&gt; 所在的目录，通过 &lt;code&gt;which java&lt;/code&gt; 查看。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-site.xml&lt;/code&gt;， 设置 hbase 的数据存储目录以及 zookeeper 的数据存储目录，默认会放到 &lt;code&gt;/tmp&lt;/code&gt; 目录下，这个目录机器重启后会清空，所以需要更改目录。&lt;/li&gt;
&lt;li&gt;执行 &lt;code&gt;bin/start-hbase.sh&lt;/code&gt; 启动 HBase，之后可以通过 &lt;code&gt;jps&lt;/code&gt; 命令来查看 HMaster 进程是否启动成功。 &lt;code&gt;bin/stop-hbase.sh&lt;/code&gt; 用于关闭 HBase。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;conf/hbase-site.xml&lt;/code&gt; 的配置示例如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/testuser/hbase&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/testuser/zookeeper&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过命令行操作-hbase&#34;&gt;通过命令行操作 HBase&lt;/h3&gt;

&lt;p&gt;这里可以稍微熟悉一下 HBase 的操作，非必须。&lt;/p&gt;

&lt;h5 id=&#34;连接到-hbase&#34;&gt;连接到 HBase&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;./bin/hbase shell&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;创建一张表&#34;&gt;创建一张表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;create &#39;test&#39;, &#39;cf&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看表信息&#34;&gt;查看表信息&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;list &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;向表中插入数据&#34;&gt;向表中插入数据&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;
put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;
put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看表中所有数据&#34;&gt;查看表中所有数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;scan &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看指定行的数据&#34;&gt;查看指定行的数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;get &#39;test&#39;, &#39;row1&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;禁用指定表-删除表或修改表设置前需要先禁用该表&#34;&gt;禁用指定表（删除表或修改表设置前需要先禁用该表）&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;disable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;恢复指定表&#34;&gt;恢复指定表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;enable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;删除表&#34;&gt;删除表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;drop &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装opentsdb&#34;&gt;安装OpenTSDB&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://debugo.com/opentsdb/&#34;&gt;http://debugo.com/opentsdb/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&#34;&gt;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;直接从 github 上下载 OpenTSDB 的 &lt;a href=&#34;https://github.com/OpenTSDB/opentsdb&#34;&gt;release&lt;/a&gt; 版本的 RPM 包。安装 &lt;code&gt;yum localinstall opentsdb-2.2.0.noarch.rpm&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置完成后，我们通过下面命令在 HBase 中建立 opentsdb 所需的表。默认情况下 opentsdb 建立的 HBase 表启用了 lzo 压缩。需要开启 Hadoop 中的 lzo 压缩支持， 这里我们直接在下面脚本中把 COMPRESSION 的支持关闭。修改 &lt;code&gt;/usr/share/opentsdb/tools/create_table.sh&lt;/code&gt;，设置 &lt;code&gt;COMPRESSION=NONE&lt;/code&gt;，并且在文件开始处设置 HBase 所在目录， &lt;code&gt;HBASE_HOME=/home/xxx/hbase-1.1.3&lt;/code&gt;。之后执行该脚本，在 HBase 中创建相应的表。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;修改 OpenTSDB 的配置文件，&lt;code&gt;/etc/opentsdb/opentsdb.conf&lt;/code&gt;，例如绑定的端口号等。&lt;strong&gt;这里需要注意的是 tsd.core.auto_create_metrics 从 false 改为 true。这样上传数据时会自动创建 metric，否则会提示 Unknown metric 的错误。也可以设置为 false，但是使用 &lt;code&gt;tsdb mkmetric proc.loadavg.1m&lt;/code&gt; 来手动添加 metric。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;启动 OpenTSDB，&lt;code&gt;service opentsdb start&lt;/code&gt; 或者 &lt;code&gt;nohup tsdb tsd &amp;amp;&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过浏览器访问 &lt;a href=&#34;http://x.x.x.x:4242&#34;&gt;http://x.x.x.x:4242&lt;/a&gt; 查看是否安装成功。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;http-api&#34;&gt;HTTP API&lt;/h3&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;/api/put&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据 url 参数的不同，可以选择是否获取详细的信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;/api/put?summary&lt;/strong&gt;        // 返回失败和成功的个数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;/api/put?details&lt;/strong&gt;        // 返回详细信息&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;errors&amp;quot;: [],
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过POST方式插入数据，JSON格式，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;metric&amp;quot;:&amp;quot;self.test&amp;quot;, 
    &amp;quot;timestamp&amp;quot;:1456123787, 
    &amp;quot;value&amp;quot;:20, 
    &amp;quot;tags&amp;quot;:{
        &amp;quot;host&amp;quot;:&amp;quot;web1&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查询数据&#34;&gt;查询数据&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;/api/query&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可以选择 Get 或者 Post 两种方式，推荐使用 Post 方式，JSON 格式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1456123705,
    &amp;quot;end&amp;quot;: 1456124985,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web2&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;start 和 end 为指定的查询时间段。&lt;/p&gt;

&lt;p&gt;queries 为一个数组，可以指定多个查询。&lt;/p&gt;

&lt;p&gt;metric 和 tags 是用于过滤的查询条件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;返回字符串也为json格式&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {},
        &amp;quot;aggregateTags&amp;quot;: [
            &amp;quot;host&amp;quot;
        ],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123785&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 10
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        },
        &amp;quot;aggregateTags&amp;quot;: [],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123784&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 15
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;聚合&#34;&gt;聚合&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;aggregator&lt;/strong&gt; 是用于对查询结果进行聚合，将同一 unix 时间戳内的数据进行聚合计算后返回结果，例如如果 tags 不填，1456123705 有两条数据，一条 &lt;code&gt;host=web1&lt;/code&gt;，另外一条 &lt;code&gt;host=web2&lt;/code&gt;，值都为10，那么返回的该时间点的值为 sum 后的 20。&lt;/p&gt;

&lt;h4 id=&#34;条件过滤&#34;&gt;条件过滤&lt;/h4&gt;

&lt;p&gt;可以针对 tag 进行一些条件的过滤，返回 tag 中 host 的值以 web 开头的数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;filters&amp;quot;: [
            {
                &amp;quot;type&amp;quot;: &amp;quot;wildcard&amp;quot;,
                &amp;quot;tagk&amp;quot;: &amp;quot;host&amp;quot;,
                &amp;quot;filter&amp;quot;: &amp;quot;web*&amp;quot;
            }
        ]
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;downsample&#34;&gt;downsample&lt;/h4&gt;

&lt;p&gt;简单来说就是对指定时间段内的数据进行聚合后返回，例如需要返回每分钟的平均值数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;downsample&amp;quot;: &amp;quot;1m-avg&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>如何使golang项目可以在任意目录下编译</title>
          <link>http://blog.fatedier.com/2016/02/25/how-to-compile-go-project-in-any-directory/</link>
          <pubDate>Thu, 25 Feb 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/02/25/how-to-compile-go-project-in-any-directory/</guid>
          <description>&lt;p&gt;通常我们将golang项目直接放在 $GOPATH/src 目录下，所有 import 的包的路径也是相对于 GOPATH 的。我在开发 frp（一个可以用于穿透内网的反向代理工具）的时候就遇到一个比较小但是挺棘手的问题，需要使这个项目可以在任意目录里被编译，方便其他成员不需要做额外的操作就可以一同开发，这里分享一下解决的方法。&lt;/p&gt;

&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/fatedier/frp&#34;&gt;frp&lt;/a&gt; 是我业余时间写的一个用于穿透内网的反向代理工具，可以将防火墙内或内网环境的机器对外暴露指定的服务，例如22端口提供ssh服务或者80端口提供一个临时的web测试环境。&lt;/p&gt;

&lt;p&gt;一开始项目是直接放在 &lt;code&gt;$GOPATH/src&lt;/code&gt; 目录下的，第三方包的引用是 &lt;code&gt;import github.com/xxx/xxx&lt;/code&gt;，内部包的引用 &lt;code&gt;import frp/xxx&lt;/code&gt;，这样编译时内部包的查找路径实际上就是 &lt;code&gt;$GOPATH/src/frp/xxx&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;后来由于使用了 &lt;a href=&#34;https://travis-ci.org/&#34;&gt;travis-ci&lt;/a&gt; 做持续集成，travis-ci 中是直接使用 &lt;code&gt;go get github.com/fatedier/frp&lt;/code&gt; 下载代码，然后编译运行。这样问题就来了，通过 go get 下载的源码在本地的路径是 &lt;code&gt;$GOPATH/src/github.com/fatedier/frp&lt;/code&gt;，内部包就找不到了，导致编译失败。&lt;/p&gt;

&lt;h3 id=&#34;使用类似第三方包的引用方式&#34;&gt;使用类似第三方包的引用方式&lt;/h3&gt;

&lt;p&gt;解决这个问题最直接的方法就是将内部包的引用方式修改成 &lt;code&gt;import github.com/fatedier/frp/xxx&lt;/code&gt;，在 travis-ci 中编译的时候就可以通过了，同时需要注意把自己本地的项目路径也更换成&lt;code&gt;$GOPATH/src/github.com/fatedier/frp&lt;/code&gt;，很多开源项目都是用的这种方式引用内部包。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：不推荐使用 ./ ../ 等相对路径来引用内部包，这样管理和定位问题其实都不是很方便。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之后由于需要其他人共同开发，fork了我的项目之后，他们也使用 go get 下载他们fork后的项目源码，这样 &lt;code&gt;fatedier&lt;/code&gt; 就替换成了他们自己的用户名，但是代码中 import 的包名并没有改变，会导致他们无法编译通过。当然，他们可以将项目再放到正确的目录，但是多了一部操作总归不方便。&lt;/p&gt;

&lt;h3 id=&#34;比较tricky的做法-修改gopath&#34;&gt;比较tricky的做法，修改GOPATH&lt;/h3&gt;

&lt;p&gt;其实问题的关键就在于 &lt;code&gt;GOPATH&lt;/code&gt; 这个环境变量，这个变量决定了查找包的绝对路径。我们在项目根目录下建立 &lt;code&gt;src/frp&lt;/code&gt; 这样的目录结构，之后将原来的源代码放到这个目录下，然后内部包的应用方式还是改成 &lt;code&gt;import frp/xxx&lt;/code&gt; 这种简洁的格式。&lt;/p&gt;

&lt;p&gt;编译的时候，把项目根目录加到 &lt;code&gt;GOPATH&lt;/code&gt; 中去，例如 &lt;code&gt;GOPATH=`pwd`:${GOPATH}&lt;/code&gt;，这样就会在自己的目录里查找内部包。&lt;/p&gt;

&lt;p&gt;可以看到，通过这样的方式不管把你把项目放到哪一个目录下，都可以编译成功，当然，为了便于管理，推荐还是放在 &lt;code&gt;$GOPATH/src&lt;/code&gt; 目录下，同时使用 &lt;a href=&#34;https://github.com/tools/godep&#34;&gt;godep&lt;/a&gt; 来管理第三方包。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Go中如何优雅地关闭net.Listener</title>
          <link>http://blog.fatedier.com/2016/02/19/how-to-shutdown-go-net-dot-listeners-gracefully/</link>
          <pubDate>Fri, 19 Feb 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/02/19/how-to-shutdown-go-net-dot-listeners-gracefully/</guid>
          <description>&lt;p&gt;在开发一个 Go 语言写的服务器项目的时候，遇到一个很有意思的问题，这个程序会根据客户端的请求动态的监听本地的一个端口，并且与客户端交互结束后需要释放这个端口。Go 的标准库提供了常用的接口，开发网络服务非常方便，网上随便就可以找到很多样例代码。&lt;/p&gt;

&lt;p&gt;但是我在释放这个监听端口的时候遇到了一些问题，我发现很难优雅地去关闭这个 &lt;strong&gt;net.Listener&lt;/strong&gt;。在网上查阅了一下资料，基本上都是程序结束时资源被系统自动回收，没发现有需要主动释放的。这个需求确实不多，不过想一下在写测试用例的时候或许可能会用到，我们先创建一个 &lt;strong&gt;net.Listener&lt;/strong&gt; 监听一个端口，&lt;strong&gt;client&lt;/strong&gt; 发送请求进行测试，通过后关闭这个 &lt;strong&gt;net.Listener&lt;/strong&gt;，再创建另外一个 &lt;strong&gt;net.Listener&lt;/strong&gt; 用于测试其他用例。&lt;/p&gt;

&lt;p&gt;初步思考了一下有两个办法来关闭 &lt;strong&gt;net.Listener&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;设置一个结束标志，为 &lt;strong&gt;net.Listener&lt;/strong&gt; 的 &lt;code&gt;accept&lt;/code&gt; 设置超时，&lt;strong&gt;net.Listener&lt;/strong&gt; 提供了一个 &lt;code&gt;SetDeadline(t time.Time)&lt;/code&gt; 接口，需要关闭时将标志置为 &lt;strong&gt;true&lt;/strong&gt;，每次超时后检查一下结束标志，如果为 &lt;strong&gt;true&lt;/strong&gt; 则退出。&lt;/li&gt;
&lt;li&gt;在另外一个协程中 &lt;strong&gt;close net.Listener&lt;/strong&gt;，检查 &lt;code&gt;accept&lt;/code&gt; 返回的 &lt;strong&gt;error&lt;/strong&gt; 信息，如果是被 &lt;strong&gt;close&lt;/strong&gt; 的话就退出，其他情况就继续。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第一个方法很显然不够优雅，在大并发量连接请求时对效率有很大影响，而且退出机制是延迟的，不能及时退出。&lt;/p&gt;

&lt;p&gt;第二个方法的问题就在于如果 &lt;strong&gt;close net.Listener&lt;/strong&gt;，&lt;code&gt;accept&lt;/code&gt; 函数返回的 &lt;strong&gt;error&lt;/strong&gt; 信息只能拿到错误的字符串信息，如果是被 &lt;strong&gt;close&lt;/strong&gt; 的话返回的信息是：&lt;code&gt;use of closed network connection&lt;/code&gt;，这个时候退出监听，如果是其他错误，则继续监听。想法是好的，然而并不能用错误信息的字符串来判断是哪一种类型的错误，有可能以后的版本中错误信息字符串变更也说不定，最好不要在代码中写死。这个 &lt;strong&gt;error&lt;/strong&gt; 其实是有类型的，在标准库中是 &lt;code&gt;errClosing&lt;/code&gt;，开头小写，说明只能在包内部使用，我们没有办法使用这个类型来判断具体是哪一种错误。个人觉得这方面可能还没有 &lt;strong&gt;c语言&lt;/strong&gt; 中通过 &lt;strong&gt;errno&lt;/strong&gt; 的值来判断是哪一种类型的错误来的方便。&lt;/p&gt;

&lt;p&gt;既然不能通过 &lt;strong&gt;error&lt;/strong&gt; 的字符串信息判断是哪一种错误，那么我们只能用类似第一个方法中使用的标志来判断了，先将结束标志置为 &lt;strong&gt;true&lt;/strong&gt;，之后 &lt;strong&gt;close net.Listener&lt;/strong&gt;，&lt;code&gt;accept&lt;/code&gt; 函数返回 &lt;code&gt;error != nil&lt;/code&gt; 时，检查结束标志，如果为 &lt;strong&gt;true&lt;/strong&gt; 就退出，这样相比较第一个方法退出时就没有延迟了，参考代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;net&amp;quot;
    &amp;quot;time&amp;quot;
)

var (
    ln        net.Listener
    closeFlag bool = false
)

func startServer() (err error) {
    ln, err = net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;:12345&amp;quot;)
    if err != nil {
        return err
    }
    defer ln.Close()

    for {
        conn, err := ln.Accept()
        if err != nil {
            fmt.Printf(&amp;quot;accept error: %v\n&amp;quot;, err)
            if closeFlag {
                break
            } else {
                continue
            }
        } else {
            conn.Close()
        }
    }
    return nil
}

func main() {
    go startServer()
    time.Sleep(1 * time.Second)
    closeFlag = true
    ln.Close()
    time.Sleep(1 * time.Second)
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>使用godep管理golang项目的第三方包</title>
          <link>http://blog.fatedier.com/2016/01/15/use-godep-to-manage-third-party-packages-of-golang-projects/</link>
          <pubDate>Fri, 15 Jan 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/01/15/use-godep-to-manage-third-party-packages-of-golang-projects/</guid>
          <description>&lt;p&gt;go语言项目的第三方包资源现在十分丰富，使用起来也非常方便，直接在代码中 import 之后再使用 go get 命令下载到本地即可。但是在合作开发一个golang项目时，经常会遇到每个人在各自的机器上使用 go get 下载的第三方包版本不一致的情况（因为 go get 会下载指定包的最新版本），很有可能会遇到版本不兼容的情况。&lt;/p&gt;

&lt;p&gt;目前 go 自身的包管理体系比较薄弱，go 1.5 以后开始使用 vendor 机制来管理，但是依然缺乏对第三方包的版本的管理。&lt;/p&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;确保已经有go语言的环境并且设置好了 GOPATH 环境变量。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;go get -u github.com/tools/godep&lt;/code&gt; 下载 godep 包并自动安装。&lt;/li&gt;
&lt;li&gt;godep 可执行程序会放在 $GOPATH/bin 目录下。所以想直接用 godep 执行命令的话需要将该路径加入到全局的环境变量 PATH 中，可以将&lt;code&gt;export PATH=&amp;quot;$PATH:$GOPATH/bin&amp;quot;&lt;/code&gt;加入到系统启动脚本中。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;使用&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;进入go项目的根目录，需要该项目已经可以使用 go build 正常编译。&lt;/p&gt;

&lt;h4 id=&#34;godep-save&#34;&gt;godep save&lt;/h4&gt;

&lt;p&gt;执行 &lt;code&gt;godep save&lt;/code&gt; 或者 &lt;code&gt;godep save ./...&lt;/code&gt;，后者会递归地查找所有引用的第三方包。&lt;/p&gt;

&lt;p&gt;如果加上 -r 参数，则会替换原来代码中的第三包的路径为 godep 在该项目下copy过后的路径，例如 &lt;code&gt;C/Godeps/_workspace/src/D&lt;/code&gt;， 这样一来，以后直接执行 &lt;code&gt;go build&lt;/code&gt; 等就可以了，不需要使用 &lt;code&gt;godep go build&lt;/code&gt;。&lt;strong&gt;（这个特性在最新版本中已经被移除了）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个命令做了以下几件事：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查找项目中所用到的所有的第三方包&lt;/li&gt;
&lt;li&gt;在项目目录下创建 &lt;code&gt;Godeps&lt;/code&gt; 目录，&lt;code&gt;Godeps/Godeps.json&lt;/code&gt; 是依赖文件，包括了go的版本，用到的第三包的引入路径，版本号等信息，json文件需要一并加入到版本控制里。&lt;/li&gt;
&lt;li&gt;所有依赖的第三包的代码会被拷贝到 &lt;code&gt;Godeps/_workspace/src&lt;/code&gt; 下，并且移除了 &lt;code&gt;.git&lt;/code&gt; 这样的版本控制信息。&lt;code&gt;Godeps/_workspace&lt;/code&gt; 里的内容如果加到版本控制里，别人下载代码后可以直接编译，不需要另外再下依赖包，但是项目大小会变大。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;godep-restore&#34;&gt;godep restore&lt;/h4&gt;

&lt;p&gt;这个命令是根据 &lt;code&gt;Godeps/Godeps.json&lt;/code&gt; 文件把项目的依赖包下载到 &lt;code&gt;$GOPATH&lt;/code&gt; 目录下，需要注意这个命令是会修改 &lt;code&gt;$GOPATH&lt;/code&gt; 下依赖包的状态的，所以最好还是将 &lt;code&gt;Godeps/_workspace&lt;/code&gt; 里的内容直接加到自己项目的版本控制里。&lt;/p&gt;

&lt;h4 id=&#34;其他命令&#34;&gt;其他命令&lt;/h4&gt;

&lt;p&gt;其他的 go 命令基本上都可以通过 godep 执行，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;godep go build
godep go install
godep go fmt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;godep 封装的 go 命令其实就是将 Godeps/_workspace 加入到 GOPATH 中，这样编译的时候就会去 Godeps/_workspace 中寻找第三方包。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>终端利器 Tmux</title>
          <link>http://blog.fatedier.com/2015/12/18/terminal-multiplexer-tmux/</link>
          <pubDate>Fri, 18 Dec 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/12/18/terminal-multiplexer-tmux/</guid>
          <description>&lt;p&gt;开发过程中通过ssh到服务器是很常见的，工作中基本上90%的时间在和终端打交道，如果没有一个称手的工具，将会在不停打开新的 tab 页，窗口切换中耗费大量的时间。Tmux 是终端复用器的意思，和 screen 类似，但是高度可定制，通过 tmux 可以方便地管理大量的 ssh 连接，并且灵活地在不同窗口，不同面板之间切换。&lt;/p&gt;

&lt;h3 id=&#34;界面&#34;&gt;界面&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-12-18-terminal-multiplexer-tmux-tmux-overview.png&#34; alt=&#34;tmux&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我用了自己的配置文件，对界面做过一些优化，左下角是 &lt;strong&gt;session&lt;/strong&gt; 名称，中间是各个 &lt;strong&gt;window&lt;/strong&gt; 的名称，可以理解为一般 IDE 中的 Tab 页，右下角显示时间，这个窗口中打开了3个 &lt;strong&gt;pane&lt;/strong&gt;，通过快捷键，我就可以在不同的 &lt;strong&gt;session&lt;/strong&gt;, &lt;strong&gt;window&lt;/strong&gt;, &lt;strong&gt;pane&lt;/strong&gt; 之间来回切换，基本上脱离了鼠标的使用。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;session： 可以用于区分不同的项目，为每个项目建立一个 session。&lt;/li&gt;
&lt;li&gt;window： 对应于其他 IDE 的 Tab 标签页，一个 window 占据一个显示屏幕，一个 session 可以有多个 window。&lt;/li&gt;
&lt;li&gt;pane： 在一个 window 中可以有多个 pane，便于大屏幕显示屏将屏幕切分成多块。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;p&gt;Centos下直接通过 &lt;code&gt;yum install -y tmux&lt;/code&gt; 来安装，其他系统也一样可以使用相应的包管理工具安装。&lt;/p&gt;

&lt;h3 id=&#34;常用命令&#34;&gt;常用命令&lt;/h3&gt;

&lt;h4 id=&#34;快捷键前缀&#34;&gt;快捷键前缀&lt;/h4&gt;

&lt;p&gt;为了避免按键冲突，使用 tmux 的快捷键都需要加上一个&lt;strong&gt;前缀按键&lt;/strong&gt;，默认是 &lt;strong&gt;Ctrl-b&lt;/strong&gt; 的组合，可以通过配置修改为自定义的按键。&lt;/p&gt;

&lt;p&gt;例如要退出 tmux 的快捷键是前缀键 + d，那么就需要按 Ctrl-b + d：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;按下组合键 Ctrl-b&lt;/li&gt;
&lt;li&gt;放开组合键 Ctrl-b&lt;/li&gt;
&lt;li&gt;按下 s 键&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我自己将 Ctrl-b 改成了 Ctrl-x ，感觉这样操作顺手一些。&lt;/p&gt;

&lt;h4 id=&#34;基本操作&#34;&gt;基本操作&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;创建一个叫做 &amp;ldquo;test&amp;rdquo; 的 session，并且进入 tmux 界面&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tmux new -s test&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看开启了哪些 session&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tmux ls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;进入 session &amp;ldquo;test&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tmux attach -t test&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;退出 tmux 环境&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + d  // 退出后 session 并不会被关闭，之后通过 attach 进入仍然会看到原来的界面&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;切换 session&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + s，之后按序号切换，或者通过方向键选择后按 Enter 键切换&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;切换 window&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Ctrl-b + &amp;lt;窗口号&amp;gt;
Ctrl-b + n  // 切换到下一个窗口
Ctrl-b + p  // 切换到上一个窗口
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;切换 pane&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这个我在配置文件中修改过，修改成了 vim 的使用习惯，具体配置见下节
Ctrl-b + h  // 左
Ctrl-b + j  // 下
Ctrl-b + k  // 上
Ctrl-b + l  // 右
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;关闭 pane&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + x  // 焦点在要关闭的 pane 内&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关闭 window&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + &amp;amp; // 焦点在要关闭的 window 内&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分割 window 成多个 pane&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这个为了记忆方便也修改了原有的配置
Ctrl-b + _  // 竖直分割
Ctrl-b + |  // 水平分割
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;重新加载配置文件&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这个被我映射到了 r 键，修改完配置文件后不用关闭所有 session 重新打开，直接重新加载即可
Ctrl-b + r
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;小技巧&#34;&gt;小技巧&lt;/h3&gt;

&lt;h4 id=&#34;复制模式&#34;&gt;复制模式&lt;/h4&gt;

&lt;p&gt;如果要在不同 &lt;strong&gt;window&lt;/strong&gt; 或者 &lt;strong&gt;pane&lt;/strong&gt; 之间复制内容，又想实现全键盘的操作，就需要借助于 tmux 的复制功能。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ctrl-b + [&lt;/strong&gt; 进入复制模式&lt;/li&gt;
&lt;li&gt;移动光标到要复制的地方，这里我配置成了 vim 的操作方式&lt;/li&gt;
&lt;li&gt;按下&lt;strong&gt;空格&lt;/strong&gt;开始复制&lt;/li&gt;
&lt;li&gt;再移动到结束的地方，按下 &lt;strong&gt;Enter&lt;/strong&gt; 键退出&lt;/li&gt;
&lt;li&gt;在需要粘贴的地方按下 &lt;strong&gt;Ctrl-b + ]&lt;/strong&gt; 粘贴&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;多-pane-批量操作&#34;&gt;多 pane 批量操作&lt;/h4&gt;

&lt;p&gt;有时候同时登录了多台机器，需要执行一样的命令来进行批量操作，借助于 tmux 同样可以实现。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;:setw synchronize-panes&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个是设置批量操作的开关，如果原来功能是关闭的，则打开，反之亦然，可以将其映射到一个快捷键方便操作。开启这个功能后，在当前 window 任意一个 pane 输入的命令，都会同时作用于该 window 中的其他 pane。&lt;/p&gt;

&lt;h3 id=&#34;配置文件&#34;&gt;配置文件&lt;/h3&gt;

&lt;p&gt;配置文件需要自己在 $HOME 目录下创建，命名为 .tmux.conf，具体内容如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Use something easier to type as the prefix.
set -g prefix C-x
unbind C-b
bind C-x send-prefix

# 窗口计数从1开始，方便切换
set -g base-index 1
setw -g pane-base-index 1

# 启用和关闭status bar
bind S set status on
bind D set status off 

# 消息背景色
set -g message-bg white

set -g mode-keys vi

# 关闭自动重命名窗口
setw -g allow-rename off 
setw -g automatic-rename off 

# bind a reload key
bind r source-file ~/.tmux.conf \; display-message &amp;quot;Config reloaded...&amp;quot;

# I personally rebind the keys so &amp;quot;|&amp;quot; splits the current window vertically, and &amp;quot;-&amp;quot; splits it horizontally. Not the easiest things to type, though easy to remember.
bind | split-window -h
bind _ split-window -v

# fixes the delay problem
set -sg escape-time 0

# 面板切换
bind-key k select-pane -U
bind-key j select-pane -D
bind-key h select-pane -L
bind-key l select-pane -R

# 面板大小调整
bind -r ^k resizep -U 10  
bind -r ^j resizep -D 10
bind -r ^h resizep -L 10
bind -r ^l resizep -R 10

# 状态栏
# 颜色
set -g status-bg black
set -g status-fg white

# 对齐方式
set-option -g status-justify centre

# 左下角
set-option -g status-left &#39;#[bg=black,fg=green][#[fg=cyan]#S#[fg=green]]&#39;
set-option -g status-left-length 20

# 窗口列表
set-window-option -g window-status-format &#39;#[dim]#I:#[default]#W#[fg=grey,dim]&#39;
set-window-option -g window-status-current-format &#39;#[fg=cyan,bold]#I#[fg=blue]:#[fg=cyan]#W#[fg=dim]&#39;

# 右下角
set -g status-right &#39;#[fg=green][#[fg=cyan]%H:%M#[fg=green]]&#39;

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配套工具&#34;&gt;配套工具&lt;/h3&gt;

&lt;h4 id=&#34;tmuxinator&#34;&gt;tmuxinator&lt;/h4&gt;

&lt;p&gt;使用 tmux 可以让我们不管在什么时候，什么地点登录服务器都能得到同样的工作界面，不用因为担心网络暂时中断而需要重新打开一大堆的 tab 页。&lt;/p&gt;

&lt;p&gt;但是如果有的时候服务器重启了，那么所有的 session 就都没了，必须重新打开，可以想象一下我开发时有4-5个 session，每个 session 中有多个 window，然后每个 winodw 中通常又有2-3个 pane，要重新一个个建立开发环境是一件多么痛苦的事。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tmuxinator/tmuxinator&#34;&gt;tmuxinator&lt;/a&gt; 可以稍微缓解一下这个问题，但是不彻底。tmuxinator 可以用于管理 tmux 的 session 和 window 布局等，便于在机器重启后能够快速恢复自己的工作环境。&lt;/p&gt;

&lt;h5 id=&#34;安装-1&#34;&gt;安装&lt;/h5&gt;

&lt;p&gt;先安装 gem， &lt;code&gt;yum install -y rubygems&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于天朝特殊的网络环境，gem的第三方包可能安装不了，可以替换成阿里提供的镜像源。&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gem sources --add [https://ruby.taobao.org/](https://ruby.taobao.org/) --remove [https://rubygems.org/](https://rubygems.org/)
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;使用&#34;&gt;使用&lt;/h5&gt;

&lt;p&gt;创建一个 tmuxinator 的 project： &lt;code&gt;tmuxinator new [project]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后编写项目的配置文件，以后重新打开这个项目所显示的界面就是根据这个配置文件来生成。具体用法可以参考项目文档： &lt;a href=&#34;https://github.com/tmuxinator/tmuxinator。&#34;&gt;https://github.com/tmuxinator/tmuxinator。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当服务器重启了以后，执行 &lt;code&gt;tmuxinator start [project]&lt;/code&gt;，tmuxinator 就会自动根据配置文件创建一个指定布局的 tmux session。&lt;/p&gt;

&lt;h5 id=&#34;缺点&#34;&gt;缺点&lt;/h5&gt;

&lt;p&gt;布局是预先在配置文件中指定好的，你在使用 tmux 过程中修改了的布局是不会记录下来的。&lt;/p&gt;

&lt;h4 id=&#34;tmux-resurrect&#34;&gt;Tmux Resurrect&lt;/h4&gt;

&lt;p&gt;Tmux Resurrect 用于保存当前的session环境到磁盘上，用于以后恢复。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于这个插件需要 tmux 1.9 及以上的版本，而 centos7 的 yum 源里现在是1.8的版本，我的开发环境全是自动构建，不方便升级，所以暂时还没有尝试。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于 Tmux Resurrect 使用的相关文档： &lt;a href=&#34;http://www.linuxidc.com/Linux/2015-07/120304.htm&#34;&gt;http://www.linuxidc.com/Linux/2015-07/120304.htm&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>gem 源被屏蔽的解决方法</title>
          <link>http://blog.fatedier.com/2015/12/06/the-solution-when-gem-source-is-shielded/</link>
          <pubDate>Sun, 06 Dec 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/12/06/the-solution-when-gem-source-is-shielded/</guid>
          <description>&lt;p&gt;由于国内的网络环境比较特殊，使用 gem install 安装 ruby 包的时候，往往不能成功，我们可以手动替换成阿里提供的镜像源来进行下载。&lt;/p&gt;

&lt;p&gt;官方原先的源地址是 &lt;a href=&#34;https://rubygems.org/&#34;&gt;https://rubygems.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以使用 &lt;code&gt;gem sources&lt;/code&gt; 命令来查看源地址。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;*** CURRENT SOURCES ***

https://rubygems.org/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过 &lt;code&gt;gem sources --add https://ruby.taobao.org/ --remove https://rubygems.org/&lt;/code&gt; 替换成阿里的源。&lt;/p&gt;

&lt;p&gt;再次查看源地址列表。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;*** CURRENT SOURCES ***

https://ruby.taobao.org/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后就可以使用 &lt;code&gt;gem install xxx -V&lt;/code&gt; 安装第三方包或应用并且显示详细过程。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>给shell的输出加上颜色</title>
          <link>http://blog.fatedier.com/2015/11/24/give-your-shell-some-color/</link>
          <pubDate>Tue, 24 Nov 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/11/24/give-your-shell-some-color/</guid>
          <description>&lt;p&gt;在写一些脚本的时候输出信息太多，对一些重要信息加上颜色提示会更加友好。&lt;/p&gt;

&lt;h3 id=&#34;前景色-文本颜色&#34;&gt;前景色(文本颜色)&lt;/h3&gt;

&lt;p&gt;例如要将 &lt;code&gt;hello&lt;/code&gt; 在控制台上输出为红色，执行如下的命令&lt;/p&gt;

&lt;p&gt;&lt;code&gt;echo -e &amp;quot;\033[31mhello\033[0m&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\033[31m&lt;/code&gt; 表示将字符的显示颜色改为红色&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\033[0m&lt;/code&gt; 表示将字符的显示颜色改为正常值&lt;/p&gt;

&lt;p&gt;可以看到 &lt;code&gt;\033[&lt;/code&gt; 以及最后的 &lt;code&gt;m&lt;/code&gt; 都是一样的，就是中间的数字有区别，这个数字就代表了要显示的颜色，含义如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;30        黑色 
31        红色 
32        绿色 
33        淡红色 
34        蓝色 
35        紫色 
36        淡蓝色 
37        灰色 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;背景色&#34;&gt;背景色&lt;/h3&gt;

&lt;p&gt;背景色和前景色设置的方法一样，只是使用的数字不同&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;40        黑色 
41        红色 
42        绿色 
43        淡红色 
44        蓝色 
45        紫色 
46        淡蓝色 
47        灰色 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果需要同时设置前景色和背景色，例如输出文本颜色为红色，背景色为绿色的字符串，需要以分号分隔两个数字，示例如下&lt;/p&gt;

&lt;p&gt;&lt;code&gt;echo -e &amp;quot;\033[31;42mhello\033[0m&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;简化&#34;&gt;简化&lt;/h3&gt;

&lt;p&gt;从上面的示例可以看到这样写起来很麻烦，可以简单的将重复的内容定义为一个变量&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lc=&#39;\033[&#39;
rc=&#39;\033[0m&#39;
cred=&#39;31m&#39;        # red
cgreen=&#39;32m&#39;      # green

echo -e &amp;quot;${lc}${cred}hello${rc}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>codis 2.x版本环境搭建与测试</title>
          <link>http://blog.fatedier.com/2015/10/07/installation-and-testing-of-codis-version-two/</link>
          <pubDate>Wed, 07 Oct 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/10/07/installation-and-testing-of-codis-version-two/</guid>
          <description>&lt;p&gt;Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别（有一些命令不支持），上层应用可以像使用单机的 Redis 一样，Codis 底层会处理请求的转发。Codis 支持不停机进行数据迁移, 对于前面的客户端来说是透明的, 可以简单的认为后面连接的是一个内存无限大的 Redis 服务。&lt;/p&gt;

&lt;h3 id=&#34;安装并启动-zookeeper&#34;&gt;安装并启动 zookeeper&lt;/h3&gt;

&lt;p&gt;codis 2.x 版本重度依赖于 zookeeper。&lt;/p&gt;

&lt;p&gt;从官网下载 &lt;a href=&#34;http://zookeeper.apache.org/releases.html&#34;&gt;zookeeper&lt;/a&gt;，解压安装。&lt;/p&gt;

&lt;p&gt;使用默认配置启动 zookeeper &lt;code&gt;sh ./bin/zkServer.sh start&lt;/code&gt;，监听地址为 &lt;code&gt;2181&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;下载安装-codis&#34;&gt;下载安装 codis&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;go get -d github.com/CodisLabs/codis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;进入源码根目录 &lt;code&gt;cd $GOPATH/src/github.com/CodisLabs/codis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;执行安装脚本 &lt;code&gt;./bootstrap.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：这里第一步和第三步（会下载第三方库到本地）需要从 github copy 数据，鉴于网络环境的问题，时间会比较长。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之后生成的可执行文件都在 &lt;code&gt;codis/bin&lt;/code&gt; 文件夹下。&lt;/p&gt;

&lt;h3 id=&#34;部署-codis-server&#34;&gt;部署 codis-server&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;codis-server&lt;/strong&gt; 基于 &lt;strong&gt;redis 2.8.21&lt;/strong&gt; 稍微进行了一些修改以支持原子性的迁移数据，具体用法和 redis 一致。&lt;/p&gt;

&lt;p&gt;将 &lt;code&gt;bin&lt;/code&gt; 文件夹下的 codis-server 拷贝到集群中每个节点，和 redis-server 的启动命令一样，指定配置文件，启动。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这里要注意 redis.conf 配置中需要设置 maxmemory，不然无法自动按照负载均衡的方式分配 slot（可以手动分配），推荐单台机器部署多个 redis 实例。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-server ./redis_conf/redis_6400.conf&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;启动-dashboard&#34;&gt;启动 dashboard&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;dashboard&lt;/strong&gt; 既是 codis 集群的管理中心，又提供了一个人性化的 web 界面，方便查看统计信息以及对集群进行管理操作。&lt;/p&gt;

&lt;p&gt;启动 web 控制面板，注意这里要用到配置文件，不指定的话就是当前目录下的 config.ini，可以用 &lt;code&gt;-c&lt;/code&gt; 参数指定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nohup ./bin/codis-config -c ./config.ini dashboard --addr=:18087 &amp;amp;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;初始化-slot&#34;&gt;初始化 slot&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot init&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;该命令会在 zookeeper 上创建 slot 相关信息。&lt;/p&gt;

&lt;h3 id=&#34;添加-group&#34;&gt;添加 group&lt;/h3&gt;

&lt;p&gt;每个 &lt;strong&gt;group&lt;/strong&gt; 只能有一个 &lt;strong&gt;master&lt;/strong&gt; 和多个 &lt;strong&gt;slave&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;命令格式： &lt;code&gt;codis-config -c ./config.ini server add &amp;lt;group_id&amp;gt; &amp;lt;redis_addr&amp;gt; &amp;lt;role&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;例如向 group 1 和 group 2 中各加入两个 codis-server 实例，一主一从。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 1 localhost:6379 master&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 1 localhost:6380 slave&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 2 localhost:6381 master&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 2 localhost:6382 slave&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1 代表 group_id，必须为数字，且从 1 开始&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;分配-slot&#34;&gt;分配 slot&lt;/h3&gt;

&lt;h4 id=&#34;手动分配&#34;&gt;手动分配&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;codis-config -c ./config.ini slot range-set &amp;lt;slot_from&amp;gt; &amp;lt;slot_to&amp;gt; &amp;lt;group_id&amp;gt; &amp;lt;status&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;slot&lt;/strong&gt; 默认为 &lt;strong&gt;1024&lt;/strong&gt; 个，范围是 &lt;strong&gt;0 - 1023&lt;/strong&gt;，需要将这 1024 个 slot 分配到集群中不同的 group 中。&lt;/p&gt;

&lt;p&gt;例如将 1024 个 slot 平均分配到&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot range-set 0 511 1 online&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot range-set 512 1023 2 online&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;自动分配&#34;&gt;自动分配&lt;/h4&gt;

&lt;p&gt;在 dashboard 上可以自动分配 slot，会按照负载均衡的方式进行分配，不推荐使用，因为可能会造成大量数据的迁移。&lt;/p&gt;

&lt;p&gt;或者使用命令进行自动分配&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot rebalance&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;启动-codis-proxy&#34;&gt;启动 codis-proxy&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-proxy -c ./config.ini -L ./log/proxy.log --cpu=8 --addr=10.10.100.1:19000 --http-addr=10.10.100.1:11000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意：这里 &amp;ndash;addr 和 &amp;ndash;http-addr 不要填 0.0.0.0，要绑定一个具体的 ip，不然 zookeeper 中存的将是hostname，会导致 dashboard 无法连接。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;codis-proxy 是无状态的，可以部署多个，且用 go 编写，可以利用多核，建议 cpu 设置核心数的一半到2/3，19000 即为访问 redis 集群的端口，11000 为获取 proxy 相关状态的端口。&lt;/p&gt;

&lt;p&gt;之后使用 codis-config 将 codis-proxy 加入进来，也就是设置online（后来更新了一个版本，默认启动后即自动注册为online）&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bin/codis-config -c ./config.ini proxy online &amp;lt;proxy_name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;需要注意的是，启动 codis-proxy，会在 zookeeper 中注册一个 node，地址为 /zk/codis/db_test/fence，如果使用 kill -9 强行杀掉进程的话，这个会一直存在，需要手工删除。且 node 名称为 [hostname:port]，所以需要注意这个组合不能重复。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;主从切换&#34;&gt;主从切换&lt;/h3&gt;

&lt;p&gt;官方建议是手工操作，避免数据不一致的问题，但是没有自动容灾的话可用性太差。&lt;/p&gt;

&lt;p&gt;官方另外提供了一个工具，&lt;strong&gt;codis-ha&lt;/strong&gt;，这是一个通过 codis 开放的 api 实现自动切换主从的工具。该工具会在检测到 master 挂掉的时候将其下线并选择其中一个 slave 提升为 master 继续提供服务。&lt;/p&gt;

&lt;p&gt;这个工具不是很好用，如果 codis-ha 连接 dashboard 失败之后进程就会自动退出，需要手动重启或者使用 supervisor 拉起来。另外，当有机器被提升为 master 之后，其他 slave 的状态不会改变，还是从原 master 同步数据。原来的 master 重启之后处于 offline 状态，也需要手动加入 group 指定为 slave。也就是说有master 挂掉后，其余机器的状态需要手动修改。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-ha --codis-config=10.10.100.3:18087 --productName=common&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;10.10.100.14:18088&lt;/code&gt; 为 dashboard 所在机器的 ip 和端口。&lt;/p&gt;

&lt;h3 id=&#34;旧数据的迁移&#34;&gt;旧数据的迁移&lt;/h3&gt;

&lt;p&gt;官方提供了一个 &lt;strong&gt;redis-port&lt;/strong&gt; 工具可以将旧 redis 中的数据实时迁移到 codis 集群中，之后需要修改各服务配置文件，重启服务，指向 codis 集群即可。&lt;/p&gt;

&lt;h3 id=&#34;性能测试&#34;&gt;性能测试&lt;/h3&gt;

&lt;p&gt;测试环境： 24核 2.1GHz，4个redis实例&lt;/p&gt;

&lt;h4 id=&#34;不启用-pipeline&#34;&gt;不启用 pipeline&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;SET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;MSET&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;redis单机&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58997.05&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58651.02&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;33557.05&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis1核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;42973.79&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;33003.30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12295.58&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis4核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;44208.66&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;39936.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;21743.86&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;39478.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;23052.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;24679.17&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis12核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;28943.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;24224.81&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;21376.66&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核2proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62085.65&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;68964.40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;48298.74&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;pipeline-100&#34;&gt;pipeline = 100&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;SET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;MSET&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;redis单机&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;259067.36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;340136.06&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;40387.72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis1核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;158982.52&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;166112.95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15199.88&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis4核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;491159.12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;403551.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;40157.42&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;518134.72&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;537634.38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58156.44&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis12核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;520833.34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;500000.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;53418.80&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核2proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;529812.81&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;607041.47&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62872.28&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;通过测试可以看出，使用 codis 会在性能上比原来直接使用 redis 会有所下降，但是优势就在于可以通过横向扩展（加机器）的方式去提高 redis 的存储容量以及并发量。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>mac上将socks5代理转为http代理</title>
          <link>http://blog.fatedier.com/2015/09/20/trans-socks5-proxy-to-http-proxy-on-mac/</link>
          <pubDate>Sun, 20 Sep 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/09/20/trans-socks5-proxy-to-http-proxy-on-mac/</guid>
          <description>&lt;p&gt;在 mac 上使用 ss 的时候创建的是 socks5 代理，浏览器可以正常设置使用，不过在 shell 中一些程序无法使用 socks5 代理，而需要使用 http 代理，通过设置 http_proxy 环境变量，就可以让 shell 通过 http 代理来访问网络。polipo 这款工具就可以帮助我们将 socks5 代理转换为 http 代理。&lt;/p&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;p&gt;我们使用 &lt;strong&gt;homebrew&lt;/strong&gt; 来安装 &lt;strong&gt;polipo&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;brew install polipo&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建-http-代理&#34;&gt;创建 http 代理&lt;/h3&gt;

&lt;p&gt;假设我们 ss 的 socks5 代理端口为 1080。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;polipo socksParentProxy=localhost:1080&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;执行这条命令后一个 http 代理就已经创建好了，默认监听的端口为 &lt;strong&gt;8123&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我们设置 http 代理端口为 8123 后就可以使用 ss 访问网络。&lt;/p&gt;

&lt;h3 id=&#34;使用-http-代理&#34;&gt;使用 http 代理&lt;/h3&gt;

&lt;p&gt;例如我们使用 wget 获取 google 的首页数据。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;http_proxy=http://127.0.0.1:8123 wget http://www.google.com&lt;/code&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Redis集群调研</title>
          <link>http://blog.fatedier.com/2015/09/15/redis-cluster-survey/</link>
          <pubDate>Tue, 15 Sep 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/09/15/redis-cluster-survey/</guid>
          <description>&lt;p&gt;Redis作为一个使用场景很高的NoSQL数据库，支持了较为丰富的数据类型，相比于其他关系型数据库在性能方面优势明显。互联网公司通常更加倾向于将一些热点数据放入Redis中来承载高吞吐量的访问。&lt;/p&gt;

&lt;p&gt;单机Redis在普通的服务器上通常ops上限在5w左右，开启pipeline的情况下在20-30w左右。对于大多数中小公司来说，通常单机的Redis已经足够，最多根据不同业务分散到多台Redis。&lt;/p&gt;

&lt;h3 id=&#34;为什么需要集群&#34;&gt;为什么需要集群&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Redis单线程特性，多请求顺序执行，单个耗时的操作会阻塞后续的操作&lt;/li&gt;
&lt;li&gt;单机内存有限&lt;/li&gt;
&lt;li&gt;某些特殊业务，带宽压力较大&lt;/li&gt;
&lt;li&gt;单点问题，缺乏高可用性&lt;/li&gt;
&lt;li&gt;不能动态扩容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Redis集群的目标就是为了实现高可用性，避免性能瓶颈，可动态扩容，易于做监控告警。&lt;/p&gt;

&lt;h3 id=&#34;三种主流的集群解决方案&#34;&gt;三种主流的集群解决方案&lt;/h3&gt;

&lt;h4 id=&#34;客户端静态分片&#34;&gt;客户端静态分片&lt;/h4&gt;

&lt;p&gt;通常需要 smart-client 支持，在业务程序端根据预先设置的路由规则进行分片，从而实现对多个redis实例的分布式访问。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-09-15-redis-cluster-survey-jedis.png&#34; alt=&#34;jedis&#34; /&gt;&lt;/p&gt;

&lt;p&gt;鉴于redis本身的高性能，并且有一些设计良好的第三方库，例如java开发者可以使用jedis，所以很多小公司使用此方案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt; 相比于使用代理，减少了一层网络传输的消耗，效率较高。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt; 当redis实例需要扩容或切换的情况下，需要修改业务端的程序，较为麻烦。并且需  要维护各个语言的客户端版本，如果要升级客户端成本也会比较高。出现故障时难以及时定位问题。（有些smart-client借助于zookeeper维护客户端访问redis实例的一致性）&lt;/p&gt;

&lt;h4 id=&#34;proxy分片&#34;&gt;Proxy分片&lt;/h4&gt;

&lt;p&gt;通过统一的代理程序访问多个redis实例，比如业内曾广泛使用的 twemproxy 以及 豌豆荚开源的 codis。（twemproxy是twitter开源的一个redis和memcache代理服务器，只用于作为简单的代理中间件，目前twitter内部已经不再使用）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt; 业务程序端只需要使用普通的api去访问代理程序即可。各种组件分离，以后升级较为容易。也避免了客户端需要维持和每个redis实例的长连接导致连接数过多。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt; 增加了一层中间件，增加了网络和数据处理的消耗，性能下降。&lt;/p&gt;

&lt;h4 id=&#34;official-redis-cluster&#34;&gt;Official Redis Cluster&lt;/h4&gt;

&lt;p&gt;Redis3.0之后的版本开始正式支持 redis cluster，核心目标是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;性能：&lt;/strong&gt;Redis作者比较看重性能，增加集群不能对性能有较大影响，所以Redis采用了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;水平扩展：&lt;/strong&gt;官方文档中称目标是能线性扩展到1000结点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可用性：&lt;/strong&gt;集群具有了以前Sentinel的监控和自动Failover能力。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;基于twemproxy的redis集群环境&#34;&gt;基于twemproxy的redis集群环境&lt;/h3&gt;

&lt;h4 id=&#34;整体架构图&#34;&gt;整体架构图&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-09-15-redis-cluster-survey-twemproxy-architecture.png&#34; alt=&#34;twemproxy_architecture&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;twemproxy的特点&#34;&gt;twemproxy的特点&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;支持失败的节点自动摘除（仅作为缓存时）&lt;/li&gt;
&lt;li&gt;所有的key通过一致性哈希算法分布到集群中所有的redis实例中&lt;/li&gt;
&lt;li&gt;代理与每个redis实例维持长连接，减少客户端和redis实例的连接数&lt;/li&gt;
&lt;li&gt;代理是无状态的，可以任意部署多套，避免单点问题&lt;/li&gt;
&lt;li&gt;默认启用pipeline，连接复用，提高效率，性能损失在 10% - 20%&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;集群组件&#34;&gt;集群组件&lt;/h4&gt;

&lt;p&gt;由于twemproxy本身只是简单的代理，所以需要依赖于一些其他的程序组件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redis Sentinel：&lt;/strong&gt; 管理主从备份，用于主从切换，当主服务器挂掉后，自动将从服务器提升为主服务器&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redis-Twemproxy Agent：&lt;/strong&gt; nodejs写的一个监控程序，用于监听 redis-sentinel 的 master 切换事件，并且及时更新twemproxy的配置文件后将其重新启动&lt;/p&gt;

&lt;h4 id=&#34;why-not-twemproxy&#34;&gt;Why not Twemproxy&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;虽然使用 c 开发，性能损失较小，但同样是单线程。所以基本上twemproxy的数量需要和后端redis实例一样甚至更多才能充分发挥多实例的并发能力，造成运维困难。&lt;/li&gt;
&lt;li&gt;twemproxy更改配置文件需要重新启动，比较坑，需要修改代码使其支持动态加载。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无法动态扩容&lt;/strong&gt;，如果需要实现这个功能，要么自己写迁移脚本，手动迁移，比较繁琐，还会影响到当前服务的正常运行。或者二次开发，增加对zookeeper的依赖，将redis节点信息以及hash域相关的数据存储在zookeeper上，然后增加动态迁移数据的模块，可以在不影响现有服务运行的情况下完成增删实例。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;redis-cluster&#34;&gt;Redis Cluster&lt;/h3&gt;

&lt;h4 id=&#34;数据分布-预分片&#34;&gt;数据分布：预分片&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-09-15-redis-cluster-survey-redis-cluster-pre-sharding.png&#34; alt=&#34;redis-cluster-pre-sharding&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;预先分配好 16384 个slot&lt;/li&gt;
&lt;li&gt;slot 和 server 的映射关系存储每一个 server 的路由表中&lt;/li&gt;
&lt;li&gt;根据 CRC16(key) mod 16384 的值，决定将一个key放到哪一个slot中&lt;/li&gt;
&lt;li&gt;数据迁移时就是调整 slot 的分布&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;架构-去中心化&#34;&gt;架构：去中心化&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-09-15-redis-cluster-survey-redis-cluster-architecture.png&#34; alt=&#34;redis-cluster-architecture&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无中心结构，每个节点都保存数据和整个集群的状态。&lt;/li&gt;
&lt;li&gt;采用 gossip 协议传播信息以及发现新节点（最终一致性）。

&lt;ul&gt;
&lt;li&gt;每个节点都和其他所有节点连接，并保持活跃。&lt;/li&gt;
&lt;li&gt;PING/PONG：心跳，附加上自己以及一些其他节点数据，每个节点每秒随机PING几个节点。会选择那些超过cluster-node-timeout一半的时间还未PING过或未收到PONG的节点。&lt;/li&gt;
&lt;li&gt;UPDATE消息：计数戳，如果收到server的计数为3，自己的为4，则发UPDATE更新对方路由表，反之更新自己的路由表，最终集群路由状态会和计数戳最大的实例一样。&lt;/li&gt;
&lt;li&gt;如果 cluster-node-timeout 设置较小，或者节点较多，数据传输量将比较可观。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Broadcast：有状态变动时先broadcast，后PING； 发布/订阅。&lt;/li&gt;
&lt;li&gt;Redis node 不作为client请求的代理（不转发请求），client根据node返回的错误信息重定向请求?（需要 smart-client 支持），所以client连接集群中任意一个节点都可以。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;可用性-master-slave&#34;&gt;可用性：Master-Slave&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;每个Redis Node可以有一个或者多个Slave，当Master挂掉时，选举一个Slave形成新的Master。&lt;/li&gt;
&lt;li&gt;Master Slave 之间异步复制（可能会丢数据）。&lt;/li&gt;
&lt;li&gt;采用 gossip 协议探测其他节点存活状态，超过 cluster-node-timeout，标记为 PFAIL，PING中附加此数据。当 Node A发现半数以上master将失效节点标记为PFAIL，将其标记为FAIL，broadcast FAIL。&lt;/li&gt;
&lt;li&gt;各 slave 等待一个随机时间后 发起选举，向其他 master broadcast，半数以上同意则赢得选举否则发起下一次选举&lt;/li&gt;
&lt;li&gt;当 slave 成为 master，先broadcast，后持续PING，最终集群实例都获知此消息&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;存在的问题&#34;&gt;存在的问题&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Gossip协议通信开销&lt;/li&gt;
&lt;li&gt;严重依赖于smart-client的成熟度

&lt;ul&gt;
&lt;li&gt;如果smart-client支持缓存slot路由，需要额外占用内存空间，为了效率需要建立和所有 redis server 的长连接（每一个使用该库的程序都需要建立这么多连接）。&lt;/li&gt;
&lt;li&gt;如果不支持缓存路由信息，会先访问任意一台 redis server，之后重定向到新的节点。&lt;/li&gt;
&lt;li&gt;需要更新当前所有的client。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;官方只提供了一个ruby程序 redis-trib 完成集群的所有操作，缺乏监控管理工具，很难清楚目前集群的状态&lt;/li&gt;
&lt;li&gt;数据迁移以Key为单位，速度较慢&lt;/li&gt;
&lt;li&gt;某些操作不支持，MultiOp和Pipeline都被限定在命令中的所有Key必须都在同一Slot内&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;codis&#34;&gt;Codis&lt;/h3&gt;

&lt;h4 id=&#34;what-is-codis&#34;&gt;What is Codis ？&lt;/h4&gt;

&lt;p&gt;Go语言开发的分布式 Redis 解决方案，对于上层的应用来说，访问 codis 和原生的 redis server 没有明显区别（不支持发布订阅等某些命令，支持 pipeline）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-09-15-redis-cluster-survey-codis-architecture.png&#34; alt=&#34;codis-architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Codis由四部分组成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Codis Proxy (codis-proxy)&lt;/li&gt;
&lt;li&gt;Codis Dashboard (codis-config)&lt;/li&gt;
&lt;li&gt;Codis Redis (codis-server)&lt;/li&gt;
&lt;li&gt;ZooKeeper/Etcd&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;codis-proxy 是客户端连接的 Redis 代理服务, codis-proxy 本身实现了 Redis 协议, 表现得和一个原生的 Redis 没什么区别 (就像 Twemproxy), 对于一个业务来说, 可以部署多个 codis-proxy, codis-proxy 本身是无状态的。&lt;/p&gt;

&lt;p&gt;codis-config 是 Codis 的管理工具, 支持包括, 添加/删除 Redis 节点, 添加/删除 Proxy 节点, 发起数据迁移等操作. codis-config 本身还自带了一个 http server, 会启动一个 dashboard, 用户可以直接在浏览器上观察 Codis 集群的运行状态。&lt;/p&gt;

&lt;p&gt;codis-server 是 Codis 项目维护的一个 Redis 分支, 基于 2.8.21 开发, 加入了 slot 的支持和原子的数据迁移指令. Codis 上层的 codis-proxy 和 codis-config 只能和这个版本的 Redis 交互才能正常运行。&lt;/p&gt;

&lt;p&gt;Codis 依赖 ZooKeeper 来存放数据路由表和 codis-proxy 节点的元信息, codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。&lt;/p&gt;

&lt;p&gt;Codis 支持按照 Namespace 区分不同的产品, 拥有不同的 product name 的产品, 各项配置都不会冲突。&lt;/p&gt;

&lt;h4 id=&#34;整体设计&#34;&gt;整体设计&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;预分片，1024 slot， key =&amp;gt; crc32(key)%1024&lt;/li&gt;
&lt;li&gt;proxy无状态，便于负载均衡，启动时在 Zookeeper 上注册一个临时节点，方便做 HA&lt;/li&gt;
&lt;li&gt;Redis 只作为存储引擎&lt;/li&gt;
&lt;li&gt;Go语言开发，可以充分利用多核，不必像 twemproxy 一样部署很多套&lt;/li&gt;
&lt;li&gt;性能损失，在不开启pipeline的情况下会损失大概40%，通过加实例线性扩展&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
      
    
      
    
      
        <item>
          <title>如何修改进程的名称</title>
          <link>http://blog.fatedier.com/2015/08/24/how-to-modify-process-name/</link>
          <pubDate>Mon, 24 Aug 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/08/24/how-to-modify-process-name/</guid>
          <description>&lt;p&gt;在开发 php 扩展的过程中，希望能创建一个独立的子进程做一些额外的处理工作，并且为子进程修改一个有意义的名称，发现还是有一些难度的。&lt;/p&gt;

&lt;h3 id=&#34;效果预览&#34;&gt;效果预览&lt;/h3&gt;

&lt;p&gt;要实现的效果就像 nginx 启动后通过 ps 查到的名称一样，这个名称就是自定义的，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-08-24-how-to-modify-process-name-nginx-process-name.png&#34; alt=&#34;nginx-process-name&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;方法一&#34;&gt;方法一&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;prctl(PR_SET_NAME, name);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个函数可以将当前进程的名称修改为 &lt;code&gt;name&lt;/code&gt; 的内容。&lt;/p&gt;

&lt;p&gt;我测试了一下，发现只有使用 &lt;code&gt;ps -L&lt;/code&gt; 才能看到，达不到想要的效果。&lt;/p&gt;

&lt;h3 id=&#34;方法二&#34;&gt;方法二&lt;/h3&gt;

&lt;p&gt;参考了 &lt;strong&gt;nginx&lt;/strong&gt; 中的源码，主要是通过修改 &lt;strong&gt;argv[0]&lt;/strong&gt; 的值来实现的，但是需要注意将后面跟着的 &lt;strong&gt;environ&lt;/strong&gt; 环境表中的信息移到其他地方，避免被覆盖。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void set_proctitle(char** argv, const char* new_name)
{
    int size = 0;
    int i;
    // 申请新的空间存放 environ 中内容
    for (i = 0; environ[i]; i++) {
        size += strlen(environ[i]) + 1;
    }
    char* p = (char*)malloc(size);
    char* last_argv = argv[0];
    for (i = 0; argv[i]; i++) {
        if (last_argv == argv[i]) {
            last_argv = argv[i] + strlen(argv[i]) + 1;
        }
    }  
    for (i = 0; environ[i]; i++) {
        if (last_argv == environ[i]) {
            size = strlen(environ[i]) + 1;
            last_argv = environ[i] + size;  
   
            memcpy(p, environ[i], size);
            environ[i] = (char*)p;
            p += size;
        }  
    }
    last_argv--;
    // 修改 argv[0]，argv剩余的空间全部填0
    strncpy(argv[0], new_name, last_argv - argv[0]);
    p = argv[0] + strlen(argv[0]) + 1;
    if (last_argv - p &amp;gt; 0) {
        memset(p, 0, last_argv - p);
    }  
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;稍微解释一下，每一个 c 程序都有个 main 函数，作为程序启动入口函数。main 函数的原型是 &lt;code&gt;int main(int argc , char *argv[])&lt;/code&gt;，其中 &lt;strong&gt;argc&lt;/strong&gt; 表示命令行参数的个数，&lt;strong&gt;argv&lt;/strong&gt; 是一个指针数组，保存所有命令行字符串。Linux进程名称是通过命令行参数 &lt;strong&gt;argv[0]&lt;/strong&gt; 来表示的。&lt;/p&gt;

&lt;p&gt;而进程执行时的环境变量信息的存储地址就是紧接着 &lt;strong&gt;argv&lt;/strong&gt; 之后，通过 &lt;code&gt;char **environ&lt;/code&gt; 变量来获取，类似于下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-08-24-how-to-modify-process-name-argv-info.png&#34; alt=&#34;argv-info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于我们需要修改 &lt;strong&gt;argv[0]&lt;/strong&gt; 的值，有可能新的字符串的长度超过原来 &lt;strong&gt;argv&lt;/strong&gt; 中所有字符串长度的总和，又因为 &lt;strong&gt;environ&lt;/strong&gt; 在内存空间上是紧跟着 &lt;strong&gt;argv&lt;/strong&gt; 的，我们如果直接修改 &lt;strong&gt;argv[0]&lt;/strong&gt; 的值，有可能会覆盖掉 &lt;strong&gt;environ&lt;/strong&gt; 的内存空间，所以需要先将 &lt;strong&gt;environ&lt;/strong&gt; 的内容 copy 到一块新的内存空间，之后再将 &lt;strong&gt;environ&lt;/strong&gt; 指针指向新的空间。&lt;/p&gt;

&lt;h3 id=&#34;php-扩展中遇到的困难&#34;&gt;php 扩展中遇到的困难&lt;/h3&gt;

&lt;p&gt;在修改 php 扩展中 fork 的子进程名称时遇到了问题，由于 php 扩展是注入的方式，提供的动态库，无法获取到从 &lt;strong&gt;main&lt;/strong&gt; 函数传入过来的 &lt;strong&gt;argv&lt;/strong&gt; 参数的地址。&lt;/p&gt;

&lt;p&gt;经过测试，发现 &lt;strong&gt;environ&lt;/strong&gt; 是一个全局变量，可以获取到它的地址，而 &lt;strong&gt;argv&lt;/strong&gt; 中内容可以用另外一种方式取得，通过查看 &lt;code&gt;/proc/10000/cmdline&lt;/code&gt; 中的值（10000是该进程的进程号），可以获取命令行启动参数的字符串（也就是 &lt;strong&gt;argv&lt;/strong&gt; 中的内容，如果 &lt;strong&gt;argv&lt;/strong&gt; 没有被其他代码修改过的话），所以用 &lt;strong&gt;environ&lt;/strong&gt; 的地址减去 &lt;strong&gt;cmdline&lt;/strong&gt; 中字符串的长度就可以得到 &lt;strong&gt;argv[0]&lt;/strong&gt; 的地址。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：需要注意的是 cmdline 不是一个普通文件，不能用 stat 或者 ftell 等函数来获取长度，必须用 read 等读取文件的函数去读取。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;参考代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void set_proctitle_unsafe(const char* new_name)
{
    // 获取该进程的启动参数字符串
    int pid = getpid();
    char file_name[100];
    snprintf(file_name, sizeof(file_name), &amp;quot;/proc/%d/cmdline&amp;quot;, pid);

    int fd = open(file_name, O_RDONLY);
    if (fd &amp;lt; 0)
        return;

    char tempCmd[513];
    long cmd_length = read(fd, tempCmd, sizeof(tempCmd));
    close(fd);

    // 获取 argv[0] 的地址
    char *argv = environ[0];
    argv = argv - cmd_length;

    int size = 0;
    int i;
    // 申请新的空间存放 environ 中内容
    for (i = 0; environ[i]; i++) {
        size += strlen(environ[i]) + 1;
    }
    char* p = (char*)malloc(size);

    char* last_argv = argv;
    last_argv = argv + cmd_length;

    for (i = 0; environ[i]; i++) {
        if (last_argv == environ[i]) {
            size = strlen(environ[i]) + 1;
            last_argv = environ[i] + size;

            memcpy(p, environ[i], size);
            environ[i] = (char*)p;
            p += size;
        }
    }
    last_argv--;

    // 修改 argv[0] 的内容
    strncpy(argv, new_name, last_argv - argv);
    p = (argv) + strlen(argv) + 1;
    if (last_argv - p &amp;gt; 0) {
        memset(p, 0, last_argv - p);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个函数是不安全的，需要小心使用，因为不能确定 &lt;strong&gt;environ&lt;/strong&gt; 的地址是否已经被其他人修改过了，比如在 php 扩展中，有可能已经被其他程序用同样的方法修改过，这样就会造成获取到的 &lt;strong&gt;argv[0]&lt;/strong&gt; 的地址是未知的，执行的程序可能就会出现内存错误。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>go语言中使用smtp发送邮件及smtp协议的相关问题</title>
          <link>http://blog.fatedier.com/2015/08/20/use-smtp-to-sendmail-in-go-and-some-problems-with-smtp/</link>
          <pubDate>Thu, 20 Aug 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/08/20/use-smtp-to-sendmail-in-go-and-some-problems-with-smtp/</guid>
          <description>&lt;p&gt;go 的标准库中有一个 smtp 包提供了一个可以非常方便的使用 smtp 协议发送邮件的函数，通常情况下使用起来简单方便，不过我在使用中却意外遇到了一个会导致邮件发送出错的情况。&lt;/p&gt;

&lt;h3 id=&#34;smtp-协议发送邮件&#34;&gt;smtp 协议发送邮件&lt;/h3&gt;

&lt;h4 id=&#34;sendmail-函数&#34;&gt;sendmail 函数&lt;/h4&gt;

&lt;p&gt;go 标准库的 net/smtp 包提供了一个 SendMail 函数用于发送邮件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func SendMail(addr string, a Auth, from string, to []string, msg []byte) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;SendMail&lt;/strong&gt;： 连接到 &lt;strong&gt;addr&lt;/strong&gt; 指定的服务器；如果支持会开启 &lt;strong&gt;TLS&lt;/strong&gt;；如果支持会使用 &lt;strong&gt;a(Auth)&lt;/strong&gt; 认证身份；然后以 &lt;strong&gt;from&lt;/strong&gt; 为邮件源地址发送邮件 &lt;strong&gt;msg&lt;/strong&gt; 到目标地址 &lt;strong&gt;to&lt;/strong&gt;。（可以是多个目标地址：群发）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;addr&lt;/strong&gt;： 邮件服务器的地址。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a&lt;/strong&gt;： 身份认证接口，可以由 &lt;code&gt;func PlainAuth(identity, username, password, host string) Auth&lt;/code&gt; 函数创建。&lt;/p&gt;

&lt;h4 id=&#34;简单发送邮件示例&#34;&gt;简单发送邮件示例&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;net/smtp&amp;quot;
    &amp;quot;strings&amp;quot;
)

func main() {
    auth := smtp.PlainAuth(&amp;quot;&amp;quot;, &amp;quot;username@qq.com&amp;quot;, &amp;quot;passwd&amp;quot;, &amp;quot;smtp.qq.com&amp;quot;)
    to := []string{&amp;quot;to-user@qq.com&amp;quot;}
    nickname := &amp;quot;test&amp;quot;
    user := &amp;quot;username@qq.com&amp;quot;
    subject := &amp;quot;test mail&amp;quot;
    content_type := &amp;quot;Content-Type: text/plain; charset=UTF-8&amp;quot;
    body := &amp;quot;This is the email body.&amp;quot;
    msg := []byte(&amp;quot;To: &amp;quot; + strings.Join(to, &amp;quot;,&amp;quot;) + &amp;quot;\r\nFrom: &amp;quot; + nickname +
        &amp;quot;&amp;lt;&amp;quot; + user + &amp;quot;&amp;gt;\r\nSubject: &amp;quot; + subject + &amp;quot;\r\n&amp;quot; + content_type + &amp;quot;\r\n\r\n&amp;quot; + body)
    err := smtp.SendMail(&amp;quot;smtp.qq.com:25&amp;quot;, auth, user, to, msg)
    if err != nil {
        fmt.Printf(&amp;quot;send mail error: %v&amp;quot;, err)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;autu&lt;/strong&gt;： 这里采用简单的明文用户名和密码的认证方式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;nickname&lt;/strong&gt;： 发送方的昵称。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;subject&lt;/strong&gt;： 邮件主题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;content_type&lt;/strong&gt;： 可以有两种方式，一种 text/plain，纯字符串，不做转义。一种 text/html，会展示成 html 页面。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;body&lt;/strong&gt;： 邮件正文内容。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;msg&lt;/strong&gt;： msg 的内容需要遵循 smtp 协议的格式，参考上例。&lt;/p&gt;

&lt;h3 id=&#34;特定邮件服务器出错&#34;&gt;特定邮件服务器出错&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;certificate signed by unknown authority
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在通过公司内部自己搭建的邮件服务器发送邮件时报了上述错误，看上去是因为认证不通过的问题，检查了一下用户名和密码没有问题。&lt;/p&gt;

&lt;p&gt;我通过抓包以及手动 telnet 执行了一遍 smtp 的过程，发送问题出现在是否加密和身份验证上。&lt;/p&gt;

&lt;h4 id=&#34;smtp-协议&#34;&gt;SMTP 协议&lt;/h4&gt;

&lt;p&gt;smtp 协议开始时客户端主动向邮件服务器发送 &lt;code&gt;EHLO&lt;/code&gt;，服务器会返回支持的所有命令，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;250-PIPELINING
250-SIZE 10240000
250-VRFY
250-ETRN
250-STARTTLS
250-AUTH PLAIN LOGIN
250-AUTH=PLAIN LOGIN
250-ENHANCEDSTATUSCODES
250-8BITMIME
250 DSN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果有 &lt;strong&gt;STARTTLS&lt;/strong&gt;，说明支持加密传输，golang 的标准库中会进行判断然后决定是否选择使用 &lt;strong&gt;STARTTLS&lt;/strong&gt; 加密传输。&lt;/p&gt;

&lt;p&gt;如果没有 &lt;strong&gt;AUTH=PLAIN LOGIN&lt;/strong&gt;，说明不支持 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式。&lt;/p&gt;

&lt;p&gt;一共有3种验证方式，可以参考这篇 blog： &lt;a href=&#34;http://blog.csdn.net/mhfh611/article/details/9470599&#34;&gt;http://blog.csdn.net/mhfh611/article/details/9470599&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;starttls-引起的错误&#34;&gt;STARTTLS 引起的错误&lt;/h4&gt;

&lt;p&gt;公司内部的邮件服务器返回了 &lt;strong&gt;STARTTLS&lt;/strong&gt;，但是实际上却不支持加密传输的认证方式，所以就导致了身份认证失败。&lt;/p&gt;

&lt;p&gt;大部分国内的邮件服务器都支持 &lt;strong&gt;LOGIN&lt;/strong&gt; 和 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式，所以我们可以在代码中直接采用 &lt;strong&gt;PLAIN&lt;/strong&gt; 的方式，不过安全性就降低了。&lt;/p&gt;

&lt;p&gt;想要强制使用 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式也不是这么容易的，因为涉及到修改 &lt;strong&gt;net/smtp&lt;/strong&gt; 的 &lt;code&gt;SendMail&lt;/code&gt; 函数，当然标准库我们修改不了，所以只能重新实现一个 &lt;code&gt;SendMail&lt;/code&gt; 函数。&lt;/p&gt;

&lt;p&gt;标准库中 &lt;code&gt;SendMail&lt;/code&gt; 函数代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func SendMail(addr string, a Auth, from string, to []string, msg []byte) error {
    c, err := Dial(addr)
    if err != nil {
        return err
    }
    defer c.Close()
    if err = c.hello(); err != nil {
        return err
    }
    if ok, _ := c.Extension(&amp;quot;STARTTLS&amp;quot;); ok {
        config := &amp;amp;tls.Config{ServerName: c.serverName}
        if testHookStartTLS != nil {
            testHookStartTLS(config)
        }
        if err = c.StartTLS(config); err != nil {
            return err
        }
    }
    if a != nil &amp;amp;&amp;amp; c.ext != nil {
        if _, ok := c.ext[&amp;quot;AUTH&amp;quot;]; ok {
            if err = c.Auth(a); err != nil {
                return err
            }
        }
    }
    if err = c.Mail(from); err != nil {
        return err
    }
    for _, addr := range to {
        if err = c.Rcpt(addr); err != nil {
            return err
        }
    }
    w, err := c.Data()
    if err != nil {
        return err
    }
    _, err = w.Write(msg)
    if err != nil {
        return err
    }
    err = w.Close()
    if err != nil {
        return err
    }
    return c.Quit()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重点就在于下面这一段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;if ok, _ := c.Extension(&amp;quot;STARTTLS&amp;quot;); ok {
    config := &amp;amp;tls.Config{ServerName: c.serverName}
    if testHookStartTLS != nil {
        testHookStartTLS(config)
    }
    if err = c.StartTLS(config); err != nil {
        return err
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;逻辑上就是检查服务器端对于 &lt;strong&gt;EHLO&lt;/strong&gt; 命令返回的所支持的命令中是否有 &lt;strong&gt;STARTTLS&lt;/strong&gt;，如果有，则采用加密传输的方式。我们自己实现的函数中直接把这部分去掉。&lt;/p&gt;

&lt;p&gt;我们仿照 &lt;code&gt;SendMail&lt;/code&gt; 函数实现一个 &lt;code&gt;NewSendMail&lt;/code&gt; 函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func NewSendMail(addr string, a smtp.Auth, from string, to []string, msg []byte) error {
    c, err := smtp.Dial(addr)
    if err != nil {
        return err 
    }   
    defer c.Close()
    if err = c.Hello(&amp;quot;localhost&amp;quot;); err != nil {
        return err 
    }   
    err = c.Auth(a)
    if err != nil {
        return err 
    }   

    if err = c.Mail(from); err != nil {
        fmt.Printf(&amp;quot;mail\n&amp;quot;)
        return err 
    }   
    for _, addr := range to {
        if err = c.Rcpt(addr); err != nil {
            return err 
        }   
    }
    w, err := c.Data()
    if err != nil {
        return err
    }
    _, err = w.Write(msg)
    if err != nil {
        return err
    }
    err = w.Close()
    if err != nil {
        return err
    }
    return c.Quit()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个函数发送邮件，则身份认证时不会采用加密的方式，而是直接使用 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>关于vim的一些小技巧</title>
          <link>http://blog.fatedier.com/2015/07/30/some-skills-about-vim/</link>
          <pubDate>Thu, 30 Jul 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/07/30/some-skills-about-vim/</guid>
          <description>&lt;p&gt;记录一下关于 vim 中一些使用频率也许并不高的小技巧。&lt;/p&gt;

&lt;h3 id=&#34;插入与删除&#34;&gt;插入与删除&lt;/h3&gt;

&lt;h4 id=&#34;插入&#34;&gt;插入&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;A&lt;/code&gt; 在行末插入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;I&lt;/code&gt; 在行首插入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;O&lt;/code&gt; 在上一行插入&lt;/p&gt;

&lt;h4 id=&#34;替换字符&#34;&gt;替换字符&lt;/h4&gt;

&lt;p&gt;普通模式下，先按下 &lt;code&gt;r&lt;/code&gt; 再按下其他按键，就是使用新的字符替换旧字符。&lt;/p&gt;

&lt;h4 id=&#34;删除&#34;&gt;删除&lt;/h4&gt;

&lt;p&gt;普通模式下，&lt;code&gt;ct;&lt;/code&gt; 依次按下三个按键，&lt;code&gt;c&lt;/code&gt; 表示删除这部分内容后直接进行插入模式，&lt;code&gt;t;&lt;/code&gt; 表示从当前位置到这一行中下一个出现 &lt;code&gt;;&lt;/code&gt; 号之前的位置，合在一起就是删除这之间的内容。 &lt;code&gt;c&lt;/code&gt; 换成 &lt;code&gt;d&lt;/code&gt; 的话就是删除当前位置到这一行中下一个出现 &lt;code&gt;;&lt;/code&gt; 之前的内容，但是不进入插入模式。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;di&amp;quot;&lt;/code&gt; 将当前行第一次出现两个 &lt;code&gt;&amp;quot;&lt;/code&gt; 之间的内容全部清空并且进入插入模式。&lt;/p&gt;

&lt;h3 id=&#34;移动&#34;&gt;移动&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;f;&lt;/code&gt; 表示移动到这一行中下一个 &lt;code&gt;;&lt;/code&gt; 号的位置。&lt;/p&gt;

&lt;h3 id=&#34;vimgrep&#34;&gt;vimgrep&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;vimgrep /匹配模式/[g][j]&lt;/code&gt; 要搜索的文件/范围&lt;/p&gt;

&lt;p&gt;&lt;code&gt;g&lt;/code&gt; 表示是否把每一行的多个匹配结果都加入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;j&lt;/code&gt; 表示是否搜索完后定位到第一个匹配位置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vimgrep /pattern/ %           // 在当前打开文件中查找
vimgrep /pattern/ *           // 在当前目录下查找所有
vimgrep /pattern/ **          // 在当前目录及子目录下查找所有
vimgrep /pattern/ *.c         // 查找当前目录下所有.c文件
vimgrep /pattern/ **/*        // 只查找子目录
cn                            // 查找下一个
cp                            // 查找上一个
copen                         // 打开quickfix
cw                            // 打开quickfix
cclose                        // 关闭qucikfix
help vimgrep                  // 查看vimgrep帮助
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;从vim正文复制单词到vim命令行&#34;&gt;从vim正文复制单词到vim命令行&lt;/h3&gt;

&lt;p&gt;例如使用 &lt;code&gt;vimgrep&lt;/code&gt; 搜索时，光标先移动到要复制的单词的起始位置，之后切到命令模式， 先按 &lt;code&gt;ctrl + r&lt;/code&gt; ，之后再按 &lt;code&gt;ctrl + w&lt;/code&gt; 即可。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>SSH 端口转发</title>
          <link>http://blog.fatedier.com/2015/07/22/ssh-port-forwarding/</link>
          <pubDate>Wed, 22 Jul 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/07/22/ssh-port-forwarding/</guid>
          <description>&lt;p&gt;作为程序员经常会有需要访问某个局域网内的某台机器的需求，例如帮别人调试某个程序，或者远程操作家里的电脑。&lt;/p&gt;

&lt;p&gt;之前是使用向日葵 VPN 和 Teamview 的方式在家里通过 ssh 访问公司内网的台式机，速度不是很理想。后来发现 SSH 端口转发可以实现类似的功能，走自己的服务器，果断尝试，这种连接方式的速度非常快，开发效率提高很多。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一台公司和家里都能访问的具有公网 IP 的机器 B，IP 假设为 11.11.11.11&lt;/li&gt;
&lt;li&gt;家里的笔记本 C&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在机器 A 上执行下面的命令&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh -oPort=22 -CNfg -R 40000:localhost:22 root@11.11.11.11&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-oPort&lt;/code&gt; 是指定用于连接 11.11.11.11 的 SSH 的端口。
&lt;code&gt;-C&lt;/code&gt; 要求进行数据压缩。
&lt;code&gt;-N&lt;/code&gt; 不执行远程命令，用于转发端口。
&lt;code&gt;-f&lt;/code&gt;  要求在执行命令前退至后台. 它用于当准备询问口令或密语, 但是用户希望它在后台进行。该选项隐含了 &lt;code&gt;-n&lt;/code&gt; 选项。
&lt;code&gt;-g&lt;/code&gt; 允许远端主机连接本地转发的端口。
&lt;code&gt;40000&lt;/code&gt; 有公网 IP 的机器绑定的端口，该端口的流量会被转发到指定的 Local IP 和 Port。
&lt;code&gt;localhost:22&lt;/code&gt; 需要转发的本地 IP 和端口，localhost 可以为 A 机器可访问到的其他机器的 IP 地址。&lt;/p&gt;

&lt;p&gt;这样在家里的笔记本 C 通过 SSH 登录 11.11.11.11 主机 B，再通过 ssh 连接本地的 40000 端口，这时候就相当于是连接到了内网的机器 A 的 22 端口，就实现了远程 SSH 连接内网的台式机。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：需要注意的是如果连接空闲一段时间的话，可能就会断开。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;解决空闲连接断开的问题&#34;&gt;解决空闲连接断开的问题&lt;/h3&gt;

&lt;h4 id=&#34;修改客户端配置&#34;&gt;修改客户端配置&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;找到所在用户的 &lt;code&gt;.ssh&lt;/code&gt; 目录，如 root 用户该目录在：&lt;code&gt;/root/.ssh/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在该目录创建 config 文件 &lt;code&gt;touch /root/.ssh/config&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;加入下面一句：&lt;code&gt;ServerAliveInterval 60&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;保存退出，重新开启 root 用户的 shell，则再 ssh 远程服务器的时候，不会因为长时间没有操作而断开。应该是加入这句之后，ssh 客户端会每隔一段时间自动与 ssh 服务器通信一次，保持心跳。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;修改服务器端配置&#34;&gt;修改服务器端配置&lt;/h4&gt;

&lt;p&gt;通过修改 &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt; 中的配置解决自动断开的问题。下面是要修改的两个配置项的含义：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ClientAliveInterval&lt;/strong&gt; 指定了服务器端向客户端请求消息的时间间隔, 默认是 0, 不发送。而 &lt;strong&gt;ClientAliveInterval 60&lt;/strong&gt; 表示每分钟发送一次，然后客户端响应，这样就保持长连接了。这里比较怪的地方是：不是客户端主动发起保持连接的请求（如FTerm, CTerm等），而是需要服务器先主动。
至于 &lt;strong&gt;ClientAliveCountMax&lt;/strong&gt;，使用默认值 3 即可。&lt;strong&gt;ClientAliveCountMax&lt;/strong&gt; 表示服务器发出请求后客户端没有响应的次数达到一定值, 就自动断开。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>MongoDB常用命令</title>
          <link>http://blog.fatedier.com/2015/06/05/common-commands-of-mongodb/</link>
          <pubDate>Fri, 05 Jun 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/06/05/common-commands-of-mongodb/</guid>
          <description>&lt;p&gt;MongoDB 是一个基于分布式文件存储的数据库，由C++编写，介于关系数据库和非关系数据库之间的产品，所以在很多业务上可以取代 mysql，提供更高的性能以及更好的扩展性。虽然 MongoDB 不支持 sql 语法，但是从常用的操作命令上来说和 sql 的用法相类似。&lt;/p&gt;

&lt;h4 id=&#34;查询有哪些数据库&#34;&gt;查询有哪些数据库&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;show dbs&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;切换数据库&#34;&gt;切换数据库&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;use &amp;lt;db_name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果数据库不存在，则创建数据库，否则切换到指定数据库。但是只有在数据库中插入数据，才会在查询数据库列表时显示。&lt;/p&gt;

&lt;h4 id=&#34;查询当前数据库的所有集合&#34;&gt;查询当前数据库的所有集合&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.getCollectionNames()&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查看指定集合的状态信息&#34;&gt;查看指定集合的状态信息&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.&amp;lt;collection_name&amp;gt;.stats()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;ns&amp;quot; : &amp;quot;&amp;lt;db_name&amp;gt;.&amp;lt;collection_name&amp;gt;&amp;quot;,
    &amp;quot;count&amp;quot; : 1,
    &amp;quot;size&amp;quot; : 4080,
    &amp;quot;avgObjSize&amp;quot; : 4080,
    &amp;quot;numExtents&amp;quot; : 1,
    &amp;quot;storageSize&amp;quot; : 8192,
    &amp;quot;lastExtentSize&amp;quot; : 8192,
    &amp;quot;paddingFactor&amp;quot; : 1,
    &amp;quot;paddingFactorNote&amp;quot; : &amp;quot;paddingFactor is unused and unmaintained in 3.0. It remains hard coded to 1.0 for compatibility only.&amp;quot;,
    &amp;quot;userFlags&amp;quot; : 1,
    &amp;quot;capped&amp;quot; : false,
    &amp;quot;nindexes&amp;quot; : 1,
    &amp;quot;totalIndexSize&amp;quot; : 8176,
    &amp;quot;indexSizes&amp;quot; : {
        &amp;quot;_id_&amp;quot; : 8176
    },
    &amp;quot;ok&amp;quot; : 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看当前数据库中的所有的索引&#34;&gt;查看当前数据库中的所有的索引&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.system.indexes.find()&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查看指定集合中的索引&#34;&gt;查看指定集合中的索引&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.col.getIndexes()&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;创建指定集合中的索引&#34;&gt;创建指定集合中的索引&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.col.ensureIndex({&amp;quot;name&amp;quot;: 1, &amp;quot;age&amp;quot;: -1})&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;根据 name 和 age 进行索引，1表示升序，-1表示降序。&lt;/p&gt;

&lt;h4 id=&#34;查看集合中的文档&#34;&gt;查看集合中的文档&lt;/h4&gt;

&lt;h5 id=&#34;查询所有文档&#34;&gt;查询所有文档&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;以易读的方式显示文档内容&#34;&gt;以易读的方式显示文档内容&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find().pretty()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查询前10个文档&#34;&gt;查询前10个文档&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find().limit(10)&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查询结果排序展示&#34;&gt;查询结果排序展示&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find().sort({&#39;clock&#39;:-1})&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查询结果按照 clock 排序展示，1 为升序，-1 为降序。&lt;/p&gt;

&lt;h5 id=&#34;where-条件&#34;&gt;where 条件&lt;/h5&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;操作&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;范例&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;RDBMS中的类似语句&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:&amp;ldquo;value&amp;rdquo;}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key = &amp;lsquo;value&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;小于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$lt:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;lt; 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;小于等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$lte:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;lt;= 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;大于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$gt:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;gt; 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;大于或等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$gte:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;gt;= 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;不等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$ne:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key != 50&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&#34;and-条件&#34;&gt;and 条件&lt;/h5&gt;

&lt;p&gt;find() 方法可以传入多个键，每个键以逗号隔开。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;db.col.find({key1:value1, key2:value2}).pretty()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;or-条件&#34;&gt;or 条件&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;db.col.find(
    {
        $or: [
            {key1: value1}, {key2:value2}
        ]
    }
).pretty()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如 &lt;code&gt;db.col.find({$or:[{&amp;quot;key1&amp;quot;:&amp;quot;value1&amp;quot;}, {&amp;quot;key2&amp;quot;: &amp;quot;value2&amp;quot;}]}).pretty()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;更新操作&#34;&gt;更新操作&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.collection.update( query, update, upsert, multi )&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;query&lt;/strong&gt;： update 的查询条件，类似 sql update 操作的 where 子句。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;update&lt;/strong&gt;： update 的对象和一些更新的操作符（如$set, $inc&amp;hellip;）等，也可以理解为 sql update 操作的 set 子句。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;upsert&lt;/strong&gt;： 可选，这个参数的意思是，如果不存在 update 的记录，是否插入新的记录，true 为插入，默认是 false，不插入。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;multi&lt;/strong&gt;： 可选，默认为 false，只更新找到的第一条记录，如果这个参数为 true，就把按条件查出来多条记录全部更新。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;db.agent_conf.update({hostid:137}, {$set: {upload:{interval:10}}}, true)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;将 agent_conf 集合中 hostid = 137 的记录将 upload.interval 的值修改为 3，如果不存在就插入，只修改匹配的第一条。&lt;/p&gt;

&lt;h4 id=&#34;删除操作&#34;&gt;删除操作&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.col.remove({id:1})&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;remove 的过滤条件同 find。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>python中使用pycurl库上传文件</title>
          <link>http://blog.fatedier.com/2015/05/08/upload-file-in-python-using-pycurl/</link>
          <pubDate>Fri, 08 May 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/05/08/upload-file-in-python-using-pycurl/</guid>
          <description>&lt;p&gt;在对外提供各种语言SDK的时候经常会遇到需要上传文件的问题，例如在python中我们可以借助pycurl库实现这个功能。&lt;/p&gt;

&lt;h3 id=&#34;项目地址&#34;&gt;项目地址&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/pycurl/pycurl&#34;&gt;https://github.com/pycurl/pycurl&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;示例代码&#34;&gt;示例代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pycurl
import StringIO

# 用于执行http请求的通用函数
# post_data: post参数字符串
# upload_file: dict类型，需要有file_path(指定要上传的文件路径)和file_name(指定上传后的文件名)
def do_http_request(method, url, post_data=&#39;&#39;, upload_file=None): 
    ch = pycurl.Curl() 
    buf = StringIO.StringIO() 
    ch.setopt(ch.URL, url) 
    ch.setopt(ch.CUSTOMREQUEST, method) 
    if upload_file != None: 
        ch.setopt(ch.HTTPPOST, [(&#39;file&#39;, (ch.FORM_FILE, upload_file[&#39;file_path&#39;], \ 
            ch.FORM_FILENAME, upload_file[&#39;file_name&#39;]))]) 
    else: 
        if method == self.METHOD_POST: 
            ch.setopt(ch.POSTFIELDS,  urlencode(post_data)) 

    ch.setopt(ch.TIMEOUT, 30) 
    ch.setopt(ch.WRITEFUNCTION, buf.write)
    ch.perform() 
    content = buf.getvalue()
    buf.close()
    ch.close()
    return content
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码是一个用pycurl库写的调用http请求的通用函数，如果upload_file不为None，则表示需要上传文件，upload_file是一个dict类型，需要有两个key，file_path(指定要上传的文件路径)和file_name(指定上传后的文件名)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ch.FORM_FILE&lt;/strong&gt;：指定要上传文件的路径&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ch.FORM_FILENAME&lt;/strong&gt;：指定要上传文件的文件名&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>在C&#43;&#43;中利用反射和简单工厂模式实现业务模块解耦</title>
          <link>http://blog.fatedier.com/2015/03/04/decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp/</link>
          <pubDate>Wed, 04 Mar 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/03/04/decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp/</guid>
          <description>&lt;p&gt;在设计一个系统框架的时候往往需要划分各个模块、组件，抽象出公共的部分，尽量避免耦合，以利于以后的扩展和复用。在这方面，JAVA的很多特性在利用各种设计模式的时候会非常容易，而在C++中就需要自己去一步步实现。&lt;/p&gt;

&lt;h3 id=&#34;业务说明&#34;&gt;业务说明&lt;/h3&gt;

&lt;p&gt;为了便于说明，举一个简单的例子。假设现在有一个项目需要建立一个和银行交互的平台，目前只接入工商银行，后续接入其他银行，每个银行的业务都有差异，报文格式可能也不一致。&lt;/p&gt;

&lt;p&gt;这里只列举几个简要的流程，仅包括拼报文，发送报文，接收报文，解析报文，其余整体架构以及后续处理等内容省略。&lt;/p&gt;

&lt;h3 id=&#34;初步设计&#34;&gt;初步设计&lt;/h3&gt;

&lt;p&gt;创建一个银行交互类 BankOpt，包括四个函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int setMsg();       // 拼报文
int sendMsg();      // 发送报文
int getMsg();       // 接收报文
int parseMsg();     // 解析报文
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在每个函数中通过if-else来判断具体是哪一个银行，之后进行相应的处理。&lt;/p&gt;

&lt;p&gt;这种设计在刚开发的时候非常方便，代码量少，但是如果后续需要接入另外一个银行时就需要改动 &lt;strong&gt;BankOpt&lt;/strong&gt; 类，不符合设计模式中的开放-封闭原则。而且单个函数中将来可能会有大量的 &lt;strong&gt;if-else&lt;/strong&gt;，使代码可读性下降。&lt;/p&gt;

&lt;h3 id=&#34;简单工厂模式&#34;&gt;简单工厂模式&lt;/h3&gt;

&lt;p&gt;通过简单工厂模式，我们可以创建一个专门的工厂类用于实例化一个合适的银行交互类，只需要这个银行交互类具有共同的接口即可。&lt;/p&gt;

&lt;p&gt;首先，为了实现更好的复用，把各个银行交互类中相同的部分抽象出来，形成一个银行交互基类，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;class BaseBank
{
public:
    virtual int setMsg() = 0;
    virtual int sendMsg() = 0;
    virtual int getMsg() = 0;
    virtual int parseMsg() = 0;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里仅仅声明了四个纯虚函数，具体的业务逻辑在子类中实现。&lt;/p&gt;

&lt;p&gt;创建两个银行交互子类GSBank（工商银行）和RMBank（人民银行），继承BaseBank，实现四个虚函数。&lt;/p&gt;

&lt;h4 id=&#34;创建一个工厂类&#34;&gt;创建一个工厂类&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;class BankFactory
{
public:
    BaseBank* createBank(const string&amp;amp; bank_name) {
    if (bank_name == &amp;quot;SBank&amp;quot;) 
        return new GSBank();
    else if (bank_name == &amp;quot;MBank&amp;quot;)
        return new RMBank();
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;工厂类中有一个 &lt;strong&gt;createBank&lt;/strong&gt; 函数，用于根据银行编码创建相应的实例并返回其基类指针，这样我们只需要通过基类指针调用相关函数即可。&lt;/p&gt;

&lt;h4 id=&#34;在主流程中调用&#34;&gt;在主流程中调用&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;BankFactory bf;
BaseBank* t = (BaseBank*)bf.createBank(bank_name);
if (t == NULL) {
    cout &amp;lt;&amp;lt; &amp;quot;银行编码错误！&amp;quot; &amp;lt;&amp;lt; endl;
    return 2;
}
t-&amp;gt;setMsg();
t-&amp;gt;sendMsg();
t-&amp;gt;getMsg();
t-&amp;gt;parseMsg();
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;优缺点&#34;&gt;优缺点&lt;/h4&gt;

&lt;p&gt;利用简单工厂模式，当我们后续接入另外的银行时，只需要添加具体的银行交互类，实现业务函数，然后在工厂类的 &lt;strong&gt;createBank&lt;/strong&gt; 函数中添加一个 &lt;strong&gt;else if&lt;/strong&gt; 子句。相对于原来的设计已经改进很多了，但是仍然需要修改原来的工厂类的代码，没有彻底实现解耦。&lt;/p&gt;

&lt;h3 id=&#34;反射&#34;&gt;反射&lt;/h3&gt;

&lt;p&gt;反射在java的一些框架中使用的比较多，而且用起来非常方便。C++本身并不支持，但是我们可以模拟一些简单的特性。&lt;/p&gt;

&lt;p&gt;我们需要一种能够根据字符串动态获取对应的银行交互类的实例的方法。这样在工厂类的 &lt;strong&gt;createBank&lt;/strong&gt; 方法中就可以根据字符串直接获取对应银行交互类的实例，而不需要再每次通过新增 &lt;strong&gt;else if&lt;/strong&gt; 子句来新增一个银行接口。&lt;/p&gt;

&lt;p&gt;也就是说，利用反射和简单工厂模式，下次当我们需要新增一个银行接口的时候只需要新增一个银行交互类即可，不需要修改原来的任何代码，实现了业务上的解耦。&lt;/p&gt;

&lt;h4 id=&#34;如何在c-中实现反射&#34;&gt;如何在C++中实现反射&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;需要一个全局的map用于存储类的信息以及创建实例的函数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;需要反射的类需要提供一个用于创建自身实例的函数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;利用类的静态变量在程序启动的时候会进行初始化来在全局map中将类名及创建实例的函数存入map中&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;相关代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef void* (*register_func)();

class Class
{
public:
static void* newInstance(const string&amp;amp; class_name) {
    map&amp;lt;string, register_func&amp;gt;::iterator it = m_register.find(class_name);
    if (it == m_register.end())
        return NULL;
    else
        return it-&amp;gt;second();
}
static void registerClass(const string&amp;amp; class_name, register_func func) {
    m_register[class_name] = func;
}

private:
    /* key is class name and value is function to create instance of class */
    static map&amp;lt;string, register_func&amp;gt; m_register;
};


class Register
{
public:
    Register(const string&amp;amp; class_name, register_func func) {
        Class::registerClass(class_name, func);
    }
};

#define REGISTER_CLASS(class_name) \
    class class_name##Register { \
    public: \
        static void* newInstance() { \
            return new class_name; \
        } \
    private: \
        static const Register reg; \
    };\
const Register class_name##Register::reg(#class_name,class_name##Register::newInstance);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还需要修改工厂类的 &lt;strong&gt;createBank&lt;/strong&gt; 函数，利用Class的 &lt;strong&gt;newInstance&lt;/strong&gt; 函数来创建实例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;BaseBank* createBank(const string&amp;amp; bank_name) {
    return (BaseBank*)Class::newInstance(bank_name);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Class类中的 &lt;strong&gt;m_register&lt;/strong&gt; 变量是 &lt;strong&gt;static&lt;/strong&gt; 类型的map，相当于全局变量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;newInstance&lt;/strong&gt; 函数，传入类名，查找map，调用回调函数，返回一个对应类的实例。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;registerClass&lt;/strong&gt; 函数传入类名和用于创建实例的回调函数并将信息存入全局的map中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Register&lt;/strong&gt; 类只有一个构造函数，会调用Class的 &lt;strong&gt;registerClass&lt;/strong&gt; 函数完成注册。&lt;/p&gt;

&lt;p&gt;利用宏定义，在每一个需要反射的类后面额外增加一个类，其中有一个 &lt;strong&gt;Register&lt;/strong&gt; 类型的 &lt;strong&gt;static const&lt;/strong&gt; 变量，这样在程序启动的时候就会完成初始化调用 &lt;strong&gt;Register&lt;/strong&gt; 类的构造函数，完成注册。&lt;/p&gt;

&lt;p&gt;之后只需要在需要反射的类，例如在工商银行交互类 GSBank 后面加上一条宏定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;REGISTER_CLASS(GSBank)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以通过工厂类传入 &amp;ldquo;GSBank&amp;rdquo; 字符串获得工商银行交互类的实例。&lt;/p&gt;

&lt;h3 id=&#34;测试&#34;&gt;测试&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-03-04-decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp-gsbank.jpg&#34; alt=&#34;GSBANK&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2015/2015-03-04-decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp-rmbank.jpg&#34; alt=&#34;RMBANK&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过传入不同的银行编码，会实例化不同的银行交互类，并且执行其对应的函数。&lt;/p&gt;

&lt;p&gt;如果需要增加新的银行接口，例如农业银行，只需要新增一个 &lt;strong&gt;NYBank&lt;/strong&gt; 类，实现具体的业务逻辑，不需要改动原来的任何代码，传入 &lt;strong&gt;NYBank&lt;/strong&gt; 字符串，就会执行农业银行相关的处理流程。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>epoll使用说明</title>
          <link>http://blog.fatedier.com/2015/01/25/introduction-of-using-epoll/</link>
          <pubDate>Sun, 25 Jan 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/01/25/introduction-of-using-epoll/</guid>
          <description>&lt;p&gt;在《UNIX网络编程》一书中介绍了如何使用select/poll来实现I/O多路复用，简而言之就是通过内核的一种机制，监视多个文件描述符，一旦某个文件描述符处于就绪状态，就通知用户程序进行相应的读写操作，这样用户程序就不用阻塞在每一个文件描述符上。&lt;/p&gt;

&lt;p&gt;epoll相对于select/poll来说有很大优势：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;不再需要每次把fd集合从用户态拷贝到内核态。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;不再需要在每次就绪时遍历fd集合中的所有fd来检查哪些fd处于就绪状态，epoll只返回就绪的fd集合。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;select一般只支持1024个文件描述符，而epoll没有类似的限制。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;epoll相关函数&#34;&gt;epoll相关函数&lt;/h3&gt;

&lt;p&gt;使用epoll只需要记住3个系统调用函数。&lt;/p&gt;

&lt;h4 id=&#34;int-epoll-create-int-size&#34;&gt;int epoll_create(int size)&lt;/h4&gt;

&lt;p&gt;创建一个epoll实例，从2.68的Linux内核开始，size参数不再生效，内核会动态分配所需的数据结构。失败返回-1，成功则该函数会返回一个文件描述符，并占用一个fd值，所以在使用完之后要记得close该文件描述符。&lt;/p&gt;

&lt;h4 id=&#34;int-epoll-ctl-int-epfd-int-op-int-fd-struct-epoll-event-event&#34;&gt;int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)&lt;/h4&gt;

&lt;p&gt;用于对epoll实例执行不同的操作的函数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;epfd&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用epoll_create()返回的文件描述符&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;op&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用三个宏表示不同的操作&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;EPOLL_CTL_ADD：注册新的fd到epfd中；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;EPOLL_CTL_MOD：修改已经注册的fd的监听事件；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;EPOLL_CTL_DEL：从epfd中删除指定fd；&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;fd&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;要监听的文件描述符&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;event&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;event 是与指定fd关联的epoll_event结构，包含了监听事件，附加数据&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;struct epoll_event&lt;/strong&gt; 的结构如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef union epoll_data {
    void        *ptr;
    int          fd;
    __uint32_t   u32;
    __uint64_t   u64;
}epoll_data_t;
 
struct epoll_event {
    __uint32_t  events;      /* Epoll events */
    epoll_data_t data;       /* User data variable */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;这里需要特别注意的是epoll_data_t是一个union结构，fd和ptr指针只能使用一个，通常我们使用void *ptr存储需要附加的用户数据结构，然后在用户数据结构中存储int型的fd，这样在epoll_wait调用后就仍然能获得该注册事件对应的文件描述符。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;events可以是如下值的集合&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）
EPOLLOUT：表示对应的文件描述符可以写
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）
EPOLLERR：表示对应的文件描述符发生错误
EPOLLHUP：表示对应的文件描述符被挂断
EPOLLET： 将EPOLL设为边缘触发(EdgeTriggered)模式，这是相对于水平触发(Level Triggered)来说的
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;int-epoll-wait-int-epfd-struct-epoll-event-events-int-maxevents-int-timeout&#34;&gt;int epoll_wait(int epfd, struct epoll_event * events, int maxevents,int timeout)&lt;/h4&gt;

&lt;p&gt;该函数等待epoll实例中的fd集合有就绪事件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;epfd：使用epoll_create()返回的文件描述符
events：指向处于就绪状态的事件集合
maxevents：最多maxevents数量的事件集合会被返回
timeout：超时时间，单位为毫秒；指定为-1没有超时时间，指定为0则立即返回并返回0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果成功，返回已就绪的事件的个数；如果达到超时时间仍然没有就绪事件，返回0；如果出现错误，返回-1并置errno值&lt;/p&gt;

&lt;h3 id=&#34;lt和et两种工作方式&#34;&gt;LT和ET两种工作方式&lt;/h3&gt;

&lt;p&gt;epoll 默认使用LT的工作方式，当指定事件就绪时，内核通知用户进行操作，如果你只处理了部分数据，只要对应的套接字缓冲区中还有剩余数据，下一次内核仍然还会继续通知用户去进行处理，所以使用这种模式来写程序较为简单。&lt;/p&gt;

&lt;p&gt;ET工作方式是一种高速工作方式，只能使用非阻塞socket，它的效率要比LT方式高。当一个新事件就绪时，内核通知用户进行操作，如果这时用户没有处理完缓冲区的数据，缓冲区中剩余的数据就会丢失，用户无法从下一次epoll_wait调用中获取到这个事件。&lt;/p&gt;

&lt;p&gt;举个例子，可以指定事件为 EPOLLIN| EPOLLET 来使用ET工作方式获取指定文件描述符的可读事件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在该事件就绪后，需要不断调用read函数来获取缓冲区数据，直到产生一个EAGAIN错误或者read函数返回的读取到的数据长度小于请求的数据长度时才认为此事件处理完成。write也是一样的处理方式。&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>如何处理僵尸进程</title>
          <link>http://blog.fatedier.com/2014/12/16/how-to-deal-with-zombie-process/</link>
          <pubDate>Tue, 16 Dec 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/12/16/how-to-deal-with-zombie-process/</guid>
          <description>&lt;p&gt;在使用c/c++开发过程中经常会用到多进程，需要fork一些子进程，但是如果不注意的话，就有可能导致子进程结束后变成了僵尸进程。从而逐渐耗尽系统资源。&lt;/p&gt;

&lt;h3 id=&#34;什么是僵尸进程&#34;&gt;什么是僵尸进程&lt;/h3&gt;

&lt;p&gt;如果父进程在子进程之前终止，则所有的子进程的父进程都会改变为init进程，我们称这些进程由init进程领养。这时使用ps命令查看后可以看到子进程的父进程ppid已经变为了1。&lt;/p&gt;

&lt;p&gt;而当子进程在父进程之前终止时，&lt;strong&gt;内核为每个终止子进程保存了一定量的信息，所以当终止进程的父进程调用wait或waitpid时&lt;/strong&gt;，可以得到这些信息。这些信息至少包括进程ID、该进程的终止状态、以及该进程使用的CPU时间总量。其他的进程所使用的存储区，打开的文件都会被内核释放。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一个已经终止、但是其父进程尚未对其进行善后处理（获取终止子进程的有关信息，释放它仍占用的资源）的进程被称为僵尸进程。&lt;/strong&gt; ps命令将僵尸进程的状态打印为Z。&lt;/p&gt;

&lt;p&gt;可以设想一下，比如一个web服务器端，假如每次接收到一个连接都创建一个子进程去处理，处理完毕后结束子进程。假如在父进程中没有使用wait或waitpid函数进行善后，这些子进程将全部变为僵尸进程，Linux系统的进程数一般有一个固定限制值，僵尸进程将会逐渐耗尽系统资源。&lt;/p&gt;

&lt;h3 id=&#34;查看僵尸进程的例子&#34;&gt;查看僵尸进程的例子&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
 
int main(int argc, char **argv)
{
    pid_t pid;
    for (int i=0; i&amp;lt;5; i++) {
        if ((pid = fork()) &amp;lt; 0) {
            printf(&amp;quot;fork error,%s\n&amp;quot;, strerror(errno));
            return -1;
        }
        
        /* child */
        if (pid == 0) {
            sleep(1);
            exit(0);
        }
    }  
    /* parent */
    sleep(20);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译完成后，在执行程序的命令后加上 &amp;ldquo;&amp;amp;&amp;rdquo; 符号，表示让当前程序在后台运行。&lt;/p&gt;

&lt;p&gt;之后输入&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ps –e –o pid,ppid,stat,command|grep [程序名]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到如下的结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;2915  1961 S    ./dd
2917  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2918  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2919  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2920  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2921  2915 Z    [dd] &amp;lt;defunct&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到5个子进程都已经是僵尸进程了。&lt;/p&gt;

&lt;h3 id=&#34;sigchld信号和处理僵尸进程&#34;&gt;SIGCHLD信号和处理僵尸进程&lt;/h3&gt;

&lt;p&gt;当子进程终止时，内核就会向它的父进程发送一个SIGCHLD信号，父进程可以选择忽略该信号，&lt;strong&gt;也可以提供一个接收到信号以后的处理函数&lt;/strong&gt;。对于这种信号的系统默认动作是忽略它。&lt;/p&gt;

&lt;p&gt;我们不希望有过多的僵尸进程产生，所以当父进程接收到SIGCHLD信号后就应该调用 wait 或 waitpid 函数对子进程进行善后处理，释放子进程占用的资源。&lt;/p&gt;

&lt;p&gt;下面是一个捕获SIGCHLD信号以后使用wait函数进行处理的简单例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;lt;sys/wait.h&amp;gt;
 
void deal_child(int sig_no)
{
    wait(NULL);
}
 
int main(int argc, char **argv)
{
    signal(SIGCHLD, deal_child);
 
    pid_t pid;
    for (int i=0; i&amp;lt;5; i++) {
        if ((pid = fork()) &amp;lt; 0) {
            printf(&amp;quot;fork error,%s\n&amp;quot;,strerror(errno));
            return -1;
        }  
 
        /* child */
        if (pid == 0) {
            sleep(1);
            exit(0);
        }  
    }  
    /* parent */
    for(int i=0; i&amp;lt;100000; i++) {
        for (int j=0; j&amp;lt;100000; j++) {
            int temp = 0;
        }  
    }  
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样在后台运行后使用ps命令查看进程状态，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;6622  1961 R    ./dd
6627  6622 Z    [dd] &amp;lt;defunct&amp;gt;
6628  6622 Z    [dd] &amp;lt;defunct&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现创建的5个进程，有3个已经被彻底销毁，但是还有2个仍然处于僵尸进程的状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这是因为当5个进程同时终止的时候，内核都会向父进程发送SIGCHLD信号，而父进程此时有可能仍然处于信号处理的deal_child函数中，那么在处理完之前，中间接收到的SIGCHLD信号就会丢失，内核并没有使用队列等方式来存储同一种信号。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;正确地处理僵尸进程的方法&#34;&gt;正确地处理僵尸进程的方法&lt;/h3&gt;

&lt;p&gt;为了解决上面出现的这种问题，我们需要使用waitpid函数。&lt;/p&gt;

&lt;p&gt;函数原型&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;pid_t waitpid(pid_t pid, int *statloc, int options);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;若成功则返回进程ID，如果设置为非阻塞方式，返回0表示子进程状态未改变，出错时返回-1。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;options参数可以设置为WNOHANG常量，表示waitpid不阻塞，如果由pid指定的子进程不是立即可用的，则立即返回0。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;只需要修改一下SIGCHLD信号的处理函数即可:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void deal_child(int sig_no)
{
    for (;;) {
        if (waitpid(-1, NULL, WNOHANG) == 0)
            break;
    }  
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再次执行程序后使用ps命令查看，发现已经不会产生僵尸进程了。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>linux core文件调试</title>
          <link>http://blog.fatedier.com/2014/12/07/debug-with-linux-core-file/</link>
          <pubDate>Sun, 07 Dec 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/12/07/debug-with-linux-core-file/</guid>
          <description>&lt;p&gt;在完成公司项目，测试进程的时候，经常会发现日志到了某一段特定的代码的时候就没了，进程直接退出，也没有捕获到任何的异常信息，如果日志打印的较多还可能比较容易发现问题
题，如果日志较少，就很难进行进一步的查错了。但是发现在该目录下生成了一个core文件，可以帮助我们查找程序崩溃的原因。&lt;/p&gt;

&lt;h3 id=&#34;什么是core文件&#34;&gt;什么是core文件&lt;/h3&gt;

&lt;p&gt;在linux系统下，如果进程不能正常运行，就可能会产生core文件。core文件就是当前内存状态的一个映像，同时加上一些调试信息。&lt;/p&gt;

&lt;p&gt;bug和操作系统或硬件的保护机制都会导致程序异常终止，操作系统会kill掉这些进程并产生core文件，比如常见的段错误等。&lt;/p&gt;

&lt;h3 id=&#34;为什么我的linux不会生成core文件&#34;&gt;为什么我的linux不会生成core文件&lt;/h3&gt;

&lt;p&gt;使用 &lt;code&gt;ulimit -a&lt;/code&gt; 命令可以查看当前系统资源的一些限制信息，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-t: cpu time (seconds)              unlimited
-f: file size (blocks)              unlimited
-d: data seg size (kbytes)          unlimited
-s: stack size (kbytes)             8192
-c: core file size (blocks)         0
-m: resident set size (kbytes)      unlimited
-u: processes                       3847
-n: file descriptors                1024
-l: locked-in-memory size (kbytes)  64
-v: address space (kbytes)          unlimited
-x: file locks                      unlimited
-i: pending signals                 3847
-q: bytes in POSIX msg queues       819200
-e: max nice                        0
-r: max rt priority                 0
-N 15:                              unlimited
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的 &lt;strong&gt;-c: core file size&lt;/strong&gt; 如果设置为0的话，当程序崩溃的时候就不会产生core文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ulimit -c unlimited
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;设置core文件大小为无限&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ulimit -c 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;阻止系统生成core文件&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：这条命令只在当前生效，如果希望永久生效，就需要在 .bash_profile 或者类似文件中加上这条命令。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;设置core-dump的核心转储文件目录和命名规则&#34;&gt;设置Core Dump的核心转储文件目录和命名规则&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;/proc/sys/kernel/core_uses_pid&lt;/strong&gt; 可以控制产生的core文件的文件名中是否添加pid作为扩展，如果添加则文件内容为1，否则为0。需要有超级用户的权限才能进行修改。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;/proc/sys/kernel/core_pattern&lt;/strong&gt; 可以设置格式化的 core文件保存位置或文件名，默认的是 &lt;strong&gt;|/usr/libexec/abrt-hook-ccpp %s %c %p %u %g %t e&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;需要修改的话，可以使用这条命令：&lt;code&gt;echo &amp;quot;/corefile/core-%e-%p-%t&amp;quot;&amp;gt; /proc/sys/kernel/core_pattern&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;将会控制所产生的core文件会存放到 /corefile 目录下，产生的文件名为 &lt;strong&gt;core-命令名-pid-时间戳&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下是参数列表：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%p - insert pid into filename 添加pid
%u - insert current uid into filename 添加当前uid
%g - insert current gid into filename 添加当前gid
%s - insert signal that caused the coredump into the filename 添加导致产生core的信号
%t - insert UNIX time that the coredump occurred into filename 添加core文件生成时的unix时间
%h - insert hostname where the coredump happened into filename 添加主机名
%e - insertcoredumping executable name into filename 添加命令名
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用core文件&#34;&gt;使用core文件&lt;/h3&gt;

&lt;p&gt;在linux上可以使用gdb来调试core文件，格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gdb [程序名] [core文件名]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你不知道这个core文件到底是哪个程序生成的，可以使用&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gdb -c[core 文件名] 来查看生成此core文件的程序名。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;显示结果中可以看出程序名，可能像下面这样&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Core wasgenerated by `./test&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后进入gdb调试状态，输入 where 就可以看到程序崩溃时堆栈信息（当前函数之前的所有已调用函数的列表（包括当前函数），我们可以借此找出是程序中的哪个部分导致了程序崩溃。注意：在编译程序的时候要加入选项-g。&lt;/p&gt;

&lt;h3 id=&#34;一个简单的例子&#34;&gt;一个简单的例子&lt;/h3&gt;

&lt;p&gt;编译如下的程序&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
using namespace std;
 
class A
{
public:
    int a;
};
 
void fun()
{
    A*t = new A();
    t-&amp;gt;a = 1;
    cout &amp;lt;&amp;lt; t-&amp;gt;a &amp;lt;&amp;lt; endl;
    delete t;
    delete t;
}
 
int main()
{
    fun();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;1
*** glibc detected *** ./test: double freeor corruption (fasttop): 0x09fd7008 ***
======= Backtrace: =========
/lib/libc.so.6[0x3ebe31]
/usr/lib/libstdc++.so.6(_ZdlPv+0x22)[0x43fc552]
./test[0x8048705]
./test[0x8048712]
/lib/libc.so.6(__libc_start_main+0xe6)[0x391d26]
./test[0x8048611]
======= Memory map: ========
00327000-00328000 r-xp 00000000 00:000          [vdso]
00334000-00351000 r-xp 00000000 08:02926955    /lib/libgcc_s-4.4.7-20120601.so.1
00351000-00352000 rw-p 0001d000 08:02926955    /lib/libgcc_s-4.4.7-20120601.so.1
00355000-00373000 r-xp 00000000 08:02926876     /lib/ld-2.12.so
00373000-00374000 r--p 0001d000 08:02926876     /lib/ld-2.12.so
00374000-00375000 rw-p 0001e000 08:02926876     /lib/ld-2.12.so
0037b000-0050c000 r-xp 00000000 08:02926877     /lib/libc-2.12.so
0050c000-0050e000 r--p 00191000 08:02926877     /lib/libc-2.12.so
0050e000-0050f000 rw-p 00193000 08:02926877     /lib/libc-2.12.so
0050f000-00512000 rw-p 00000000 00:00 0
00543000-0056b000 r-xp 00000000 08:02926889     /lib/libm-2.12.so
0056b000-0056c000 r--p 00027000 08:02926889     /lib/libm-2.12.so
0056c000-0056d000 rw-p 00028000 08:02926889     /lib/libm-2.12.so
0434d000-0442e000 r-xp 00000000 08:02155001     /usr/lib/libstdc++.so.6.0.13
0442e000-04432000 r--p 000e0000 08:02155001     /usr/lib/libstdc++.so.6.0.13
04432000-04434000 rw-p 000e4000 08:02155001     /usr/lib/libstdc++.so.6.0.13
04434000-0443a000 rw-p 00000000 00:00 0
08048000-08049000 r-xp 00000000 08:02419326    /home/wcl/fate/src/app/test/test
08049000-0804a000 rw-p 00000000 08:02419326    /home/wcl/fate/src/app/test/test
09fd7000-09ff8000 rw-p 00000000 00:000          [heap]
b7719000-b771c000 rw-p 00000000 00:00 0
b7727000-b772a000 rw-p 00000000 00:00 0
bfd2a000-bfd3f000 rw-p 00000000 00:000          [stack]
Aborted (core dumped)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为我们对一个已经delete过了的指针再次delete，所以程序down掉了，可以看到在当前目录下已经生成了一个core.4377的文件，4377就是之前程序启动的PID。&lt;/p&gt;

&lt;p&gt;调试core文件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gdb test core.4377
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入gdb调试后，键入where命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(gdb) where
#0 0x00327424 in __kernel_vsyscall ()
#1 0x003a5b11 in raise () from /lib/libc.so.6
#2 0x003a73ea in abort () from /lib/libc.so.6
#3 0x003e59d5 in __libc_message () from /lib/libc.so.6
#4 0x003ebe31 in malloc_printerr () from /lib/libc.so.6
#5 0x043fc552 in operator delete(void*) () from/usr/lib/libstdc++.so.6
#6 0x08048705 in fun() ()
#7 0x08048712 in main ()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以很明显的看出是在main函数中调用fun函数，之后delete指针的时候出错了，后面的函数调用栈就是程序输出错误信息的部分了，和我们的用户代码无关。到这一步，我们就能推断是是fun()这个函数中delete某个指针的时候出现了错误，就可以有的放矢地查找具体的问题了。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>linux shell中的条件判断</title>
          <link>http://blog.fatedier.com/2014/11/24/conditional-judgement-in-linux-shell/</link>
          <pubDate>Mon, 24 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/24/conditional-judgement-in-linux-shell/</guid>
          <description>&lt;p&gt;在日常开发中经常需要编写一些简单的部署或者测试统计之类的脚本，直接用shell来编写几条命令就可以实现一些较为复杂的功能，十分方便。不过 linux shell 中的条件判断和其他编程语言略有不同，有一些需要特别注意的地方。&lt;/p&gt;

&lt;h3 id=&#34;退出状态&#34;&gt;退出状态&lt;/h3&gt;

&lt;p&gt;在Linux系统中，每当一条命令执行完成后，系统都会返回一个退出状态，这个状态被存放在$? 这个变量中，是一个整数值，我们可以根据这个值来判断命令运行的结果是否正确。&lt;/p&gt;

&lt;p&gt;通常情况下，退出状态值为0，表示执行成功，不为0的时候表示执行失败。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;POSIX规定的退出状态和退出状态的含义&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;0 （运行成功）&lt;/p&gt;

&lt;p&gt;1-255 （运行失败，脚本命令、系统命令错误或参数传递错误）&lt;/p&gt;

&lt;p&gt;126 （找到了该命令但无法执行）&lt;/p&gt;

&lt;p&gt;127 （未找到要运行的命令）&lt;/p&gt;

&lt;p&gt;128 （命令被系统强行结束）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;测试命令&#34;&gt;测试命令&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test expression
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用test命令进行测试，expression是一个表达式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[ expression ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了提高可读性，可以使用简化的这种格式&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;需要注意的是大括号和表达式之间需要有一个空格，不能省略。这种方式和if、case、while等语句结合，可以作为shell脚本中的判断条件。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;整数比较运算符&#34;&gt;整数比较运算符&lt;/h3&gt;

&lt;p&gt;在shell中对两个数进行比较，不像在C/C++中可以使用 &amp;ldquo;&amp;gt;&amp;rdquo; 之类的运算符，而是使用类似参数选项的格式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-eq  # 如果等于则为真
-ge  # 如果大于或等于则为真
-gt  # 如果大于则为真
-le  # 如果小于或等于则为真
-lt  # 如果小于则为真
-ne  # 如果不等于则为真
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;其中的参数可以这样理解e(equal)，g(greater)，t(than)，l(less)，n(not)，这样方便记忆。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;字符串相关运算符&#34;&gt;字符串相关运算符&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-n string            # 字符串不为空则为真
-z string            # 字符串为空则为真
string1 = string2    # 字符串相等则为真 （或者 == 也可以）
string1 != string2   # 字符串不等则为真
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;这里有一个需要注意的地方，就是使用 -n 这个运算符进行判断的时候需要注意在变量两边加上双引号。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;例如 if [ -n $string ] 应该写成 if [ -n “$string” ] ，不然该表达式总是会返回真，因为当string变量为空的时候就相当于是 if [ -n ]。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;文件操作符&#34;&gt;文件操作符&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-d file # 测试file是否为目录
-e file # 测试file是否存在
-f file # 测试file是否为普通文件
-r file # 测试file是否是进程可读文件
-s file # 测试file的长度是否不为0
-w file # 测试file是否是进程可写文件
-x file # 测试file是否是进程可执行文件
-L file # 测试file是否符号化链接
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;逻辑运算符&#34;&gt;逻辑运算符&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;! expression                # 非
expression1 -a expression2  # 与
expression1 -o expression2  # 或
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多重的嵌套&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ $a == 1 ] &amp;amp;&amp;amp; [ $b == 1 -o $b == 3 ]
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>能否被8整除</title>
          <link>http://blog.fatedier.com/2014/11/13/can-be-divisible-by-eight/</link>
          <pubDate>Thu, 13 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/13/can-be-divisible-by-eight/</guid>
          <description>&lt;p&gt;题目：给定一个非负整数，问能否重排它的全部数字，使得重排后的数能被8整除。 输入格式： 多组数据，每组数据是一个非负整数。非负整数的位数不超过10000位。 输出格式 每组数据输出一行,YES或者NO，表示能否重排它的全部数字得到能被8整除的数。注意：重排可以让0开头。&lt;/p&gt;

&lt;h3 id=&#34;思路&#34;&gt;思路&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;考虑到64位整型可以直接取余8求得结果，所以当输入非负整数位数小于20位的时候，可以直接转换成64位整型进行计算。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对于一个非负整数，最后四位相当于是 p*1000 + x*100 + y*10 + z ，可以很显然的看出p*1000必然能被8整除，所以一个非负整数只需要后三位能被8整除，那么这个数就一定能被8整除。所以如果我们能从这个数中任意取出三位，作为最后三位，其值能被8整除，就输出YES，否则NO。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;没必要对可能的10000位做全排列，因为0-9每个数最多只能用3次，我们只需要遍历一遍每一位，将0-9出现的次数记录下来，最多允许记录3次。这样最坏的情况下需要对30个数进行全排列即可，效率会非常高。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;代码&#34;&gt;代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;sys/types.h&amp;gt;

#define MAX 10001

int has_num[10];    //0-9在这个数中出现的次数

bool check()
{
    int deal_num[30];   //0-9每个数最多可以用3次，只需要30的空间
    int n = 0;
    //将所有出现过数依次存放在deal_num数组中
    for (int i=0; i&amp;lt;10; i++) {
        for (int j=0; j&amp;lt;has_num[i]; j++) {
            deal_num[n] = i;
            n++;
        }
    }

    //排列任意三个数组成一个整数，其值能被8整除，返回true，否则false
    for (int i=0; i&amp;lt;n; i++) {
        for (int j=0; j&amp;lt;n; j++) {
            if (j == i)
                continue;
            for (int k=0; k&amp;lt;n; k++) {
                if (k == i || k == j) {
                    continue;
                }
                if ((deal_num[i]*100 + deal_num[j]*10 + deal_num[k]) % 8 == 0)
                    return true;
            }
        }
    }
    return false;
}

int main()
{
    char str_num[MAX];  //用于保存不超过10000位的整数
    int n;
    long long temp = 0; //如果位数小于等于19，直接转换为64位整型

    for (;;) {
        memset(str_num, 0, sizeof(str_num));
        for (int i=0; i&amp;lt;10; i++) {
            has_num[i] = 0;
        }
        if (scanf(&amp;quot;%s&amp;quot;, &amp;amp;str_num) == 1) {
            n = strlen(str_num);
            //转换为64位整型
            if (n &amp;lt;= 19) {
                sscanf(str_num, &amp;quot;%lld&amp;quot;, &amp;amp;temp);
                if ((temp % 8) == 0)
                    printf(&amp;quot;YES\n&amp;quot;);
                else
                    printf(&amp;quot;NO\n&amp;quot;);
                continue;
            }
            
            //将0-9出现的次数保存在has_num数组中，最多3次
            for (int i=0; i&amp;lt;n; i++) {
                if (has_num[(int)str_num[i] - 48] &amp;lt; 3)
                    has_num[(int)str_num[i] - 48]++;
            }
            if (check())
                printf(&amp;quot;YES\n&amp;quot;);
            else
                printf(&amp;quot;NO\n&amp;quot;);
            continue;

        } else {
            break;
        }
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>使用astyle进行代码格式化</title>
          <link>http://blog.fatedier.com/2014/11/10/use-astyle-to-format-code/</link>
          <pubDate>Mon, 10 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/10/use-astyle-to-format-code/</guid>
          <description>&lt;p&gt;在参与团队的开发的时候，由于平台和编写代码的工具的不同等等问题，经常会遇到代码格式非常混乱的情况，严重影响了代码的阅读效率。后来发现了一款比较好的工具 &amp;ndash; &amp;ldquo;astyle&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;astyle这个工具可以将现有的代码格式转换为指定的风格，当你将乱七八糟的代码用astyle转换一下之后，就会感觉整个世界都清静了……&lt;/p&gt;

&lt;h3 id=&#34;如何获取&#34;&gt;如何获取&lt;/h3&gt;

&lt;p&gt;astyle是一个开放源码的项目，支持C/C++、C#和java的代码格式化&lt;/p&gt;

&lt;p&gt;SourceForge地址: &lt;a href=&#34;http://sourceforge.net/projects/astyle/&#34;&gt;http://sourceforge.net/projects/astyle/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我的Github拷贝: &lt;a href=&#34;https://github.com/fatedier/fatedier-tools/tree/master/astyle&#34;&gt;https://github.com/fatedier/fatedier-tools/tree/master/astyle&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;编译&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;直接写一个Makefile编译下源码，我的Github的拷贝里有写好的Makefile，直接用gmake命令编译一下就可以用了。&lt;/p&gt;

&lt;h3 id=&#34;示例&#34;&gt;示例&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./astyle --style=ansi test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行之后会提示&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Formatted  xxx/test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;astyle&lt;/strong&gt; 会在当前目录下生成一个备份文件，以 &lt;strong&gt;.orig&lt;/strong&gt; 结尾，例如 &amp;ldquo;test.cpp.orig&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;而 &lt;strong&gt;test.cpp&lt;/strong&gt; 就已经转换为了 &lt;strong&gt;ansi&lt;/strong&gt; 代码风格了。&lt;/p&gt;

&lt;h3 id=&#34;常用选项&#34;&gt;常用选项&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;注：使用 &amp;ndash;help 选项可以查看astyle的帮助文档&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;style风格设置&#34;&gt;style风格设置&lt;/h4&gt;

&lt;p&gt;常用的代码风格主要有三种: &lt;strong&gt;ansi&lt;/strong&gt; 和 &lt;strong&gt;k&amp;amp;r&lt;/strong&gt; 以及 &lt;strong&gt;java&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&amp;ndash;style=allman  OR &amp;ndash;style=ansi OR &amp;ndash;style=bsd OR &amp;ndash;style=break OR -A1&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int Foo()
{
   if (isBar)
    {
       bar();
       return 1;
    }
   else
    {
       return 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;style=kr OR &amp;ndash;style=k&amp;amp;r OR &amp;ndash;style=k/r OR -A3&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int Foo()
{
   if (isBar) {
       bar();
       return 1;
    }else {
       return 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;style=java OR &amp;ndash;style=attach OR -A2&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int Foo() {
   if (isBar) {
       bar();
       return 1;
    }else {
       return 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;tab选项&#34;&gt;Tab选项&lt;/h4&gt;

&lt;p&gt;默认是使用4个空格替换一个tab。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&amp;ndash;indent=spaces=# OR -s#&lt;/p&gt;

&lt;p&gt;指定用几个空格替换一个tab，例如 &amp;ndash;indent=spaces=8 ，指定用8个空格替换一个tab。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;indent=tab OR &amp;ndash;indent=tab=# OR -t OR -t#&lt;/p&gt;

&lt;p&gt;指定缩进使用tab，=#同上，指定一个tab占几个空格，不说明的话默认是4个。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;递归处理&#34;&gt;递归处理&lt;/h4&gt;

&lt;p&gt;&amp;ndash;recursive OR -r OR -R&lt;/p&gt;

&lt;p&gt;可以递归处理所有子目录的文件。&lt;/p&gt;

&lt;h4 id=&#34;排除不处理的文件&#34;&gt;排除不处理的文件&lt;/h4&gt;

&lt;p&gt;&amp;ndash;exclude=####&lt;/p&gt;

&lt;p&gt;指定哪些文件或者文件夹不需要进行处理。&lt;/p&gt;

&lt;h4 id=&#34;指定配置文件&#34;&gt;指定配置文件&lt;/h4&gt;

&lt;p&gt;&amp;ndash;options=####&lt;/p&gt;

&lt;p&gt;可以指定读取某个文件的内容作为参数选项。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Linux下如何进行文件编码格式转换</title>
          <link>http://blog.fatedier.com/2014/11/03/how-to-convert-file-encoding-format-on-linux/</link>
          <pubDate>Mon, 03 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/03/how-to-convert-file-encoding-format-on-linux/</guid>
          <description>&lt;p&gt;最近把项目放到github上，但是发现代码中注释的中文部分有些是乱码，检查后发现是因为我的Centos装在虚拟机上，而我是在Windows环境下通过UE来写代码的，而UE默认是使用ASCII编码。为了避免在UE里对一个个文件进行手动修改，希望在Linux上使用命令来批量转换编码格式。&lt;/p&gt;

&lt;p&gt;查了资料后发现可以使用 &lt;strong&gt;iconv&lt;/strong&gt; 命令。&lt;/p&gt;

&lt;p&gt;首先使用 &lt;strong&gt;file&lt;/strong&gt; 命令来检测文件的类型&lt;/p&gt;

&lt;p&gt;例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;file test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ISO-8859 Cprogram text
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;iconv命令的参数说明&#34;&gt;iconv命令的参数说明&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-l  列出所有已知的字符集
-f  原始文本编码
-t  输出文本编码
-o  输出文件名
-s  关闭警告
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;例子&#34;&gt;例子&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iconv -f GB2312 -t UTF-8 test.cpp &amp;gt; test_utf.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为iconv默认输出到标准输出，所以我们需要重定向到一个其他文件。&lt;strong&gt;（这里不能重定向到自身，否则会清空文件内容）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果想要把输出内容直接输出到当前文件，可以这样用：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iconv -f GB2312 -t UTF-8 -o test.cpp test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;附上我自己用的编码转换脚本-iconvfa-sh&#34;&gt;附上我自己用的编码转换脚本 iconvfa.sh&lt;/h3&gt;

&lt;h4 id=&#34;使用说明&#34;&gt;使用说明&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Usage:
    iconvfa.sh [option] [file|dir]
    from GB2312 to UTF-8, the old file will be replaced by the new converted file

Options:
    -R: convert files recursively, the following parameter should be the directory name
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;脚本代码&#34;&gt;脚本代码&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/env bash

function show_help
{
    echo &amp;quot;Usage:&amp;quot;
    echo &amp;quot;  iconvfa.sh [option] [file|dir]&amp;quot;
    echo -e &amp;quot;  from GB2312 to UTF-8, the old file will be replaced by the new converted file\n&amp;quot;
    echo &amp;quot;Options:&amp;quot;
    echo &amp;quot;  -R: convert files recursively, the following parameter should be the directory name&amp;quot;
}

# param 1: directory name
function convert_rescursive()
{
   local dir_path=`echo $1 | sed &#39;s/\(.*\)\/$/\1/g&#39;`
   local dir_names=`ls ${dir_path} -l | awk &#39;/^d/{print $NF}&#39;`
   
   # convert files in this directory
   local file_names=`ls ${dir_path} -l | awk &#39;/^-/{print $NF}&#39;`
   for file in ${file_names}
   do
       iconv -f ${from_code} -t ${to_code} ${dir_path}/${file} &amp;amp;&amp;gt; /dev/null
       if [ $? == 0 ]; then
           iconv -f ${from_code} -t ${to_code} &amp;lt; ${dir_path}/${file} &amp;gt; $@.$$$$
           cp $@.$$$$ ${dir_path}/${file}
           rm -f $@.$$$$
           echo &amp;quot;File ${dir_path}/${file} is formatted.&amp;quot;
       fi
   done

   # if the directory has no other directory, return 0
   if [ &amp;quot;${dir_names}X&amp;quot; == &amp;quot;X&amp;quot; ]; then
       return 0
   fi

   # continue convert files in directories recursively
   for dir in ${dir_names}
   do
       convert_rescursive &amp;quot;${dir_path}/${dir}&amp;quot;
   done 
}

# defines
from_code=&amp;quot;GB2312&amp;quot;
to_code=&amp;quot;UTF-8&amp;quot;

case &amp;quot;$1&amp;quot; in
&amp;quot;-R&amp;quot;)
    ls $2 &amp;amp;&amp;gt; /dev/null
    if [ $? != 0 -o &amp;quot;$2X&amp;quot; == &amp;quot;X&amp;quot; ]; then
        echo &amp;quot;#### error: please check the directory name following the &#39;-R&#39; option!&amp;quot;
        exit 1
    fi
    convert_rescursive $2
    ;;
&amp;quot;&amp;quot;)
    show_help
    ;;
*)
    iconv -f ${from_code} -t ${to_code} $1 &amp;amp;&amp;gt; /dev/null
    if [ $? == 0 ]; then
        iconv -f ${from_code} -t ${to_code} &amp;lt; $1 &amp;gt; $@.$$$$
        cp $@.$$$$ $1
        rm -f $@.$$$$
        echo &amp;quot;File $1 is formatted.&amp;quot;
    else
        echo &amp;quot;Convert wrong!&amp;quot;
    fi
    ;;
esac
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>使用Vim打造自己的IDE</title>
          <link>http://blog.fatedier.com/2014/10/29/use-vim-to-make-my-ide/</link>
          <pubDate>Wed, 29 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/29/use-vim-to-make-my-ide/</guid>
          <description>&lt;p&gt;之前一直使用UE的FTP功能编辑Linux虚拟机上的代码文件，之后再切换到Linux上去编译，调试程序，感觉这样比较麻烦，而且UE的功能也不像VS以及Eclipse的IDE那样强大，所以就查阅了一些资料，想要把Linux下最常用的文本编辑工具Vim打造成一个适合自己的IDE，可以直接ssh登陆到远程机器上直接进行开发。&lt;/p&gt;

&lt;p&gt;配置自己的Vim过程中参考了以下的blog和文档：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/fbfsber008/article/details/7055842&#34;&gt;http://blog.csdn.net/fbfsber008/article/details/7055842&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.douban.com/note/257815917/&#34;&gt;http://www.douban.com/note/257815917/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/vim-scripts/vundle&#34;&gt;https://github.com/vim-scripts/vundle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最终的效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2014/2014-10-29-use-vim-to-make-my-ide-overview.jpg&#34; alt=&#34;overview&#34; /&gt;&lt;/p&gt;

&lt;p&gt;现在把整个配置的过程记录下来，方便以后参考。&lt;/p&gt;

&lt;h3 id=&#34;前期准备&#34;&gt;前期准备&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;有一个github帐号&lt;/li&gt;
&lt;li&gt;Linux上安装git版本控制工具，可以使用命令安装，例如 yum install git&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;github是一个好地方，不仅可以浏览很多的开源程序，而且可以把自己正在开发的项目或者有用的文档托管在上面，不管在其他任何的计算机上都可以很容易的获取到。&lt;/p&gt;

&lt;p&gt;比如我的 .vimrc 的配置文件就放在了Github上，有一个版本库是专门用来存放配置文件的。&lt;/p&gt;

&lt;p&gt;地址为：&lt;a href=&#34;https://github.com/fatedier/dot_file&#34;&gt;https://github.com/fatedier/dot_file&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;vim常用配置&#34;&gt;vim常用配置&lt;/h3&gt;

&lt;p&gt;个人的vim配置文件一般是放在用户主目录下的.vimrc文件。&lt;/p&gt;

&lt;p&gt;配置文件中 &lt;code&gt;&amp;quot;&lt;/code&gt; 之后的部分都被当作注释。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;if v:lang =~ &amp;quot;utf8$&amp;quot; || v:lang =~&amp;quot;UTF-8$&amp;quot;
    set fileencodings=ucs-bom,utf-8,latin1
endif
       
set nocompatible            &amp;quot; Use Vim defaults (much better!)
set bs=indent,eol,start     &amp;quot; allow backspacing overeverything in insert mode
set viminfo=&#39;20,\&amp;quot;50        &amp;quot; read/write a .viminfo file, don&#39;t store more
                            &amp;quot; than 50 lines of registers
set history=50              &amp;quot; keep 50 lines of command line history
set ruler                   &amp;quot; show the cursor position all the time
                                    
&amp;quot; -----------个人设置-----------
filetype off

set ts=4          &amp;quot; tab所占空格数
set shiftwidth=4  &amp;quot; 自动缩进所使用的空格数
set expandtab     &amp;quot; 用空格替换tab
set autoindent    &amp;quot; 自动缩进
set smartindent   &amp;quot; C语言缩进
set number        &amp;quot; 显示行号
set ignorecase    &amp;quot; 搜索忽略大小写
set incsearch     &amp;quot; 输入字符串就显示匹配点
set showtabline=2 &amp;quot; 总是显示标签页
                                      
if has(&amp;quot;mouse&amp;quot;)
    set mouse=iv  &amp;quot; 在 insert 和 visual 模式使用鼠标定位
endif
      
&amp;quot; -------------颜色配置-------------
&amp;quot; 补全弹出窗口
hi Pmenu ctermbg=light magenta
&amp;quot; 补全弹出窗口选中条目
hi PmenuSel ctermbg=yellow ctermfg=black
       
&amp;quot; -------------键盘映射-------------
&amp;quot; Ctrl+S 映射为保存
nnoremap &amp;lt;C-S&amp;gt; :w&amp;lt;CR&amp;gt;
inoremap &amp;lt;C-S&amp;gt;&amp;lt;Esc&amp;gt;:w&amp;lt;CR&amp;gt;a
        
&amp;quot; Ctrl+C 复制，Ctrl+V 粘贴
inoremap &amp;lt;C-C&amp;gt; y
inoremap &amp;lt;C-V&amp;gt; &amp;lt;Esc&amp;gt;pa
vnoremap &amp;lt;C-C&amp;gt; y
vnoremap &amp;lt;C-V&amp;gt; p
nnoremap &amp;lt;C-V&amp;gt; p

&amp;quot; F3 查找当前高亮的单词
inoremap &amp;lt;F3&amp;gt;*&amp;lt;Esc&amp;gt;:noh&amp;lt;CR&amp;gt;:match Todo /\k*\%#\k*/&amp;lt;CR&amp;gt;v
vnoremap &amp;lt;F3&amp;gt;*&amp;lt;Esc&amp;gt;:noh&amp;lt;CR&amp;gt;:match Todo /\k*\%#\k*/&amp;lt;CR&amp;gt;v

&amp;quot; Ctrl+\ 取消缩进
inoremap &amp;lt;C-\&amp;gt; &amp;lt;Esc&amp;gt;&amp;lt;&amp;lt;i
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用vundle管理vim插件&#34;&gt;使用vundle管理vim插件&lt;/h3&gt;

&lt;p&gt;很多时候我们的vim都需要安装大量的插件，需要进行各种配置，而且插件路径下面的文件也会变的非常混乱，这个时候使用 &lt;strong&gt;vundle&lt;/strong&gt; 就是一个不错的选择。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vim-scripts/vundle&#34;&gt;vundle&lt;/a&gt; 是可以算是一个用来管理各种vim插件的插件。&lt;/p&gt;

&lt;h4 id=&#34;安装ctags&#34;&gt;安装ctags&lt;/h4&gt;

&lt;p&gt;直接使用命令 yuminstall ctags 进行安装。&lt;/p&gt;

&lt;p&gt;之后在你的项目文件的根目录中执行如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ctags -R
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会发现当前目录下生成了一个名为tags的文件。&lt;/p&gt;

&lt;p&gt;tags文件是由ctags程序产生的一个索引文件，如果你在读程序时看了一个函数调用, 或者一个变量, 或者一个宏等等, 你想知道它们的定义在哪儿，tags文件就起作用了。使用把光标移动到你想查的地方，按下&amp;rdquo;Ctrl + ]&amp;ldquo;，就可以跳转到定义处。&lt;/p&gt;

&lt;p&gt;最后需要在vim配置文件中将tags文件加入到vim中来：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;set tags=~/tags
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注：这里需要填具体的tags文件所在路径。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;先安装vundle这个插件&#34;&gt;先安装vundle这个插件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后其他的插件也都会被放在~/.vim/bundle这个目录下。&lt;/p&gt;

&lt;h4 id=&#34;安装其他需要的插件&#34;&gt;安装其他需要的插件&lt;/h4&gt;

&lt;p&gt;以后当你需要安装其他的vim插件的时候，直接在.vimrc中加上如下部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;filetype off
 
setrtp+=~/.vim/bundle/vundle/
call vundle#rc()
&amp;quot; Bundles
&amp;quot; 显示变量、函数列表等
Bundle&amp;quot;taglist.vim&amp;quot;
&amp;quot; 窗口管理器
Bundle&amp;quot;winmanager&amp;quot;
&amp;quot; 标签工具
Bundle&amp;quot;Visual-Mark&amp;quot;
&amp;quot; 代码补全工具
Bundle&amp;quot;neocomplcache&amp;quot;
  
filetype pluginindent on
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bundle 后面的插件名称用引号引起来，最后在vim中输入:BundleInstall就会完成自动安装，实际上是也是从github上下载各种插件，因为大多数的插件已经备份在了github上的vim-scripts上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;:PluginSearch&lt;/code&gt; 命令可以查看有哪些插件可以直接使用插件名下载的。&lt;/p&gt;

&lt;p&gt;如果你需要的插件在这个里面没有找到，那么在.vimrc配置文件中可以直接用git远程仓库的地址，例如要安装command-t这个插件，可以在配置文件中加上：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;Bundle &amp;quot;git://git.wincent.com/command-t.git&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会直接从这个地址上下载所需插件。&lt;/p&gt;

&lt;h3 id=&#34;其他插件的配置与使用&#34;&gt;其他插件的配置与使用&lt;/h3&gt;

&lt;h4 id=&#34;快速浏览源码-taglist&#34;&gt;快速浏览源码：TagList&lt;/h4&gt;

&lt;p&gt;在Windows平台我经常用来浏览项目源码的工具就是SourceInsight，会在窗口左边列出当前文件中的变量、宏、函数名等等，点击以后就会快速跳转到页面相应的地方，使用taglist就可以在vim中实现相同的效果。&lt;/p&gt;

&lt;p&gt;通过vundle安装完成后，在vim中使用 &lt;code&gt;:Tlist&lt;/code&gt; 命令就可以打开TagList窗口。&lt;/p&gt;

&lt;h4 id=&#34;窗口管理器-winmanager&#34;&gt;窗口管理器：WinManager&lt;/h4&gt;

&lt;p&gt;WinManager可以帮助我们管理在屏幕上显示的多个窗口。&lt;/p&gt;

&lt;p&gt;之后我们需要设置一下在normal模式下可以直接输入wm来打开文件管理窗口以及TagList，.vimrc文件增加如下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;let g:winManagerWindowLayout=&#39;FileExplorer|TagList&#39;
nnoremap wm:WMToggle&amp;lt;cr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注：nnoremap是设置键盘映射。第一个字母n是normal模式，i是insert模式，v是visual模式。加上nore表示不会递归替换命令，比如a映射到b，b映射到c，那么按a不会得到按c的效果。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;高亮标签-visualmark&#34;&gt;高亮标签：VisualMark&lt;/h4&gt;

&lt;p&gt;这个插件的作用就是在浏览代码的时候在指定的行上添加标签，之后可以快速跳转回来，方便快捷。&lt;/p&gt;

&lt;p&gt;安装完成之后直接就可以在vim中使用。&lt;/p&gt;

&lt;p&gt;&amp;ldquo;mm&amp;rdquo; 命令会在当前行添加标签，再次按 &amp;ldquo;mm&amp;rdquo; 会取消标签。&lt;/p&gt;

&lt;p&gt;按下“F2”可以在多个标签之间进行快速跳转。&lt;/p&gt;

&lt;h4 id=&#34;自动补全-neocomplcache&#34;&gt;自动补全：neocomplcache&lt;/h4&gt;

&lt;p&gt;这个补全插件需要tags文件的支持，所以需要安装ctags，并且在项目根目录生成tags文件，之后在.vimrc中加入这个tags文件。&lt;/p&gt;

&lt;p&gt;并且在配置文件中加上如下配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;let g:neocomplcache_enable_at_startup = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这一行是设置是否自动启用补全，为1代表启用。这样就不需要每次都使用Ctrl+P或者Ctrl+N来弹出补全列表。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;let g:neocomplcache_enable_auto_select = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这一行是设置是否启用自动选择，为1代表启用。这个时候弹出补全列表的时候会自动选择第一个，按下Enter键就会使用列表的第一项，否则每一次都需要自己多按一次进行选择。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>vimdiff常用命令</title>
          <link>http://blog.fatedier.com/2014/10/24/vimdiff-common-commands/</link>
          <pubDate>Fri, 24 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/24/vimdiff-common-commands/</guid>
          <description>&lt;p&gt;整理了一下在使用vimdiff进行文件合并的时候用到的一些常用的命令，方便以后查询。&lt;/p&gt;

&lt;p&gt;可以有多种方式使用vimdiff，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vimdiff [file1] [file2]

vim -d [file1] [file2]
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;其他的一些的编辑命令与vim相同，这里主要记录一些常用的合并文件需要用到的命令：&lt;/p&gt;

&lt;h4 id=&#34;ctrl-w之后按w&#34;&gt;Ctrl+w之后按w&lt;/h4&gt;

&lt;p&gt;可以切换到另外一个文件&lt;/p&gt;

&lt;h4 id=&#34;c&#34;&gt;[c&lt;/h4&gt;

&lt;p&gt;跳转到上一个差异点&lt;/p&gt;

&lt;h4 id=&#34;c-1&#34;&gt;]c&lt;/h4&gt;

&lt;p&gt;跳转到下一个差一点&lt;/p&gt;

&lt;h4 id=&#34;zo或者i&#34;&gt;zo或者i&lt;/h4&gt;

&lt;p&gt;展开折叠区域，或者使用i进入插入模式也会进行展开&lt;/p&gt;

&lt;h4 id=&#34;zc&#34;&gt;zc&lt;/h4&gt;

&lt;p&gt;重新折叠，可以把使用zo展开折叠的区域恢复原样&lt;/p&gt;

&lt;h4 id=&#34;dp-diff-put的意思&#34;&gt;dp（diff put的意思）&lt;/h4&gt;

&lt;p&gt;把当前文件的差异点内容复制到另一个文件&lt;/p&gt;

&lt;h4 id=&#34;do-diff-obtain的意思&#34;&gt;do（diff obtain的意思）&lt;/h4&gt;

&lt;p&gt;把另一个文件的差异点内容复制到当前文件&lt;/p&gt;

&lt;h4 id=&#34;diffupdate&#34;&gt;:diffupdate&lt;/h4&gt;

&lt;p&gt;有时候修改了文件之后不会立即刷新重新比对，使用该命令可以重新进行文件比较。&lt;/p&gt;

&lt;h4 id=&#34;qa&#34;&gt;qa&lt;/h4&gt;

&lt;p&gt;退出所有打开的文件，但是不保存&lt;/p&gt;

&lt;h4 id=&#34;wqa&#34;&gt;wqa&lt;/h4&gt;

&lt;p&gt;退出并保存所有已打开的文件&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Git常用命令</title>
          <link>http://blog.fatedier.com/2014/10/17/git-usually-command/</link>
          <pubDate>Fri, 17 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/17/git-usually-command/</guid>
          <description>&lt;p&gt;在用Git进行项目管理的时候有一些经常会遇到的问题处理起来比较复杂，本文记录了一些常用的命令和操作。&lt;/p&gt;

&lt;h3 id=&#34;修改某一次提交的说明信息&#34;&gt;修改某一次提交的说明信息&lt;/h3&gt;

&lt;p&gt;有时候我们需要修改之前提交的时候的说明信息，没有操作命令可以直接完成，但是使用rebase命令可以实现。&lt;/p&gt;

&lt;p&gt;例如我们要修改倒数第二次的提交的说明信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rebase -i HEAD~3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注意：这里HEAD~后面跟着的是3而不是2，因为这里指的是要修改的提交的父提交。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之后会进入到文本编辑界面，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2014/2014-10-17-git-usually-command-git-reset-commit-message.jpg&#34; alt=&#34;reset-commit-message&#34; /&gt;&lt;/p&gt;

&lt;p&gt;将要修改的提交前面的 &lt;strong&gt;pick&lt;/strong&gt; 改为 &lt;strong&gt;edit&lt;/strong&gt; ，保存后退出。&lt;/p&gt;

&lt;p&gt;这个时候执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit --amend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以修改该次提交的说明了，修改完成后保存并退出。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rebase --continue
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行这条命令后，后续的提交说明将不会改变。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：不要修改已经 push 到远程仓库的提交！！！会引起版本混乱，使提交历史变的不清晰！&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;查看-删除-重命名远程分支&#34;&gt;查看、删除、重命名远程分支&lt;/h3&gt;

&lt;p&gt;查看所有的分支（包括远程分支）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当一个分支已经被合并到主分支后，我们通常会删除这个分支，如果仅仅 git branch -d 是删除本地分支&lt;/p&gt;

&lt;p&gt;删除远程分支的话可以使用如下命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push origin --delete &amp;lt;branchName&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重命名一个分支不是很常用，可以先删除远程分支，再重命名本地分支，之后将重命名后的本地分支推送到远程仓库&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push --delete origin &amp;lt;branchName&amp;gt;

$ git branch -m &amp;lt;branchName&amp;gt; &amp;lt;newBranchName&amp;gt;

$ git push origin &amp;lt;newBranchName&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;合并多个提交&#34;&gt;合并多个提交&lt;/h3&gt;

&lt;p&gt;比如要合并最后两次的提交，其实和修改某一次提交的说明信息有点类似。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rebase -i HEAD~2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后同样会进入到文本编辑界面，将第二行开头的 &lt;strong&gt;pick&lt;/strong&gt; 改为 &lt;strong&gt;squash&lt;/strong&gt; 或 &lt;strong&gt;s&lt;/strong&gt;，保存后退出。&lt;/p&gt;

&lt;p&gt;这时git会把两次提交合并，并且提示让你输入新的提交信息，保存后退出就成功完成两次提交的合并了。&lt;/p&gt;

&lt;h3 id=&#34;强制回退远程仓库到指定提交&#34;&gt;强制回退远程仓库到指定提交&lt;/h3&gt;

&lt;p&gt;当我们在开发的时候出现一些关键性的错误，并且确认现在已经做的开发工作是无意义的时候，可能需要回退到之前的版本。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git reset --hard &amp;lt;commit_id&amp;gt;

$ git push origin HEAD --force
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外，reset命令还有几个可选参数&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;git reset &amp;ndash;mixed&lt;/strong&gt;：此为默认方式，不带任何参数的git reset，即时这种方式，它回退到某个版本，只保留源码，回退commit和index信息。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;git reset &amp;ndash;soft&lt;/strong&gt;：回退到某个版本，只回退了commit的信息，不会恢复到indexfile一级。如果还要提交，直接commit即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;git reset &amp;ndash;hard&lt;/strong&gt;：彻底回退到某个版本，本地的源码也会变为上一个版本的内容。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;reset-hard之后的恢复&#34;&gt;reset &amp;ndash;hard之后的恢复&lt;/h3&gt;

&lt;p&gt;使用 &lt;code&gt;git reset --hard&lt;/code&gt; 之后，也许才发现这是一次错误的操作，那么我们就想要恢复到之前的版本。&lt;/p&gt;

&lt;p&gt;这个时候用git log是看不到之前的提交历史记录的。&lt;/p&gt;

&lt;p&gt;需要使用 &lt;code&gt;$ git reflog&lt;/code&gt; 找到我们需要恢复的HEAD的ID，然后使用reset命令恢复回去。&lt;/p&gt;

&lt;h3 id=&#34;查看指定版本的某个文件的内容&#34;&gt;查看指定版本的某个文件的内容&lt;/h3&gt;

&lt;p&gt;例如要查看 f4869b0 这次提交的 test.cpp 文件的内容，test.cpp的路径需要使用相对于git目录的路径名，使用如下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git show f4869b0:test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文件的内容会全部显示在界面上，可以使用文件重定向到另外的文件，再进行后续操作。&lt;/p&gt;

&lt;h3 id=&#34;将远程分支已经删除的残留的本地分支追踪信息删除&#34;&gt;将远程分支已经删除的残留的本地分支追踪信息删除&lt;/h3&gt;

&lt;p&gt;经过一段时间的开发后，远端的一些被 merge 后删除的分支，在本地使用 &lt;code&gt;git branch -a&lt;/code&gt; 还是能看到，需要取消追踪并删除。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git fetch --prune
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>Git使用备忘</title>
          <link>http://blog.fatedier.com/2014/10/16/git-use-for-remind/</link>
          <pubDate>Thu, 16 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/16/git-use-for-remind/</guid>
          <description>&lt;p&gt;Git是一款免费、开源的分布式版本控制系统，由于 GitHub 的存在，我们很方便的用于管理我们平时的开发项目。&lt;/p&gt;

&lt;p&gt;Git的命令较多，虽然大多数都不是很常用，但是还是需要记下来方便日后查看。&lt;/p&gt;

&lt;h3 id=&#34;git的配置&#34;&gt;Git的配置&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;/etc/gitconfig 文件：系统中对所有用户都普遍适用的配置。若使用 git config 时用 &amp;ndash;system 选项，读写的就是这个文件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;~/.gitconfig 文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 &amp;ndash;global 选项，读写的就是这个文件。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当前项目的 Git 目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所.git/config 里的配置会覆盖 /etc/gitconfig 中的同名变量。&lt;/p&gt;

&lt;h4 id=&#34;设置用户信息&#34;&gt;设置用户信息&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git config --globaluser.name  &amp;quot;your-uasername&amp;quot;
$ git config --global user.email example@example.com
$ git config --global core.editor vim
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;设置差异分析工具&#34;&gt;设置差异分析工具&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git config --global merge.tool vimdiff
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;如何获取帮助文档&#34;&gt;如何获取帮助文档&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git help &amp;lt;verb&amp;gt;
$ git &amp;lt;verb&amp;gt; --help
$ man git-&amp;lt;verb&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如 &lt;code&gt;man git-config&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;git基础操作&#34;&gt;Git基础操作&lt;/h3&gt;

&lt;h4 id=&#34;取得git仓库-从现有仓库克隆&#34;&gt;取得Git仓库（从现有仓库克隆）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/schacon/fatest.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会在当前目录下创建一个fatest的目录，其中的.git目录保存所有的版本记录。fatest下是项目的所有文件。&lt;/p&gt;

&lt;p&gt;如果要自定义目录名称，可以在末尾指定，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/schacon/fatest.git fatestnew
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在创建的目录就是fatestnew而不是fatest了，其他的都一样。&lt;/p&gt;

&lt;h4 id=&#34;检查当前项目文件状态&#34;&gt;检查当前项目文件状态&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到有哪些文件是没有加入到版本中的，哪些是修改了还没提交的等等。&lt;/p&gt;

&lt;h4 id=&#34;将新文件加入到版本中&#34;&gt;将新文件加入到版本中&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git add test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注：&lt;code&gt;git add&lt;/code&gt;命令对于不同状态的文件有不同的效果，可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。&lt;/p&gt;

&lt;p&gt;*注意*修改过后的文件处于未暂存状态，提交的时候处于未暂存状态的文件将不会提交，需要使用git add命令更改为暂存状态，之后再提交就会提交到仓库中了。&lt;/p&gt;

&lt;h4 id=&#34;忽略某些文件&#34;&gt;忽略某些文件&lt;/h4&gt;

&lt;p&gt;对于不需要加入到版本中，并且使用git status时不再提示的文件。&lt;/p&gt;

&lt;p&gt;在 .gitignore 文件中进行配置，例如*.exe&lt;/p&gt;

&lt;p&gt;那么所有的以.exe结尾的文件都会被忽略，而不再提醒。&lt;/p&gt;

&lt;p&gt;例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 此为注释，将被 Git 忽略
# 忽略所有 .a 结尾的文件
*.a
# 但 lib.a 除外
!lib.a
# 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO
/TODO
# 忽略 build/ 目录下的所有文件
build/
# 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt
doc/*.txt
# ignore all .txt files in the doc/ directory
doc/**/*.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看已暂存和未暂存的更新文件差异&#34;&gt;查看已暂存和未暂存的更新文件差异&lt;/h4&gt;

&lt;p&gt;未暂存：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git diff
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;已暂存：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git diff --staged
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;提交更新&#34;&gt;提交更新&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后进入vim编辑提交说明，保存即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit --m &amp;quot;comment&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 &lt;em&gt;-m&lt;/em&gt; 命令可以直接在一行命令中写说明。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 &lt;em&gt;-a&lt;/em&gt; 命令，会把未暂存和已暂存的文件一起提交，不然只会提交已暂存的文件。&lt;/p&gt;

&lt;h4 id=&#34;删除文件和取消跟踪&#34;&gt;删除文件和取消跟踪&lt;/h4&gt;

&lt;p&gt;可以先本地使用rm命令删掉，这时候放在未暂存区域，之后用“git rm文件名”删掉。&lt;/p&gt;

&lt;p&gt;也可以直接使用 &lt;code&gt;git rm 文件名&lt;/code&gt; 删掉。&lt;/p&gt;

&lt;p&gt;另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仅是从跟踪清单中删除。比如一些大型日志文件或者一堆 .a 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 &amp;ndash;cached 选项即可：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rm --cached readme.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;移动文件&#34;&gt;移动文件&lt;/h4&gt;

&lt;p&gt;例如要把 test.cpp 改为 tt.cpp&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git mv test.cpp tt.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就相当于是&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mv README.txt README
$ git rm README.txt
$ git add README
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看提交历史&#34;&gt;查看提交历史&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;撤销操作&#34;&gt;撤销操作&lt;/h4&gt;

&lt;h5 id=&#34;覆盖上一次的提交&#34;&gt;覆盖上一次的提交&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit --amend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会将上次提交和这次提交合并起来，算作一次提交。&lt;/p&gt;

&lt;h5 id=&#34;取消已暂存文件&#34;&gt;取消已暂存文件&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git reset HEAD &amp;lt;file&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个时候文件状态就从已暂存变为未暂存&lt;/p&gt;

&lt;h5 id=&#34;取消对文件的修改-还没有放到暂存区&#34;&gt;取消对文件的修改（还没有放到暂存区）&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout -- &amp;lt;file&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;运程仓库的使用&#34;&gt;运程仓库的使用&lt;/h4&gt;

&lt;h5 id=&#34;查看当前的远程库&#34;&gt;查看当前的远程库&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会列出每个远程库的简短的名字，默认使用origin表示原始仓库&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会额外列出远程库对应的克隆地址&lt;/p&gt;

&lt;h5 id=&#34;添加远程仓库&#34;&gt;添加远程仓库&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote add [shortname] [url]
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;从远程仓库抓取数据&#34;&gt;从远程仓库抓取数据&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git fetch [remote-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;抓取数据，但并不合并到当前分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git pull
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自动抓取数据，并自动合并到当前分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -r
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看所有远程分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout -b test origin/test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;获取远程分支到本地新的分支上，并切换到新分支&lt;/p&gt;

&lt;h5 id=&#34;推送数据到远程仓库&#34;&gt;推送数据到远程仓库&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push [remote-name] [branch-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;推送操作会默认使用origin和master名字&lt;/p&gt;

&lt;h5 id=&#34;查看远程仓库信息&#34;&gt;查看远程仓库信息&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote show [remote-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除了对应的克隆地址外，它还给出了许多额外的信息。它友善地告诉你如果是在 master 分支，就可以用 git pull 命令抓取数据合并到本地。另外还列出了所有处于跟踪状态中的远端分支。&lt;/p&gt;

&lt;h5 id=&#34;远程仓库的删除&#34;&gt;远程仓库的删除&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote rm [remote-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;标签的使用&#34;&gt;标签的使用&lt;/h4&gt;

&lt;h5 id=&#34;显示已有的标签&#34;&gt;显示已有的标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;新建标签&#34;&gt;新建标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag v1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新建一个简单的标签&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag -a v1.0 -m &#39;my version 1.0&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-m 指定了对应标签的说明&lt;/p&gt;

&lt;h5 id=&#34;后期加注标签&#34;&gt;后期加注标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log --pretty=oneline --abbrev-commit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先显示提交历史&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag -a v1.1 9fceb02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;补加标签&lt;/p&gt;

&lt;h5 id=&#34;推送标签&#34;&gt;推送标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push origin [tagname]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;设置命令别名&#34;&gt;设置命令别名&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git config --global alias.co checkout
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;git分支&#34;&gt;Git分支&lt;/h3&gt;

&lt;h4 id=&#34;新建分支&#34;&gt;新建分支&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会在当前commit对象上新建一个分支指针&lt;/p&gt;

&lt;p&gt;&lt;em&gt;注：HEAD这个特别的指针是指向正在工作中的本地分支的指针&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;切换分支&#34;&gt;切换分支&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;切换到testing分支上&lt;/p&gt;

&lt;h4 id=&#34;分支的合并&#34;&gt;分支的合并&lt;/h4&gt;

&lt;p&gt;在master分支上，执行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git merge testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将tesing分支合并回master&lt;/p&gt;

&lt;h4 id=&#34;使用合并工具-可以自己设置-例如设置成vimdiff&#34;&gt;使用合并工具（可以自己设置，例如设置成vimdiff）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git mergetool
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;分支的管理&#34;&gt;分支的管理&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch --merged
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看哪些分支已经被并入当前分支，通常这些都可以删除了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -d testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;删除一个分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -D testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果该分支尚没有合并，可以使用-D选项强制删除。&lt;/p&gt;

&lt;h4 id=&#34;推送本地分支&#34;&gt;推送本地分支&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push origin testing
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;分支的衍合&#34;&gt;分支的衍合&lt;/h4&gt;

&lt;p&gt;例如现在有两个分支，一个master，一个testing&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout testing
$ git rebase master
$ git checkout master
$ git merge testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常在贡献自己的代码之前先衍合，再提交，会让历史提交记录更清晰。&lt;/p&gt;

&lt;h3 id=&#34;git调试&#34;&gt;Git调试&lt;/h3&gt;

&lt;h4 id=&#34;文件标注&#34;&gt;文件标注&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git blame -L 12,22 test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看test.cpp文件对每一行进行修改的最近一次提交。&lt;/p&gt;

&lt;h4 id=&#34;查看文件的历史提交&#34;&gt;查看文件的历史提交&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log --pretty=oneline test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看test.cpp文件的历史提交记录&lt;/p&gt;

&lt;h4 id=&#34;查看文件的历史版本&#34;&gt;查看文件的历史版本&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git show [commit] [file]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如：&lt;code&gt;$ git show 7da7c23 test.cpp&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看7da7c23这次提交的test.cpp文件。&lt;/p&gt;

&lt;h4 id=&#34;查看历史提交的详细文件变化&#34;&gt;查看历史提交的详细文件变化&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log -p -2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这条命令可以看到最近两次提交的文件变化情况，删除的部分会以 &amp;ldquo;-&amp;rdquo; 开头，新增的部分会以 &amp;ldquo;+&amp;rdquo; 开头，方便查看。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>学习Git的常用网站</title>
          <link>http://blog.fatedier.com/2014/10/16/learn-git-website/</link>
          <pubDate>Thu, 16 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/16/learn-git-website/</guid>
          <description>&lt;p&gt;学习Git的使用的过程中参考了很多的网站，主要是两个地方讲的比较清楚，例子也很丰富，特别记录一下。&lt;/p&gt;

&lt;h4 id=&#34;git官方文档&#34;&gt;Git官方文档&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://git-scm.com/book/zh/&#34;&gt;http://git-scm.com/book/zh/&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;廖雪峰git教程&#34;&gt;廖雪峰Git教程&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000&#34;&gt;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>主机使用代理上网，虚拟机Linux的shell如何连外网</title>
          <link>http://blog.fatedier.com/2014/10/14/how-virtual-machine-connect-internet-while-host-getonline-with-agent/</link>
          <pubDate>Tue, 14 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/14/how-virtual-machine-connect-internet-while-host-getonline-with-agent/</guid>
          <description>&lt;p&gt;在公司电脑上网都需要使用代理，虚拟机里面装的Linux系统需要使用yum命令来安装软件，所以需要在shell界面能连上外网才行。&lt;/p&gt;

&lt;p&gt;因为公司限制了每个人只能用一个IP，所以虚拟机中的Linux系统使用NAT方式和主机相连。主机是Win7操作系统，会发现网络里面多了VMnet8这个网络。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2014/2014-10-14-how-virtual-machine-connect-internet-while-host-getonline-with-agent-vmware-net.jpg&#34; alt=&#34;vmware-net&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在VMware界面，点击“编辑”，“虚拟网络编辑器”&lt;/p&gt;

&lt;p&gt;可以看到子网地址分配的是192.168.131.0&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;一般来说这时我们的主机会自动分配一个IP类似192.168.131.1这样的，子网掩码为255.255.255.0，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2014/2014-10-14-how-virtual-machine-connect-internet-while-host-getonline-with-agent-host-net.jpg&#34; alt=&#34;host-net&#34; /&gt;&lt;/p&gt;

&lt;p&gt;现在进入虚拟机的Linux进行设置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2014/2014-10-14-how-virtual-machine-connect-internet-while-host-getonline-with-agent-network-configuration.jpg&#34; alt=&#34;network-configuration&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意IP需要设置成192.168.131.x的形势，网关是192.168.131.2。&lt;/p&gt;

&lt;p&gt;之后使用 &lt;code&gt;service network restart&lt;/code&gt; 命令重启网络服务。&lt;/p&gt;

&lt;p&gt;然后可以用 &lt;code&gt;ifconfig&lt;/code&gt; 命令检查配置是否正确。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;最后，修改自己目录下的配置文件，使用“cd”命令进入自己的根目录。&lt;/p&gt;

&lt;p&gt;比如我的是.bash_profile&lt;/p&gt;

&lt;p&gt;添加代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export http_proxy=&amp;quot;http://proxy_addr:port&amp;quot;
export https_proxy=&amp;quot;http://proxy_addr:port&amp;quot;
export ftp_proxy=&amp;quot;http://proxy_addr:port&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;proxy_addr&lt;/strong&gt; 就是代理的IP地址&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;port&lt;/strong&gt; 是代理的款口号&lt;/p&gt;

&lt;p&gt;如果代理需要用户名和密码的话，这样设置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export http_proxy=&amp;quot;http://username:password@proxy_addr:port&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在就可以使用yum命令安装需要的软件了。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>C/C&#43;&#43;获取精确到微秒级的系统时间</title>
          <link>http://blog.fatedier.com/2014/09/30/get-systime-accurate-to-microseconds-in-c-or-cpp/</link>
          <pubDate>Tue, 30 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/30/get-systime-accurate-to-microseconds-in-c-or-cpp/</guid>
          <description>&lt;p&gt;最近要为自己的项目开发一个日志模块，需要获取精确到微秒级的系统时间，查阅了一些资料，发现在C/C++里面可以通过 gettimeofday(struct timeval * tv,struct timezone * tz) 和 localtime(const time_t * timep) 这两个函数的配合使用来得到我想要的结果。&lt;/p&gt;

&lt;p&gt;先贴一下这两个函数的说明&lt;/p&gt;

&lt;h4 id=&#34;gettimeofday&#34;&gt;gettimeofday&lt;/h4&gt;

&lt;p&gt;头文件：&lt;strong&gt;#include &lt;sys/time.h&gt;   #include &lt;unistd.h&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数定义：&lt;strong&gt;int gettimeofday (struct timeval * tv, struct timezone * tz);&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数说明：gettimeofday()会把目前的时间有tv 所指的结构返回，当地时区的信息则放到tz 所指的结构中。时间是从公元 1970 年1 月1 日的UTC 时间从0 时0 分0 秒算起到现在所经过的时间。&lt;/p&gt;

&lt;p&gt;timeval 结构定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct timeval
{
    long tv_sec;     // 秒
    long tv_usec;    // 微秒
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;timezone 结构定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct timezone
{
    int tz_minuteswest;  // 和格林威治时间差了多少分钟
    int tz_dsttime;      // 日光节约时间的状态
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;localtime&#34;&gt;localtime&lt;/h4&gt;

&lt;p&gt;头文件：&lt;strong&gt;#include &lt;time.h&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数定义：&lt;strong&gt;struct tm *localtime (const time_t *timep);&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数说明：localtime()将参数timep 所指的time_t 结构中的信息转换成真实世界所使用的时间日期表示方法，然后将结果由结构tm 返回。&lt;/p&gt;

&lt;p&gt;结构tm 的定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int tm_sec;   // 代表目前秒数, 正常范围为0-59, 但允许至61 秒
int tm_min;   // 代表目前分数, 范围0-59
int tm_hour;  // 从午夜算起的时数, 范围为0-23
int tm_mday;  // 目前月份的日数, 范围1-31
int tm_mon;   // 代表目前月份, 从一月算起, 范围从0-11
int tm_year;  // 从1900 年算起至今的年数
int tm_wday;  // 一星期的日数, 从星期一算起, 范围为0-6
int tm_yday;  // 从今年1 月1 日算起至今的天数, 范围为0-365
int tm_isdst; // 日光节约时间的旗标
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用localtime函数的时候需要注意计算年份的时候需要加上1900，计算月份的时候需要加1。&lt;/p&gt;

&lt;h3 id=&#34;使用说明&#34;&gt;使用说明&lt;/h3&gt;

&lt;p&gt;我们先调用gettimeofday函数获取到从公元 1970年1 月1 日的UTC 时间从0 时0 分0 秒算起到现在所经过的秒数加上微秒数，然后将秒数作为参数再调用localtime函数，转换为本地时区的当前时间即可，之后可以使用localtime函数返回的tm结构体对象来获取具体的年月日时分秒等数据。&lt;/p&gt;

&lt;h3 id=&#34;示例代码&#34;&gt;示例代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;time.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
using namespace std;
 
string fa_getSysTime()
{
    struct timeval tv;
    gettimeofday(&amp;amp;tv,NULL);
    struct tm* pTime;
    pTime = localtime(&amp;amp;tv.tv_sec);
    
    charsTemp[30] = {0};
    snprintf(sTemp, sizeof(sTemp), &amp;quot;%04d%02d%02d%02d%02d%02d%03d%03d&amp;quot;, pTime-&amp;gt;tm_year+1900, \
    pTime-&amp;gt;tm_mon+1, pTime-&amp;gt;tm_mday, pTime-&amp;gt;tm_hour, pTime-&amp;gt;tm_min, pTime-&amp;gt;tm_sec, \
    tv.tv_usec/1000,tv.tv_usec%1000);
    return (string)sTemp;
}
 
int main()
{
    cout&amp;lt;&amp;lt; &amp;quot;当前时间：&amp;quot; &amp;lt;&amp;lt; fa_getSysTime() &amp;lt;&amp;lt; endl;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;输出为&#34;&gt;输出为&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;当前时间：20140930110457794678
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>size() == 0和empty()的比较</title>
          <link>http://blog.fatedier.com/2014/09/26/function-size-equal-zero-compare-with-empty/</link>
          <pubDate>Fri, 26 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/26/function-size-equal-zero-compare-with-empty/</guid>
          <description>&lt;p&gt;最近开发公司项目的时候发现大量用到了STL模板库，而且很多地方都需要判断一个容器是否为空，看到了两种写法，分别使用了容器的 size() 函数和 empty()函数。&lt;/p&gt;

&lt;p&gt;我觉得很好奇，这两种写法有什么区别呢？在网上查阅了一些资料，发现说empty()效率更高的占大多数。又查看了SGI STL的帮助文档，里面有一句话：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you are testing whether a container is empty, you should always write c.empty()instead of c.size() == 0. The two expressions are equivalent, but the formermay be much faster.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;大致上的意思就是在检测容器是否为空的时候，推荐用empty()代替使用size() == 0，两者的含义是相等的，但是前者可能会更快一些。&lt;/p&gt;

&lt;p&gt;之后又在stackoverflow上看到有人提了一个类似的问题，并且贴出了STL的实现源码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;bool empty()const
    {return(size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这就让我更诧异了，这样的话empty()会比size() == 0更高效吗？&lt;/p&gt;

&lt;p&gt;实践是检验真理的唯一标准，那么我们就亲自来测试一下吧。&lt;/p&gt;

&lt;p&gt;为了公平起见，也为了测试方便，我分别在两个平台上进行测试，分别是Aix5.3以及Centos6.5。&lt;/p&gt;

&lt;p&gt;由于容器的内部实现的不同，我们测试三种比较典型也用的较多的容器：vector、list以及map。&lt;/p&gt;

&lt;p&gt;测试的代码如下，因为代码基本上差别不大，这里只贴一下测试vector的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;vector&amp;gt;
using namespace std;

class A
{
public:
    int a;
};

int main()
{
    cout &amp;lt;&amp;lt; &amp;quot;vector:&amp;quot; &amp;lt;&amp;lt; endl;

    long number = 20000000;
    vector&amp;lt;A&amp;gt; tmpList;
    A temp;
    temp.a = 1;

    struct timeval tv_begin, tv_end;

    //初始化tmpList中元素个数为：number
    tmpList.resize(number);

    //对size() == 0计时
    int flag = 0;
    gettimeofday(&amp;amp;tv_begin, NULL);
    for(long i=0; i&amp;lt;number*5; i++)
    {
        if(tmpList.size() == 0)
        {
        }
    }
    gettimeofday(&amp;amp;tv_end, NULL);
    cout &amp;lt;&amp;lt; &amp;quot;size() msec: &amp;quot; &amp;lt;&amp;lt; (tv_end.tv_sec - tv_begin.tv_sec)*1000 + (tv_end.tv_usec - tv_begin.tv_usec)/1000 &amp;lt;&amp;lt; endl;

    //对empty()计时
    gettimeofday(&amp;amp;tv_begin, NULL);
    for(long i=0; i&amp;lt;number*5; i++)
    {
        if(tmpList.empty())
        {
        }
    }
    gettimeofday(&amp;amp;tv_end, NULL);
    cout &amp;lt;&amp;lt; &amp;quot;empty() msec: &amp;quot; &amp;lt;&amp;lt; (tv_end.tv_sec - tv_begin.tv_sec)*1000 + (tv_end.tv_usec - tv_begin.tv_usec)/1000 &amp;lt;&amp;lt; endl;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里用到了gettimeofday这个函数用来计时，在需要计时的地方分别调用两次该函数之后得到的时间相减即可获得该代码段执行的时间。&lt;/p&gt;

&lt;p&gt;timeval结构体有两个变量分别是tv_sec和tv_usec分别是精确到秒和微秒级别。&lt;/p&gt;

&lt;p&gt;因为这两个函数本身耗时太短，不方便测算时间，所以采取重复调用再计时的方法。&lt;/p&gt;

&lt;h3 id=&#34;vector&#34;&gt;vector&lt;/h3&gt;

&lt;h4 id=&#34;aix&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec:2736
empty() msec:4820

第2次输出：
vector:
size() msec:2762
empty() msec:4877
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;centos&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 298
empty() msec:1541

第2次输出：
vector:
size() msec: 283
empty() msec:1530
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;list&#34;&gt;list&lt;/h3&gt;

&lt;h4 id=&#34;aix-1&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 13
empty() msec: 22

第2次输出：
vector:
size() msec: 13
empty() msec: 22
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;centos-1&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 241696
empty() msec: 1

第2次输出：
vector:
size() msec: 242109
empty() msec: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;map&#34;&gt;map&lt;/h3&gt;

&lt;h4 id=&#34;aix-2&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 1337
empty() msec: 1733

第2次输出：
vector:
size() msec: 1339
empty() msec: 1733
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;centos-2&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 291
empty() msec: 267

第2次输出：
vector:
size() msec: 290
empty() msec: 304
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出，并非在所有情况下empty()的效率都是优于size()的。具体的效率还和所使用的平台相关，准确的说是和STL源码的实现方式有关。&lt;/p&gt;

&lt;p&gt;下面我们就一起来看一下两个系统中STL源码部分是如何实现size()和empty()的。&lt;/p&gt;

&lt;h3 id=&#34;vector源码&#34;&gt;vector源码&lt;/h3&gt;

&lt;h4 id=&#34;aix-3&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    {return (_Size); }
 
bool empty() const
    {return (size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出Aix上vector的empty()函数实际上是调用了size()函数进行判断，size()函数返回的是表示当前容器数量的一个变量，所以，显然，size() == 0的效率是要高于empty()的，因为少了函数调用部分的耗时。&lt;/p&gt;

&lt;h4 id=&#34;centos-3&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    { return size_type(this-&amp;gt;_M_impl._M_finish -this-&amp;gt;_M_impl._M_start); }
 
bool empty() const
    { return begin() == end(); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里size()是尾指针减去头指针得到的，而empty()是比较头指针和尾指针是否相等。在empty()里多了函数调用以及临时变量赋值等操作。&lt;/p&gt;

&lt;h3 id=&#34;list源码&#34;&gt;list源码&lt;/h3&gt;

&lt;h4 id=&#34;aix-4&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    {return (_Size); }
 
bool empty() const
    {return (size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Aix上对于在list中的处理方式依然和vector一样，维护了一个_Size变量，empty()多了一层函数调用，效率较低。&lt;/p&gt;

&lt;h4 id=&#34;centos-4&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    { return std::distance(begin(), end()); }
 
bool empty() const
    { return this-&amp;gt;_M_impl._M_node._M_next ==&amp;amp;this-&amp;gt;_M_impl._M_node; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;size()函数调用了distance函数用遍历的方法取得两个指针间的元素个数，然后返回。而empty()函数则是判断头指针的下一个节点是否是自己本身，只需要进行一次判断。所以，当list容器元素个数较多的时候，这里的empty()效率远大于size() == 0。&lt;/p&gt;

&lt;h3 id=&#34;map源码&#34;&gt;map源码&lt;/h3&gt;

&lt;h4 id=&#34;aix-5&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    {return (_Size); }
 
bool empty() const
    {return (size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不出意外，可以看出Aix上依然维护了一个_Size变量，在判断的时候都是用这个变量来判断，但是empty()多了一层函数调用，所以效率上会稍微低一些。&lt;/p&gt;

&lt;h4 id=&#34;centos-5&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;bool empty() const
    { return _M_impl._M_node_count == 0; }
 
size_type size() const
    { return _M_impl._M_node_count; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的map用到了红黑树，就不详细解释了，有兴趣的同学可以自己查阅相关资料。代码中empty()和size()用到的都是保存红黑树的节点数的变量，可以看出empty()和size() == 0两者其实是等价的。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;并不是所有的时候用empty()的效率都比size() == 0要高。&lt;/p&gt;

&lt;p&gt;例如在Aix上，由于所有的容器都维护了一个保存元素个数的值，调用size()的时候直接返回，而调用empty()的时候还是要去调用size()函数，所以会多一次函数调用的开销。在Aix上，显然使用size() == 0替代empty()将会使程序效率更高。&lt;/p&gt;

&lt;p&gt;而在Centos上，由于STL源码的实现方式不同，需要考虑到使用的容器，不同的容器调用size()和empty()的开销也不同，但是，相对来说，使用empty()的效率更加平均，例如在使用list容器的时候，如果数据量较大，size()的开销太大，而empty()则不会出现这种极端情况。&lt;/p&gt;

&lt;p&gt;如果考虑到平台迁移等等将来可能出现的状况，显然，empty()比size() == 0更加合适，可以确保你的程序不会出现太大的性能问题。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>从简单实例开始，学会写Makefile（二）</title>
          <link>http://blog.fatedier.com/2014/09/24/learn-to-write-makefile-02/</link>
          <pubDate>Wed, 24 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/24/learn-to-write-makefile-02/</guid>
          <description>&lt;p&gt;如果文件间存在着相互之间的引用关系该怎么办？如果把.h文件和.cpp文件放在了不同的目录下该怎么办？如果我想生成静态库，然后在其他地方引用静态库该怎么办？如果我想将程序迁移到Unix平台下，使用不同的编译器，难道要依次修改所有的Makefile？&lt;/p&gt;

&lt;h3 id=&#34;d文件-解决文件间的相互引用&#34;&gt;.d文件，解决文件间的相互引用&lt;/h3&gt;

&lt;h4 id=&#34;自动生成依赖关系&#34;&gt;自动生成依赖关系&lt;/h4&gt;

&lt;p&gt;在前文的项目基础上，考虑一下这种情况：如果我们在w1.h文件里包含了头文件w2.h以及w3.h并且用到其中定义的函数。&lt;/p&gt;

&lt;p&gt;第一次编译没有遇到问题，但是如果后续的开发过程中修改了w2.h或者w3.h文件中的内容，再执行gmake命令的时候，就遇到问题了——w1.cpp文件不会被重新编译了！&lt;/p&gt;

&lt;p&gt;显然，我们需要将生成目标文件w1.o的规则的依赖项加上w2.h和w3.h。可是如果手动的去检查每一个文件的引用关系，然后修改Makefile文件，这样做的效率就太低了。&lt;/p&gt;

&lt;p&gt;万幸的是，编译器可以帮助我们自动生成依赖关系，只需要在编译命令中加上“-M”选项，就可以让编译器自动寻找源文件中包含的头文件，并生成一个依赖关系，例如，你可以在shell界面下敲下如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++-MM w1.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，其输出为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;w1.o:w1.cpp w2.h w3.h。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里需要特别注意的是，我们使用“-MM”而不是“-M”，因为我们使用的是GUN的C/C++编译器，使用“-M”参数会将标准库的头文件也一并包含进来，但这并不是我们想要的，而使用“-MM”则不会。&lt;/p&gt;

&lt;p&gt;现在的问题是，如何利用这个命令去写好我们的Makefile呢？&lt;/p&gt;

&lt;p&gt;GUN组织建议把每一个源文件自动生成的依赖关系放到一个.d文件中，让每一个.cpp文件都对应一个.d文件，例如之前的w1.cpp，我们可以生成一个w1.d文件，内容为自动生成的依赖关系 w1.o:w1.cpp w2.h w3.h，然后在Makefile中包含所有的.d文件，我们只需要写出.cpp文件和.d文件的依赖关系，让make自动更新或生成.d文件即可。&lt;/p&gt;

&lt;h4 id=&#34;生成-d文件&#34;&gt;生成.d文件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dep/%.d:%.cpp
    @if test ! -d &amp;quot;dep&amp;quot;; then\
        mkdir -p dep;\
    fi; \
    set -e; rm -f $@;
    g++ -MM $&amp;lt; &amp;gt; $@.$$$$; \
    sed &#39;s/$*\.o[ :]*/obj\/$*\.o dep\/$*\.d: /g&#39; &amp;lt; $@.$$$$ &amp;gt; $@; \
    rm -f $@.$$$$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Makefile中加上如上的代码，就可以生成我们所需要的.d文件了。&lt;/p&gt;

&lt;p&gt;又是一堆莫名其妙的符号，我们还是来逐句进行分析。&lt;/p&gt;

&lt;h5 id=&#34;dep-d-cpp&#34;&gt;dep/%.d: %.cpp&lt;/h5&gt;

&lt;p&gt;使所有的.d文件依赖于对应的.cpp文件，也就是说只要.cpp更新了，我们就重新生成对应的.d文件。这里和.o文件类似的，我们也创建一个dep目录用来存放所有的.d文件，既能保持项目文件的整洁和统一，也方便管理。&lt;/p&gt;

&lt;h5 id=&#34;if-test-d-dep-then&#34;&gt;@if test ! -d &amp;ldquo;dep&amp;rdquo;; then&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;@if test ! -d &amp;quot;dep&amp;quot;; then\
    mkdir -p dep;\
fi; \
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;检查当前目录下是否存在dep目录，如果不存在，就使用mkdir命令创建dep目录。&lt;/p&gt;

&lt;h5 id=&#34;set-e-rm-f&#34;&gt;set -e; rm -f $@;&lt;/h5&gt;

&lt;p&gt;set–e 的作用是如果命令执行出错就直接退出。$@的含义之前已经说过，这里rm –f $@的意思就是删除所有的目标文件。&lt;/p&gt;

&lt;h5 id=&#34;g-mm&#34;&gt;g++ -MM $&amp;lt; &amp;gt; $@.$$$$; &lt;/h5&gt;

&lt;p&gt;$&amp;lt; 的含义是第一个依赖项的名称，&amp;gt; 是重定向符号，将输出结果重定向到指定文件中。$@.$$$$ 就是这个文件的文件名，其中“$$$$”表示一个随机的编号，例如如果有目标文件是w1.d，那么“$@.$$$$”一个可能的结果就是w1.d.12345。那么，这句话的含义就是将g++ -MM w1.cpp的输出结果重定向到w1.d.12345这个文件中。&lt;/p&gt;

&lt;h5 id=&#34;sed-s-o-obj-o-dep-d-g&#34;&gt;sed &amp;rsquo;s/$&lt;em&gt;.o[ :]&lt;/em&gt;/obj\/$&lt;em&gt;.o dep\/$&lt;/em&gt;.d : /g&amp;rsquo; &amp;lt; $@.$$$$ &amp;gt; $@;&lt;/h5&gt;

&lt;p&gt;这里使用了sed这个工具对文本进行替换处理，单引号中的规则是’s/old/new/g’，s表示替换，末尾的g代表全局的意思，对文本中所有符合要求的字符串进行替换，sed会将符合old模式的字符串替换为new，具体的使用方法可以查阅一下sed这个工具的帮助文档。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;$@$$$$，将这个文件的内容作为sed工具的输入。

&amp;gt;$@，将sed处理后的内容重定向输出到这个文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过这一步的处理后，就把自动生成的依赖关系：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;w1.o:w1.cpp w2.h w3.h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;转成：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;w1.o w1.d:w1.cpp w2.h w3.h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样，我们的.d文件也会自动更新啦。&lt;/p&gt;

&lt;h5 id=&#34;rm-f&#34;&gt;rm -f $@.$$$$&lt;/h5&gt;

&lt;p&gt;删除掉这个临时文件。&lt;/p&gt;

&lt;h4 id=&#34;使用include包含其他文件&#34;&gt;使用include包含其他文件&lt;/h4&gt;

&lt;p&gt;在Makefile中我们也可以像在C++文件中那样包含其他文件。&lt;/p&gt;

&lt;p&gt;现在在我们的Makefile中加上这样一句：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;include w1.d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用这个语句就可以将之前我们生成的.d文件中的内容包含到当前的Makefile中。&lt;/p&gt;

&lt;p&gt;当然，也可以用这个命令来包含其他的Makefile文件。具体的用法后面再进行介绍。&lt;/p&gt;

&lt;p&gt;我们希望把所有的.d文件都包含在当前的Makefile中。&lt;/p&gt;

&lt;p&gt;先定义一个变量，存放所有的.d文件名：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DEPS = $(addsuffix .d,$(addprefix dep/,$(BASE)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后使用include$(DEPS) 包含所有的.d文件。&lt;/p&gt;

&lt;h3 id=&#34;i-引用其他目录下的-h文件&#34;&gt;-I，引用其他目录下的.h文件&lt;/h3&gt;

&lt;p&gt;考虑这种情况：现在有两个目录，一个inc目录用来存放.h文件，一个src目录，用来存放.cpp文件。怎么让编译器找到引用的.h文件在哪个目录下呢？&lt;/p&gt;

&lt;p&gt;我们可以使用“-I”选项。  格式为“-I目录名”，这样在编译的时候，编译器就会依次到我们指定的目录中寻找.h文件。&lt;/p&gt;

&lt;p&gt;同样，先定义一个变量，存放所有头文件的目录名：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;INCLUDEDIR = -I../inc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后将&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;g++ -c -o $@ $&amp;lt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样的编译命令中写成&lt;/p&gt;

&lt;p&gt;g++ -c -o $@ $(INCLUDEDIR) $&amp;lt;&lt;/p&gt;

&lt;p&gt;OK，再来尝试用gmake命令编译一下吧，已经可以成功编译了。&lt;/p&gt;

&lt;p&gt;如果需要包含多个目录下的.h文件，可以重复使用-I选项，中间需要用空格隔开。&lt;/p&gt;

&lt;h3 id=&#34;使用静态库&#34;&gt;使用静态库&lt;/h3&gt;

&lt;h4 id=&#34;修改生成静态库的makefile&#34;&gt;修改生成静态库的Makefile&lt;/h4&gt;

&lt;p&gt;有的时候我们不需要生成一个可执行的程序，而是生成一个静态库文件，之后在其他的地方引用这个静态库文件。&lt;/p&gt;

&lt;p&gt;假设我们的项目目录结构是这样的，src是项目根目录，src下面有common和app以及lib两个目录，common和app下面都有inc和src两个目录。common存放公共库的源文件，app存放程序源文件，lib存放生成的静态库。&lt;/p&gt;

&lt;p&gt;修改我们在common目录下的Makefile文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;top_srcdir = ../..
#生成静态库后所存放的位置
libdir = $(top_srcdir)/lib
#静态库文件名
LIBNAME = libfa_common.a
#路径+静态库文件名
TARGET = $(libdir)/$(LIBNAME)

$(TARGET): $(OBJS)
    -rm -f $@
    ar cr $(TARGET) $(OBJS)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;top_srcdir是项目根目录的路径，使用相对路径，方便我们在后面引用其他目录。&lt;/li&gt;
&lt;li&gt;libdir是生成的静态库所存放的路径。&lt;/li&gt;
&lt;li&gt;LIBNAME是静态库名称，注意，静态库的命名必须以“lib”开头，以“.a”结尾。&lt;/li&gt;
&lt;li&gt;TARGET是目标文件名称，包含路径。&lt;/li&gt;
&lt;li&gt;在生成静态库文件的规则中，使用ar这个命令。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;修改引用静态库的makefile&#34;&gt;修改引用静态库的Makefile&lt;/h4&gt;

&lt;p&gt;在app/src目录下的源文件中，编译的时候需要引用libfa_common.a这个静态库，这就需要我们再修改app目录下的Makefile文件。&lt;/p&gt;

&lt;p&gt;这里使用了两个新的参数，“-l”和“-L”。&lt;/p&gt;

&lt;p&gt;“-l”参数指定要引用的库的名称。例如我们要引用libfa_common.a这个静态库，那么需要在编译命令里加上“-lfa_common”，可以看出，-l后面的库名称需要去除前面的“lib”和后面的“.a”。&lt;/p&gt;

&lt;p&gt;“-L”参数指定了要引用的库的目录，用法和之前的“-I”一样。这里需要注意的是，我们需要修改一下VPATH这个变量，指明要引用的静态库的目录。类似这样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;VPATH:= -L $(top_srcdir)/lib
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;完整的makefile&#34;&gt;完整的Makefile&lt;/h3&gt;

&lt;p&gt;其实在每一个目录下的Makefile中有很多部分是重复的，我们可以考虑将重复的部分提取出来，单独放在一个公共的Makefile中，然后在其他Makefile中用include包含这个公共的Makefile即可。&lt;/p&gt;

&lt;p&gt;我写了三套Makefile，分别是Makefile（app）、Makefile（lib）、Make.rules。&lt;/p&gt;

&lt;p&gt;其中，Make.rules是公共部分，Makefile（app）是用来生成可执行程序的，Makefile（lib）是用来生成静态库的，为了以后迁移方便，考虑到Linux和Unix平台的差异，以及各个编译器之间的差异，可以将各种命令也定义成变量，之后使用宏定义进行条件编译。&lt;/p&gt;

&lt;p&gt;贴一下完整的Makefile代码。&lt;/p&gt;

&lt;h4 id=&#34;make-rules&#34;&gt;Make.rules&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#公用Make规则配置

#设置编译器类型
CXX := g++
CC := gcc

#设置编译.d文件相关内容
DEPFLAGS := -MM
DEPFILE = $@.$$$$

#设置所有静态库文件所在位置，会根据每个Makefile文件的top_srcdir设置相对位置
LIBDIR := $(top_srcdir)/lib

#设置编译程序时需要在哪些目录查找静态库文件
LDFLAGS := -L.\
           -L$(top_srcdir)/lib

#设置VPATH，在检查依赖关系时，如果查找-lxxxx时，在哪些目录查找静态库文件
VPATH := $(LIBDIR)

#设置编译程序时查找头文件的目录位置
INCLUDEDIR := -I.\
              -I../inc\

#声明要生成的目标文件，具体规则在具体的Makefile中定义
$(TARGET):

#生成.o文件所依赖的.cpp和.c文件
obj/%.o:%.cpp
@if test ! -d &amp;quot;obj&amp;quot;; then\
    mkdir-p obj;\
fi;
$(CXX)-c -o $@ $(INCLUDEDIR) $&amp;lt;

obj/%.o:%.c
    @iftest ! -d &amp;quot;obj&amp;quot;; then\
            mkdir-p obj;\
    fi;
    $(CC)-c -o $@ $(INCLUDEDIR) $&amp;lt;

#生成.d文件,存放.cpp文件的所有依赖规则
dep/%.d: %.cpp
    @iftest ! -d &amp;quot;dep&amp;quot;; then\
            mkdir-p dep;\
    fi;\
    set-e; rm -f $@;
    $(CXX)$(DEPFLAGS) $(INCLUDEDIR) $&amp;lt; &amp;gt;$(DEPFILE); \
    sed&#39;s/$*\.o[ :]*/obj\/$*\.o dep\/$*\.d : /g&#39; &amp;lt; $@.$$$$ &amp;gt; $@;\
    rm-f $@.$$$$

#生成.d文件,存放.c文件的所有依赖规则
dep/%.d: %.c
    @iftest ! -d &amp;quot;dep&amp;quot;; then\
            mkdir-p dep;\
    fi;\
    set-e; rm -f $@;
    $(CC)$(DEPFLAGS) $(INCLUDEDIR) $&amp;lt; &amp;gt; $(DEPFILE); \
    sed&#39;s/$*\.o[ :]*/obj\/$*\.o dep\/$*\.d : /g&#39; &amp;lt; $@.$$$$ &amp;gt; $@; \
    rm-f $@.$$$$

include $(DEPS)

#检测是否有文件被修改，只要有就全部编译
all: $(SRCS) $(TARGETS)

#清除编译文件
.PHONY:clean
clean:
    -rm-f $(TARGET)
    -rm-f obj/*.o
    -rm-f dep/*.d
    -rm-f core
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;makefile-lib&#34;&gt;Makefile（lib）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#需要生成静态库的Makefile

#程序根目录
top_srcdir         =../../..

#生成静态库后所存放的位置
libdir = $(top_srcdir)/lib
#静态库文件名
LIBNAME          =libfa_common.a
#路径+静态库文件名
TARGET           =$(libdir)/$(LIBNAME)

CPP_FILES = $(shell ls *.cpp)
C_FILES = $(-shell ls *.c)
SRCS = $(CPP_FILES) $(C_FILES)
BASE = $(basename $(SRCS))
OBJS = $(addsuffix .o, $(addprefixobj/,$(BASE)))
DEPS = $(addsuffix .d, $(addprefixdep/,$(BASE)))

#包含公共Make规则
include$(top_srcdir)/makeinclude/Make.rules

#设置头文件及库文件的位置
INCLUDEDIR := $(INCLUDEDIR)

$(TARGET): $(OBJS)
    -rm-f $@
    ar cr $(TARGET) $(OBJS)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;makefile-app&#34;&gt;Makefile（app）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#需要生成可执行程序的Makefile

#程序根目录
top_srcdir         =../../..

#目标程序名
TARGET = test

CPP_FILES = $(shell ls *.cpp)
C_FILES = $(-shell ls *.c)
SRCS = $(CPP_FILES) $(C_FILES)
BASE = $(basename $(SRCS))
OBJS = $(addsuffix .o, $(addprefixobj/,$(BASE)))
DEPS = $(addsuffix .d, $(addprefixdep/,$(BASE)))

#包含公共Make规则
include $(top_srcdir)/makeinclude/Make.rules

#额外需要包含的头文件的目录位置
INCLUDEDIR := $(INCLUDEDIR)\
              -I$(top_srcdir)/src/common/inc\

#所有要包含的静态库的名称
LIBS := -lfa_common

#设置目标程序依赖的.o文件
$(TARGET):$(OBJS) $(LIBS)
    -rm-f $@
    $(CXX)-o $(TARGET) $(INCLUDEDIR) $(LDFLAGS) $(OBJS) $(LIBS)
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>从简单实例开始，学会写Makefile（一）</title>
          <link>http://blog.fatedier.com/2014/09/08/learn-to-write-makefile-01/</link>
          <pubDate>Mon, 08 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/08/learn-to-write-makefile-01/</guid>
          <description>&lt;p&gt;作为一个刚刚从大学毕业的新人，进公司不久就遇到了一个不大不小的门槛——看不懂Makefile！而Makefile所干的事却关系到程序的编译和链接，一个好的Makefile文件可以极大地提升编译项目文件的效率，免去手动编译的烦恼。&lt;/p&gt;

&lt;p&gt;不会写Makefile虽然还不至于影响到项目进度，从别的地方拷贝一份过来稍加修改就可以用了，但是，对于咱们“程序猿”来说这实在是一件让人感觉很不爽的事。于是，百度，谷歌（PS：吐槽一下，不XX的话Google已经完全不能用了，Bing的效果都要比百度好一些），各种看资料，看大牛的博客，或许是本人比较笨，也或许是网上的资料不太适合咱们这种新人，缺乏生动的实例讲解，所以决定自己动手研究一下，并把过程分享给大家，希望新人们看完这篇文章后就能够自己动手，为自己的项目编写合适的Makefile啦。&lt;/p&gt;

&lt;h3 id=&#34;为什么要写makefile&#34;&gt;为什么要写Makefile&lt;/h3&gt;

&lt;p&gt;首先要确定我们的目标，Makefile是用来干嘛的？&lt;/p&gt;

&lt;p&gt;曾经很长时间我都是在从事Windows环境下的开发，所以根本不知道Makefile是个什么东西。因为早已经习惯了使用VS、Eclipse等等优秀的IDE做开发，只要点一个按钮，程序就可以运行啦。但是进入公司以后，从事的是Unix环境下的开发工作，没有了IDE，要怎么才能让我写的代码编译后运行呢？&lt;/p&gt;

&lt;p&gt;在这里，Makefile的作用就体现出来了，简单的四个字—— “自动编译”。一旦整个项目的Makefile都写好了以后，只需要一个简单的make命令，就可以实现自动编译了。当然，准确的说，是make这个命令工具帮助我们实现了我们想要做的事，而Makefile就相当于是一个规则文件，make程序会按照Makefile所指定的规则，去判断哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译。&lt;/p&gt;

&lt;p&gt;俗话说，懒人创造了整个世界，程序员就是在不断偷懒的过程中获得进步，使用Makefile最根本的目的就是简化我们的工作。&lt;/p&gt;

&lt;p&gt;下面我们就从头开始，一步一步的去学习如何写好一个Makefile文件吧！&lt;/p&gt;

&lt;h3 id=&#34;从单个文件开始&#34;&gt;从单个文件开始&lt;/h3&gt;

&lt;h4 id=&#34;1-单个文件的编译&#34;&gt;1、单个文件的编译&lt;/h4&gt;

&lt;p&gt;为了便于大家学习，这篇文章是以常见的Linux平台为基础的，系统为Centos6.5，使用GNU make工具进行编译，项目文件为C++格式。这里假定看到这篇文章的都是已经对C++程序的编译等基础知识和相关命令有了一定的了解的，鉴于篇幅限制，如果还有不清楚的就请自行查阅相关资料啦。&lt;/p&gt;

&lt;p&gt;假设我们在src目录下有一个test.cpp文件，我们是如何编译它的呢？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++ -o test test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在shell界面执行这句命令，当前目录下会生成一个名为test的可执行程序，使用./test就可以执行该程序，看到输出结果。&lt;/p&gt;

&lt;p&gt;现在我们尝试使用编写Makefile的方式来实现这一编译过程。 首先在当前目录下新建文件并命名为“Makefile”，这样编译的时候直接使用gmake命令即可，默认使用“Makefile”文件进行编译，也可以是其他名字，那样的话需要使用“gmake -f 文件名”的格式来指定Makefile文件。&lt;/p&gt;

&lt;p&gt;Makefile文件内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test:test.cpp
    g++-o test test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在shell界面下执行gmake命令，敲下回车，OK。&lt;/p&gt;

&lt;p&gt;可以发现，g++ -o test test.cpp 这条命令已经被自动执行了，生成了名为test的程序。&lt;/p&gt;

&lt;h4 id=&#34;2-makefile的描述规则&#34;&gt;2、Makefile的描述规则&lt;/h4&gt;

&lt;p&gt;至此，我们已经完成了一个最简单的Makefile文件，向我们的最终目标迈出了一大步！&lt;/p&gt;

&lt;p&gt;有的人会问，传说中的自动化编译呢？难道每一个文件都要自己去写文件名和命令？&lt;/p&gt;

&lt;p&gt;不用急，我们先来分析一下这个Makefile文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;TARGET... :PREREQUISITES...
    COMMAND
    ...
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是最简单的Makefile文件的描述规则，可以说，这也是Makefile中最精华的部分，其他部分都是围绕着这个最基本的描述规则的。先来解释一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TARGET：规则生成的目标文件，通常是需要生成的程序名（例如前面出现的程序名test）或者过程文件（类似.o文件）。&lt;/li&gt;
&lt;li&gt;PREREQUISITES：规则的依赖项，比如前面的Makefile文件中我们生成test程序所依赖的就是test.cpp。&lt;/li&gt;
&lt;li&gt;COMMAND：规则所需执行的命令行，通常是编译命令。这里需要注意的是每一行命令都需要以[TAB]字符开头。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;再来看我们之前写过的Makefile文件，这个规则，用通俗的自然语言翻译过来就是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果目标test文件不存在，根据规则创建它。&lt;/li&gt;
&lt;li&gt;目标test文件存在，并且test文件的依赖项中存在任何一个比目标文件更新（比如修改了一个函数，文件被更新了），根据规则重新生成它。&lt;/li&gt;
&lt;li&gt;目标test文件存在，并且它比所有的依赖项都更新，那么什么都不做。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当我们第一次执行gmake命令时，test文件还不存在，所以就会执行g++-o test test.cpp这条命令创建test文件。&lt;/p&gt;

&lt;p&gt;而当我们再一次执行gmake时，会提示文件已经是最新的，什么都不做。&lt;/p&gt;

&lt;p&gt;这时候，如果修改了test.cpp命令，再次执行gmake命令。&lt;/p&gt;

&lt;p&gt;由于依赖项比目标文件更新，g++ -o test test.cpp这条命令就又会被再一次执行。&lt;/p&gt;

&lt;p&gt;现在，我们已经学会如何写一个简单的Makefile文件了，每次修改过源文件以后，只要执行gmake命令就可以得到我们想要生成的程序，而不需要一遍遍地重复敲g++ -o test test.cpp这个命令。&lt;/p&gt;

&lt;h3 id=&#34;多个文件的编译&#34;&gt;多个文件的编译&lt;/h3&gt;

&lt;h4 id=&#34;1-使用命令行编译多个文件&#34;&gt;1、使用命令行编译多个文件&lt;/h4&gt;

&lt;p&gt;一个项目不可能只有一个文件，学会了单个文件的编译，自然而然就要考虑如何去编译多个文件呢？&lt;/p&gt;

&lt;p&gt;同样，假设当前目录下有如下7个文件，test.cpp、w1.h、w1.cpp、w2.h、w2.cpp、w3.h、w3.cpp。其中test.cpp包含main函数，并且引用了w1.h、w2.h以及w3.h。我们需要生成的程序名为test。&lt;/p&gt;

&lt;p&gt;在shell界面下，为了正确编译我们的项目，我们需要敲下如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++ -c -o w1.ow1.cpp
g++ -c -o w2.o w2.cpp
g++ -c -o w3.o w3.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时当前目录下会生成w1.o、w2.o、w3.o三个.o文件。这里需要注意的是，“-c”命令是只编译，不链接，通常生成.o文件的时候使用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++ -o testtest.cpp w1.o w2.o w3.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行完这条命令后，编译成功，得到了我们想要的test文件。&lt;/p&gt;

&lt;h4 id=&#34;2-使用makefile编译多个文件&#34;&gt;2、使用Makefile编译多个文件&lt;/h4&gt;

&lt;p&gt;既然单个文件的Makefile会写了，相信多个文件举一反三也不是问题了。&lt;/p&gt;

&lt;p&gt;Makefile具体内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test:test.cppw1.o w2.o w3.o
    g++ -o test test.cpp w1.o w2.o w3.o
w1.o:w1.cpp
    g++ -c -o w1.o w1.cpp
w2.o:w2.cpp
    g++ -c -o w2.o w2.cpp
w3.o:w3.cpp
    g++ -c -o w3.o w3.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里需要注意的是，我们写的第一个规则的目标，将会成为“终极目标”，也就是我们最终希望生成的程序，这里是“test”文件。根据我们的“终极目标”，make会进行自动推导，例如“终极目标”依赖于的.o文件，make就会寻找生成这些.o文件的规则，然后执行相应的命令去生成这些文件，这样一层一层递归地进行下去，直到最终生成了“终极目标”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.fatedier.com/pic/2014/2014-09-08-learn-to-write-makefile-01-gmake-target.jpg&#34; alt=&#34;gmake-target&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，虽然生成test文件的规则写在最前面，但是由于依赖于w1.o、w2.o、w3.o，make会先执行生成w1.o、w2.o、w3.o所需的命令，然后才会执行g++ -o test test.cpp w1.o w2.o w3.o 来生成test文件。&lt;/p&gt;

&lt;h4 id=&#34;3-使用伪目标来清除过程文件&#34;&gt;3、使用伪目标来清除过程文件&lt;/h4&gt;

&lt;p&gt;我们现在已经可以自动编译多个文件的项目了，但是当我们需要全部重新编译的时候，难道还要手动地一个一个去删除那些生成的.o文件吗？&lt;/p&gt;

&lt;p&gt;既然已经使用了Makefile，我们的目标就是实现自动化编译，那么这些清除过程文件这点小事必须得能够用一个命令搞定啦。&lt;/p&gt;

&lt;p&gt;我们只需要在Makefile文件的最后加上如下几行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;clean:
    -rm–f test *.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK，轻松搞定，然后在shell界面下执行gmakeclean。仔细看看，是不是所有的.o文件和最后生成的程序文件已经被清除了？&lt;/p&gt;

&lt;p&gt;这里说明一下，rm是Linux下删除文件或目录的命令，前面加上“-”符号意思是忽略执行rm产生的错误。“-f”参数是指强制删除，忽略不存在的文件。&lt;/p&gt;

&lt;p&gt;这样的目标叫做“伪目标”，通过“gmake 目标名”来指定这个目标，然后执行这个目标规则下的命令。&lt;/p&gt;

&lt;h3 id=&#34;使用变量简化makefile&#34;&gt;使用变量简化Makefile&lt;/h3&gt;

&lt;p&gt;作为一个“懒惰”的程序员，现在问题又来了。如果按照上面的写法，在文件数量和名称不变的情况的下确实是没有问题，但是如果我们新增一个文件的话，岂不是又要去修改Makefile了，一个项目多的可能有成百上千的文件，这样管理起来得有多麻烦呀！&lt;/p&gt;

&lt;p&gt;还记得我们在Linux下如果要查看当前目录下所有的cpp文件的时候，使用的命令吗？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls *.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个命令，我们就可以将所有的cpp文件名称显示在界面上。而在Makefile中我们同样可以使用类似的规则来做简化，进一步减少后续开发过程中对Makefile文件的修改。&lt;/p&gt;

&lt;p&gt;修改后的Makefile文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;TARGET = test

CPP_FILES = $(shell ls *.cpp)
BASE = $(basename $(CPP_FILES))
OBJS = $(addsuffix .o, $(addprefix obj/,$(BASE)))
 
$(TARGET):$(OBJS)
    -rm -f $@
    g++ -o $(TARGET)$(OBJS)
 
obj/%.o:%.cpp
    @if test ! -d&amp;quot;obj&amp;quot;; then\
    mkdir -pobj;\
    fi;
    g++ -c -o $@ $&amp;lt;
 
clean:
    -rm -f test
    -rm -f obj/*.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是不是瞬间有种摸不着头脑的感觉？别急，这是因为我们用到了一些新的语法和命令，其实，本质上和我们之前所写的Makefile文件是一个意思，下面我们就逐条来进行分析。&lt;/p&gt;

&lt;h5 id=&#34;target-test&#34;&gt;TARGET = test&lt;/h5&gt;

&lt;p&gt;定义一个变量，保存目标文件名，这里我们需要生成的程序名就叫test。&lt;/p&gt;

&lt;h5 id=&#34;cpp-files-shell-ls-cpp&#34;&gt;CPP_FILES = $(shell ls *.cpp)&lt;/h5&gt;

&lt;p&gt;定义一个变量，内容为所有的以.cpp为后缀的文件的文件名，以空格隔开。&lt;/p&gt;

&lt;p&gt;这里&amp;amp;(shell 命令)的格式，说明这里将会用shell命令执行后输出的内容进行替换，就和在命令行下输入ls *.cpp得到的结果一样。&lt;/p&gt;

&lt;h5 id=&#34;base-basename-cpp-files&#34;&gt;BASE = $(basename $(CPP_FILES))&lt;/h5&gt;

&lt;p&gt;定义一个变量，内容为所有的以.cpp为后缀的文件的文件名去除掉后缀部分。&lt;/p&gt;

&lt;p&gt;$(CPP_FILES)是引用CPP_FIFES这个变量的内容，相信学过如何写shell命令的同学肯定不会陌生。basename 是一个函数，其作用就是去除掉文件名的后缀部分，例如“test.cpp”，经过这一步后就变成了“test”。&lt;/p&gt;

&lt;h5 id=&#34;objs-addsuffix-o-addprefix-obj-base&#34;&gt;OBJS = $(addsuffix .o, $(addprefix obj/,$(BASE)))&lt;/h5&gt;

&lt;p&gt;定义一个变量，内容为所有的以.cpp为后缀的文件去除调后缀部分后加上“.o”。&lt;/p&gt;

&lt;p&gt;和basename一样，addsuffix和addprefix同样也是调用函数。addprefix的作用是给每个文件名加上前缀，这里是加上“obj/”，而addsuffix的作用是给每个文件名加上后缀，这里是在文件名后加上“.o”。例如“test”，经过变换后变成了“obj/test.o”。&lt;/p&gt;

&lt;p&gt;为什么要在文件名前加上“obj/”？&lt;/p&gt;

&lt;p&gt;这个不是必须的，只是我自己觉得将所有的.o文件放在一个obj目录下统一管理会让目录结构显得更加清晰，包括以后的.d文件会统一放在dep目录下一样。当然，你也可以选择不这样做，而是全部放在当前目录下。&lt;/p&gt;

&lt;h5 id=&#34;target-objs&#34;&gt;$(TARGET):$(OBJS)&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$(TARGET):$(OBJS)
    -rm -f $@
    g++ -o $(TARGET) $(OBJS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个描述规则和我们之前写过的很像，只不过，使用了变量进行替换。其中需要注意的是$@这个奇怪的符号，它的含义是这个规则的目标文件的名称，在这里就相当于是$(TARGET)。&lt;/p&gt;

&lt;p&gt;把这里的变量替换成我们之前项目中的实际值，就相当于：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test:test.ow1.o w2.o w3.o
    -rm-f test
    g++ -o test test.o w1.o w2.o w3.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果按照这种写法，当我们新增了一个w4.cpp文件的时候，就需要对Makefile进行修改，而如果我们使用了变量进行替换，那么我们就什么都不用做，直接再执行一遍gmake命令即可。&lt;/p&gt;

&lt;h5 id=&#34;obj-o-cpp&#34;&gt;obj/%.o:%.cpp&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;obj/%.o:%.cpp
    @if test ! -d&amp;quot;obj&amp;quot;; then\
        mkdir -p obj;\
    fi;
    g++ -c -o $@ $&amp;lt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是依次生成所有cpp文件所对应的.o文件的规则。&lt;/p&gt;

&lt;p&gt;%.o和%.c表示以.o和.c结尾的文件名。因为我们准备把所有的.o文件放在obj目录下，所以这里在“%.o”前面加上前缀“obj/”。&lt;/p&gt;

&lt;p&gt;下面命令行的前三行，具体的作用是检查当前目录下是否有名为“obj”的目录，如果没有，则使用mkdir命令创建这个目录。如果不了解的同学不如先去看一下shell编程的相关知识吧。&lt;/p&gt;

&lt;p&gt;最后一句中的$@前面已经解释过了，是代表规则的目标文件名称，而$&amp;lt;与之对应的，则是代表规则的依赖项中第一个依赖文件的名称。&lt;/p&gt;

&lt;p&gt;例如obj/test.o:test.cpp&lt;/p&gt;

&lt;p&gt;那么$@的值为“test.o”，$&amp;lt;的值为“test.cpp”&lt;/p&gt;

&lt;h5 id=&#34;clean&#34;&gt;clean:&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;clean:
    -rm -f test
    -rm -f obj/*.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个就没什么好说的啦，这里只是修改了一下.o文件的路径。&lt;/p&gt;

&lt;p&gt;到这里，相信你对如何使用Makefile来编译一个小的项目已经颇有些眉目了吧。使用这个Makefile文件，不管你往这个目录下加多少文件，轻轻松松一个gmake命令搞定，不需要再因为加了一个新的文件而去修改Makefile了。&lt;/p&gt;

&lt;p&gt;但是，你难道没有觉得仍然存在着很多问题吗？&lt;/p&gt;

&lt;p&gt;如果文件间存在着相互之间的引用关系该怎么办？&lt;/p&gt;

&lt;p&gt;如果把.h文件和.cpp文件放在了不同的目录下该怎么办？&lt;/p&gt;

&lt;p&gt;如果我想生成静态库，然后在其他地方引用静态库该怎么办？&lt;/p&gt;

&lt;p&gt;如果我想将程序迁移到Unix平台下，使用不同的编译器，难道要依次修改所有的Makefile？&lt;/p&gt;

&lt;p&gt;大家可以先尝试着自己解决以上的问题，在之后的篇幅中我们会就以上几点继续通过举例的方式来加以解决。&lt;/p&gt;</description>
        </item>
      
    

  </channel>
</rss>
