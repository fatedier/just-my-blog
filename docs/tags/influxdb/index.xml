<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fatedier blog </title>
    <link>http://blog.fatedier.com/tags/influxdb/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2016</rights>
    <updated>2016-08-15 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>InfluxDB详解之TSM存储引擎解析（二）</title>
          <link>http://blog.fatedier.com/2016/08/15/detailed-in-influxdb-tsm-storage-engine-two</link>
          <pubDate>Mon, 15 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/08/15/detailed-in-influxdb-tsm-storage-engine-two</guid>
          <description>

&lt;p&gt;上一篇文章主要介绍了 TSM 存储引擎一些相关的概念、组件以及数据存储的目录结构，文件组成结构等内容。这一篇将会尽量从 InfluxDB 源码的角度，深入讲解数据插入、查询、合并等操作的具体流程以及内部数据结构的设计。&lt;/p&gt;

&lt;p&gt;上一篇文章传送门： &lt;a href=&#34;http://blog.fatedier.com/2016/08/05/detailed-in-influxdb-tsm-storage-engine-one/&#34;&gt;『InfluxDB详解之TSM存储引擎解析（一）』&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;主要数据结构&#34;&gt;主要数据结构&lt;/h3&gt;

&lt;p&gt;InfluxDB 中的数据结构主要分为以下几个层次：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;tsdb.Store
    -- map[string]*tsdb.DatabaseIndex
        -- map[string]*tsdb.Measurement
        -- map[string]*tsdb.Series
    -- map[uint64]*tsdb.Shard
        -- Engine // 抽象接口，可插拔设计，目前是 tsm1 存储引擎
            -- tsm1.WAL
            -- tsm1.Cache
            -- tsm1.Compactor
            -- tsm1.FileStore
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;store&#34;&gt;Store&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Store struct {
    path string         // 数据库文件在磁盘上的存储路径

    // 数据库索引文件，key 为数据库名
    databaseIndexes map[string]*DatabaseIndex

    // 所有 shards 的索引，key 为其 shard ID
    shards map[uint64]*Shard
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Store 是存储结构中最顶层的抽象结构体，主要包含了 InfluxDB 中所有数据库的 &lt;strong&gt;索引&lt;/strong&gt; 和 &lt;strong&gt;实际存储数据的 Shard 对象&lt;/strong&gt;。InfluxDB 中的其他服务都需要通过 Store 对象对底层数据进行操作。&lt;/p&gt;

&lt;h4 id=&#34;shard&#34;&gt;Shard&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Shard struct {
    index   *DatabaseIndex      // 所在数据库的索引对象
    path    string              // shard 在磁盘上的路径
    walPath string              // 对应的 wal 文件所在目录
    id      uint64              // shard ID，就是在磁盘上的文件名
    database        string      // 所在数据库名
    retentionPolicy string      // 对应存储策略名
    engine  Engine              // 存储引擎
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每一个 Shard 对象都有一个单独的底层数据存储引擎，engine 负责和底层的文件数据打交道。Shard 还保存了一个指向所在数据库索引的指针，便于快速检索到该 Shard 中的元数据信息。&lt;/p&gt;

&lt;h4 id=&#34;engine&#34;&gt;Engine&lt;/h4&gt;

&lt;p&gt;Engine 是一个抽象接口，对于 InfluxDB 来说，可以很方便地替换掉底层的存储引擎。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Engine interface {
    LoadMetadataIndex(shardID uint64, index *DatabaseIndex) error

    Backup(w io.Writer, basePath string, since time.Time) error
    Restore(r io.Reader, basePath string) error

    CreateIterator(opt influxql.IteratorOptions) (influxql.Iterator, error)
    WritePoints(points []models.Point) error
    ContainsSeries(keys []string) (map[string]bool, error)
    DeleteSeries(keys []string) error
    DeleteSeriesRange(keys []string, min, max int64) error
    DeleteMeasurement(name string, seriesKeys []string) error
    SeriesCount() (n int, err error)
    MeasurementFields(measurement string) *MeasurementFields
    CreateSnapshot() (string, error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;目前 tsm1 存储引擎中 Engine 的结构：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Engine struct {
    path      string
    index             *tsdb.DatabaseIndex                 // 数据库索引信息，目前没和存储引擎放在一起，看起来后续会更改设计作为存储引擎的一部分
    measurementFields map[string]*tsdb.MeasurementFields  // 所有 measurement 对应的 fields 对象
    WAL            *WAL                 // WAL 文件对象
    Cache          *Cache               // WAL 文件在内存中的缓存
    Compactor      *Compactor           // 压缩合并管理对象
    CompactionPlan CompactionPlanner
    FileStore      *FileStore           // 数据文件对象
    MaxPointsPerBlock int               // 每个 block 中最多存储的 Points 数量

    // Cache 超过指定大小后内容会被写入一个新的 TSM 文件
    CacheFlushMemorySizeThreshold uint64

    // Cache 超过多长时间后还没有数据写入，会将内容写入新的 TSM 文件
    CacheFlushWriteColdDuration time.Duration
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Engine 负责维护和管理 &lt;strong&gt;Cache, FileStore, WAL&lt;/strong&gt; 等对象。当用户进行插入或查询操作时，Engine 都会对这些对象进行相应的操作，而这些对上层用户和服务来说是透明的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;从代码中的注释来看，在后续的版本中会把 tsdb.DatabaseIndex 移到 Engine 这一层，由存储引擎自己维护，降低代码的耦合程度。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;数据写入&#34;&gt;数据写入&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_usage,host=server01 value=0.64 1434055562000000000&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;通过-httpd-插入数据&#34;&gt;通过 httpd 插入数据&lt;/h4&gt;

&lt;p&gt;通常我们通过 HTTP 的接口写入一条或同时写入多条数据。在 InfluxDB 启动时会启动一个  httpd 服务，代码在 &lt;code&gt;services/httpd&lt;/code&gt; 包中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (h *Handler) serveWrite(w http.ResponseWriter, r *http.Request, user *meta.UserInfo) {
    ...
    err := h.PointsWriter.WritePoints(database, r.URL.Query().Get(&amp;quot;rp&amp;quot;), consistency, points)
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;httpd 服务解析出要插入的所有 Points，以及数据库，存储策略等内容，之后调用 PointsWriter 的 WritePoints 方法插入数据。&lt;/p&gt;

&lt;h4 id=&#34;pointswriter&#34;&gt;PointsWriter&lt;/h4&gt;

&lt;p&gt;PointsWriter 的结构在 &lt;code&gt;coordinator&lt;/code&gt; 包定义中，所有对数据的操作实际上都是通过这个对象来进行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (w *PointsWriter) WritePoints(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, points []models.Point) error {
    ...
    // 将要写入的 Points 按照时间划分到要写入的 shard，返回一个 Point 和 shard 之间的映射关系
    shardMappings, err := w.MapShards(&amp;amp;WritePointsRequest{Database: database, RetentionPolicy: retentionPolicy, Points: points})
    ...
    
    // 每一个 shard 都有一个独立的协程负责写入，只要有一个出错，就立即返回错误信息
    ch := make(chan error, len(shardMappings.Points))
    for shardID, points := range shardMappings.Points {
        go func(shard *meta.ShardInfo, database, retentionPolicy string, points []models.Point) {
            ch &amp;lt;- w.writeToShard(shard, database, retentionPolicy, points)
        }(shardMappings.Shards[shardID], database, retentionPolicy, points)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;WritePoints&lt;/code&gt; 函数会&lt;strong&gt;根据 Point 的时间戳判断出其属于哪一个 Shard&lt;/strong&gt;，之后调用 &lt;code&gt;writeToShard&lt;/code&gt; 函数批量将 Points 分别写入到不同的 Shard 中。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;writeToShard&lt;/code&gt; 函数中，实际上是调用了 &lt;code&gt;TSDBStore&lt;/code&gt; 的 &lt;code&gt;WriteToShard&lt;/code&gt;。这里的 &lt;code&gt;TSDBStore&lt;/code&gt; 就是前文中提到的 &lt;code&gt;Store&lt;/code&gt; 对象，是一个负责数据存储的顶层的抽象数据结构。而在 &lt;code&gt;Store&lt;/code&gt; 对象中存储了所有 Shard 的管理对象，数据将会交由指定的 Shard 去处理。Shard 会继续调用底层 tsm1 引擎的 engine 对象来真正意义上的写入数据。代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// PointsWirte.writeToShard -&amp;gt; TSDBStore.WriteToShard
func (w *PointsWriter) writeToShard(shard *meta.ShardInfo, database, retentionPolicy string, points []models.Point) error {
    ...
    err := w.TSDBStore.WriteToShard(shard.ID, points)
    ...
}

// TSDBStore.WriteToShard -&amp;gt; shard.WritePoints
func (s *Store) WriteToShard(shardID uint64, points []models.Point) error {
    ...
    sh, ok := s.shards[shardID]
    if !ok {
        return ErrShardNotFound
    }
    return sh.WritePoints(points)
}

// shard.WritePoints -&amp;gt; engine.WritePoints
func (s *Shard) WritePoints(points []models.Point) error {
    ...
    err := s.engine.WritePoints(points)
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;engine-实际写入数据&#34;&gt;Engine 实际写入数据&lt;/h4&gt;

&lt;p&gt;从下面的代码中可以看出，写入操作实际上就是将 value 写入 Cache 和 WAL 中，Cache 中主要是一个 Map 的结构，根据 key 缓存不同时间戳的 value，而 WAL 文件中的数据就是内存中数据的一个持久化的存储文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (e *Engine) WritePoints(points []models.Point) error {
    values := map[string][]Value{}
    for _, p := range points {
        // 一条插入语句中一个 series 对应的多个 value 会被拆分出来，形成多条数据
        for k, v := range p.Fields() {
            // 这里的 key 是 seriesKey + 分隔符 + filedName
            key := string(p.Key()) + keyFieldSeparator + k
            values[key] = append(values[key], NewValue(p.Time().UnixNano(), v))
        }    
    }    
    e.mu.RLock()
    defer e.mu.RUnlock()

    // 向 cache 中写入 value 数据，如果超过了内存阀值上限，返回错误
    err := e.Cache.WriteMulti(values)
    if err != nil {
        return err
    }    

    // 将数据写入 wal 文件中
    _, err = e.WAL.WritePoints(values)
    return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;数据删除&#34;&gt;数据删除&lt;/h3&gt;

&lt;p&gt;InfluxDB 支持对数据的删除操作，和其他 LSM Tree 类似的数据库一样，都是采用了标记要删除的键的方式来进行操作，等到需要进行压缩合并时，再真正意义上地删除这些数据。&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;data&lt;/code&gt; 中和 tsm file 同一级的目录下，会存在一些以 &lt;code&gt;.tombstone&lt;/code&gt; 文件，其中就记录了哪些 key 在哪一个时间段内的数据需要删除。&lt;/p&gt;

&lt;p&gt;有两种情况需要用到这些文件，一种是在查询时，对于查询结果，需要和 &lt;code&gt;.tombstone&lt;/code&gt; 文件中的内容进行比对，把不符合条件的 value 剔除。另外就是在 &lt;code&gt;Compactor&lt;/code&gt; 进行压缩合并多个 tsm file 时，这些被删除的数据将不会被转存到新的 tsm file 中，从而达到删除数据，释放磁盘空间的目的。&lt;/p&gt;

&lt;h3 id=&#34;数据查询与索引结构&#34;&gt;数据查询与索引结构&lt;/h3&gt;

&lt;p&gt;由于 LSM Tree 的原理就是通过将大量的随机写转换为顺序写，从而极大地提升了数据写入的性能，与此同时牺牲了部分读的性能。TSM 存储引擎是基于 LSM Tree 开发的，所以情况类似。通常设计数据库时会采用索引文件的方式（例如 LevelDB 中的 Mainfest 文件） 或者 Bloom filter 来对 LSM Tree 这样的数据结构的读取操作进行优化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;InfluxDB 中采用索引的方式进行优化，主要存在两种类型的索引。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;元数据索引&#34;&gt;元数据索引&lt;/h4&gt;

&lt;p&gt;一个数据库的元数据索引通过 &lt;strong&gt;DatabaseIndex&lt;/strong&gt; 这个结构体来存储，在数据库启动时，会进行初始化，从所有 shard 下的 tsm file 中加载 index 数据，获取其中所有 &lt;strong&gt;Measurement&lt;/strong&gt; 以及 &lt;strong&gt;Series&lt;/strong&gt; 的信息并缓存到内存中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type DatabaseIndex struct {
    measurements map[string]*Measurement // 该数据库下所有 Measurement 对象
    series       map[string]*Series      // 所有 Series 对象，SeriesKey = measurement + tags
    name string // 数据库名
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个结构体中最主要存放的就是该数据下所有 &lt;code&gt;Measurement&lt;/code&gt; 和 &lt;code&gt;Series&lt;/code&gt; 的内容，其数据结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Measurement struct {
    Name       string `json:&amp;quot;name,omitempty&amp;quot;`
    fieldNames map[string]struct{}      // 此 measurement 中的所有 filedNames

    // 内存中的索引信息
    // id 以及其对应的 series 信息，主要是为了在 seriesByTagKeyValue 中存储Id节约内存
    seriesByID          map[uint64]*Series              // lookup table for series by their id

    // 根据 tagk 和 tagv 的双重索引，保存排好序的 SeriesID 数组
    // 这个 map 用于在查询操作时，可以根据 tags 来快速过滤出要查询的所有 SeriesID，之后根据 SeriesKey 以及时间范围从文件中读取相应内容
    seriesByTagKeyValue map[string]map[string]SeriesIDs // map from tag key to value to sorted set of series ids

    // 此 measurement 中所有 series 的 id，按照 id 排序
    seriesIDs           SeriesIDs                       // sorted list of series IDs in this measurement
}

type Series struct {
    Key         string              // series key
    Tags        map[string]string   // tags
    id          uint64              // id
    measurement *Measurement        // 所属 measurement
    // 在哪些 shard 中存在
    shardIDs    map[uint64]bool // shards that have this series defined
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;元数据查询&#34;&gt;元数据查询&lt;/h4&gt;

&lt;p&gt;InfluxDB 支持一些特殊的查询语句（支持正则表达式匹配），可以查询一些 measurement 以及 tags 相关的数据，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SHOW MEASUREMENTS
SHOW TAG KEYS FROM &amp;quot;measurement_name&amp;quot;
SHOW TAG VALUES FROM &amp;quot;measurement_name&amp;quot; WITH KEY = &amp;quot;tag_key&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如我们需要查询 &lt;code&gt;cpu_usage&lt;/code&gt; 这个 measurement 上传数据的机器有哪些，一个可能的查询语句为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SHOW TAG VALUES FROM &amp;quot;cpu_usage&amp;quot; WITH KEY = &amp;quot;host&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;首先根据 measurement 可以在 &lt;code&gt;DatabaseIndex.measurements&lt;/code&gt; 中拿到 &lt;code&gt;cpu_usage&lt;/code&gt; 所对应的 &lt;code&gt;Measurement&lt;/code&gt; 对象。&lt;/li&gt;
&lt;li&gt;通过 &lt;code&gt;Measurement.seriesByTagKeyValue&lt;/code&gt; 获取 &lt;code&gt;tagk=host&lt;/code&gt; 所对应的以 &lt;code&gt;tagv&lt;/code&gt; 为键的 map 对象。&lt;/li&gt;
&lt;li&gt;遍历这个 map 对象，所有的 key 则为我们需要获取的数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;普通数据查询的定位&#34;&gt;普通数据查询的定位&lt;/h4&gt;

&lt;p&gt;对于普通的数据查询语句，则可以通过上述的元数据索引快速定位到要查询的数据所包含的所有 &lt;strong&gt;seriesKey，fieldName 和时间范围&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;举个例子，假设查询语句为获取 &lt;code&gt;server01&lt;/code&gt; 这台机器上 &lt;code&gt;cpu_usage&lt;/code&gt; 指标最近一小时的数据：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;`SELECT value FROM &amp;quot;cpu_usage&amp;quot; WHERE host=&#39;server01&#39; AND time &amp;gt; now() - 1h`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先根据 &lt;code&gt;measurement=cpu_usage&lt;/code&gt; 从 &lt;code&gt;DatabaseIndex.measurements&lt;/code&gt; 中获取到 &lt;code&gt;cpu_usage&lt;/code&gt; 对应的 &lt;code&gt;Measurement&lt;/code&gt; 对象。&lt;/p&gt;

&lt;p&gt;之后通过 &lt;code&gt;DatabaseIndex.measurements[&amp;quot;cpu_usage&amp;quot;].seriesByTagKeyValue[&amp;quot;host&amp;quot;][&amp;quot;server01&amp;quot;]&lt;/code&gt; 获取到所有匹配的 &lt;code&gt;series&lt;/code&gt; 的 ID值，再通过 &lt;code&gt;Measurement.seriesByID&lt;/code&gt; 这个 map 对象根据 &lt;code&gt;series ID&lt;/code&gt; 获取它们的实际对象。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意这里虽然只指定了 &lt;code&gt;host=server01&lt;/code&gt;，但不代表 &lt;code&gt;cpu_usage&lt;/code&gt; 下只有这一个 &lt;code&gt;series&lt;/code&gt;，可能还有其他的 tags 例如 &lt;code&gt;user=1&lt;/code&gt; 以及 &lt;code&gt;user=2&lt;/code&gt;，这样获取到的 &lt;code&gt;series ID&lt;/code&gt; 实际上有两个，获取数据时需要获取所有 &lt;code&gt;series&lt;/code&gt; 下的数据。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;Series&lt;/code&gt; 结构体中的 &lt;code&gt;shardIDs&lt;/code&gt; 这个 map 变量存放了哪些 shard 中存在这个 series 的数据。而 &lt;code&gt;Measurement.fieldNames&lt;/code&gt; 这个 map 可以帮助过滤掉 fieldName 不存在的情况。&lt;/p&gt;

&lt;p&gt;至此，我们在 o(1) 的时间复杂度内，获取到了所有符合要求的 series key、这些 series key 所存在的 shardID，要查询数据的时间范围，之后我们就可以创建数据迭代器从不同的 shard 中获取每一个 series key 在指定时间范围内的数据。后续的查询则和 tsm file 中的 Index 的在内存中的缓存相关。&lt;/p&gt;

&lt;h4 id=&#34;tsm-file-索引&#34;&gt;TSM File 索引&lt;/h4&gt;

&lt;p&gt;上一篇文章中讲过了对于 tsm file 中的 Index 部分会在内存中做间接索引，从而可以实现快速检索的目的。这里看一下具体的数据结构：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type indirectIndex struct {
    b []byte                // 下层详细索引的字节流
    offsets []int32         // 偏移量数组，记录了一个 key 在 b 中的偏移量
    minKey, maxKey string   
    minTime, maxTime int64  // 此文件中的最小时间和最大时间，根据这个可以快速判断要查询的数据在此文件中是否存在，是否有必要读取这个文件
    tombstones map[string][]TimeRange   // 用于记录哪些 key 在指定范围内的数据是已经被删除的
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;b&lt;/code&gt; 直接对应着 tsm file 中的 Index 部分，通过对 offsets 进行二分查找，可以获取到指定 key 的所有 block 的索引信息，之后根据 offset 和 size 信息可以取出一个指定的 block 中的所有数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type indexEntries struct {
    Type    byte 
    entries []IndexEntry
}

type IndexEntry struct {
    // 一个 block 中的 point 都在这个最小和最大的时间范围内
    MinTime, MaxTime int64

    // block 在 tsm 文件中偏移量
    Offset int64

    // block 的具体大小
    Size uint32
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上一节中说明了通过元数据索引可以获取到所有 &lt;strong&gt;符合要求的 series key，它们对应的 shardID，时间范围&lt;/strong&gt;。通过 tsm file 索引，我们就可以根据 series key 和 时间范围快速定位到数据在 tsm file 中的位置。&lt;/p&gt;

&lt;h4 id=&#34;从-tsm-file-中读取数据&#34;&gt;从 tsm file 中读取数据&lt;/h4&gt;

&lt;p&gt;InfluxDB 中的所有数据读取操作都通过 &lt;strong&gt;Iterator&lt;/strong&gt; 来完成。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Iterator&lt;/strong&gt; 是一个抽象概念，并且支持嵌套，一个 Iterator 可以从底层的其他 Iterator 中获取数据并进行处理，之后再将结果传递给上层的 Iterator。&lt;/p&gt;

&lt;p&gt;这部分的代码逻辑比较复杂，这里不展开说明。实际上 &lt;strong&gt;Iterator&lt;/strong&gt; 底层最主要的就是通过 &lt;code&gt;cursor&lt;/code&gt; 来获取数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type cursor interface {
    next() (t int64, v interface{})
}

type floatCursor interface {
    cursor
    nextFloat() (t int64, v float64)
}

// 底层主要是 KeyCursor，每次读取一个 block 的数据
type floatAscendingCursor struct {
    // 内存中的 value 对象
    cache struct {
        values Values
        pos    int
    }

    tsm struct {
        tdec      TimeDecoder   // 时间序列化对象
        vdec      FloatDecoder  // value 序列化对象
        buf       []FloatValue
        values    []FloatValue  // 从 tsm 文件中读取到的 FloatValue 的缓存
        pos       int
        keyCursor *KeyCursor
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;cursor&lt;/strong&gt; 提供了一个 &lt;code&gt;next()&lt;/code&gt; 方法用于获取一个 value 值。每一种数据类型都有一个自己的 &lt;code&gt;cursor&lt;/code&gt; 实现。&lt;/p&gt;

&lt;p&gt;底层实现都是 &lt;strong&gt;KeyCursor&lt;/strong&gt;，&lt;strong&gt;KeyCursor&lt;/strong&gt; 会缓存每个 Block 的数据，通过 &lt;code&gt;Next()&lt;/code&gt; 函数依次返回，当一个 Block 中的内容读完后再通过 &lt;code&gt;ReadBlock()&lt;/code&gt; 函数读取下一个 Block 中的内容。&lt;/p&gt;

&lt;h3 id=&#34;数据压缩与合并&#34;&gt;数据压缩与合并&lt;/h3&gt;

&lt;p&gt;主要涉及到两个结构体：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Compactor struct {
    Dir  string
    Size int
    FileStore interface {
        NextGeneration() int
    }
}

type CompactionPlanner interface {
    Plan(lastWrite time.Time) []CompactionGroup
    PlanLevel(level int) []CompactionGroup
    PlanOptimize() []CompactionGroup
}

// 默认的压缩合并计划
type DefaultPlanner struct {
    FileStore interface {
        Stats() []FileStat
        LastModified() time.Time
        BlockCount(path string, idx int) int
    }

    // 如果一个 shard 对应的 wal 文件超过指定时间一直没有数据写入
    // 存储引擎将会将此 shard 中的 tsm 文件进行一次全量压缩合并
    CompactFullWriteColdDuration time.Duration

    // 如果为 true，表示此 shard 中的 tsm 文件要么只有一个，要么已经处于单个文件最大值
    lastPlanCompactedFull bool

    // lastPlanCheck is the last time Plan was called
    lastPlanCheck time.Time
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 InfluxDB 创建一个 Shard 对应的底层的存储引擎时，会启用一些协程，每隔 1s 检查是否有需要压缩合并的任务，如果有就去执行相应的操作，部分代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (e *Engine) SetCompactionsEnabled(enabled bool) {
    if enabled {
        ...
        e.done = make(chan struct{})
        // 启用压缩合并功能
        e.Compactor.Open()

        // 启用另外的协程去定期检测是否需要进行压缩合并
        e.wg.Add(5)
        // 将 cache 中的内容刷新到磁盘上的新的 tsm 文件中
        go e.compactCache()
        // 下面是定期合并不同 level 的 tsm 文件
        go e.compactTSMFull()
        go e.compactTSMLevel(true, 1)
        go e.compactTSMLevel(true, 2)
        go e.compactTSMLevel(false, 3)
    }
    ...
}

func (e *Engine) compactCache() {
    defer e.wg.Done()
    // 每秒钟检查一次
    for {
        select {
        case &amp;lt;-e.done:
            return

        default:
            // 更新缓存据上一次快照时间的间隔时间
            e.Cache.UpdateAge()
            if e.ShouldCompactCache(e.WAL.LastWriteTime()) {
                start := time.Now()
                err := e.WriteSnapshot()
                ...
            }
        }
        time.Sleep(time.Second)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;compactCache()&lt;/code&gt; 函数负责定期检测 Cache 中的容量是否达到阀值，如果超过阀值会将 Cache 中的内容做一个快照，之后写入到一个新的 tsm file 中。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;compactTSMLevel()&lt;/code&gt; 函数则负责对 tsm file 文件进行合并，每一个协程负责不同级别的文件，多个文件合并后，生成的新的文件级别会是旧文件中级别最高的那个文件加1。合并过程中，会在同一目录下创建以 &lt;code&gt;.tmp&lt;/code&gt; 结尾的临时文件存储合并后的数据，当合并操作完成后，会进行替换操作，删除已经被合并完成的文件。&lt;code&gt;.tombstone&lt;/code&gt; 文件在合并时也会被利用以过滤无效数据。&lt;/p&gt;

&lt;h3 id=&#34;一些问题&#34;&gt;一些问题&lt;/h3&gt;

&lt;h4 id=&#34;go-不支持泛型&#34;&gt;Go 不支持泛型&lt;/h4&gt;

&lt;p&gt;由于 go 不支持泛型，所以 InfluxDB 中很多代码需要兼容各种类型，例如 float,int,string 等都是通过模版文件来 generate 源文件的方式来生成的。&lt;/p&gt;

&lt;p&gt;这样导致代码可读性比较差，并且有大段大段的重复内容。如果使用 interface 的话，势必效率会下降很多。&lt;/p&gt;

&lt;p&gt;对比一下 C++ 的 STL 库，go 在这方面的支持还不是很好，标准库里的 list, heap 等容器包还是用的 interface 的方式，自己要开发一个通用的算法或者容器时也不方便，还是希望之后能支持泛型这样的功能。&lt;/p&gt;

&lt;h4 id=&#34;多个-wal-文件同时写入&#34;&gt;多个 WAL 文件同时写入&lt;/h4&gt;

&lt;p&gt;由于每一个 shard 都有一个独立的 wal 文件，如果使用者创建了多个数据库、存储策略并且数据没有按照时间顺序插入，就会造成写入性能的下降。官方文档中有说之后会采用一个总的 WAL 文件来解决这个问题，不过可能会带来一些其他方面的问题。&lt;/p&gt;

&lt;h4 id=&#34;索引数据对内存的占用&#34;&gt;索引数据对内存的占用&lt;/h4&gt;

&lt;p&gt;InfluxDB 中对于所有 measument 以及 series 的元数据都是缓存在内存中，特别是 tsm file 的 Index 部分的数据，随着保留的数据越来越多，这部分的内存占用也会逐渐增加。&lt;/p&gt;

&lt;p&gt;官方设计文档里也提到了一些方案缓解这类问题，例如采用 LRU 策略，或是采用和 OpenTSDB 中类似的对 key 进行压缩的方法。还有一个方案是将索引数据放到另外一个数据库例如 BoltDB 中进行存储。&lt;/p&gt;

&lt;p&gt;综合来说，InfluxDB 在性能和资源占用等方面都表现得很优秀，1.0.0 版本的稳定性也很高，我在测试环境中使用的一个月中没有出现过异常状况。可能目前最重要的问题就是不支持集群，对数据量有要求的公司需要自己进行二次开发。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>InfluxDB详解之TSM存储引擎解析（一）</title>
          <link>http://blog.fatedier.com/2016/08/05/detailed-in-influxdb-tsm-storage-engine-one</link>
          <pubDate>Fri, 05 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/08/05/detailed-in-influxdb-tsm-storage-engine-one</guid>
          <description>

&lt;p&gt;InfluxDB 项目更新比较快，google 了一下网上的一些文档基本上都是简单介绍了一下，而且很多都已经过时了，比如其中使用的 TSM 存储引擎，甚至官方文档上的内容都不是最新的。在源码里的 README 中有最新的设计实现的一些概要说明。&lt;/p&gt;

&lt;p&gt;我认为像这样的针对特殊场景进行优化的数据库会是今后数据库领域发展的主流，这里针对 InfluxDB 1.0.0 版本的源码深入研究一下 TSM 引擎的实现原理。TSM 存储引擎解决了 InfluxDB 之前使用的 LevelDB 和 BoltDB 时遇到的一些问题。&lt;/p&gt;

&lt;p&gt;因为 TSM 是根据 LSM Tree 针对时间序列数据优化而来，所以总体架构设计上相差并不是很大，LSM Tree 的概念可以参考 &lt;a href=&#34;http://blog.fatedier.com/2016/06/15/learn-lsm-tree/&#34;&gt;『LSM Tree 学习笔记』&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;p&gt;首先需要简单了解 InfluxDB 的总体的架构以及一些关键概念，有一个总的思路，知道这个数据库是为了存储什么样的数据，解决哪些问题而诞生的，便于后面理解 TSM 存储引擎的详细的结构。可以简单看一下我之前的文章，&lt;a href=&#34;http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb/&#34;&gt;『时间序列数据库调研之InfluxDB』&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;数据格式&#34;&gt;数据格式&lt;/h4&gt;

&lt;p&gt;在 InfluxDB 中，我们可以粗略的将要存入的一条数据看作&lt;strong&gt;一个虚拟的 key 和其对应的 value(field value)&lt;/strong&gt;，格式如下：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cpu_usage,host=server01,region=us-west value=0.64 1434055562000000000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;虚拟的 key 包括以下几个部分： database, retention policy, measurement, tag sets, field name, timestamp。&lt;/strong&gt; database 和 retention policy 在上面的数据中并没有体现，通常在插入数据时在 http 请求的相应字段中指定。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;database&lt;/strong&gt;: 数据库名，在 InfluxDB 中可以创建多个数据库，不同数据库中的数据文件是隔离存放的，存放在磁盘上的不同目录。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;retention policy&lt;/strong&gt;: 存储策略，用于设置数据保留的时间，每个数据库刚开始会自动创建一个默认的存储策略 autogen，数据保留时间为永久，之后用户可以自己设置，例如保留最近2小时的数据。插入和查询数据时如果不指定存储策略，则使用默认存储策略，且默认存储策略可以修改。InfluxDB 会定期清除过期的数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;measurement&lt;/strong&gt;: 测量指标名，例如 cpu_usage 表示 cpu 的使用率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tag sets&lt;/strong&gt;: tags 在 InfluxDB 中会按照字典序排序，不管是 tagk 还是 tagv，只要不一致就分别属于两个 key，例如 &lt;code&gt;host=server01,region=us-west&lt;/code&gt; 和 &lt;code&gt;host=server02,region=us-west&lt;/code&gt; 就是两个不同的 tag set。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;field name&lt;/strong&gt;: 例如上面数据中的 &lt;code&gt;value&lt;/code&gt; 就是 fieldName，InfluxDB 中支持一条数据中插入多个 fieldName，这其实是一个语法上的优化，在实际的底层存储中，是当作多条数据来存储。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;timestamp&lt;/strong&gt;: 每一条数据都需要指定一个时间戳，在 TSM 存储引擎中会特殊对待，以为了优化后续的查询操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;point&#34;&gt;Point&lt;/h4&gt;

&lt;p&gt;InfluxDB 中单条插入语句的数据结构，&lt;code&gt;series + timestamp&lt;/code&gt; 可以用于区别一个 point，也就是说一个 point 可以有多个 field name 和 field value。&lt;/p&gt;

&lt;h4 id=&#34;series&#34;&gt;Series&lt;/h4&gt;

&lt;p&gt;series 相当于是 InfluxDB 中一些数据的集合，在同一个 database 中，retention policy、measurement、tag sets 完全相同的数据同属于一个 series，同一个 series 的数据在物理上会按照时间顺序排列存储在一起。&lt;/p&gt;

&lt;p&gt;series 的 key 为 &lt;code&gt;measurement + 所有 tags 的序列化字符串&lt;/code&gt;，这个 key 在之后会经常用到。&lt;/p&gt;

&lt;p&gt;代码中的结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Series struct {
    mu          sync.RWMutex
    Key         string              // series key
    Tags        map[string]string   // tags
    id          uint64              // id
    measurement *Measurement        // measurement
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;shard&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;shard 在 InfluxDB 中是一个比较重要的概念，它和 retention policy 相关联。每一个存储策略下会存在许多 shard，每一个 shard 存储一个指定时间段内的数据，并且不重复，例如 7点-8点 的数据落入 shard0 中，8点-9点的数据则落入 shard1 中。每一个 shard 都对应一个底层的 tsm 存储引擎，有独立的 cache、wal、tsm file。&lt;/p&gt;

&lt;p&gt;创建数据库时会自动创建一个默认存储策略，永久保存数据，对应的在此存储策略下的 shard 所保存的数据的时间段为 7 天，计算的函数如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func shardGroupDuration(d time.Duration) time.Duration {
    if d &amp;gt;= 180*24*time.Hour || d == 0 { // 6 months or 0
        return 7 * 24 * time.Hour
    } else if d &amp;gt;= 2*24*time.Hour { // 2 days
        return 1 * 24 * time.Hour
    }
    return 1 * time.Hour
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果创建一个新的 retention policy 设置数据的保留时间为 1 天，则单个 shard 所存储数据的时间间隔为 1 小时，超过1个小时的数据会被存放到下一个 shard 中。&lt;/p&gt;

&lt;h3 id=&#34;组件&#34;&gt;组件&lt;/h3&gt;

&lt;p&gt;TSM 存储引擎主要由几个部分组成： &lt;strong&gt;cache、wal、tsm file、compactor&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-architecture.png&#34; alt=&#34;tsm-architecture&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;shard-1&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;shard 并不能算是其中的一个组件，因为这是在 tsm 存储引擎之上的一个概念。在 InfluxDB 中按照数据的时间戳所在的范围，会去创建不同的 shard，每一个 shard 都有自己的 cache、wal、tsm file 以及 compactor，这样做的目的就是为了可以通过时间来快速定位到要查询数据的相关资源，加速查询的过程，并且也让之后的批量删除数据的操作变得非常简单且高效。&lt;/p&gt;

&lt;p&gt;在 LSM Tree 中删除数据是通过给指定 key 插入一个删除标记的方式，数据并不立即删除，需要等之后对文件进行压缩合并时才会真正地将数据删除，所以删除大量数据在 LSM Tree 中是一个非常低效的操作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;而在 InfluxDB 中，通过 retention policy 设置数据的保留时间，当检测到一个 shard 中的数据过期后，只需要将这个 shard 的资源释放，相关文件删除即可，这样的做法使得删除过期数据变得非常高效。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;cache&#34;&gt;Cache&lt;/h4&gt;

&lt;p&gt;cache 相当于是 LSM Tree 中的 memtable，在内存中是一个简单的 map 结构，这里的 key 为 &lt;code&gt;seriesKey + 分隔符 + filedName&lt;/code&gt;，目前代码中的分隔符为 &lt;code&gt;#!~#&lt;/code&gt;，entry 相当于是一个按照时间排序的存放实际值的数组，具体结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Cache struct {
    commit  sync.Mutex
    mu      sync.RWMutex
    store   map[string]*entry
    size    uint64              // 当前使用内存的大小
    maxSize uint64              // 缓存最大值

    // snapshots are the cache objects that are currently being written to tsm files
    // they&#39;re kept in memory while flushing so they can be queried along with the cache.
    // they are read only and should never be modified
    // memtable 快照，用于写入 tsm 文件，只读
    snapshot     *Cache
    snapshotSize uint64
    snapshotting bool

    // This number is the number of pending or failed WriteSnaphot attempts since the last successful one.
    snapshotAttempts int

    stats        *CacheStatistics
    lastSnapshot time.Time
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;插入数据时，实际上是同时往 cache 与 wal 中写入数据，可以认为 cache 是 wal 文件中的数据在内存中的缓存。当 InfluxDB 启动时，会遍历所有的 wal 文件，重新构造 cache，这样即使系统出现故障，也不会导致数据的丢失。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cache 中的数据并不是无限增长的，有一个 maxSize 参数用于控制当 cache 中的数据占用多少内存后就会将数据写入 tsm 文件。&lt;/strong&gt;如果不配置的话，默认上限为 25MB，每当 cache 中的数据达到阀值后，会将当前的 cache 进行一次快照，之后清空当前 cache 中的内容，再创建一个新的 wal 文件用于写入，剩下的 wal 文件最后会被删除，快照中的数据会经过排序写入一个新的 tsm 文件中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;目前的 cache 的设计有一个问题&lt;/strong&gt;，当一个快照正在被写入一个新的 tsm 文件时，当前的 cache 由于大量数据写入，又达到了阀值，此时前一次快照还没有完全写入磁盘，InfluxDB 的做法是让后续的写入操作失败，用户需要自己处理，等待恢复后继续写入数据。&lt;/p&gt;

&lt;h4 id=&#34;wal&#34;&gt;WAL&lt;/h4&gt;

&lt;p&gt;wal 文件的内容与内存中的 cache 相同，其作用就是为了持久化数据，当系统崩溃后可以通过 wal 文件恢复还没有写入到 tsm 文件中的数据。&lt;/p&gt;

&lt;p&gt;由于数据是被顺序插入到 wal 文件中，所以写入效率非常高。但是如果写入的数据没有按照时间顺序排列，而是以杂乱无章的方式写入，数据将会根据时间路由到不同的 shard 中，每一个 shard 都有自己的 wal 文件，这样就不再是完全的顺序写入，对性能会有一定影响。看到官方社区有说后续会进行优化，只使用一个 wal 文件，而不是为每一个 shard 创建 wal 文件。&lt;/p&gt;

&lt;p&gt;wal 单个文件达到一定大小后会进行分片，创建一个新的 wal 分片文件用于写入数据。&lt;/p&gt;

&lt;h4 id=&#34;tsm-file&#34;&gt;TSM file&lt;/h4&gt;

&lt;p&gt;单个 tsm file 大小最大为 2GB，用于存放数据。&lt;/p&gt;

&lt;p&gt;TSM file 使用了自己设计的格式，对查询性能以及压缩方面进行了很多优化，在后面的章节会具体说明其文件结构。&lt;/p&gt;

&lt;h4 id=&#34;compactor&#34;&gt;Compactor&lt;/h4&gt;

&lt;p&gt;compactor 组件在后台持续运行，每隔 1 秒会检查一次是否有需要压缩合并的数据。&lt;/p&gt;

&lt;p&gt;主要进行两种操作，一种是 cache 中的数据大小达到阀值后，进行快照，之后转存到一个新的 tsm 文件中。&lt;/p&gt;

&lt;p&gt;另外一种就是合并当前的 tsm 文件，将多个小的 tsm 文件合并成一个，使每一个文件尽量达到单个文件的最大大小，减少文件的数量，并且一些数据的删除操作也是在这个时候完成。&lt;/p&gt;

&lt;h3 id=&#34;目录与文件结构&#34;&gt;目录与文件结构&lt;/h3&gt;

&lt;p&gt;InfluxDB 的数据存储主要有三个目录。&lt;/p&gt;

&lt;p&gt;默认情况下是 &lt;strong&gt;meta&lt;/strong&gt;, &lt;strong&gt;wal&lt;/strong&gt; 以及 &lt;strong&gt;data&lt;/strong&gt; 三个目录。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;meta&lt;/strong&gt; 用于存储数据库的一些元数据，&lt;strong&gt;meta&lt;/strong&gt; 目录下有一个 &lt;code&gt;meta.db&lt;/code&gt; 文件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;wal&lt;/strong&gt; 目录存放预写日志文件，以 &lt;code&gt;.wal&lt;/code&gt; 结尾。&lt;strong&gt;data&lt;/strong&gt; 目录存放实际存储的数据文件，以 &lt;code&gt;.tsm&lt;/code&gt; 结尾。这两个目录下的结构是相似的，其基本结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# wal 目录结构
-- wal
   -- mydb
      -- autogen
         -- 1
            -- _00001.wal
         -- 2
            -- _00035.wal
      -- 2hours
         -- 1
            -- _00001.wal

# data 目录结构
-- data
   -- mydb
      -- autogen
         -- 1
            -- 000000001-000000003.tsm
         -- 2
            -- 000000001-000000001.tsm
      -- 2hours
         -- 1
            -- 000000002-000000002.tsm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;strong&gt;mydb&lt;/strong&gt; 是数据库名称，&lt;strong&gt;autogen&lt;/strong&gt; 和 &lt;strong&gt;2hours&lt;/strong&gt; 是存储策略名称，再下一层目录中的以数字命名的目录是 shard 的 ID 值，比如 &lt;strong&gt;autogen&lt;/strong&gt; 存储策略下有两个 shard，ID 分别为 1 和 2，shard 存储了某一个时间段范围内的数据。再下一级的目录则为具体的文件，分别是 &lt;code&gt;.wal&lt;/code&gt; 和 &lt;code&gt;.tsm&lt;/code&gt; 结尾的文件。&lt;/p&gt;

&lt;h4 id=&#34;wal-文件&#34;&gt;WAL 文件&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-wal-entry.png&#34; alt=&#34;wal-entry&#34; /&gt;&lt;/p&gt;

&lt;p&gt;wal 文件中的一条数据，对应的是一个 key(measument + tags + fieldName) 下的所有 value 数据，按照时间排序。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type (1 byte)&lt;/strong&gt;: 表示这个条目中 value 的类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key Len (2 bytes)&lt;/strong&gt;: 指定下面一个字段 key 的长度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key (N bytes)&lt;/strong&gt;: 这里的 key 为 measument + tags + fieldName。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Count (4 bytes)&lt;/strong&gt;: 后面紧跟着的是同一个 key 下数据的个数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Time (8 bytes)&lt;/strong&gt;: 单个 value 的时间戳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value (N bytes)&lt;/strong&gt;: value 的具体内容，其中 float64, int64, boolean 都是固定的字节数存储比较简单，通过 Type 字段知道这里 value 的字节数。string 类型比较特殊，对于 string 来说，N bytes 的 Value 部分，前面 4 字节用于存储 string 的长度，剩下的部分才是 string 的实际内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;tsm-文件&#34;&gt;TSM 文件&lt;/h4&gt;

&lt;p&gt;单个 tsm 文件的主要格式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file.png&#34; alt=&#34;tsm-file&#34; /&gt;&lt;/p&gt;

&lt;p&gt;主要分为四个部分： &lt;strong&gt;Header, Blocks, Index, Footer&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;其中 &lt;strong&gt;Index&lt;/strong&gt; 部分的内容会被缓存在内存中，下面详细说明一下每一个部分的数据结构。&lt;/p&gt;

&lt;h5 id=&#34;header&#34;&gt;Header&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-header.png&#34; alt=&#34;tsm-file-header&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MagicNumber  (4 bytes)&lt;/strong&gt;: 用于区分是哪一个存储引擎，目前使用的 tsm1 引擎，MagicNumber 为 &lt;code&gt;0x16D116D1&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Version (1 byte)&lt;/strong&gt;: 目前是 tsm1 引擎，此值固定为 &lt;code&gt;1&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;blocks&#34;&gt;Blocks&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-blocks.png&#34; alt=&#34;tsm-file-blocks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Blocks 内部是一些连续的 Block，block 是 InfluxDB 中的最小读取对象，每次读取操作都会读取一个 block。每一个 Block 分为 CRC32 值和 Data 两部分，CRC32 值用于校验 Data 的内容是否有问题。Data 的长度记录在之后的 Index 部分中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data 中的内容根据数据类型的不同，在 InfluxDB 中会采用不同的压缩方式&lt;/strong&gt;，float 值采用了 Gorilla float compression，而 timestamp 因为是一个递增的序列，所以实际上压缩时只需要记录时间的偏移量信息。string 类型的 value 采用了 snappy 算法进行压缩。&lt;/p&gt;

&lt;p&gt;Data 的数据解压后的格式为 8 字节的时间戳以及紧跟着的 value，value 根据类型的不同，会占用不同大小的空间，其中 string 为不定长，会在数据开始处存放长度，这一点和 WAL 文件中的格式相同。&lt;/p&gt;

&lt;h5 id=&#34;index&#34;&gt;Index&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-index.png&#34; alt=&#34;tsm-file-index&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Index 存放的是前面 Blocks 里内容的索引。索引条目的顺序是先按照 key 的字典序排序，再按照 time 排序。InfluxDB 在做查询操作时，可以根据 Index 的信息快速定位到 tsm file 中要查询的 block 的位置。&lt;/p&gt;

&lt;p&gt;这张图只展示了其中一部分，用结构体来表示的话类似下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type BlockIndex struct {
    MinTime     int64
    MaxTime     int64
    Offset      int64
    Size        uint32
}

type KeyIndex struct {
    KeyLen      uint16
    Key         string
    Type        byte
    Count       uint32
    Blocks      []*BlockIndex
}

type Index []*KeyIndex
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Key Len (2 bytes)&lt;/strong&gt;: 下面一个字段 key 的长度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key (N bytes)&lt;/strong&gt;: 这里的 key 指的是 seriesKey + 分隔符 + fieldName。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type (1 bytes)&lt;/strong&gt;: fieldName 所对应的 fieldValue 的类型，也就是 Block 中 Data 内的数据的类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Count (2 bytes)&lt;/strong&gt;: 后面紧跟着的 Blocks 索引的个数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;后面四个部分是 block 的索引信息，根据 Count 中的个数会重复出现，每个 block 索引固定为 28 字节，按照时间排序。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Min Time (8 bytes)&lt;/strong&gt;: block 中 value 的最小时间戳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Time (8 bytes)&lt;/strong&gt;: block 中 value 的最大时间戳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Offset (8 bytes)&lt;/strong&gt;: block 在整个 tsm file 中的偏移量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Size (4 bytes)&lt;/strong&gt;: block 的大小。根据 Offset + Size 字段就可以快速读取出一个 block 中的内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;间接索引&#34;&gt;间接索引&lt;/h5&gt;

&lt;p&gt;间接索引只存在于内存中，是为了可以快速定位到一个 key 在详细索引信息中的位置而创建的，可以被用于二分查找来实现快速检索。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-index-simple.png&#34; alt=&#34;tsm-file-index-simple&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-sub-index.png&#34; alt=&#34;tsm-file-sub-index&#34; /&gt;&lt;/p&gt;

&lt;p&gt;offsets 是一个数组，其中存储的值为每一个 key 在 Index 表中的位置，由于 key 的长度固定为 2字节，所以根据这个位置就可以找到该位置上对应的 key 的内容。&lt;/p&gt;

&lt;p&gt;当指定一个要查询的 key 时，就可以通过二分查找，定位到其在 Index 表中的位置，再根据要查询的数据的时间进行定位，由于 KeyIndex  中的 BlockIndex 结构是定长的，所以也可以进行一次二分查找，找到要查询的数据所在的 BlockIndex 的内容，之后根据偏移量以及 block 长度就可以从 tsm 文件中快速读取出一个 block 的内容。&lt;/p&gt;

&lt;h5 id=&#34;footer&#34;&gt;Footer&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-08-05-detailed-in-influxdb-tsm-storage-engine-one-tsm-file-footer.png&#34; alt=&#34;tsm-file-footer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;tsm file 的最后8字节的内容存放了 Index 部分的起始位置在 tsm file 中的偏移量，方便将索引信息加载到内存中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于内容较多，具体的写入与查询操作的流程，以及部分代码的详解会在下一篇文章中介绍。&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>时间序列数据库调研之InfluxDB</title>
          <link>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb</link>
          <pubDate>Tue, 05 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb</guid>
          <description>

&lt;p&gt;基于 Go 语言开发，社区非常活跃，项目更新速度很快，日新月异，关注度高。&lt;/p&gt;

&lt;h3 id=&#34;测试版本&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;1.0.0_beta2-1&lt;/p&gt;

&lt;h3 id=&#34;安装部署&#34;&gt;安装部署&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo yum localinstall influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;配置文件路径为 &lt;code&gt;/etc/influxdb/influxdb.conf&lt;/code&gt;，修改后启动服务&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo service influxdb start&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;特点&#34;&gt;特点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可以设置metric的保存时间。&lt;/li&gt;
&lt;li&gt;支持通过条件过滤以及正则表达式删除数据。&lt;/li&gt;
&lt;li&gt;支持类似 sql 的语法。&lt;/li&gt;
&lt;li&gt;可以设置数据在集群中的副本数。&lt;/li&gt;
&lt;li&gt;支持定期采样数据，写入另外的measurement，方便分粒度存储数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式-line-protocol&#34;&gt;数据格式 Line Protocol&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;measurement[,tag_key1=tag_value1...] field_key=field_value[,field_key2=field_value2] [timestamp]

cpu_load,host_id=1 value=0.1 1434055562000000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比于 JSON 格式，无需序列化，更加高效。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;measurement: metric name，例如 cpu_load。&lt;/li&gt;
&lt;li&gt;field-key, field-value: 通常用来存储数据，类似 opentsdb 中的 value=0.6，但是支持各种类型，数据存储时不会进行索引，每条数据必须拥有一个 field-key，如果使用 field-key 进行过滤，需要遍历一遍所有数据。&lt;/li&gt;
&lt;li&gt;tags-key, tags-value: 和 field-key 类似，但是会进行索引，方便查询时用于过滤条件。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;series&#34;&gt;Series&lt;/h4&gt;

&lt;p&gt;measurement, tag set, retention policy 相同的数据集合算做一个 series。&lt;/p&gt;

&lt;p&gt;假设 cpu_load 有两个 tags，host_id 和 name，host_id 的数量为 100，name 的数量为 200，则 series 基数为 100 * 200 = 20000。&lt;/p&gt;

&lt;h4 id=&#34;数据存储&#34;&gt;数据存储&lt;/h4&gt;

&lt;p&gt;measurements, tag keys, field keys，tag values 全局存一份。&lt;/p&gt;

&lt;p&gt;field values 和 timestamps 每条数据存一份。&lt;/p&gt;

&lt;h4 id=&#34;retention-policy&#34;&gt;Retention Policy&lt;/h4&gt;

&lt;p&gt;保留策略包括设置数据保存的时间以及在集群中的副本个数。&lt;/p&gt;

&lt;p&gt;默认的 RP 为 &lt;strong&gt;default&lt;/strong&gt;，保存时间不限制，副本个数为 1，默认 RP 是可以修改的，并且我们可以创建新的 RP。&lt;/p&gt;

&lt;h4 id=&#34;continuous-query&#34;&gt;Continuous Query&lt;/h4&gt;

&lt;p&gt;CQ 是预先配置好的一些查询命令，&lt;strong&gt;SELECT&lt;/strong&gt; 语句必须包含 &lt;strong&gt;GROUP BY time()&lt;/strong&gt;，influxdb 会定期自动执行这些命令并将查询结果写入指定的另外的 measurement 中。&lt;/p&gt;

&lt;p&gt;利用这个特性并结合 RP 我们可以方便地保存不同粒度的数据，根据数据粒度的不同设置不同的保存时间，这样不仅节约了存储空间，而且加速了时间间隔较长的数据查询效率，避免查询时再进行聚合计算。&lt;/p&gt;

&lt;h4 id=&#34;shard&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;Shard 这个概念并不对普通用户开放，实际上是 InfluxDB 将连续一段时间内的数据作为一个 shard 存储，根据数据保存策略来决定，通常是保存1天或者7天的数据。例如如果保存策略 RP 是无限制的话，shard 将会保存7天的数据。这样方便之后的删除操作，直接关闭下层对应的一个数据库即可。&lt;/p&gt;

&lt;h3 id=&#34;存储引擎&#34;&gt;存储引擎&lt;/h3&gt;

&lt;p&gt;从 LevelDB（LSM Tree），到 BoltDB（mmap B+树），现在是自己实现的 TSM Tree 的算法，类似 LSM Tree，针对 InfluxDB 的使用做了特殊优化。&lt;/p&gt;

&lt;h4 id=&#34;leveldb&#34;&gt;LevelDB&lt;/h4&gt;

&lt;p&gt;LevelDB 底层使用了 LSM Tree 作为数据结构，用于存储大量的 key 值有序的 K-V 数据，鉴于时序数据的特点，只要将时间戳放入 key 中，就可以非常快速的遍历指定时间范围内的数据。LSM Tree 将大量随机写变成顺序写，所以拥有很高的写吞吐量，并且 LevelDB 内置了压缩功能。&lt;/p&gt;

&lt;p&gt;数据操作被先顺序写入 WAL 日志中，成功之后写入内存中的 MemTable，当 MemTable 中的数据量达到一定阀值后，会转换为 Immutable MemTable，只读，之后写入 SSTable。SSTable 是磁盘上只读的用于存储有序键值对的文件，并且会持续进行合并，生成新的 SSTable。在 LevelDB 中是分了不同层级的 SSTable 用于存储数据。&lt;/p&gt;

&lt;p&gt;LevelDB 不支持热备份，它的变种 RocksDB 和 HyperLevelDB 实现了这个功能。&lt;/p&gt;

&lt;p&gt;最严重的问题是由于 InfluxDB 通过 shard 来组织数据，每一个 shard 对应的就是一个 LevelDB 数据库，而由于 LevelDB 的底层存储是大量 SSTable 文件，所以当用户需要存储长时间的数据，例如几个月或者一年的时候，会产生大量的 shard，从而消耗大量文件描述符，将系统资源耗尽。&lt;/p&gt;

&lt;h4 id=&#34;boltdb&#34;&gt;BoltDB&lt;/h4&gt;

&lt;p&gt;之后 InfluxDB 采用了 BoltDB 作为数据存储引擎。BoltDB 是基于 LMDB 使用 Go 语言开发的数据库。同 LevelDB 类似的是，都可以用于存储 key 有序的 K-V 数据。&lt;/p&gt;

&lt;p&gt;虽然采用 BoltDB 的写效率有所下降，但是考虑到用于生产环境需要更高的稳定性，BoltDB 是一个合适的选择，而且 BoltDB 使用纯 Go 编写，更易于跨平台编译部署。&lt;/p&gt;

&lt;p&gt;最重要的是 BoltDB 的一个数据库存储只使用一个单独的文件。Bolt 还解决了热备的问题，很容易将一个 shard 从一台机器转移到另外一台。&lt;/p&gt;

&lt;p&gt;但是当数据库容量达到数GB级别时，同时往大量 series 中写入数据，相当于是大量随机写，会造成 IOPS 上升。&lt;/p&gt;

&lt;h4 id=&#34;tsm-tree&#34;&gt;TSM Tree&lt;/h4&gt;

&lt;p&gt;TSM Tree 是 InfluxDB 根据实际需求在 LSM Tree 的基础上稍作修改优化而来。&lt;/p&gt;

&lt;h5 id=&#34;wal&#34;&gt;WAL&lt;/h5&gt;

&lt;p&gt;每一个 shard 对应底层的一个数据库。每一个数据库有自己的 WAL 文件，压缩后的元数据文件，索引文件。&lt;/p&gt;

&lt;p&gt;WAL 文件名类似 &lt;code&gt;_000001.wal&lt;/code&gt;，数字递增，每达到 2MB 时，会关闭此文件并创建新的文件，有一个写锁用于处理多协程并发写入的问题。&lt;/p&gt;

&lt;p&gt;可以指定将 WAL 从内存刷新到磁盘上的时间，例如30s，这样会提高写入性能，同时有可能会丢失这30s内的数据。&lt;/p&gt;

&lt;p&gt;每一个 WAL 中的条目遵循 TLV 的格式，1字节用于表示类型（points，new fields，new series，delete），4字节表示 block 的长度，后面则是具体压缩后的 block 内容。WAL 文件中得内容在内存中会进行缓存，并且不会压缩，每一个 point 的 key 为 measurement, tagset 以及 unique field，每一个 field 按照自己的时间顺序排列。&lt;/p&gt;

&lt;p&gt;查询操作将会去 WAL 以及索引中查询，WAL 在内存中缓存有一个读写锁进行控制。删除操作会将缓存中的key删除，同时在 WAL 文件中进行记录并且在内存的索引中进行删除标记。&lt;/p&gt;

&lt;h5 id=&#34;data-files-sstables&#34;&gt;Data Files(SSTables)&lt;/h5&gt;

&lt;p&gt;这部分 InfluxDB 自己定义了特定的数据结构，将时间戳编码到了 DataFiles 中，进行了相对于时间序列数据的优化。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;通过 HTTP 访问 influxdb。&lt;/p&gt;

&lt;p&gt;语法上是一种类似于 SQL 的命令，官方称为 InfluxQL。&lt;/p&gt;

&lt;h4 id=&#34;创建数据库&#34;&gt;创建数据库&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -POST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;cpu_load_short 是 measurement，host 和 region 是 tags-key，value 是 field-key。&lt;/p&gt;

&lt;p&gt;多条数据时，用换行区分每条数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server02 value=0.67
cpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257
cpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;读取数据&#34;&gt;读取数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -GET &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时查询多条数据时，以分号分隔&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -G &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;;SELECT count(value) FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 &lt;code&gt;--data-urlencode &amp;quot;epoch=s&amp;quot;&lt;/code&gt; 会使返回的时间戳为 unix 时间戳格式。&lt;/p&gt;

&lt;h4 id=&#34;创建-rp&#34;&gt;创建 RP&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE RETENTION POLICY two_hours ON food_data DURATION 2h REPLICATION 1 DEFAULT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里将 &lt;strong&gt;two_hours&lt;/strong&gt; 设置成了默认保存策略，存入 food_data 中的数据如果没有明确指定 RP 将会默认采用此策略，数据保存时间为 2 小时，副本数为 1。&lt;/p&gt;

&lt;h4 id=&#34;创建-cq&#34;&gt;创建 CQ&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE CONTINUOUS QUERY cq_5m ON food_data BEGIN SELECT mean(website) AS mean_website,mean(phone) AS mean_phone INTO food_data.&amp;quot;default&amp;quot;.downsampled_orders FROM orders GROUP BY time(5m) END
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里创建了一个 CQ，每个5分钟将 two_hours.orders 中的数据计算5分钟的平均值后存入 default.downsampled_orders 中，default 这个 RP 中的数据是永久保存的。&lt;/p&gt;

&lt;h4 id=&#34;where&#34;&gt;WHERE&lt;/h4&gt;

&lt;p&gt;查询时指定查询的限制条件，例如查询最近1小时内 host_id=1 的机器的 cpu 数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT value FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;group-by&#34;&gt;GROUP BY&lt;/h4&gt;

&lt;p&gt;类似于 SQL 中的语法，可以对细粒度数据进行聚合计算，例如查询最近1小时内 host_id=1 的机器的 cpu 的数据，并且采样为每5分钟的平均值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT mean(value) FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1 GROUP BY time(5m)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;官方推荐硬件配置&#34;&gt;官方推荐硬件配置&lt;/h3&gt;

&lt;h4 id=&#34;单节点&#34;&gt;单节点&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Load&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Writes per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Queries per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Unique series&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Low&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Moderate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;High&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Probably infeasible&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 500 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 10 million&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;Low: CPU 2-4, RAM 2-4GB, IOPS 500&lt;/li&gt;
&lt;li&gt;Moderate: CPU 4-6, RAM 8-32GB, IOPS 500-1000&lt;/li&gt;
&lt;li&gt;High: CPU CPU 8+, RAM 32GB+, IOPS 1000+&lt;/li&gt;
&lt;li&gt;Probably infeasible: 可能单机无法支持，需要集群环境&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;集群&#34;&gt;集群&lt;/h4&gt;

&lt;p&gt;InfluxDB 从 0.12 版本开始将不再开源其 cluster 源码，而是被用做提供商业服务。&lt;/p&gt;

&lt;p&gt;如果考虑到以后的扩展，需要自己在前端做代理分片或者类似的开发工作。&lt;/p&gt;

&lt;p&gt;已知七牛是采用了 InfluxDB 作为时间序列数据的存储，自研了调度器以及高可用模块，具有横向扩展的能力。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;目前最火热的时间序列数据库项目，社区开发活跃，迭代更新较快，存储引擎经常变化，网上的一些资料都比较过时，例如最新的 TSM 存储引擎只能看到官方的文档简介，还没有详细的原理说明的文章。&lt;/p&gt;

&lt;p&gt;就单机来说，在磁盘占用、cpu使用率、读写速度方面都让人眼前一亮。如果数据量级不是非常大的情况下，单节点的 InfluxDB 就可以承载数十万每秒的写入，是一个比较合适的选择。&lt;/p&gt;

&lt;p&gt;另一方面，从 0.12 版本开始不再开源其集群代码（虽然之前的集群部分就比较烂），如果考虑到之后进行扩展的话，需要进行二次开发。&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
