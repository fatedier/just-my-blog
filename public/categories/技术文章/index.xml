<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fatedier blog </title>
    <link>http://blog.fatedier.com/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2016</rights>
    <updated>2016-08-01 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>golang 中使用 statik 将静态资源编译进二进制文件中</title>
          <link>http://blog.fatedier.com/2016/08/01/compile-assets-into-binary-file-with-statik-in-golang</link>
          <pubDate>Mon, 01 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/08/01/compile-assets-into-binary-file-with-statik-in-golang</guid>
          <description>

&lt;p&gt;现在的很多程序都会提供一个 Dashboard 类似的页面用于查看程序状态并进行一些管理的功能，通常都不会很复杂，但是其中用到的图片和网页的一些静态资源，如果需要用户额外存放在一个目录，也不是很方便，如果能打包进程序发布的二进制文件中，用户下载以后可以直接使用，就方便很多。&lt;/p&gt;

&lt;p&gt;最近在阅读 InfluxDB 的源码，发现里面提供了一个 admin 管理的页面，可以通过浏览器来执行一些命令以及查看程序运行的信息。但是我运行的时候只运行了一个 influxd 的二进制文件，并没有看到 css, html 等文件。&lt;/p&gt;

&lt;p&gt;原来 InfluxDB 中使用了 statik 这个工具将静态资源都编译进了二进制文件中，这样用户只需要运行这个程序即可，而不需要管静态资源文件存放的位置。&lt;/p&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;p&gt;先下载并安装 statik 这个工具&lt;/p&gt;

&lt;p&gt;&lt;code&gt;go get -d github.com/rakyll/statik&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;go install github.com/rakyll/statik&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注意将 &lt;code&gt;$GOPATH/bin&lt;/code&gt; 加入到 PATH 环境变量中。&lt;/p&gt;

&lt;h3 id=&#34;创建测试项目&#34;&gt;创建测试项目&lt;/h3&gt;

&lt;p&gt;创建一个测试用的 golang 项目，这里假设目录为 &lt;code&gt;$GOPATH/src/test/testStatikFS&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;创建一个 assets 目录用于放静态资源文件。包括 &lt;code&gt;./assets/a&lt;/code&gt; 和 &lt;code&gt;./assets/tmp/b&lt;/code&gt; 两个文件，文件内容分别为 &lt;code&gt;aaa&lt;/code&gt; 和 &lt;code&gt;bbb&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;创建 main.go 文件，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//go:generate statik -src=./assets
//go:generate go fmt statik/statik.go

package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
    &amp;quot;os&amp;quot;

    _ &amp;quot;test/testStatikFS/statik&amp;quot;
    &amp;quot;github.com/rakyll/statik/fs&amp;quot;
)

// Before buildling, run go generate.
func main() {
    statikFS, err := fs.New()
    if err != nil {
        fmt.Printf(&amp;quot;err: %v\n&amp;quot;, err)
        os.Exit(1)
    }   

    file, err := statikFS.Open(&amp;quot;/tmp/b&amp;quot;)
    if err != nil {
        fmt.Printf(&amp;quot;err: %v\n&amp;quot;, err)
        os.Exit(1)
    }   
    content, err := ioutil.ReadAll(file)
    if err != nil { 
        fmt.Printf(&amp;quot;err: %v\n&amp;quot;, err)
        os.Exit(1)
    }   
    fmt.Printf(&amp;quot;content: %s\n&amp;quot;, content)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意文件最开始的两行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//go:generate statik -src=./assets
//go:generate go fmt statik/statik.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个注释是告诉 &lt;code&gt;go generate&lt;/code&gt; 需要执行的命令，之后就可以通过 &lt;code&gt;go generate&lt;/code&gt; 生成我们需要的 go 文件。&lt;/p&gt;

&lt;p&gt;这段代码的功能就是从 &lt;strong&gt;statikFS&lt;/strong&gt; 提供的文件系统接口中获取 &lt;code&gt;/tmp/b&lt;/code&gt; 这个文件的内容并输出，可以看到操作起来和操作普通文件的方法基本一致。&lt;/p&gt;

&lt;h3 id=&#34;将静态资源打包成-go-文件&#34;&gt;将静态资源打包成 go 文件&lt;/h3&gt;

&lt;p&gt;执行 &lt;code&gt;go generate&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在项目目录下执行这个命令会生成一个 &lt;strong&gt;statik&lt;/strong&gt; 目录，里面存放的是自动生成的 go 文件，将所有 &lt;code&gt;./assets&lt;/code&gt; 下的文件变成了一个压缩后的字符串放在了这个文件中，并且在程序启动时会解析这个字符串，构造一个 &lt;strong&gt;http.FileSystem&lt;/strong&gt; 对象，之后就可以使用对文件系统类似的操作来获取文件内容。&lt;/p&gt;

&lt;h3 id=&#34;编译&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;go build -o test ./main.go&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在 main.go 中我们 import 了两个包&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;_ &amp;quot;test/testStatikFS/statik&amp;quot;
&amp;quot;github.com/rakyll/statik/fs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个就是 &lt;code&gt;go generate&lt;/code&gt; 自动生成的目录，其中只有一个 &lt;code&gt;init()&lt;/code&gt; 函数，初始化相关的资源，我们不需要调用这个包里面的函数，只执行 &lt;code&gt;init()&lt;/code&gt; 函数，所以在包名前加上 &lt;code&gt;_&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;运行&#34;&gt;运行&lt;/h3&gt;

&lt;p&gt;运行编译后的文件： &lt;code&gt;./test&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;输出了文件 &lt;code&gt;./assets/tmp/b&lt;/code&gt; 中的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;content: bbb
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;文件系统接口&#34;&gt;文件系统接口&lt;/h3&gt;

&lt;p&gt;由于 statik 实现了标准库中的 http.FileSystem 接口，所以也可以直接使用 http 包提供静态资源的访问服务，关键部分代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
  &amp;quot;github.com/rakyll/statik/fs&amp;quot;

    _ &amp;quot;./statik&amp;quot; // TODO: Replace with the absolute import path
)

// ...

statikFS, _ := fs.New()
http.ListenAndServe(&amp;quot;:8080&amp;quot;, http.FileServer(statikFS))
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>使用gvm在不同go版本之间切换</title>
          <link>http://blog.fatedier.com/2016/07/25/use-different-go-version-by-gvm</link>
          <pubDate>Mon, 25 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/25/use-different-go-version-by-gvm</guid>
          <description>

&lt;p&gt;Centos7上通过 yum 从 epel 仓库里直接安装的 go 版本还是 1.4.2，从源码编译安装最新的 go 版本比较麻烦，而且开发中有时需要调试在不同编译环境下可能存在的问题，不能忽略使用最新版本是存在某些 bug 的可能性。&lt;/p&gt;

&lt;p&gt;Go 的更新速度比较快，2015年8月发布 1.5 版本，2016年2月发布 1.6 版本，2016年8月即将发布 1.7 版本，在性能以及GC方便都在不断优化，及时更新到新版本的 go 很有优势。&lt;/p&gt;

&lt;h3 id=&#34;go-版本切换的问题&#34;&gt;Go 版本切换的问题&lt;/h3&gt;

&lt;p&gt;二进制文件的管理比较简单，通过链接使用不同版本的程序即可，实际上主要是一些环境变量和标准库的设置问题，环境变量主要是 &lt;code&gt;GOPATH&lt;/code&gt; 以及 &lt;code&gt;GOROOT&lt;/code&gt;，标准库的话需要在切换 go 版本时也能跟着切换。&lt;strong&gt;gvm&lt;/strong&gt; 实际上就是帮助完成这些配置工作。&lt;/p&gt;

&lt;h3 id=&#34;安装-gvm&#34;&gt;安装 gvm&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;gvm&lt;/strong&gt; 的项目地址：&lt;a href=&#34;https://github.com/moovweb/gvm&#34;&gt;https://github.com/moovweb/gvm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装命令：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bash &amp;lt;&amp;lt; (curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果你使用的是 &lt;code&gt;zsh&lt;/code&gt; 的话将前面的 &lt;code&gt;bash&lt;/code&gt; 改为 &lt;code&gt;zsh&lt;/code&gt; 即可，这条命令主要是下载 &lt;strong&gt;gvm&lt;/strong&gt; 相关的文件，创建所需目录，并且在 &lt;code&gt;.bashrc&lt;/code&gt; 或者 &lt;code&gt;.zshrc&lt;/code&gt; 中加入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[[ -s &amp;quot;/home/wcl/.gvm/scripts/gvm&amp;quot; ]] &amp;amp;&amp;amp; source &amp;quot;/home/wcl/.gvm/scripts/gvm&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;使每次登录 shell 时都可以生效。&lt;/p&gt;

&lt;h3 id=&#34;安装指定-go-版本&#34;&gt;安装指定 go 版本&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;gvm install go1.6.3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;需要注意这里实际上是先执行&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git clone https://go.googlesource.com/go $GVM_ROOT/archive/go&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个网站在墙外。&lt;/p&gt;

&lt;p&gt;我们可以通过配置使 git 可以通过 http 代理访问，修改 &lt;code&gt;.gitconfig&lt;/code&gt; 文件，加上 http 代理服务器的地址：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[http]
        proxy = http://[proxydomain]:[port]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下载成功后，有可能提示编译失败，因为 go1.6.3 需要依赖于 go1.4 来编译，需要设置 &lt;code&gt;GOROOT_BOOTSTRAP&lt;/code&gt; 变量。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;go env&lt;/code&gt; 查看 &lt;code&gt;GOROOT&lt;/code&gt; 的路径，通常 &lt;code&gt;GOROOT_BOOTSTRAP&lt;/code&gt; 就设置成 &lt;code&gt;GOROOT&lt;/code&gt;，centos7 下需要注意 /usr/lib/golang/bin 下并没有 &lt;code&gt;go&lt;/code&gt; 的二进制文件，通过 cp 命令复制一个过去。&lt;/p&gt;

&lt;p&gt;之后再次执行 &lt;code&gt;gvm install go1.6.3&lt;/code&gt; 即可安装完成。&lt;/p&gt;

&lt;h3 id=&#34;修改配置信息方便使用&#34;&gt;修改配置信息方便使用&lt;/h3&gt;

&lt;p&gt;最初测试时发现每次切换 go 版本后都会被修改 &lt;code&gt;GOPATH&lt;/code&gt; 变量，而实际上我并不需要这个功能，只是希望用新版本来编译已有的项目，所以我们需要把 &lt;code&gt;~/.gvm/environments&lt;/code&gt; 文件夹下所有 &lt;code&gt;GOPATH&lt;/code&gt; 的设置全部删除。&lt;/p&gt;

&lt;p&gt;另外还需要将 &lt;code&gt;~/.zshrc&lt;/code&gt; 或者 &lt;code&gt;~/.bashrc&lt;/code&gt; 中的&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[[ -s &amp;quot;~/.gvm/scripts/gvm&amp;quot; ]] &amp;amp;&amp;amp; source &amp;quot;~/.gvm/scripts/gvm&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;移到设置 &lt;code&gt;GOPATH&lt;/code&gt; 变量之前，避免登录 shell 之后被修改 &lt;code&gt;GOPATH&lt;/code&gt; 变量。&lt;/p&gt;

&lt;h3 id=&#34;使用&#34;&gt;使用&lt;/h3&gt;

&lt;h4 id=&#34;切换到安装好的指定-go-版本&#34;&gt;切换到安装好的指定 go 版本&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm use go1.6.3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;go version&lt;/code&gt; 可以看到已经是新版本的二进制文件，通过 &lt;code&gt;go env&lt;/code&gt; 可以查看 &lt;code&gt;GOROOT&lt;/code&gt; 信息，例如我的就是 &lt;code&gt;~/.gvm/gos/go1.6.3&lt;/code&gt;，这样编译项目时就会在这个目录下找标准库中的文件。&lt;/p&gt;

&lt;h4 id=&#34;切换到原来的系统版本&#34;&gt;切换到原来的系统版本&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm use system&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查看当前已经安装的所有版本&#34;&gt;查看当前已经安装的所有版本&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm list&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gvm gos (installed)

=&amp;gt; go1.6.3
   system
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;设置某个版本为默认&#34;&gt;设置某个版本为默认&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;gvm use go1.6.3 --default&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这样设置后，再登录 shell 就默认使用 &lt;code&gt;go1.6.3&lt;/code&gt; 的版本，而不是系统原来的版本了。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>linux下查看指定进程的所有连接信息</title>
          <link>http://blog.fatedier.com/2016/07/18/stat-all-connection-info-of-special-process-in-linux</link>
          <pubDate>Mon, 18 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/18/stat-all-connection-info-of-special-process-in-linux</guid>
          <description>&lt;p&gt;定位某个进程的网络故障时经常需要用到的一个功能就是查找所有连接的信息。通常查找某个端口的连接信息使用 ss 或者 netstat 可以轻松拿到，如果是主动与别的机器建立的连接信息则可以通过 lsof 命令来获得。&lt;/p&gt;

&lt;p&gt;例如我想要查看进程 &lt;code&gt;frps&lt;/code&gt; 当前的所有连接信息，先获得进程的 pid：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ps -ef|grep frps&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wcl       4721     1  0 10:27 ?        00:00:01 ./frps
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到进程 pid 为 &lt;strong&gt;4721&lt;/strong&gt;，之后通过 lsof 命令查看所有 TCP 连接信息：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lsof -p 4721 -nP | grep TCP&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;显示结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;frps    4721  wcl    4u     IPv6 117051764      0t0     TCP *:7000 (LISTEN)
frps    4721  wcl    6u     IPv6 117051765      0t0     TCP *:7003 (LISTEN)
frps    4721  wcl    7u     IPv6 117092563      0t0     TCP 139.129.11.120:7000-&amp;gt;116.231.70.223:61545 (ESTABLISHED)
frps    4721  wcl    8u     IPv6 117092565      0t0     TCP *:6000 (LISTEN)
frps    4721  wcl    9u     IPv6 117334426      0t0     TCP 139.129.11.120:7000-&amp;gt;116.237.93.230:64898 (ESTABLISHED)
frps    4721  wcl   10u     IPv6 117053538      0t0     TCP 139.129.11.120:7000-&amp;gt;115.231.20.123:41297 (ESTABLISHED)
frps    4721  wcl   11u     IPv6 117053540      0t0     TCP *:6005 (LISTEN)
frps    4721  wcl   12u     IPv6 117334428      0t0     TCP *:6004 (LISTEN)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从 &lt;strong&gt;lsof&lt;/strong&gt; 的输出结果中可以清楚的看到 &lt;strong&gt;frps&lt;/strong&gt; 进程监听了 5 个端口，并且在 7000 端口上建立了 3 个连接，连接两端的 ip 信息也都可以查到。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;lsof&lt;/strong&gt; 的 &lt;strong&gt;-nP&lt;/strong&gt; 参数用于将 ip 地址和端口号显示为正常的数值类型，否则可能会用别名表示。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>InfluxDB 与 OpenTSDB 对比测试</title>
          <link>http://blog.fatedier.com/2016/07/06/test-influxdb-and-opentsdb</link>
          <pubDate>Wed, 06 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/06/test-influxdb-and-opentsdb</guid>
          <description>

&lt;p&gt;通过调研，在时间序列数据库的选择上，从社区活跃度，易用程度，综合性能上来看比较合适的就是 OpenTSDB 和 InfluxDB，所以对这两个数据库进行了一个简单测试。&lt;/p&gt;

&lt;h3 id=&#34;时间序列数据库热度排名&#34;&gt;时间序列数据库热度排名&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-07-06-test-influxdb-and-opentsdb-db-rank.png&#34; alt=&#34;db-rank&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;测试环境&#34;&gt;测试环境&lt;/h3&gt;

&lt;p&gt;青云 centos7&lt;/p&gt;

&lt;p&gt;4 cpu，8GB RAM&lt;/p&gt;

&lt;h3 id=&#34;测试样本&#34;&gt;测试样本&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;metric&lt;/strong&gt; 从 cpu_load1 - cpu_load10 共10个。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tags&lt;/strong&gt; 只有一个，host_id 为 1-100。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;time&lt;/strong&gt; 为 1467000000 - 1467010000，各维度每秒生成1条数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;value&lt;/strong&gt; 取值为 0.1-0.9。&lt;/p&gt;

&lt;p&gt;合计数据量为 10 * 100 * 10000 = 1000w。&lt;/p&gt;

&lt;h3 id=&#34;查询测试用例&#34;&gt;查询测试用例&lt;/h3&gt;

&lt;h4 id=&#34;查询1-单条查询&#34;&gt;查询1：单条查询&lt;/h4&gt;

&lt;p&gt;指定 metricName 以及 host_id，对 time 在 1467000000 和 1467005000 内的数据按照每3分钟的粒度进行聚合计算平均值。&lt;/p&gt;

&lt;p&gt;例如 InfluxDB 中的查询语句&lt;/p&gt;

&lt;p&gt;&lt;code&gt;select mean(value) from cpu_load1 where host_id = &#39;1&#39; and time &amp;gt; 1467000000000000000 and time &amp;lt; 1467005000000000000 group by time(3m)&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查询2-批量10条不同-metricname-查询&#34;&gt;查询2：批量10条不同 metricName 查询&lt;/h4&gt;

&lt;p&gt;单条查询的基础上修改成不同的 metricName&lt;/p&gt;

&lt;h3 id=&#34;influxdb&#34;&gt;InfluxDB&lt;/h3&gt;

&lt;p&gt;并发数 50 通过 http 写入，每次 100 条数据&lt;/p&gt;

&lt;h4 id=&#34;资源占用&#34;&gt;资源占用&lt;/h4&gt;

&lt;p&gt;cpu 使用率维持在 100% 左右，耗时 1m58s，约 84746/s&lt;/p&gt;

&lt;p&gt;磁盘占用 70MB&lt;/p&gt;

&lt;h4 id=&#34;查询1&#34;&gt;查询1&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num1: 0.010s&lt;/li&gt;
&lt;li&gt;Num2: 0.010s&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;查询2&#34;&gt;查询2&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num 1: 0.029s&lt;/li&gt;
&lt;li&gt;Num 2: 0.021s&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;opentsdb&#34;&gt;OpenTSDB&lt;/h3&gt;

&lt;p&gt;并发数 50 通过http写入，每次 100 条数据&lt;/p&gt;

&lt;h4 id=&#34;资源占用-1&#34;&gt;资源占用&lt;/h4&gt;

&lt;p&gt;cpu 开始时跑满，之后在250%左右 耗时 2m16s，约 73529/s&lt;/p&gt;

&lt;p&gt;磁盘占用 1.6GB，由于是简单部署，这里 HBase 没有启用 lzo 压缩，据说压缩之后只需要占用原来 &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; 的空间，也就是 320MB。&lt;/p&gt;

&lt;h4 id=&#34;查询1-1&#34;&gt;查询1&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num 1: 0.285s&lt;/li&gt;
&lt;li&gt;Num 2: 0.039s&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;查询2-1&#34;&gt;查询2&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Num 1: 0.111s&lt;/li&gt;
&lt;li&gt;Num 2: 0.040s&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;一开始是准备在本地的一个2核2GB的虚拟机里进行测试，InfluxDB 虽然比较慢，但是测试完成，而 OpenTSDB 测试过程中，要么 zookeeper 出现故障，要么 Hbase 异常退出，要么无法正常写入数据，始终无法完成测试。更换成配置更高的青云服务器后，两者都能正常完成测试。&lt;/p&gt;

&lt;p&gt;在单机部署上，InfluxDB 非常简单，一两分钟就可以成功运行，而 OpenTSDB 需要搭建 Hbase，创建 TSD 用到的数据表，配置 JAVA 环境等，相对来说更加复杂。&lt;/p&gt;

&lt;p&gt;资源占用方面，InfluxDB 都要占据优势，cpu 消耗更小，磁盘占用更是小的惊人。&lt;/p&gt;

&lt;p&gt;查询速度，由于测试样本数据量还不够大，速度都非常快，可以看到 InfluxDB 的查询在 10ms 这个数量级，而 OpenTSDB 则慢了接近 10 倍，第二次查询时，由于缓存的原因，OpenTSDB 的查询速度也相当快。&lt;/p&gt;

&lt;p&gt;集群方面，目前 InfluxDB 还没有比较好的解决方案，而 OpenTSDB 基于 HBase，这一套集群方案已经被很多大公司采用，稳定运行。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>时间序列数据库调研之InfluxDB</title>
          <link>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb</link>
          <pubDate>Tue, 05 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb</guid>
          <description>

&lt;p&gt;基于 Go 语言开发，社区非常活跃，项目更新速度很快，日新月异，关注度高。&lt;/p&gt;

&lt;h3 id=&#34;测试版本&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;1.0.0_beta2-1&lt;/p&gt;

&lt;h3 id=&#34;安装部署&#34;&gt;安装部署&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo yum localinstall influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;配置文件路径为 &lt;code&gt;/etc/influxdb/influxdb.conf&lt;/code&gt;，修改后启动服务&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo service influxdb start&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;特点&#34;&gt;特点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可以设置metric的保存时间。&lt;/li&gt;
&lt;li&gt;支持通过条件过滤以及正则表达式删除数据。&lt;/li&gt;
&lt;li&gt;支持类似 sql 的语法。&lt;/li&gt;
&lt;li&gt;可以设置数据在集群中的副本数。&lt;/li&gt;
&lt;li&gt;支持定期采样数据，写入另外的measurement，方便分粒度存储数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式-line-protocol&#34;&gt;数据格式 Line Protocol&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;measurement[,tag_key1=tag_value1...] field_key=field_value[,field_key2=field_value2] [timestamp]

cpu_load,host_id=1 value=0.1 1434055562000000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比于 JSON 格式，无需序列化，更加高效。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;measurement: metric name，例如 cpu_load。&lt;/li&gt;
&lt;li&gt;field-key, field-value: 通常用来存储数据，类似 opentsdb 中的 value=0.6，但是支持各种类型，数据存储时不会进行索引，每条数据必须拥有一个 field-key，如果使用 field-key 进行过滤，需要遍历一遍所有数据。&lt;/li&gt;
&lt;li&gt;tags-key, tags-value: 和 field-key 类似，但是会进行索引，方便查询时用于过滤条件。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;series&#34;&gt;Series&lt;/h4&gt;

&lt;p&gt;measurement, tag set, retention policy 相同的数据集合算做一个 series。&lt;/p&gt;

&lt;p&gt;假设 cpu_load 有两个 tags，host_id 和 name，host_id 的数量为 100，name 的数量为 200，则 series 基数为 100 * 200 = 20000。&lt;/p&gt;

&lt;h4 id=&#34;数据存储&#34;&gt;数据存储&lt;/h4&gt;

&lt;p&gt;measurements, tag keys, field keys，tag values 全局存一份。&lt;/p&gt;

&lt;p&gt;field values 和 timestamps 每条数据存一份。&lt;/p&gt;

&lt;h4 id=&#34;retention-policy&#34;&gt;Retention Policy&lt;/h4&gt;

&lt;p&gt;保留策略包括设置数据保存的时间以及在集群中的副本个数。&lt;/p&gt;

&lt;p&gt;默认的 RP 为 &lt;strong&gt;default&lt;/strong&gt;，保存时间不限制，副本个数为 1，默认 RP 是可以修改的，并且我们可以创建新的 RP。&lt;/p&gt;

&lt;h4 id=&#34;continuous-query&#34;&gt;Continuous Query&lt;/h4&gt;

&lt;p&gt;CQ 是预先配置好的一些查询命令，&lt;strong&gt;SELECT&lt;/strong&gt; 语句必须包含 &lt;strong&gt;GROUP BY time()&lt;/strong&gt;，influxdb 会定期自动执行这些命令并将查询结果写入指定的另外的 measurement 中。&lt;/p&gt;

&lt;p&gt;利用这个特性并结合 RP 我们可以方便地保存不同粒度的数据，根据数据粒度的不同设置不同的保存时间，这样不仅节约了存储空间，而且加速了时间间隔较长的数据查询效率，避免查询时再进行聚合计算。&lt;/p&gt;

&lt;h4 id=&#34;shard&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;Shard 这个概念并不对普通用户开放，实际上是 InfluxDB 将连续一段时间内的数据作为一个 shard 存储，根据数据保存策略来决定，通常是保存1天或者7天的数据。例如如果保存策略 RP 是无限制的话，shard 将会保存7天的数据。这样方便之后的删除操作，直接关闭下层对应的一个数据库即可。&lt;/p&gt;

&lt;h3 id=&#34;存储引擎&#34;&gt;存储引擎&lt;/h3&gt;

&lt;p&gt;从 LevelDB（LSM Tree），到 BoltDB（mmap B+树），现在是自己实现的 TSM Tree 的算法，类似 LSM Tree，针对 InfluxDB 的使用做了特殊优化。&lt;/p&gt;

&lt;h4 id=&#34;leveldb&#34;&gt;LevelDB&lt;/h4&gt;

&lt;p&gt;LevelDB 底层使用了 LSM Tree 作为数据结构，用于存储大量的 key 值有序的 K-V 数据，鉴于时序数据的特点，只要将时间戳放入 key 中，就可以非常快速的遍历指定时间范围内的数据。LSM Tree 将大量随机写变成顺序写，所以拥有很高的写吞吐量，并且 LevelDB 内置了压缩功能。&lt;/p&gt;

&lt;p&gt;数据操作被先顺序写入 WAL 日志中，成功之后写入内存中的 MemTable，当 MemTable 中的数据量达到一定阀值后，会转换为 Immutable MemTable，只读，之后写入 SSTable。SSTable 是磁盘上只读的用于存储有序键值对的文件，并且会持续进行合并，生成新的 SSTable。在 LevelDB 中是分了不同层级的 SSTable 用于存储数据。&lt;/p&gt;

&lt;p&gt;LevelDB 不支持热备份，它的变种 RocksDB 和 HyperLevelDB 实现了这个功能。&lt;/p&gt;

&lt;p&gt;最严重的问题是由于 InfluxDB 通过 shard 来组织数据，每一个 shard 对应的就是一个 LevelDB 数据库，而由于 LevelDB 的底层存储是大量 SSTable 文件，所以当用户需要存储长时间的数据，例如几个月或者一年的时候，会产生大量的 shard，从而消耗大量文件描述符，将系统资源耗尽。&lt;/p&gt;

&lt;h4 id=&#34;boltdb&#34;&gt;BoltDB&lt;/h4&gt;

&lt;p&gt;之后 InfluxDB 采用了 BoltDB 作为数据存储引擎。BoltDB 是基于 LMDB 使用 Go 语言开发的数据库。同 LevelDB 类似的是，都可以用于存储 key 有序的 K-V 数据。&lt;/p&gt;

&lt;p&gt;虽然采用 BoltDB 的写效率有所下降，但是考虑到用于生产环境需要更高的稳定性，BoltDB 是一个合适的选择，而且 BoltDB 使用纯 Go 编写，更易于跨平台编译部署。&lt;/p&gt;

&lt;p&gt;最重要的是 BoltDB 的一个数据库存储只使用一个单独的文件。Bolt 还解决了热备的问题，很容易将一个 shard 从一台机器转移到另外一台。&lt;/p&gt;

&lt;p&gt;但是当数据库容量达到数GB级别时，同时往大量 series 中写入数据，相当于是大量随机写，会造成 IOPS 上升。&lt;/p&gt;

&lt;h4 id=&#34;tsm-tree&#34;&gt;TSM Tree&lt;/h4&gt;

&lt;p&gt;TSM Tree 是 InfluxDB 根据实际需求在 LSM Tree 的基础上稍作修改优化而来。&lt;/p&gt;

&lt;h5 id=&#34;wal&#34;&gt;WAL&lt;/h5&gt;

&lt;p&gt;每一个 shard 对应底层的一个数据库。每一个数据库有自己的 WAL 文件，压缩后的元数据文件，索引文件。&lt;/p&gt;

&lt;p&gt;WAL 文件名类似 &lt;code&gt;_000001.wal&lt;/code&gt;，数字递增，每达到 2MB 时，会关闭此文件并创建新的文件，有一个写锁用于处理多协程并发写入的问题。&lt;/p&gt;

&lt;p&gt;可以指定将 WAL 从内存刷新到磁盘上的时间，例如30s，这样会提高写入性能，同时有可能会丢失这30s内的数据。&lt;/p&gt;

&lt;p&gt;每一个 WAL 中的条目遵循 TLV 的格式，1字节用于表示类型（points，new fields，new series，delete），4字节表示 block 的长度，后面则是具体压缩后的 block 内容。WAL 文件中得内容在内存中会进行缓存，并且不会压缩，每一个 point 的 key 为 measurement, tagset 以及 unique field，每一个 field 按照自己的时间顺序排列。&lt;/p&gt;

&lt;p&gt;查询操作将会去 WAL 以及索引中查询，WAL 在内存中缓存有一个读写锁进行控制。删除操作会将缓存中的key删除，同时在 WAL 文件中进行记录并且在内存的索引中进行删除标记。&lt;/p&gt;

&lt;h5 id=&#34;data-files-sstables&#34;&gt;Data Files(SSTables)&lt;/h5&gt;

&lt;p&gt;这部分 InfluxDB 自己定义了特定的数据结构，将时间戳编码到了 DataFiles 中，进行了相对于时间序列数据的优化。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;通过 HTTP 访问 influxdb。&lt;/p&gt;

&lt;p&gt;语法上是一种类似于 SQL 的命令，官方称为 InfluxQL。&lt;/p&gt;

&lt;h4 id=&#34;创建数据库&#34;&gt;创建数据库&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -POST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;cpu_load_short 是 measurement，host 和 region 是 tags-key，value 是 field-key。&lt;/p&gt;

&lt;p&gt;多条数据时，用换行区分每条数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server02 value=0.67
cpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257
cpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;读取数据&#34;&gt;读取数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -GET &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时查询多条数据时，以分号分隔&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -G &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;;SELECT count(value) FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 &lt;code&gt;--data-urlencode &amp;quot;epoch=s&amp;quot;&lt;/code&gt; 会使返回的时间戳为 unix 时间戳格式。&lt;/p&gt;

&lt;h4 id=&#34;创建-rp&#34;&gt;创建 RP&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE RETENTION POLICY two_hours ON food_data DURATION 2h REPLICATION 1 DEFAULT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里将 &lt;strong&gt;two_hours&lt;/strong&gt; 设置成了默认保存策略，存入 food_data 中的数据如果没有明确指定 RP 将会默认采用此策略，数据保存时间为 2 小时，副本数为 1。&lt;/p&gt;

&lt;h4 id=&#34;创建-cq&#34;&gt;创建 CQ&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE CONTINUOUS QUERY cq_5m ON food_data BEGIN SELECT mean(website) AS mean_website,mean(phone) AS mean_phone INTO food_data.&amp;quot;default&amp;quot;.downsampled_orders FROM orders GROUP BY time(5m) END
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里创建了一个 CQ，每个5分钟将 two_hours.orders 中的数据计算5分钟的平均值后存入 default.downsampled_orders 中，default 这个 RP 中的数据是永久保存的。&lt;/p&gt;

&lt;h4 id=&#34;where&#34;&gt;WHERE&lt;/h4&gt;

&lt;p&gt;查询时指定查询的限制条件，例如查询最近1小时内 host_id=1 的机器的 cpu 数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT value FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;group-by&#34;&gt;GROUP BY&lt;/h4&gt;

&lt;p&gt;类似于 SQL 中的语法，可以对细粒度数据进行聚合计算，例如查询最近1小时内 host_id=1 的机器的 cpu 的数据，并且采样为每5分钟的平均值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT mean(value) FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1 GROUP BY time(5m)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;官方推荐硬件配置&#34;&gt;官方推荐硬件配置&lt;/h3&gt;

&lt;h4 id=&#34;单节点&#34;&gt;单节点&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Load&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Writes per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Queries per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Unique series&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Low&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Moderate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;High&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Probably infeasible&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 500 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 10 million&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;Low: CPU 2-4, RAM 2-4GB, IOPS 500&lt;/li&gt;
&lt;li&gt;Moderate: CPU 4-6, RAM 8-32GB, IOPS 500-1000&lt;/li&gt;
&lt;li&gt;High: CPU CPU 8+, RAM 32GB+, IOPS 1000+&lt;/li&gt;
&lt;li&gt;Probably infeasible: 可能单机无法支持，需要集群环境&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;集群&#34;&gt;集群&lt;/h4&gt;

&lt;p&gt;InfluxDB 从 0.12 版本开始将不再开源其 cluster 源码，而是被用做提供商业服务。&lt;/p&gt;

&lt;p&gt;如果考虑到以后的扩展，需要自己在前端做代理分片或者类似的开发工作。&lt;/p&gt;

&lt;p&gt;已知七牛是采用了 InfluxDB 作为时间序列数据的存储，自研了调度器以及高可用模块，具有横向扩展的能力。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;目前最火热的时间序列数据库项目，社区开发活跃，迭代更新较快，存储引擎经常变化，网上的一些资料都比较过时，例如最新的 TSM 存储引擎只能看到官方的文档简介，还没有详细的原理说明的文章。&lt;/p&gt;

&lt;p&gt;就单机来说，在磁盘占用、cpu使用率、读写速度方面都让人眼前一亮。如果数据量级不是非常大的情况下，单节点的 InfluxDB 就可以承载数十万每秒的写入，是一个比较合适的选择。&lt;/p&gt;

&lt;p&gt;另一方面，从 0.12 版本开始不再开源其集群代码（虽然之前的集群部分就比较烂），如果考虑到之后进行扩展的话，需要进行二次开发。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>时间序列数据库调研之OpenTSDB</title>
          <link>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb</link>
          <pubDate>Mon, 04 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb</guid>
          <description>

&lt;p&gt;Java 项目，基于 HBase（2.3版本貌似开始支持 Google BigTable 和 Cassandra） 的一个时间序列数据库，被广泛应用于监控系统中。很多大公司都在使用，社区较为活跃。&lt;/p&gt;

&lt;h3 id=&#34;测试版本&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;hbase-1.1.5&lt;/p&gt;

&lt;p&gt;opentsdb-2.2.0&lt;/p&gt;

&lt;h3 id=&#34;单机部署&#34;&gt;单机部署&lt;/h3&gt;

&lt;p&gt;单机部署可以参考我之前的一篇文章，集群部署比较复杂，这里仅使用单机进行测试。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/&#34;&gt;OpenTSDB部署与使用&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式&#34;&gt;数据格式&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;metric: 一个可测量的单位的标称。&lt;/li&gt;
&lt;li&gt;tags: 对 metric 的具体描述。&lt;/li&gt;
&lt;li&gt;timestamp: 时间戳。&lt;/li&gt;
&lt;li&gt;value: metric 的实际测量值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;uid&#34;&gt;UID&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，每一个 metric、tagk 或者 tagv 在创建的时候被分配一个唯一标识叫做 UID。在后续的实际存储中，实际上存储的是 UID，而不是它们原本的字符串，UID 占 3个字节（也可以修改源码改为4字节），这样可以节省存储空间。&lt;/p&gt;

&lt;h4 id=&#34;tsuid&#34;&gt;TSUID&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;metric_UID&amp;gt;&amp;lt;timestamp&amp;gt;&amp;lt;tagk1_UID&amp;gt;&amp;lt;tagv1_UID&amp;gt;[...&amp;lt;tagkN_UID&amp;gt;&amp;lt;tagvN_UID&amp;gt;]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;写入 HBase 时的 row key 格式，其中的 metric、tagk 和 tagv 都被转换成了 UID。&lt;/p&gt;

&lt;h4 id=&#34;data-table-schema&#34;&gt;Data Table Schema&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-data-table-schema.png&#34; alt=&#34;data-table-schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RowKey&lt;/strong&gt; 就是上述的 TSUID，除了时间戳占 4 byte，其余 UID 占 3 byte。&lt;/p&gt;

&lt;p&gt;时间戳的部分只保留到了小时粒度，具体相对于小时的偏移量被存储在了 &lt;strong&gt;列族 t&lt;/strong&gt; 中。这样就减小了 HBase 中的存储行数。也就是说对于同一个小时的 metric + tags 相同的数据都会存放在一个 row 下面，这样的设计提高了 row 的检索速度。&lt;/p&gt;

&lt;p&gt;这样的 RowKey 设计使得 metric + tags 相同的数据都会连续存放，且 metric 相同的数据也会连续存放，底层 HBase 中会放在同一 Region 中，在做 Scan 的时候可以快速读取到大片数据，加速查询的过程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;value&lt;/strong&gt; 使用 8 bytes 存储，既可以存储 long,也可以存储 double。&lt;/p&gt;

&lt;h4 id=&#34;compaction&#34;&gt;Compaction&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，会将多列合并到一列之中以减少磁盘占用空间，这个过程会在 TSD 写数据或者查询过程中不定期的发生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-compaction.png&#34; alt=&#34;compaction&#34; /&gt;&lt;/p&gt;

&lt;p&gt;例如图中，将列 1890 和 列 1892 合并到了一起。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;OpenTSDB 同样提供了一套基于 HTTP 的 API 接口。&lt;/p&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/put&#34;&gt;http://localhost:4242/api/put&lt;/a&gt;, POST&lt;/p&gt;

&lt;p&gt;内容为 JSON 格式，支持同时插入多条数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 18,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web01&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 9,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web02&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查询数据&#34;&gt;查询数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/query&#34;&gt;http://localhost:4242/api/query&lt;/a&gt;, POST&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1463452826,
    &amp;quot;end&amp;quot;: 1463453026,
    &amp;quot;globalAnnotations&amp;quot;: true,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;avg&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.disk.usage&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.load&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;start&lt;/strong&gt; 和 &lt;strong&gt;end&lt;/strong&gt; 指定了查询的时间范围。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tags&lt;/strong&gt; 指定了过滤条件，2.2 版本中将不被推荐，取而代之的是 filters 参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;downsample&lt;/strong&gt; 聚合计算，例如上面是对每隔60s的数据计算一次平均值。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;OpenTSDB 在存储时间序列数据这一领域拥有很大的优势，被大多数公司所采用，网上的相关文档也比较全面。&lt;/p&gt;

&lt;p&gt;底层存储依托于 HBase，采用特殊设计过的数据存储格式，提供了非常快的查询速度，在此基础之上也更容易横向扩展。&lt;/p&gt;

&lt;p&gt;但是，相对于 InfluxDB 这种即使是新手也可以在两分钟内部署运行完成，OpenTSDB 的部署和运维显然要麻烦很多，由于底层依赖于 HBase，想要大规模运行起来，需要相当专业、细心的运维工作。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>kubernetes 初探及部署实践</title>
          <link>http://blog.fatedier.com/2016/06/24/demystifying-kubernetes-and-deployment</link>
          <pubDate>Fri, 24 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/06/24/demystifying-kubernetes-and-deployment</guid>
          <description>

&lt;p&gt;Kubernetes 是 Google 开源的容器集群管理系统，作为 Go 语言开发的热门项目之一，它提供了应用部署、维护、 扩展机制等功能，利用 Kubernetes 能够方便地管理跨机器运行的容器化应用，目前主要是针对 Docker 的管理。&lt;/p&gt;

&lt;h3 id=&#34;主要概念&#34;&gt;主要概念&lt;/h3&gt;

&lt;h4 id=&#34;pod&#34;&gt;Pod&lt;/h4&gt;

&lt;p&gt;在 Kubernetes 中是最基本的调度单元，可以包含多个相关的容器，属于同一个 pod 的容器会被运行在同一个机器上，看作一个统一的管理单元。例如我们的一个应用由 nginx、web网站、数据库三部分组成，每一部分都运行在一个单独的容器中，那么我们可以将这三个容器创建成一个 pod。&lt;/p&gt;

&lt;h4 id=&#34;service&#34;&gt;Service&lt;/h4&gt;

&lt;p&gt;Service 是 pod 的路由代理抽象，主要是为了解决 pod 的服务发现问题。因为当有机器出现故障导致容器异常退出时，这个 pod 可能就会被 kubernetes 分配到另外一个正常且资源足够的机器上，此时 IP 地址以及端口都有可能发生变化，所以我们并不能通过 host 的真实 IP 地址和端口来访问。Service 的引入正是为了解决这样的问题，通过 service 这层代理我们就可以访问到 pod 中的容器，目前的版本是通过 iptables 来实现的。&lt;/p&gt;

&lt;h4 id=&#34;replicationcontroller&#34;&gt;ReplicationController&lt;/h4&gt;

&lt;p&gt;ReplicationController 的概念比较简单，从名字就可以看出是用于管理 pod 的多副本运行的。它用于确保 kubernetes 集群中指定的 pod 始终会有指定数量的副本在运行。如果检测到有容器异常退出，replicationController 会立即重新启动新的容器，并且通过 replicationController 我们还可以动态地调整 pod 的副本数量。&lt;/p&gt;

&lt;h4 id=&#34;label&#34;&gt;Label&lt;/h4&gt;

&lt;p&gt;Label 是用于将上述几个概念关联起来的一些 k-v 值。例如我们创建了一个 pod 并且设置了 label 为 &lt;code&gt;app=nginx&lt;/code&gt;，同样在创建 service 和 replicationController 时也设置相同的 label，这样通过 label 的 selector 机制就可以将创建好的 service 和 replicationController 作用在之前创建的 pod 上。&lt;/p&gt;

&lt;h3 id=&#34;主要组件&#34;&gt;主要组件&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-06-24-demystifying-kubernetes-and-deployment-k8s-overview.png&#34; alt=&#34;k8s-overview&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes 集群中主要存在两种类型的节点，分别是 master 节点，以及 minion 节点。&lt;/p&gt;

&lt;p&gt;Minion 节点是实际运行 Docker 容器的节点，负责和节点上运行的 Docker 进行交互，并且提供了代理功能。&lt;/p&gt;

&lt;p&gt;Master 节点负责对外提供一系列管理集群的 API 接口，并且通过和 Minion 节点交互来实现对集群的操作管理。&lt;/p&gt;

&lt;h4 id=&#34;apiserver&#34;&gt;apiserver&lt;/h4&gt;

&lt;p&gt;用户和 kubernetes 集群交互的入口，封装了核心对象的增删改查操作，提供了 RESTFul 风格的 API 接口，通过 etcd 来实现持久化并维护对象的一致性。&lt;/p&gt;

&lt;h4 id=&#34;scheduler&#34;&gt;scheduler&lt;/h4&gt;

&lt;p&gt;负责集群资源的调度和管理，例如当有 pod 异常退出需要重新分配机器时，scheduler 通过一定的调度算法从而找到最合适的节点。&lt;/p&gt;

&lt;h4 id=&#34;controller-manager&#34;&gt;controller-manager&lt;/h4&gt;

&lt;p&gt;主要是用于保证 replicationController 定义的复制数量和实际运行的 pod 数量一致，另外还保证了从 service 到 pod 的映射关系总是最新的。&lt;/p&gt;

&lt;h4 id=&#34;kubelet&#34;&gt;kubelet&lt;/h4&gt;

&lt;p&gt;运行在 minion 节点，负责和节点上的 Docker 交互，例如启停容器，监控运行状态等。&lt;/p&gt;

&lt;h4 id=&#34;proxy&#34;&gt;proxy&lt;/h4&gt;

&lt;p&gt;运行在 minion 节点，负责为 pod 提供代理功能，会定期从 etcd 获取 service 信息，并根据 service 信息通过修改 iptables 来实现流量转发（最初的版本是直接通过程序提供转发功能，效率较低。），将流量转发到要访问的 pod 所在的节点上去。&lt;/p&gt;

&lt;h3 id=&#34;部署实践&#34;&gt;部署实践&lt;/h3&gt;

&lt;p&gt;Kubernetes 的部署十分简单，先从 Github 上下载编译好的二进制文件（我自己尝试编译耗时太久，遂作罢），这里强调简单的原因是因为每个组件并不需要配置文件，而是直接通过启动参数来设置。相比于很多 Java 项目一系列的环境设置，组件搭建，k8s 还是比较友好的。下面主要说一下各个组件常用的启动参数的设置。&lt;/p&gt;

&lt;h4 id=&#34;etcd&#34;&gt;etcd&lt;/h4&gt;

&lt;p&gt;安装并启动 etcd 集群，这里以一台作为示例，比较简单，不具体说明，假设访问地址为 &lt;code&gt;192.168.2.129:2379&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;flannel&#34;&gt;flannel&lt;/h4&gt;

&lt;p&gt;Flannel 是 CoreOS 团队针对 Kubernetes 设计的一个覆盖网络（Overlay Network）工具，需要另外下载部署。我们知道当我们启动 Docker 后会有一个用于和容器进行交互的 IP 地址，如果不去管理的话可能这个 IP 地址在各个机器上是一样的，并且仅限于在本机上进行通信，无法访问到其他机器上的 Docker 容器。&lt;/p&gt;

&lt;p&gt;Flannel 的目的就是为集群中的所有节点重新规划 IP 地址的使用规则，从而使得不同节点上的容器能够获得同属一个内网且不重复的 IP 地址，并让属于不同节点上的容器能够直接通过内网 IP 通信。&lt;/p&gt;

&lt;p&gt;具体实现原理可以参考： &lt;a href=&#34;http://www.open-open.com/news/view/1aa473a&#34;&gt;http://www.open-open.com/news/view/1aa473a&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&#34;安装-flannel&#34;&gt;安装 flannel&lt;/h5&gt;

&lt;p&gt;在 etcd 中创建 flannel 需要用到的键，假设我们 Minion 中 flannel 所使用的子网范围为&lt;code&gt;172.17.1.0~172.17.254.0&lt;/code&gt;（每一个Minion节点都有一个独立的flannel子网）。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;etcdctl mk /coreos.com/network/config &#39;{&amp;quot;Network&amp;quot;:&amp;quot;172.17.0.0/16&amp;quot;, &amp;quot;SubnetMin&amp;quot;: &amp;quot;172.17.1.0&amp;quot;, &amp;quot;SubnetMax&amp;quot;: &amp;quot;172.17.254.0&amp;quot;}&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;启动参数&#34;&gt;启动参数&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;flanneld -etcd-endpoints=http://192.168.2.129:2379 -etcd-prefix=/coreos.com/network --log_dir=./ --logtostderr=false&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-etcd-endpoints: etcd 集群的地址
-etcd-prefix: etcd 中存储 flannel 信息的前缀
--log_dir: 设置日志文件存储目录
--logtostderr: 设置错误信息是否存储到标准输出中
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;修改-docker0-网卡的-ip-地址&#34;&gt;修改 docker0 网卡的 IP 地址&lt;/h5&gt;

&lt;p&gt;默认情况下启动 docker 后会有一个 docker0 的虚拟网卡，每一台机器的 docker0 网卡对应的 ip 地址都是相同的。&lt;/p&gt;

&lt;p&gt;修改启动 docker 的参数，centos7 下可以修改 &lt;code&gt;/usr/lib/systemd/system/docker.service&lt;/code&gt; 文件。&lt;/p&gt;

&lt;p&gt;增加 &lt;code&gt;EnvironmentFile=-/run/flannel/subnet.env&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ExecStart&lt;/code&gt; 增加两个参数 &lt;code&gt;--bip=${FLANNEL_SUBNET}  --mtu=${FLANNEL_MTU}&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;FLANNEL_SUBNET&lt;/code&gt; 和 &lt;code&gt;FLANNEL_MTU&lt;/code&gt; 这两个变量就是从 &lt;code&gt;/run/flannel/subnet.env&lt;/code&gt; 文件中读取，记录了 flannel 在这台机器上被分配到的一个网段。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;systemctl daemon-reload&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;systemctl start docker.service&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后通过 &lt;code&gt;ifconfig&lt;/code&gt; 可以看到 docker0 的网卡 ip 已经变成了 flannel 的网段。&lt;/p&gt;

&lt;h4 id=&#34;kube-apiserver&#34;&gt;kube-apiserver&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-apiserver --logtostderr=false --log-dir=./ --v=0 --etcd-servers=http://192.168.2.129:2379 --address=0.0.0.0 --port=8080 --kubelet-port=10250 --allow-privileged=true --service-cluster-ip-range=10.254.0.0/16&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-scheduler&#34;&gt;kube-scheduler&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-scheduler --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-controller-manager&#34;&gt;kube-controller-manager&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-controller-manager --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kubelet-1&#34;&gt;kubelet &lt;/h4&gt;

&lt;p&gt;部署在 Minion 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubelet --logtostderr=false --log-dir=./ --v=0 --api-servers=http://192.168.2.129:8080 --address=0.0.0.0 --port=10250 --allow-privileged=true&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-proxy&#34;&gt;kube-proxy&lt;/h4&gt;

&lt;p&gt;部署在 Minion 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-proxy --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;遇到的问题&#34;&gt;遇到的问题&lt;/h3&gt;

&lt;p&gt;通过上面的步骤，k8s 集群就差不多搭建成功了，但是仍然遇到了一些问题，有的甚至目前还没有找到解决方案，直接导致了我丧失了将 k8s 用于实际开发环境的动力。&lt;/p&gt;

&lt;h4 id=&#34;pause-镜像&#34;&gt;pause 镜像&lt;/h4&gt;

&lt;p&gt;在每个 Minion 节点上的 Docker 需要安装  gcr.io/google_containers/pause 镜像，这个镜像是在 kubernetes 集群启动用户配置的容器时需要用到。&lt;/p&gt;

&lt;p&gt;本来启动容器后会直接从 google 官方源下载，因为墙的原因，在国内无法下载成功，这里可以先从 dockerhub 上下载，&lt;code&gt;sudo docker pull kubernetes/pause&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;之后再打上 tag，&lt;code&gt;sudo docker tag kubernetes/pause gcr.io/google_containers/pause:2.0&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;我装的 &lt;code&gt;kubernetes 1.2.3&lt;/code&gt; 版本对应的 tag 是 &lt;code&gt;pause:2.0&lt;/code&gt;，如果不知道版本，可以尝试运行一个 pod ，之后通过查看错误信息得到。&lt;/p&gt;

&lt;p&gt;后来查看文档发现也可以通过在 kubelet 的启动参数中设置这个镜像的地址，不过还没有测试过。&lt;/p&gt;

&lt;h4 id=&#34;搭建私有-docker-镜像仓库&#34;&gt;搭建私有 docker 镜像仓库&lt;/h4&gt;

&lt;p&gt;为了便于使用，最好自己搭建内网环境的私有镜像仓库，因为 k8s 中每一台机器上的 docker 都需要 pull 镜像到本地，如果从外网环境拉镜像的话效率较低，而且以后更新镜像等操作将变的非常不方便。&lt;/p&gt;

&lt;p&gt;具体的步骤可以参考我之前的一篇文章， &lt;a href=&#34;http://blog.fatedier.com/2016/05/16/install-private-docker-registry/&#34;&gt;『搭建私有docker仓库』&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;service-访问问题&#34;&gt;service 访问问题&lt;/h4&gt;

&lt;p&gt;测试时可以在一台机器上的容器内部通过 service 提供的内网 IP 地址访问到运行在另外一台机器上的容器。但是必须是在容器内部才行，如果直接在这个机器上通过 telnet 或者 curl 访问，则无法正确地根据这个内网 IP 转发到对应节点的容器中。&lt;/p&gt;

&lt;p&gt;因为是通过 iptables 来进行转发，我查看了 iptables 的规则，并没有发现问题，后来通过抓包发现这个包的目的 IP 地址被替换成功了，但是源地址并没有被正确替换，导致对方节点无法正确回复。这个问题我还没有发现具体的原因，目前不能在容器外部通过 service 提供的 IP 地址来访问容器，导致很多应用没有了实际部署的意义，后面有时间还是要研究下。&lt;/p&gt;

&lt;h4 id=&#34;文件存储&#34;&gt;文件存储&lt;/h4&gt;

&lt;p&gt;由于 pod 可能会被在任意一台机器上重新启动，所以并不能简单的像运行单机 Docker 那样将容器内部的目录映射到宿主机的指定目录上，否则将会丢失文件。所以通常我们需要使用类似 NFS、ceph、glusterFS 这样的分布式存储系统来为 k8s 集群提供后端的统一存储。这样一来，无疑就增加了部署的难度，比如要搭建一个靠谱的 ceph 集群，无疑是需要有比较靠谱的运维团队的。&lt;/p&gt;

&lt;h3 id=&#34;测试-nginx-容器&#34;&gt;测试 nginx 容器&lt;/h3&gt;

&lt;h4 id=&#34;创建并启动-replicationcontroller&#34;&gt;创建并启动 replicationController&lt;/h4&gt;

&lt;p&gt;创建配置文件 &lt;code&gt;nginx-rc.yaml&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1 
kind: ReplicationController 
metadata: 
  name: nginx-controller 
spec: 
  replicas: 2 
  selector: 
    name: nginx 
  template: 
    metadata: 
      labels: 
        name: nginx 
    spec: 
      containers: 
        - name: nginx
          image: nginx
          ports: 
            - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里定义了一个 nginx pod 的复制器，复制份数为2。&lt;/p&gt;

&lt;p&gt;执行下面的操作创建nginx pod复制器：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 create -f nginx-rc.yaml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看创建 pod 的状态：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 get pods&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;创建并启动-service&#34;&gt;创建并启动 service&lt;/h4&gt;

&lt;p&gt;Service 的 type 有 ClusterIP 和 NodePort 之分，缺省是 ClusterIP，这种类型的 Service 只能在集群内部访问，而 NodePort 可以在集群外部访问，但是它的原理就是在所有节点上都绑定这个端口，之后将所有的流量转发到正确的节点上。&lt;/p&gt;

&lt;p&gt;创建配置文件 &lt;code&gt;nginx-service-clusterip.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1 
kind: Service 
metadata: 
  name: nginx-service-clusterip 
spec: 
  ports: 
    - port: 8001 
      targetPort: 80 
      protocol: TCP 
  selector: 
    name: nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行下面的命令创建 service：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 create -f ./nginx-service-clusterip.yaml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看 service 提供的 IP 地址和端口：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 get service&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后就可以通过 curl 来验证是否能够成功访问到之前部署的 nginx 容器，由于启用了 service，会自动帮我们进行负载均衡，流量会被分发到后端的多个 pod 中。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>LSM Tree 学习笔记</title>
          <link>http://blog.fatedier.com/2016/06/15/learn-lsm-tree</link>
          <pubDate>Wed, 15 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/06/15/learn-lsm-tree</guid>
          <description>

&lt;p&gt;最近发现很多数据库都使用了 LSM Tree 的存储模型，包括 LevelDB，HBase，Google BigTable，Cassandra，InfluxDB 等。之前还没有留意这么设计的原因，最近调研时间序列数据库的时候才发现这样设计的优势所在，所以重新又复习了一遍 LSM Tree 的原理。&lt;/p&gt;

&lt;h3 id=&#34;特点&#34;&gt;特点&lt;/h3&gt;

&lt;p&gt;总的来说就是通过将大量的随机写转换为顺序写，从而极大地提升了数据写入的性能，虽然与此同时牺牲了部分读的性能。&lt;/p&gt;

&lt;p&gt;只适合存储 key 值有序且写入大于读取的数据，或者读取操作通常是 key 值连续的数据。&lt;/p&gt;

&lt;h3 id=&#34;存储模型&#34;&gt;存储模型&lt;/h3&gt;

&lt;h4 id=&#34;wal&#34;&gt;WAL&lt;/h4&gt;

&lt;p&gt;在设计数据库的时候经常被使用，当插入一条数据时，数据先顺序写入 WAL 文件中，之后插入到内存中的 MemTable 中。这样就保证了数据的持久化，不会丢失数据，并且都是顺序写，速度很快。当程序挂掉重启时，可以从 WAL 文件中重新恢复内存中的 MemTable。&lt;/p&gt;

&lt;h4 id=&#34;memtable&#34;&gt;MemTable&lt;/h4&gt;

&lt;p&gt;MemTable 对应的就是 WAL 文件，是该文件内容在内存中的存储结构，通常用 SkipList 来实现。MemTable 提供了 k-v 数据的写入、删除以及读取的操作接口。其内部将 k-v 对按照 key 值有序存储，这样方便之后快速序列化到 SSTable 文件中，仍然保持数据的有序性。&lt;/p&gt;

&lt;h4 id=&#34;immutable-memtable&#34;&gt;Immutable Memtable&lt;/h4&gt;

&lt;p&gt;顾名思义，Immutable Memtable 就是在内存中只读的 MemTable，由于内存是有限的，通常我们会设置一个阀值，当 MemTable 占用的内存达到阀值后就自动转换为 Immutable Memtable，Immutable Memtable 和 MemTable 的区别就是它是只读的，系统此时会生成新的 MemTable 供写操作继续写入。&lt;/p&gt;

&lt;p&gt;之所以要使用 Immutable Memtable，就是为了避免将 MemTable 中的内容序列化到磁盘中时会阻塞写操作。&lt;/p&gt;

&lt;h4 id=&#34;sstable&#34;&gt;SSTable&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-06-15-learn-lsm-tree-sstable.png&#34; alt=&#34;sstable&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SSTable 就是 MemTable 中的数据在磁盘上的有序存储，其内部数据是根据 key 从小到大排列的。通常为了加快查找的速度，需要在 SSTable 中加入数据索引，可以快读定位到指定的 k-v 数据。&lt;/p&gt;

&lt;p&gt;SSTable 通常采用的分级的结构，例如 LevelDB 中就是如此。MemTable 中的数据达到指定阀值后会在 Level 0 层创建一个新的 SSTable。当某个 Level 下的文件数超过一定值后，就会将这个 Level 下的一个 SSTable 文件和更高一级的 SSTable 文件合并，由于 SSTable 中的 k-v 数据都是有序的，相当于是一个多路归并排序，所以合并操作相当快速，最终生成一个新的 SSTable 文件，将旧的文件删除，这样就完成了一次合并过程。&lt;/p&gt;

&lt;h3 id=&#34;常用操作的实现&#34;&gt;常用操作的实现&lt;/h3&gt;

&lt;h4 id=&#34;写入&#34;&gt;写入&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-06-15-learn-lsm-tree-write.png&#34; alt=&#34;write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在 LSM Tree 中，写入操作是相当快速的，只需要在 WAL 文件中顺序写入当次操作的内容，成功之后将该 k-v 数据写入 MemTable 中即可。尽管做了一次磁盘 IO，但是由于是顺序追加写入操作，效率相对来说很高，并不会导致写入速度的降低。数据写入 MemTable 中其实就是往 SkipList 中插入一条数据，过程也相当简单快速。&lt;/p&gt;

&lt;h4 id=&#34;更新&#34;&gt;更新&lt;/h4&gt;

&lt;p&gt;更新操作其实并不真正存在，和写入一个 k-v 数据没有什么不同，只是在读取的时候，会从 Level0 层的 SSTable 文件开始查找数据，数据在低层的 SSTable 文件中必然比高层的文件中要新，所以总能读取到最新的那条数据。也就是说此时在整个 LSM Tree 中可能会同时存在多个 key 值相同的数据，只有在之后合并 SSTable 文件的时候，才会将旧的值删除。&lt;/p&gt;

&lt;h4 id=&#34;删除&#34;&gt;删除&lt;/h4&gt;

&lt;p&gt;删除一条记录的操作比较特殊，并不立即将数据从文件中删除，而是记录下对这个 key 的删除操作标记，同插入操作相同，插入操作插入的是 k-v 值，而删除操作插入的是 k-del 标记，只有当合并 SSTable 文件时才会真正的删除。&lt;/p&gt;

&lt;h4 id=&#34;compaction&#34;&gt;Compaction&lt;/h4&gt;

&lt;p&gt;当数据不断从  Immutable Memtable 序列化到磁盘上的 SSTable 文件中时，SSTable 文件的数量就不断增加，而且其中可能有很多更新和删除操作并不立即对文件进行操作，而只是存储一个操作记录，这就造成了整个 LSM Tree 中可能有大量相同 key 值的数据，占据了磁盘空间。&lt;/p&gt;

&lt;p&gt;为了节省磁盘空间占用，控制 SSTable 文件数量，需要将多个 SSTable 文件进行合并，生成一个新的 SSTable 文件。比如说有 5 个 10 行的 SSTable 文件要合并成 1 个 50 行的 SSTable 文件，但是其中可能有 key 值重复的数据，我们只需要保留其中最新的一条即可，这个时候新生成的 SSTable 可能只有 40 行记录。&lt;/p&gt;

&lt;p&gt;通常在使用过程中我们采用分级合并的方法，其特点如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每一层都包含大量 SSTable 文件，key 值范围不重复，这样查询操作只需要查询这一层的一个文件即可。(第一层比较特殊，key 值可能落在多个文件中，并不适用于此特性）&lt;/li&gt;
&lt;li&gt;当一层的文件达到指定数量后，其中的一个文件会被合并进入上一层的文件中。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;读取&#34;&gt;读取&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-06-15-learn-lsm-tree-read.png&#34; alt=&#34;read&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LSM Tree 的读取效率并不高，当需要读取指定 key 的数据时，先在内存中的 MemTable 和 Immutable MemTable 中查找，如果没有找到，则继续从 Level 0 层开始，找不到就从更高层的 SSTable 文件中查找，如果查找失败，说明整个 LSM Tree 中都不存在这个 key 的数据。如果中间在任何一个地方找到这个 key 的数据，那么按照这个路径找到的数据都是最新的。&lt;/p&gt;

&lt;p&gt;在每一层的 SSTable 文件的 key 值范围是不重复的，所以只需要查找其中一个 SSTable 文件即可确定指定 key 的数据是否存在于这一层中。Level 0 层比较特殊，因为数据是 Immutable MemTable 直接写入此层的，所以 Level 0 层的 SSTable 文件的 key 值范围可能存在重复，查找数据时有可能需要查找多个文件。&lt;/p&gt;

&lt;h4 id=&#34;优化读取&#34;&gt;优化读取&lt;/h4&gt;

&lt;p&gt;因为这样的读取效率非常差，通常会进行一些优化，例如 LevelDB 中的 Mainfest 文件，这个文件记录了 SSTable 文件的一些关键信息，例如 Level 层数，文件名，最小 key 值，最大 key 值等，这个文件通常不会太大，可以放入内存中，可以帮助快速定位到要查询的 SSTable 文件，避免频繁读取。&lt;/p&gt;

&lt;p&gt;另外一个经常使用的方法是布隆解析器(Bloom filter)，布隆解析器是一个使用内存判断文件是否包含一个关键字的有效方法。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;LSM Tree 的思想非常实用，将随机写转换为顺序写来大幅提高写入操作的性能，但是牺牲了部分读的性能。&lt;/p&gt;

&lt;p&gt;由于时间序列数据库的特性，运用 LSM Tree 的算法非常合适。持续写入数据量大，数据和时间相关，编码到 key 值中很容易使 key 值有序。读取操作相对来说较少，而且通常不是读取单个 key 的值，而是一段时间范围内的数据，这样就把 LSM Tree 读取性能差的劣势缩小了，反而由于数据在 SSTable 中是按照 key 值顺序排列，读取大块连续的数据时效率也很高。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>部署openstack的对象存储服务swift</title>
          <link>http://blog.fatedier.com/2016/05/25/deploy-openstack-swift</link>
          <pubDate>Wed, 25 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/05/25/deploy-openstack-swift</guid>
          <description>

&lt;p&gt;OpenStack Swift 是一个开源项目，提供了弹性可伸缩、高可用的分布式对象存储服务，适合存储大规模非结构化数据。由于要开发自己的分布式存储应用，需要借鉴 swift 的一些架构，所以在自己的机器上搭建了一个集群环境用于测试。&lt;/p&gt;

&lt;h3 id=&#34;环境&#34;&gt;环境&lt;/h3&gt;

&lt;p&gt;一台物理机上，开了三台虚拟机，操作系统是 Centos7&lt;/p&gt;

&lt;p&gt;ip 为 &lt;strong&gt;192.168.2.129, 192.168.2.130, 192.168.2.131&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之前安装过一次，当时是 2.4.0 版本，目前最新的是 2.7.0 版本，最新的版本由于我的机器上缺少某些动态库，所以还是选择了比较熟悉的 2.4.0 版本，基本上的步骤是一样的。&lt;/p&gt;

&lt;p&gt;后续的安装步骤需要在三台机器上全部执行一遍，下文中的 &lt;code&gt;user:user&lt;/code&gt; 根据需要修改为自己机器上的用户。&lt;/p&gt;

&lt;p&gt;整个步骤参考了官方的文档： &lt;a href=&#34;http://docs.openstack.org/developer/swift/development_saio.html&#34;&gt;http://docs.openstack.org/developer/swift/development_saio.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装各种依赖&#34;&gt;安装各种依赖&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo yum install curl gcc memcached rsync sqlite xfsprogs git-core \
    libffi-devel xinetd liberasurecode-devel \
    python-setuptools \
    python-coverage python-devel python-nose \
    pyxattr python-eventlet \
    python-greenlet python-paste-deploy \
    python-netifaces python-pip python-dns \
    python-mock
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;创建磁盘设备&#34;&gt;创建磁盘设备&lt;/h3&gt;

&lt;p&gt;由于 swift 需要使用 xfs 格式的磁盘，这里我们使用回环设备。&lt;/p&gt;

&lt;h4 id=&#34;创建一个用于回环设备的2gb大小的文件&#34;&gt;创建一个用于回环设备的2GB大小的文件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir /srv
sudo truncate -s 1GB /srv/swift-disk
sudo mkfs.xfs /srv/swift-disk
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;修改-etc-fstab&#34;&gt;修改 /etc/fstab&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/srv/swift-disk /srv/node/sdb1 xfs loop,noatime,nodiratime,nobarrier,logbufs=8 0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建挂载点并进行挂载&#34;&gt;创建挂载点并进行挂载&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /srv/node/sdb1
sudo mount /srv/node/sdb1
sudo chown -R user:user /srv/node
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;下载安装-swift-和-swift-client&#34;&gt;下载安装 swift 和 swift-client&lt;/h4&gt;

&lt;p&gt;从 git 下载这两个项目之后切换到 2.4.0 版本，安装 python 依赖以后使用 &lt;code&gt;python setup.py&lt;/code&gt; 安装。&lt;/p&gt;

&lt;p&gt;直接通过 yum 安装的 pip 可能版本不是最新的，需要升级，使用 &lt;code&gt;pip install --upgrade pip&lt;/code&gt; 升级。&lt;/p&gt;

&lt;h5 id=&#34;swift-client&#34;&gt;swift-client&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/openstack/python-swiftclient.git
git checkout 2.4.0
cd ./python-swiftclient; sudo python setup.py develop; cd -
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;swift&#34;&gt;swift&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/openstack/swift.git
git checkout 2.4.0
cd ./swift; sudo pip install -r requirements.txt; sudo python setup.py develop; cd -
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;配置-etc-rc-local&#34;&gt;配置 /etc/rc.local&lt;/h5&gt;

&lt;p&gt;需要在每次开机时都创建一些需要的目录。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /var/run/swift
sudo chown user:user /var/run/swift
sudo mkdir -p /var/cache/swift
sudo chown user:user /var/cache/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置-rsync&#34;&gt;配置 rsync&lt;/h3&gt;

&lt;h4 id=&#34;修改-etc-rsyncd-conf&#34;&gt;修改 /etc/rsyncd.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# /etc/rsyncd: configuration file for rsync daemon mode
uid = user
gid = user
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
address = 0.0.0.0

[account]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/account.lock

[container]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/container.lock

[object]
max connections = 25
path = /srv/node/
read only = false
lock file = /var/lock/object.lock
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;启动-rsync-并设置开机启动&#34;&gt;启动 rsync 并设置开机启动&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo chkconfig rsyncd on
sudo service rsyncd start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置rsyslog让每个程序输出独立的日志-可选&#34;&gt;配置rsyslog让每个程序输出独立的日志（可选）&lt;/h3&gt;

&lt;p&gt;swift 默认将日志信息输出到文件 /var/log/syslog 中。如果要按照个人需求设置 rsyslog，生成另外单独的 swift日志文件，就需要另外配置。&lt;/p&gt;

&lt;h4 id=&#34;创建日志配置文件-etc-rsyslog-d-10-swift-conf&#34;&gt;创建日志配置文件 /etc/rsyslog.d/10-swift.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Uncomment the following to have a log containing all logs together
#local1,local2,local3,local4,local5.*   /var/log/swift/all.log

# Uncomment the following to have hourly proxy logs for stats processing
$template HourlyProxyLog,&amp;quot;/var/log/swift/hourly/%$YEAR%%$MONTH%%$DAY%%$HOUR%&amp;quot;
#local1.*;local1.!notice ?HourlyProxyLog

local1.*;local1.!notice /var/log/swift/proxy.log
local1.notice           /var/log/swift/ proxy.error
local1.*                ~

local2.*;local2.!notice /var/log/swift/object.log
local2.notice           /var/log/swift/ object.error
local2.*                ~

local3.*;local3.!notice /var/log/swift/container.log
local3.notice           /var/log/swift/ container.error
local3.*                ~

local4.*;local4.!notice /var/log/swift/account.log
local4.notice           /var/log/swift/ account.error
local4.*                ~
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;编辑文件-etc-rsyslog-conf-更改参数-privdroptogroup-为-adm&#34;&gt;编辑文件 /etc/rsyslog.conf，更改参数 $PrivDropToGroup 为 adm&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$PrivDropToGroup adm
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-var-log-swift-目录-用于存放独立日志&#34;&gt;创建 /var/log/swift 目录，用于存放独立日志&lt;/h4&gt;

&lt;p&gt;此外，上面的 &lt;code&gt;10-swift.conf&lt;/code&gt; 文件中设置了输出 Swift Proxy Server 每小时的 stats 日志信息，于是也要创建 &lt;code&gt;/var/log/swift/hourly&lt;/code&gt; 目录。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir -p /var/log/swift/hourly
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;更改-swift-独立日志目录的权限&#34;&gt;更改 swift 独立日志目录的权限&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chown -R root.adm /var/log/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;重启-rsyslog-服务&#34;&gt;重启 rsyslog 服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo service rsyslog restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动-memcached-并设置开机启动&#34;&gt;启动 memcached 并设置开机启动&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo service memcached start
sudo chkconfig memcached on
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置swift相关的配置文件&#34;&gt;配置swift相关的配置文件&lt;/h3&gt;

&lt;h4 id=&#34;创建存储-swift-配置文件的目录&#34;&gt;创建存储 swift 配置文件的目录&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mkdir /etc/swift
sudo chown -R user:user /etc/swift
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-swift-配置文件-etc-swift-swift-conf&#34;&gt;创建 swift 配置文件 /etc/swift/swift.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[swift-hash]

# random unique string that can never change (DO NOT LOSE)
swift_hash_path_suffix = jtangfs
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-account-服务-etc-swift-account-server-conf&#34;&gt;配置 account 服务 /etc/swift/account-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6002
workers = 4
user = wcl
log_facility = LOG_LOCAL4

[pipeline:main]
pipeline = account-server

[app:account-server]
use = egg:swift#account

[account-replicator]
[account-auditor]
[account-reaper]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-container-服务-etc-swift-container-server-conf&#34;&gt;配置 container 服务 /etc/swift/container-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6001
workers = 4
user = wcl
log_facility = LOG_LOCAL3

[pipeline:main]
pipeline = container-server

[app:container-server]
use = egg:swift#container

[container-replicator]

[container-updater]

[container-auditor]

[container-sync]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-object-服务-etc-swift-object-server-conf&#34;&gt;配置 object 服务 /etc/swift/object-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
devices = /srv/node
mount_check = false
bind_ip = 0.0.0.0
bind_port = 6000
workers = 4
user = wcl
log_facility = LOG_LOCAL2

[pipeline:main]
pipeline = object-server

[app:object-server]
use = egg:swift#object

[object-replicator]

[object-updater]

[object-auditor]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置-proxy-服务-etc-swift-proxy-server-conf&#34;&gt;配置 proxy 服务 /etc/swift/proxy-server.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[DEFAULT]
bind_port = 8080
user = wcl
workers = 2
log_facility = LOG_LOCAL1

[pipeline:main]
pipeline = healthcheck cache tempauth proxy-logging proxy-server

[app:proxy-server]
use = egg:swift#proxy
allow_account_management = true
account_autocreate = true

[filter:tempauth]
use = egg:swift#tempauth
user_admin_admin = admin .admin .reseller_admin
user_test_tester = testing .admin
user_test2_tester2 = testing2 .admin
user_test_tester3 = testing3
reseller_prefix = AUTH
token_life = 86400
# account和token的命名前缀，注意此处不可以加&amp;quot;_&amp;quot;。
# 例如X-Storage-Ur可能l为http://127.0.0.1:8080/v1/AUTH_test
# 例如X-Auth-Token为AUTH_tk440e9bd9a9cb46d6be07a5b6a585f7d1# token的有效期，单位：秒。

[filter:healthcheck]
use = egg:swift#healthcheck

[filter:cache]
use = egg:swift#memcache

# 这里可以是多个memcache server，proxy会自动当作一个集群来使用# 例如 memcache_servers = 192.168.2.129:11211,192.168.2.130:11211,192.168.2.131

[filter:proxy-logging]
use = egg:swift#proxy_logging
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注：&lt;code&gt;user_admin_admin = admin .admin .reseller_admin&lt;/code&gt; 后面还可以增加一项 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt;，显示地指定 swift 为该用户提供的存储服务入口，admin 用户通过认证后，swift 会把 Token 和该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt;  返回给用户，此后 admin 用户可以使用该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 访问 swift 来请求存储服务。特别值得说明的是，如果在 Proxy Server 前面增加了负载均衡器（如 nginx），那么该 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 应该指向负载均衡器，使得用户在通过认证后，向负载均衡器发起存储请求，再由负载均衡器将请求均衡地分发给 Proxy Server 集群。此时的 &lt;code&gt;&amp;lt;storage-url&amp;gt;&lt;/code&gt; 形如 &lt;code&gt;http://&amp;lt;LOAD_BALANCER_HOSTNAME&amp;gt;:&amp;lt;PORT&amp;gt;/v1/AUTH_admin&lt;/code&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建-ring-文件&#34;&gt;创建 ring 文件&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;swift&lt;/strong&gt; 安装完成后会有一个 &lt;strong&gt;swift-ring-builder&lt;/strong&gt; 程序用于对 ring 的相关操作。&lt;/p&gt;

&lt;h4 id=&#34;生成-ring&#34;&gt;生成 ring&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder create 18 3 1
swift-ring-builder container.builder create 18 3 1
swift-ring-builder object.builder create 18 3 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要事先创建好3个 ring，18 表示 partition 数为2的18次方，3表示 replication 数为3，1 表示分区数据的最短迁移间隔时间为1小时。（官网说明里如果移除设备的话不在这个限制内）&lt;/p&gt;

&lt;h3 id=&#34;向-ring-中加入设备&#34;&gt;向 ring 中加入设备&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder add z1-192.168.2.129:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.129:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.129:6000/sdb1 100

swift-ring-builder account.builder add z2-192.168.2.130:6002/sdb1 100
swift-ring-builder container.builder add z2-192.168.2.130:6001/sdb1 100
swift-ring-builder object.builder add z2-192.168.2.130:6000/sdb1 100

swift-ring-builder account.builder add z2-192.168.2.131:6002/sdb1 100
swift-ring-builder container.builder add z2-192.168.2.131:6001/sdb1 100
swift-ring-builder object.builder add z2-192.168.2.131:6000/sdb1 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;z1&lt;/strong&gt; 和 &lt;strong&gt;z2&lt;/strong&gt; 表示 &lt;strong&gt;zone1&lt;/strong&gt; 和 &lt;strong&gt;zone2&lt;/strong&gt;（&lt;strong&gt;zone&lt;/strong&gt; 这个概念是虚拟的，可以将一个 &lt;strong&gt;device&lt;/strong&gt; 划定到一个 &lt;strong&gt;zone&lt;/strong&gt;，在分配 &lt;strong&gt;partition&lt;/strong&gt; 的时候会考虑到这个因素，尽量划分到不同的 &lt;strong&gt;zone&lt;/strong&gt; 中）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sdb1&lt;/strong&gt; 为 &lt;strong&gt;swift&lt;/strong&gt; 所使用的存储空间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;100&lt;/strong&gt; 代表设备的权重，也是在分配 &lt;strong&gt;partition&lt;/strong&gt; 的时候会考虑的因素。&lt;/p&gt;

&lt;h4 id=&#34;rebalance&#34;&gt;rebalance&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift-ring-builder account.builder rebalance
swift-ring-builder container.builder rebalance
swift-ring-builder object.builder rebalance
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;将-ring-文件传输到其他机器的-etc-swift-目录下&#34;&gt;将 ring 文件传输到其他机器的 /etc/swift 目录下&lt;/h4&gt;

&lt;p&gt;最终生成的 ring 文件以 &lt;code&gt;.gz&lt;/code&gt; 结尾。&lt;/p&gt;

&lt;h3 id=&#34;创建初始化-起停等脚本&#34;&gt;创建初始化、起停等脚本&lt;/h3&gt;

&lt;p&gt;由于 swift 涉及的组件较多，起停都比较麻烦，所以最好先写好起停脚本。&lt;/p&gt;

&lt;h4 id=&#34;remake-rings-sh-脚本文件-用于完成-ring-的重新创建&#34;&gt;remake_rings.sh 脚本文件，用于完成 ring 的重新创建&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
cd /etc/swift

rm -f *.builder *.ring.gz backups/*.builder backups/*.ring.gz

swift-ring-builder account.builder create 18 3 1
swift-ring-builder container.builder create 18 3 1
swift-ring-builder object.builder create 18 3 1

swift-ring-builder account.builder add z1-192.168.2.129:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.129:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.129:6000/sdb1 100

swift-ring-builder account.builder add z1-192.168.2.130:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.130:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.130:6000/sdb1 100

swift-ring-builder account.builder add z1-192.168.2.131:6002/sdb1 100
swift-ring-builder container.builder add z1-192.168.2.131:6001/sdb1 100
swift-ring-builder object.builder add z1-192.168.2.131:6000/sdb1 100

swift-ring-builder account.builder rebalance
swift-ring-builder container.builder rebalance
swift-ring-builder object.builder rebalance
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;reset-swift-sh-脚本文件-用于一键清空-swift-的对象数据和日志-完全重置&#34;&gt;reset_swift.sh 脚本文件，用于一键清空 swift 的对象数据和日志，完全重置&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init all stop

find /var/log/swift -type f -exec rm -f {} \;

sudo umount /srv/node/sdb1
sudo mkfs.xfs -f -i size=1024 /srv/swift-disk
sudo mount /srv/node/sdb1

sudo chown wcl:wcl /srv/node/sdb1

sudo rm -f /var/log/debug /var/log/messages /var/log/rsyncd.log /var/log/syslog
sudo service rsyslog restart
sudo service rsyncd restart
sudo service memcached restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;start-main-sh-脚本文件-用于启动-swift-所有基础服务&#34;&gt;start_main.sh 脚本文件，用于启动 swift 所有基础服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init main start
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-main-sh-脚本文件-用于关闭-swift-所有基础服务&#34;&gt;stop_main.sh 脚本文件，用于关闭 swift 所有基础服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init main stop
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;start-all-sh-脚本文件&#34;&gt;start_all.sh 脚本文件&lt;/h4&gt;

&lt;p&gt;一键启动 swift 的所有服务。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init proxy start
swift-init account-server start
swift-init account-replicator start
swift-init account-auditor start
swift-init container-server start
swift-init container-replicator start
swift-init container-updater start
swift-init container-auditor start
swift-init object-server start
swift-init object-replicator start
swift-init object-updater start
swift-init object-auditor start
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;stop-all-sh-脚本文件&#34;&gt;stop_all.sh 脚本文件&lt;/h4&gt;

&lt;p&gt;一键关闭 swift的所有服务。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
swift-init proxy stop
swift-init account-server stop
swift-init account-replicator stop
swift-init account-auditor stop
swift-init container-server stop
swift-init container-replicator stop
swift-init container-updater stop
swift-init container-auditor stop
swift-init object-server stop
swift-init object-replicator stop
swift-init object-updater stop
swift-init object-auditor stop
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;启动-swift-服务&#34;&gt;启动 swift 服务&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./start_all.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;动态扩容&#34;&gt;动态扩容&lt;/h3&gt;

&lt;p&gt;重新编写 &lt;strong&gt;remake_rings.sh&lt;/strong&gt; 脚本中的内容，加上需要添加的机器信息，重新生成 ring 文件。&lt;/p&gt;

&lt;p&gt;将新生成的 ring 文件放到每一个服务器的 &lt;code&gt;/etc/swift&lt;/code&gt; 目录下。&lt;/p&gt;

&lt;p&gt;swift 的各个组件程序会定期重新读取 rings 文件。&lt;/p&gt;

&lt;h3 id=&#34;一些需要注意的地方&#34;&gt;一些需要注意的地方&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;服务器时间必须一致，不一致的话会出现问题。测试中有一台服务器比其他的慢了2小时，结果向这台 proxy  上传文件，返回成功，但是其实并没有上传成功，可能是由于时间原因，在其他机器看来这个文件已经被删除掉了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;restful-api-及测试&#34;&gt;RESTful API 及测试&lt;/h3&gt;

&lt;p&gt;swift 可以通过 swift-proxy 提供的 RESTful API 来进行操作。&lt;/p&gt;

&lt;p&gt;另外一种方法就是使用 &lt;code&gt;swift&lt;/code&gt; 程序来进行增删查改的操作，可以实现和 RESTful API 相同的功能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;所有的操作都需要先获取一个 auth-token，之后的所有操作都需要在 header 中附加上 X-Auth-Token 字段的信息进行权限认证。有一定时效性，过期后需要再次获取。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;获取-x-storage-url-和-x-auth-token&#34;&gt;获取 X-Storage-Url 和 X-Auth-Token&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/auth/v1.0 -v -H &#39;X-Storage-User: test:tester&#39; -H &#39;X-Storage-Pass: testing&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的用户和密码是在 &lt;code&gt;proxy-server.conf&lt;/code&gt; 中配置的。&lt;/p&gt;

&lt;p&gt;返回结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt; HTTP/1.1 200 OK
&amp;lt; X-Storage-Url: http://127.0.0.1:8080/v1/AUTH_test
&amp;lt; X-Auth-Token: AUTH_tk039a65cb62594b319faea9dc492039a2
&amp;lt; Content-Type: text/html; charset=UTF-8
&amp;lt; X-Storage-Token: AUTH_tk039a65cb62594b319faea9dc492039a2
&amp;lt; X-Trans-Id: tx7bcd450378d84b56b1482-005745b5c8
&amp;lt; Content-Length: 0
&amp;lt; Date: Wed, 25 May 2016 14:25:12 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看账户信息&#34;&gt;查看账户信息&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/v1/AUTH_test -v -H &#39;X-Auth-Token: AUTH_tk039a65cb62594b319faea9dc492039a2&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt; HTTP/1.1 200 OK
&amp;lt; Content-Length: 5
&amp;lt; X-Account-Object-Count: 1
&amp;lt; X-Account-Storage-Policy-Policy-0-Bytes-Used: 4
&amp;lt; X-Account-Storage-Policy-Policy-0-Container-Count: 1
&amp;lt; X-Timestamp: 1464106581.68979
&amp;lt; X-Account-Storage-Policy-Policy-0-Object-Count: 1
&amp;lt; X-Account-Bytes-Used: 4
&amp;lt; X-Account-Container-Count: 1
&amp;lt; Content-Type: text/plain; charset=utf-8
&amp;lt; Accept-Ranges: bytes
&amp;lt; X-Trans-Id: tx59e9c2f1772349d684d04-005745b713
&amp;lt; Date: Wed, 25 May 2016 14:30:43 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;创建-container&#34;&gt;创建 container&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://127.0.0.1:8080/v1/AUTH_test/default -X PUT -H &amp;quot;X-Auth_Token: AUTH_tk039a65cb62594b319faea9dc492039a2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 test 用户下创建了一个名为 default 的 container。&lt;/p&gt;

&lt;h4 id=&#34;restful-api-总结&#34;&gt;RESTful API 总结&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;资源类型&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;URL&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;PUT&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;POST&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;DELETE&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;HEAD&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;账户&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取容器列表&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取账户元数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/container&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象列表&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;创建容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;更新容器元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;删除容器&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取容器元数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;/account/container/object&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象内容和元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;创建、更新或拷贝对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;更新对象元数据&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;删除对象&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;获取对象元数据&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;直接使用-swift-客户端程序进行操作&#34;&gt;直接使用 swift 客户端程序进行操作&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;-A&lt;/strong&gt; 参数指定 url，&lt;strong&gt;-U&lt;/strong&gt; 参数指定用户，&lt;strong&gt;-K&lt;/strong&gt; 参数指定密码。&lt;/p&gt;

&lt;h5 id=&#34;查看指定账户的-swift-存储信息&#34;&gt;查看指定账户的 swift 存储信息&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing stat
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;创建-container-1&#34;&gt;创建 container&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing post default
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看-test-用户的-container-列表&#34;&gt;查看 test 用户的 container 列表&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing list
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;上传object-文件-上传-test-cpp-文件到-default-容器中&#34;&gt;上传Object（文件），上传 test.cpp 文件到 default 容器中&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing upload default ./dd.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看容器中的内容&#34;&gt;查看容器中的内容&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing list default
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;下载object-文件&#34;&gt;下载Object（文件）&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing download default dd.cpp
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>搭建私有docker仓库</title>
          <link>http://blog.fatedier.com/2016/05/16/install-private-docker-registry</link>
          <pubDate>Mon, 16 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/05/16/install-private-docker-registry</guid>
          <description>

&lt;p&gt;docker 使用起来确实非常方便，易于部署，但是在国内如果要从 DockerHub 上下载镜像实在是一件非常吃力的事，而且公司内部环境使用或者搭建类似 kubernetes 集群的话就需要搭建一个私有的 docker 镜像仓库，方便在集群上快速部署 docker 服务。&lt;/p&gt;

&lt;h3 id=&#34;registry-镜像下载&#34;&gt;registry 镜像下载&lt;/h3&gt;

&lt;p&gt;直接下载官方提供的 docker 镜像&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker pull registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里有一点需要注意的比较坑的是官方的 &lt;code&gt;latest&lt;/code&gt; 的镜像指向的是 &lt;code&gt;0.9.1&lt;/code&gt; 版本，使用 python 开发的，已经被废弃了，新版本采用 go 开发，效率和安全方面都提升很多，所以需要手动指定最新的版本。&lt;/p&gt;

&lt;h3 id=&#34;启动-registry-容器&#34;&gt;启动 registry 容器&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker run -d --name registry -p 5000:5000 -v /opt/registry:/var/lib/registry registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;由于需要做目录映射，如果你的机器上开启了 &lt;strong&gt;SELINUX&lt;/strong&gt;，则使用如下命令：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker run -d --name registry -p 5000:5000 -v /opt/registry:/var/lib/registry:Z registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;否则在 docker 容器中可能没有操作此目录的权限，也可以临时关闭 &lt;strong&gt;SELINUX&lt;/strong&gt;，执行 &lt;code&gt;setenforce 0&lt;/code&gt;，永久关闭的话需要修改配置文件 &lt;code&gt;/etc/selinux/config&lt;/code&gt;，将 &lt;code&gt;SELINUX=enforcing&lt;/code&gt; 改为&lt;code&gt;SELINUX=disabled&lt;/code&gt;，并且重启系统。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-p 5000:5000&lt;/strong&gt;： 对外暴露 5000 端口用于提供服务&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-v  /opt/registry:/var/lib/registry&lt;/strong&gt;： 将宿主机的 &lt;code&gt;/opt/registry&lt;/code&gt; 目录映射到容器内的 &lt;code&gt;/var/lib/registry&lt;/code&gt;，这个目录用来存储 docker 的镜像文件，为了持久化存储，不然容器关闭后这些镜像文件会丢失。&lt;/p&gt;

&lt;p&gt;这里根据 registry 镜像的不同版本，存储镜像文件的目录可能并不是 &lt;code&gt;/var/lib/registry&lt;/code&gt;，&lt;code&gt;2.4&lt;/code&gt; 版本是 &lt;code&gt;/var/lib/registry&lt;/code&gt;，如果是其他版本可以查看具体的 Dockerfile 来确认。&lt;/p&gt;

&lt;h3 id=&#34;上传下载镜像&#34;&gt;上传下载镜像&lt;/h3&gt;

&lt;p&gt;由于 docker 的安全策略限制，如果要从私有的仓库上传下载镜像需要修改 docker 的启动参数，把我们自己搭建的 registry 的 ip 地址或者域名添加进来。&lt;/p&gt;

&lt;p&gt;centos7 上的配置文件位置为 &lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;设置 &lt;code&gt;INSECURE_REGISTRY=&#39;--insecure-registry 192.168.2.129:5000&#39;&lt;/code&gt;，重启 docker 服务，以后要和这个 registry 交互的机器都需要执行上述步骤。&lt;/p&gt;

&lt;p&gt;另外一个方法就是自己签一组证书，把 &lt;code&gt;ca.crt&lt;/code&gt; 拷贝到 &lt;code&gt;/etc/docker/certs.d/192.168.2.199:5000/ca.crt&lt;/code&gt; 就可以了，这样就不需要重启 docker 服务，这个方法目前还没试过，之后可以尝试一下。&lt;/p&gt;

&lt;h4 id=&#34;上传镜像&#34;&gt;上传镜像&lt;/h4&gt;

&lt;p&gt;给要上传的镜像打上 tag，修改前缀为我们的 registry 的 ip 和 port&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker tag centos 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker push 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;可以看到上传的镜像已经被存储在 /opt/registry 上了&lt;/p&gt;

&lt;h4 id=&#34;下载镜像&#34;&gt;下载镜像&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;docker pull 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;直接从内网环境下载镜像的速度相当快。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;Registry 的 API 也更新到了 V2 版本，可以通过 HTTP API 对私有仓库进行一些管理操作。具体的说明可以参考 github 上的项目文档 &lt;a href=&#34;https://github.com/docker/distribution。&#34;&gt;https://github.com/docker/distribution。&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>go程序中dns解析无法使用所有域名服务器</title>
          <link>http://blog.fatedier.com/2016/04/27/go-program-does-not-use-all-nameservers-for-dns-lookups</link>
          <pubDate>Wed, 27 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/04/27/go-program-does-not-use-all-nameservers-for-dns-lookups</guid>
          <description>

&lt;p&gt;最近线上服务经常会出现异常，从错误日志来看是因为域名解析失败导致的，我们在 /etc/resolv.conf 中配置了多个域名服务器，第一个是内网的，用于解析内网域名，如果是外网域名，则会通过其他的域名服务器进行解析，按道理来说应该不会有问题，但是最近却频繁发生这样的故障，为了彻底解决问题，特意研究了一下 golang 中进行 dns 查询的源码并最终解决了此问题。&lt;/p&gt;

&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;

&lt;h4 id=&#34;nameserver-配置&#34;&gt;nameserver 配置&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;/etc/resolv.conf&lt;/code&gt; 中配置了多个 nameserver&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nameserver 10.10.100.3
nameserver 114.114.114.114
nameserver 8.8.8.8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;10.10.100.3&lt;/code&gt; 用于解析内网域名，外网域名通过 &lt;code&gt;114.114.114.114&lt;/code&gt; 或者 &lt;code&gt;8.8.8.8&lt;/code&gt; 来解析。&lt;/p&gt;

&lt;h4 id=&#34;测试代码&#34;&gt;测试代码&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main

import (
    &amp;quot;net&amp;quot;
    &amp;quot;fmt&amp;quot;
)

func main() {
    hostname := &amp;quot;www.baidu.com&amp;quot;
    addrs, err := net.LookupHost(hostname)
    if err != nil {
        fmt.Printf(&amp;quot;lookup host error: %v\n&amp;quot;, err)
    } else {
        fmt.Printf(&amp;quot;addrs: %v&amp;quot;, addrs)
    }   
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;结果&#34;&gt;结果&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lookup host error: lookup www.baidu.com on 10.10.100.3:53: no such host
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 go1.5 版本进行编译，发现程序并没有按照预想的过程来解析，通过 &lt;code&gt;10.10.100.3&lt;/code&gt; 无法解析后就直接返回了错误信息。&lt;/p&gt;

&lt;p&gt;而使用 go1.4 版本编译运行后，确得到了正确的结果。&lt;/p&gt;

&lt;h3 id=&#34;调试标准库的方法&#34;&gt;调试标准库的方法&lt;/h3&gt;

&lt;p&gt;调试 golang 的标准库非常简单，先找到标准库源码的存放位置，然后将要修改的文件备份一份，之后直接在其中添加输出语句，大部分可以 &lt;code&gt;import &amp;quot;fmt&amp;quot;&lt;/code&gt; 后使用 &lt;code&gt;fmt.Printf&lt;/code&gt; 函数进行输出，有的包中需要使用其他方式，避免循环引用，这里不详述，因为我们要改的 &lt;code&gt;net&lt;/code&gt; 包并不涉及这个问题，注意调试完之后将标准库的文件恢复。&lt;/p&gt;

&lt;h4 id=&#34;查找标准库所在的目录&#34;&gt;查找标准库所在的目录&lt;/h4&gt;

&lt;p&gt;执行 &lt;code&gt;go env&lt;/code&gt; 查看 go 的环境变量如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GOARCH=&amp;quot;amd64&amp;quot;
GOBIN=&amp;quot;&amp;quot;GOCHAR=&amp;quot;6&amp;quot;GOEXE=&amp;quot;&amp;quot;GOHOSTARCH=&amp;quot;amd64&amp;quot;GOHOSTOS=&amp;quot;linux&amp;quot;GOOS=&amp;quot;linux&amp;quot;
GOPATH=&amp;quot;/home/wcl/go_projects&amp;quot;
GORACE=&amp;quot;&amp;quot;
GOROOT=&amp;quot;/usr/lib/golang&amp;quot;
GOTOOLDIR=&amp;quot;/usr/lib/golang/pkg/tool/linux_amd64&amp;quot;
CC=&amp;quot;gcc&amp;quot;
GOGCCFLAGS=&amp;quot;-fPIC -m64 -pthread -fmessage-length=0&amp;quot;
CXX=&amp;quot;g++&amp;quot;
CGO_ENABLED=&amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;GOROOT&lt;/strong&gt; 的值即是标准库所在的目录，&lt;code&gt;net&lt;/code&gt; 包的具体路径为 &lt;code&gt;/usr/lib/golang/src/net&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;go-1-4-与-1-5-版本中-dns-查询逻辑的不同&#34;&gt;go 1.4 与 1.5 版本中 dns 查询逻辑的不同&lt;/h3&gt;

&lt;p&gt;因为最近很多程序都是使用 &lt;strong&gt;go1.5&lt;/strong&gt; 版本进行编译的，所以理所当然查看了两个版本这部分源码的区别，还真的有所改变。&lt;/p&gt;

&lt;p&gt;标准库对外暴露的 dns 查询函数是 &lt;code&gt;func LookupHost(host string) (addrs []string, err error)&lt;/code&gt; &lt;strong&gt;(net/lookup.go)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个函数会调用实际处理函数 &lt;code&gt;lookupHost&lt;/code&gt; &lt;strong&gt;(net/lookup_unix.go)&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;cgo-与纯-go-实现的-dns-查询&#34;&gt;cgo 与纯 go 实现的 dns 查询&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;go1.4 版本源码&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;func lookupHost(host string) (addrs []string, err error) {
    addrs, err, ok := cgoLookupHost(host)
    if !ok {
        addrs, err = goLookupHost(host)
    }
    return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;go1.5 版本源码&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;func lookupHost(host string) (addrs []string, err error) {
    order := systemConf().hostLookupOrder(host)
    if order == hostLookupCgo {
        if addrs, err, ok := cgoLookupHost(host); ok {
            return addrs, err
        }
        // cgo not available (or netgo); fall back to Go&#39;s DNS resolver
        order = hostLookupFilesDNS
    }
    return goLookupHostOrder(host, order)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;可以明显的看到 1.4 的源码中默认使用 cgo 的方式进行 dns 查询&lt;/strong&gt;（这个函数最终会创建一个线程调用c的 getaddrinfo 函数来获取 dns 查询结果），如果查询失败则会再使用纯 go 实现的查询方式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;而在 1.5 的源码中，这一点有所改变，cgo 的方式不再是默认值，而是根据 &lt;code&gt;systemConf().hostLookupOrder(host)&lt;/code&gt; 的返回值来判断具体使用哪种方式&lt;/strong&gt;。这个函数定义在 &lt;strong&gt;net/conf.go&lt;/strong&gt; 中，稍微看了一下， 除非通过编译标志强制使用 cgo 方式或者在某些特定的系统上会使用 cgo 方式，其他时候都使用纯 go 实现的查询方式。&lt;/p&gt;

&lt;p&gt;cgo 的方式没有问题，看起来程序会并发地向 &lt;code&gt;/etc/resolv.conf&lt;/code&gt; 中所有配置的域名服务器发送 dns 解析请求，然后将最先成功响应的结果返回。&lt;/p&gt;

&lt;h4 id=&#34;纯-go-实现的-dns-查询分析&#34;&gt;纯 go 实现的 dns 查询分析&lt;/h4&gt;

&lt;p&gt;问题就出在纯 go 实现的查询上，主要看一下 go1.5 的实现。&lt;/p&gt;

&lt;p&gt;函数调用逻辑如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;LookupHost (net/lookup.go)
    lookupHost  (net/lookup_unix.go)
        goLookupHostOrder  (net/dnsclient_unix.go)
            goLookupIPOrder  (net/dnsclient_unix.go)
                tryOneName   (net/dnsclient_unix.go)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;大部分实现代码在 &lt;code&gt;net/dnsclient_unix.go&lt;/code&gt; 这个文件中。&lt;/p&gt;

&lt;p&gt;重点看一下 &lt;code&gt;tryOneName&lt;/code&gt; 这个函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;func tryOneName(cfg *dnsConfig, name string, qtype uint16) (string, []dnsRR, error) {
    if len(cfg.servers) == 0 {
        return &amp;quot;&amp;quot;, nil, &amp;amp;DNSError{Err: &amp;quot;no DNS servers&amp;quot;, Name: name}
    }
    if len(name) &amp;gt;= 256 {
        return &amp;quot;&amp;quot;, nil, &amp;amp;DNSError{Err: &amp;quot;DNS name too long&amp;quot;, Name: name}
    }
    timeout := time.Duration(cfg.timeout) * time.Second
    var lastErr error
    for i := 0; i &amp;lt; cfg.attempts; i++ {
        for _, server := range cfg.servers {
            server = JoinHostPort(server, &amp;quot;53&amp;quot;)
            msg, err := exchange(server, name, qtype, timeout)
            if err != nil {
                lastErr = &amp;amp;DNSError{
                    Err:    err.Error(),
                    Name:   name,
                    Server: server,
                }
                if nerr, ok := err.(Error); ok &amp;amp;&amp;amp; nerr.Timeout() {
                    lastErr.(*DNSError).IsTimeout = true
                }
                continue
            }
            cname, rrs, err := answer(name, server, msg, qtype)
            if err == nil || msg.rcode == dnsRcodeSuccess || msg.rcode == dnsRcodeNameError &amp;amp;&amp;amp; msg.recursion_available {
                return cname, rrs, err
            }
            lastErr = err
        }
    }
    return &amp;quot;&amp;quot;, nil, lastErr
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一层 for 循环是尝试的次数，第二层 for 循环是遍历 &lt;code&gt;/etc/resolv.conf&lt;/code&gt; 中配置的所有域名服务器，&lt;code&gt;exchange&lt;/code&gt; 函数是发送 dns 查询请求并将响应结果解析到 &lt;code&gt;msg&lt;/code&gt; 变量中返回，初看到这里，觉得实现是没问题的，顺序向每一个域名服务器发送 dns 查询请求，如果成功就返回，如果失败就尝试下一个。&lt;/p&gt;

&lt;p&gt;问题出现在判断是否成功的那一行代码 &lt;code&gt;if err == nil || msg.rcode == dnsRcodeSuccess || msg.rcode == dnsRcodeNameError &amp;amp;&amp;amp; msg.recursion_available&lt;/code&gt;，这里的意思是如果 dns 查询成功，或者出错了但是对方支持递归查询的话，就直接返回，不继续请求下一个域名服务器。如果对方支持递归查询但是仍然没有查到的话，说明上级服务器也没有这个域名的记录，没有必要继续往下查。（这个逻辑在 go1.6 版本中被修改了，出错了以后不再判断是否支持递归查询，仍然尝试向下一个域名服务器发送请求）&lt;/p&gt;

&lt;p&gt;&lt;code&gt;msg.rcode&lt;/code&gt; 这个值很重要，是问题的关键。&lt;/p&gt;

&lt;h3 id=&#34;dns-查询协议格式&#34;&gt;dns 查询协议格式&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-27-go-program-does-not-use-all-nameservers-for-dns-lookups-dns-query-package.png&#34; alt=&#34;dns-query-package&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们只需要关注首部的12字节。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ID:占16位，2个字节。此报文的编号，由客户端指定。DNS回复时带上此标识，以指示处理的对应请应请求。&lt;/li&gt;
&lt;li&gt;QR:占1位，1/8字节。0代表查询，1代表DNS回复&lt;/li&gt;
&lt;li&gt;Opcode:占4位，1/2字节。指示查询种类：0:标准查询；1:反向查询；2:服务器状态查询；3-15:未使用。&lt;/li&gt;
&lt;li&gt;AA:占1位，1/8字节。是否权威回复。&lt;/li&gt;
&lt;li&gt;TC:占1位，1/8字节。因为一个UDP报文为512字节，所以该位指示是否截掉超过的部分。&lt;/li&gt;
&lt;li&gt;RD:占1位，1/8字节。此位在查询中指定，回复时相同。设置为1指示服务器进行递归查询。&lt;/li&gt;
&lt;li&gt;RA:占1位，1/8字节。由DNS回复返回指定，说明DNS服务器是否支持递归查询。&lt;/li&gt;
&lt;li&gt;Z:占3位，3/8字节。保留字段，必须设置为0。&lt;/li&gt;
&lt;li&gt;RCODE:占4位，1/2字节。由回复时指定的返回码：0:无差错；1:格式错；2:DNS出错；3:域名不存在；4:DNS不支持这类查询；5:DNS拒绝查询；6-15:保留字段。　&lt;/li&gt;
&lt;li&gt;QDCOUNT:占16位，2字节。一个无符号数指示查询记录的个数。&lt;/li&gt;
&lt;li&gt;ANCOUNT:占16位，2字节。一个无符号数指明回复记录的个数。&lt;/li&gt;
&lt;li&gt;NSCOUNT:占16位，2字节。一个无符号数指明权威记录的个数。&lt;/li&gt;
&lt;li&gt;ARCOUNT:占16位，2字节。一个无符号数指明格外记录的个数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中 &lt;strong&gt;RCODE&lt;/strong&gt; 是回复时用于判断查询结果是否成功的，对应前面的 &lt;code&gt;msg.rcode&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;bind-的-dns-回复问题&#34;&gt;bind 的 dns 回复问题&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;10.10.100.3&lt;/code&gt; 上是使用 &lt;strong&gt;bind&lt;/strong&gt; 搭建的本地域名服务器。&lt;/p&gt;

&lt;p&gt;使用 &lt;code&gt;dig @10.10.100.3 www.baidu.com&lt;/code&gt; 命令查看解析结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.8.2rc1-RedHat-9.8.2-0.23.rc1.el6_5.1 &amp;lt;&amp;lt;&amp;gt;&amp;gt; @10.10.100.3 www.baidu.com ;
(1 server found) 
;; global options: +cmd 
;; Got answer: 
;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 55909 
;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 13, ADDITIONAL: 0 
;; WARNING: recursion requested but not available 

;; QUESTION SECTION: 
;www.baidu.com.         IN  A 

;; AUTHORITY SECTION: 
.           518400  IN  NS  H.ROOT-SERVERS.NET.  
.           518400  IN  NS  K.ROOT-SERVERS.NET.  
.           518400  IN  NS  C.ROOT-SERVERS.NET.  
.           518400  IN  NS  A.ROOT-SERVERS.NET.  
.           518400  IN  NS  B.ROOT-SERVERS.NET.  
.           518400  IN  NS  F.ROOT-SERVERS.NET.  
.           518400  IN  NS  L.ROOT-SERVERS.NET.  
.           518400  IN  NS  D.ROOT-SERVERS.NET.  
.           518400  IN  NS  I.ROOT-SERVERS.NET.  
.           518400  IN  NS  E.ROOT-SERVERS.NET.  
.           518400  IN  NS  G.ROOT-SERVERS.NET.  
.           518400  IN  NS  M.ROOT-SERVERS.NET.  
.           518400  IN  NS  J.ROOT-SERVERS.NET.  

;; Query time: 1 msec 
;; SERVER: 10.10.100.3#53(10.10.100.3) 
;; WHEN: Wed Apr 27 17:35:15 2016 
;; MSG SIZE  rcvd: 242 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;bind&lt;/strong&gt; 并没有返回 &lt;code&gt;www.baidu.com&lt;/code&gt; 的 A 记录，而是返回了13个根域名服务器的地址，并且 &lt;strong&gt;status&lt;/strong&gt; 的状态是 &lt;strong&gt;NOERROR&lt;/strong&gt;（这个值就是前述的 &lt;strong&gt;RCODE&lt;/strong&gt;，这里返回0表示没有错误)，问题就在这里，没有查到 A 记录还返回 &lt;code&gt;RCODE=0&lt;/code&gt;，回顾一下上面 go 代码中的判断条件&lt;/p&gt;

&lt;p&gt;&lt;code&gt;if err == nil || msg.rcode == dnsRcodeSuccess || msg.rcode == dnsRcodeNameError &amp;amp;&amp;amp; msg.recursion_available&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果返回的 &lt;strong&gt;RCODE&lt;/strong&gt; 值为 0，则直接退出，不继续尝试后面的域名服务器，从而导致了域名解析失败。&lt;/p&gt;

&lt;h3 id=&#34;解决方案&#34;&gt;解决方案&lt;/h3&gt;

&lt;h4 id=&#34;仍然使用-go1-4-版本进行编译&#34;&gt;仍然使用 go1.4 版本进行编译&lt;/h4&gt;

&lt;p&gt;不推荐这么做，毕竟升级后在 gc 以及很多其他方面都有优化。&lt;/p&gt;

&lt;h4 id=&#34;使用-go1-5-及以上版本编译但是通过环境变量强制使用-cgo-的-dns-查询方式&#34;&gt;使用 go1.5 及以上版本编译但是通过环境变量强制使用 cgo 的 dns 查询方式&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;export GODEBUG=netdns=cgo go build&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;使用 cgo 的方式会在每一次调用时创建一个线程，在并发量较大时可能会对系统资源造成一定影响。而且需要每一个使用 go 编写的程序编译时都加上此标志，较为繁琐。&lt;/p&gt;

&lt;h4 id=&#34;修改-bind-的配置文件&#34;&gt;修改 bind 的配置文件&lt;/h4&gt;

&lt;p&gt;在 &lt;strong&gt;bind&lt;/strong&gt; 中彻底关闭对递归查询的支持也可以解决此问题，但是由于对 &lt;strong&gt;bind&lt;/strong&gt; 不是很熟悉，具体是什么原因导致没有查到 &lt;strong&gt;A 记录&lt;/strong&gt;但仍然返回 &lt;strong&gt;NOERROR&lt;/strong&gt; 不是很清楚，猜测可能和递归转发的查询方式有关，有可能 &lt;strong&gt;bind&lt;/strong&gt; 认为返回了根域名服务器的地址，&lt;strong&gt;client&lt;/strong&gt; 可以去这些地址上查，所以该次请求并不算做出错。&lt;/p&gt;

&lt;p&gt;修改配置文件加上以下内容以后，再次查询时会返回 &lt;strong&gt;RCODE=5&lt;/strong&gt;，拒绝递归查询，这样可以达到我们的目的，查询非内网域名时通过其他域名服务器查询&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;recursion no;
allow-query-cache { none; };
allow-recursion { none; };
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>利用docker搭建gitlab及持续集成模块</title>
          <link>http://blog.fatedier.com/2016/04/05/install-gitlab-supporting-ci-with-docker</link>
          <pubDate>Tue, 05 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/04/05/install-gitlab-supporting-ci-with-docker</guid>
          <description>

&lt;p&gt;版本控制的重要性应该是毋庸置疑了，git 作为现在最流行的版本控制工具，各种规模的公司都在用。通常开源项目都会放在 github 上，基础功能是免费的，私有项目收费。对于一个小团队来说，gitlab 就是另外一个替代品，可以用来搭建自己私有的git服务器。&lt;/p&gt;

&lt;h3 id=&#34;为什么需要版本控制和持续继承&#34;&gt;为什么需要版本控制和持续继承？&lt;/h3&gt;

&lt;p&gt;经常听到很多程序员说自己没有时间写测试用例，但其实很多人的时间都花在了手动测试，修复bug，调试程序上。如果写好测试用例，每次提交代码后都自动进行编译，然后将测试用例全部跑一遍，如果测试失败能够获取到足够的反馈信息，这样避免了重复构建测试环境，手动运行测试用例等低效率的工作，而这就是持续集成的好处。&lt;/p&gt;

&lt;h3 id=&#34;准备工作&#34;&gt;准备工作&lt;/h3&gt;

&lt;h4 id=&#34;docker-环境&#34;&gt;docker 环境&lt;/h4&gt;

&lt;p&gt;安装 &lt;code&gt;docker&lt;/code&gt; 环境，&lt;code&gt;centos&lt;/code&gt; 的话可以使用 &lt;code&gt;sudo yum install -y docker&lt;/code&gt; 直接安装&lt;/p&gt;

&lt;p&gt;之后启动 &lt;code&gt;docker&lt;/code&gt;，&lt;code&gt;sudo service docker start&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;docker-镜像加速&#34;&gt;docker 镜像加速&lt;/h4&gt;

&lt;p&gt;由于国内的网络环境过于恶劣，多次尝试从 &lt;a href=&#34;https://gitlab.com/&#34;&gt;gitlab&lt;/a&gt; 官网下载源码安装包未果，之后发现  gitlab 还提供 docker 镜像，这样不仅部署方便，利用国内一些云服务商提供的镜像加速功能，可以加速 docker 镜像的下载。&lt;/p&gt;

&lt;p&gt;推荐 daocloud 的镜像加速服务，&lt;a href=&#34;https://dashboard.daocloud.io/mirror&#34;&gt;https://dashboard.daocloud.io/mirror&lt;/a&gt;，安装之后，使用 &lt;code&gt;dao pull&lt;/code&gt; 替代 &lt;code&gt;docker pull&lt;/code&gt; 即可。&lt;/p&gt;

&lt;h4 id=&#34;下载相关docker镜像&#34;&gt;下载相关docker镜像&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;gitlab/gitlab-ce:latest （gitlab 的 docker镜像）&lt;/li&gt;
&lt;li&gt;gitlab/gitlab-runner:latest （用于持续集成，构建测试环境）&lt;/li&gt;
&lt;li&gt;golang:1.5 （golang基础环境，用于编译代码，运行测试用例）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;启动-gitlab&#34;&gt;启动 gitlab&lt;/h3&gt;

&lt;p&gt;具体的官方说明文档：&lt;a href=&#34;http://doc.gitlab.com/omnibus/docker/README.html&#34;&gt;http://doc.gitlab.com/omnibus/docker/README.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;启动 &lt;code&gt;gitlab&lt;/code&gt; 就是启动相应的 &lt;code&gt;docker&lt;/code&gt; 镜像，设置好相关配置参数，命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --detach \
    --hostname x.x.x.x \
    --publish 7000:443 --publish 80:80 --publish 7002:22 \
    --name gitlab \
    --restart always \
    --volume /srv/gitlab/config:/etc/gitlab \
    --volume /srv/gitlab/logs:/var/log/gitlab \
    --volume /srv/gitlab/data:/var/opt/gitlab \
    gitlab/gitlab-ce:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你的机器开启了 &lt;code&gt;SELINUX&lt;/code&gt;，需要使用如下的命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --detach \
    --hostname x.x.x.x \
    --publish 7000:443 --publish 80:80 --publish 7002:22 \
    --name gitlab \
    --restart always \
    --volume /srv/gitlab/config:/etc/gitlab:Z \
    --volume /srv/gitlab/logs:/var/log/gitlab:Z \
    --volume /srv/gitlab/data:/var/opt/gitlab:Z \
    gitlab/gitlab-ce:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;hostname&lt;/code&gt; 可以是gitlab服务器的ip，也可以是绑定的域名，80端口需要映射到宿主机的80端口，因为之后 &lt;code&gt;github-ci-runner&lt;/code&gt; 会从这个端口下载测试源码。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/srv/gitlab&lt;/code&gt; 是用于持久化 docker 容器中产生的数据，例如 &lt;strong&gt;redis&lt;/strong&gt;，&lt;strong&gt;postgresql&lt;/strong&gt; 等等，gitlab 的docker 镜像中已经内置了这些服务。&lt;/p&gt;

&lt;p&gt;启动成功后，可以通过浏览器访问80端口来使用 gitlab 了，可能是由于我的测试服务器配置较低，等待约2分钟后才能访问。&lt;/p&gt;

&lt;p&gt;初始帐号和密码为 &lt;code&gt;root&lt;/code&gt;  &lt;code&gt;5iveL!fe&lt;/code&gt;，第一次登录成功后需要修改密码。&lt;/p&gt;

&lt;p&gt;gitlab 的具体使用文档比较多，这里就不详细介绍了。&lt;/p&gt;

&lt;h3 id=&#34;创建测试项目&#34;&gt;创建测试项目&lt;/h3&gt;

&lt;p&gt;简单创建一个 &lt;code&gt;test&lt;/code&gt; 项目，先不要提交到 gitlab 仓库。&lt;/p&gt;

&lt;p&gt;包含一个 &lt;code&gt;a.go&lt;/code&gt; 文件，文件内容如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import fmt 

func main() {
    fmt.Printf(&amp;quot;aaa\n&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;可以看到 import 包名没有加双引号，显然编译时就会出错。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;添加-gitlab-ci-yml-文件&#34;&gt;添加 .gitlab-ci.yml 文件&lt;/h4&gt;

&lt;p&gt;配置文件详细内容请参考 &lt;a href=&#34;http://doc.gitlab.com/ce/ci/yaml/README.html&#34;&gt;http://doc.gitlab.com/ce/ci/yaml/README.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里简单写一下，仅仅用于测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;image: golang:1.5

job1:
    script:
        - go build a.go
        - ./a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;image&lt;/code&gt; 表示使用 &lt;code&gt;golang:1.5&lt;/code&gt; 的 docker 镜像来部署编译和测试代码，我们之前已经下好了。&lt;/p&gt;

&lt;p&gt;测试命令有两条，&lt;code&gt;go build a.go&lt;/code&gt; 编译源码， &lt;code&gt;./a&lt;/code&gt; 执行编译后的程序。&lt;/p&gt;

&lt;h3 id=&#34;获取-runner-registration-token&#34;&gt;获取 Runner registration token&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-registration-token.png&#34; alt=&#34;registration-token&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;gitlab&lt;/code&gt; 的管理员配置界面，左边有一个 &lt;code&gt;Runners&lt;/code&gt;，点进去之后可以看到有一个 &lt;code&gt;Registration token&lt;/code&gt;，这个是用于之后创建的 &lt;code&gt;runner&lt;/code&gt; 服务与 &lt;code&gt;gitlab&lt;/code&gt; 通信的时候认证使用。&lt;/p&gt;

&lt;p&gt;例如图中的 &lt;code&gt;Registration token&lt;/code&gt; 为 &lt;code&gt;XKZmVj9t8j4xj1e5k34N&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;启动-runner&#34;&gt;启动 Runner&lt;/h3&gt;

&lt;p&gt;Runner 官方详细说明文档： &lt;a href=&#34;https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/install/docker.md&#34;&gt;https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/install/docker.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Runner&lt;/code&gt;其实就是用于编译和管理测试环境的服务，当 &lt;code&gt;gitlab&lt;/code&gt; 上的项目有 &lt;code&gt;commit&lt;/code&gt; 或 &lt;code&gt;merge&lt;/code&gt; 的时候，&lt;code&gt;Runner&lt;/code&gt; 可以 hook 到相关信息，然后从 &lt;code&gt;gitlab&lt;/code&gt; 上拉取代码，利用 &lt;code&gt;docker&lt;/code&gt; 创建一个新的测试环境，之后执行 &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; 文件中预先配置好的命令。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --name gitlab-runner --restart always \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v /srv/gitlab-runner/config:/etc/gitlab-runner \
      gitlab/gitlab-runner:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你的机器开启了 SELINUX，需要使用如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --name gitlab-runner --restart always \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v /srv/gitlab-runner/config:/etc/gitlab-runner:Z \
      gitlab/gitlab-runner:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;关联-gitlab&#34;&gt;关联 gitlab&lt;/h4&gt;

&lt;p&gt;启动成功后的 &lt;code&gt;Runner&lt;/code&gt; 需要在 &lt;code&gt;gitlab&lt;/code&gt; 上注册，通过在 &lt;code&gt;Runner&lt;/code&gt; 上执行注册命令，会调用 &lt;code&gt;gitlab&lt;/code&gt; 的相关接口注册。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -it gitlab-runner gitlab-runner register

Please enter the gitlab-ci coordinator URL (e.g. [https://gitlab.com/ci](https://gitlab.com/ci) )
[https://gitlab.com/ci](https://gitlab.com/ci)（这里的gitlab.com替换成之前启动gitlab时填写的 hostname）

Please enter the gitlab-ci token for this runner
xxx（填写获取到的 runner registration token）

Please enter the gitlab-ci description for this runner
my
INFO[0034] fcf5c619 Registering runner... succeeded

Please enter the executor: shell, docker, docker-ssh, ssh?
docker

Please enter the Docker image (eg. ruby:2.1):
golang:1.5
INFO[0037] Runner registered successfully. Feel free to start it, but if it&#39;s
running already the config should be automatically reloaded!
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试&#34;&gt;测试&lt;/h3&gt;

&lt;p&gt;利用 &lt;code&gt;docker&lt;/code&gt; 来搭建这套环境还是非常简单的。&lt;/p&gt;

&lt;p&gt;接着提交我们之前创建的两个文件，&lt;code&gt;a.go&lt;/code&gt; 和 &lt;code&gt;.gitlab-ci.yml&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;访问 &lt;code&gt;gitlab&lt;/code&gt; 查看 &lt;code&gt;build&lt;/code&gt; 的结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-commit.png&#34; alt=&#34;test-commit&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到提交记录右边有一个红叉，表示测试未通过，点击红叉，可以看到测试的摘要信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-info.png&#34; alt=&#34;test-info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;继续点 红色的 &lt;code&gt;failed&lt;/code&gt; 按钮就可以看到详细的测试信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-deatil.png&#34; alt=&#34;test-deatil&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从 &lt;code&gt;Runner&lt;/code&gt; 测试过程的输出信息可以看出来，&lt;code&gt;Runner&lt;/code&gt; 先 &lt;code&gt;pull&lt;/code&gt; 我们指定的 &lt;code&gt;docker&lt;/code&gt; 镜像，这里是 &lt;code&gt;golang:1.5&lt;/code&gt;，之后 &lt;code&gt;git clone&lt;/code&gt; 代码到测试环境，然后开始执行测试命令，在执行 &lt;code&gt;go build a.go&lt;/code&gt; 的时候出现了错误，并且显示了错误信息。&lt;/p&gt;

&lt;p&gt;将错误的代码修改后再次提交&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
)

func main() {
    fmt.Printf(&amp;quot;aaa\n&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到能够通过测试了，执行程序后的输出 &lt;code&gt;aaa&lt;/code&gt; 也能够看到。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-commit-all.png&#34; alt=&#34;test-commit-all&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-succ-detail.png&#34; alt=&#34;test-succ-detail&#34; /&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>简记用sed对文件执行批量替换字符串的方法</title>
          <link>http://blog.fatedier.com/2016/03/25/using-sed-to-batch-replace-strings-in-files</link>
          <pubDate>Fri, 25 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/03/25/using-sed-to-batch-replace-strings-in-files</guid>
          <description>

&lt;p&gt;每次要进行一些批量的文本处理，例如 sed, awk 处理数据或者涉及到正则表达式的时候，都需要临时去再查一遍资料，看一下怎么用。这里简要记录一下对大量文件进行正则匹配后批量替换文本的方法，方便以后要用的时候回顾一下。&lt;/p&gt;

&lt;p&gt;因为 blog 的图片迁到了七牛云上（提供CDN加速服务），原来的图片链接必然要替换成七牛云提供的二级域名，在 markdown 文件中有很多图片的标签，也不可能一个一个手动改，最好是能一个命令下去直接全部修改完毕并且以后也可以很轻松地改成其他域名。&lt;/p&gt;

&lt;p&gt;执行的命令如下：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sed -i &amp;quot;s?](.*|pic|?](http://xxx.clouddn.com|pic|?g&amp;quot; `grep &amp;quot;|pic|&amp;quot; -rl ./`&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：本文中所有的 &lt;code&gt;|pic|&lt;/code&gt; 其实是 &lt;code&gt;/pic/&lt;/code&gt;，这样是为了避免被误替换。也可以通过 &lt;code&gt;grep -v&lt;/code&gt; 来手动指定不替换的文件。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;markdown 中的图片标签一般的格式是 &lt;code&gt;![label](http://www.xxx.com/a.jpg)&lt;/code&gt;，我的图片链接则是都会有一个 &lt;code&gt;pic&lt;/code&gt; 的目录前缀。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;grep&#34;&gt;grep&lt;/h4&gt;

&lt;p&gt;先看后面，&lt;code&gt;grep &amp;quot;|pic|&amp;quot; -rl ./&lt;/code&gt; 用于递归查找所有含有 &lt;code&gt;|pic|&lt;/code&gt; 这个字符串的文件所在路径的路径名，按行显示。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-r&lt;/code&gt; 参数表示会对目录进行递归查找。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-l&lt;/code&gt; 参数会输出匹配的文件名&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;sed&#34;&gt;sed&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;sed&lt;/strong&gt; 和 &lt;strong&gt;awk&lt;/strong&gt; 都是文本处理的利器。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sed&lt;/code&gt; 进行文本替换的常用的格式是 &lt;code&gt;sed &amp;quot;s/aa/bb/g&amp;quot; ./testfile&lt;/code&gt;，表示将文件中所有的 &lt;strong&gt;aa&lt;/strong&gt; 替换成 &lt;strong&gt;bb&lt;/strong&gt;， 最后的 &lt;code&gt;g&lt;/code&gt; 表示作用域是全局。&lt;/p&gt;

&lt;p&gt;这里分隔符用的 &lt;code&gt;/&lt;/code&gt;，也可以换成其他符号，比如上面我用的是 &lt;code&gt;?&lt;/code&gt;，只要保证这三个地方的符号一致并且没有歧义即可。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;](.*|pic|&lt;/code&gt; 是一个正则匹配， &lt;code&gt;.&lt;/code&gt; 表示匹配任意一个字符，&lt;code&gt;*&lt;/code&gt; 表示匹配0个或多个前面的字符，这里两个合起来就是匹配任意字符串。完整的意思就是匹配以 &lt;code&gt;](&lt;/code&gt; 开头，以 &lt;code&gt;|pic|&lt;/code&gt; 结尾的任意字符串。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;](http://xxx.clouddn.com|pic|&lt;/code&gt; 是替换后的字符串。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-i&lt;/code&gt; 表示将替换后的结果写入文件中，而不是直接输出。&lt;/p&gt;

&lt;h4 id=&#34;查看修改结果&#34;&gt;查看修改结果&lt;/h4&gt;

&lt;p&gt;一开始不确定修改是否正确最好不要给予使用 &lt;code&gt;-i&lt;/code&gt; 参数将修改后的结果写入文件，可以将上面的命令换成如下的内容来检查是否替换正确：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sed -n &amp;quot;s?](.*|pic|?](http://xxx.clouddn.com|pic|?gp&amp;quot; `grep &amp;quot;|pic|&amp;quot; -rl ./`&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;-n&lt;/code&gt; 表示静默模式，如果有输出内容的话，不会输出整个文件的内容，而仅仅是匹配的内容。&lt;/p&gt;

&lt;p&gt;后面的 &lt;code&gt;gp&lt;/code&gt;，&lt;code&gt;g&lt;/code&gt; 前面说过是表示作用域是全局，&lt;code&gt;p&lt;/code&gt; 表示会输出匹配的内容。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OpenTSDB部署与使用</title>
          <link>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb</link>
          <pubDate>Sat, 12 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb</guid>
          <description>

&lt;p&gt;OpenTSDB 是基于 HBase 存储时间序列数据的一个开源数据库，对于存储监控系统采集的数据来说非常合适，不仅在写入查询上有很高的效率，而且节省存储空间。&lt;/p&gt;

&lt;h3 id=&#34;安装-hbase&#34;&gt;安装 HBase&lt;/h3&gt;

&lt;p&gt;因为 OpenTSDB 的后端存储使用的是 HBase，所以我们需要先安装 HBase。&lt;/p&gt;

&lt;p&gt;参考文档： &lt;a href=&#34;https://hbase.apache.org/book.html#quickstart&#34;&gt;Quick Start - Standalone HBase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里简单搭建了一个&lt;strong&gt;单机&lt;/strong&gt;的 HBase 环境：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;安装 JDK 环境，centos 上可以直接通过 yum 安装。&lt;/li&gt;
&lt;li&gt;下载 HBase，&lt;a href=&#34;http://apache.fayea.com/hbase/stable&#34;&gt;http://apache.fayea.com/hbase/stable&lt;/a&gt;，这里我们选择下载 stable 的 1.1.3 版本，文件名为 &lt;code&gt;hbase-1.1.3-bin.tar.gz&lt;/code&gt;，解压到任意目录。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-env.sh&lt;/code&gt; ，设置  &lt;code&gt;JAVA_HOME=/usr&lt;/code&gt;，这个是 &lt;code&gt;/bin/java&lt;/code&gt; 所在的目录，通过 &lt;code&gt;which java&lt;/code&gt; 查看。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-site.xml&lt;/code&gt;， 设置 hbase 的数据存储目录以及 zookeeper 的数据存储目录，默认会放到 &lt;code&gt;/tmp&lt;/code&gt; 目录下，这个目录机器重启后会清空，所以需要更改目录。&lt;/li&gt;
&lt;li&gt;执行 &lt;code&gt;bin/start-hbase.sh&lt;/code&gt; 启动 HBase，之后可以通过 &lt;code&gt;jps&lt;/code&gt; 命令来查看 HMaster 进程是否启动成功。 &lt;code&gt;bin/stop-hbase.sh&lt;/code&gt; 用于关闭 HBase。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;conf/hbase-site.xml&lt;/code&gt; 的配置示例如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/testuser/hbase&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/testuser/zookeeper&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过命令行操作-hbase&#34;&gt;通过命令行操作 HBase&lt;/h3&gt;

&lt;p&gt;这里可以稍微熟悉一下 HBase 的操作，非必须。&lt;/p&gt;

&lt;h5 id=&#34;连接到-hbase&#34;&gt;连接到 HBase&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;./bin/hbase shell&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;创建一张表&#34;&gt;创建一张表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;create &#39;test&#39;, &#39;cf&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看表信息&#34;&gt;查看表信息&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;list &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;向表中插入数据&#34;&gt;向表中插入数据&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;
put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;
put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看表中所有数据&#34;&gt;查看表中所有数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;scan &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看指定行的数据&#34;&gt;查看指定行的数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;get &#39;test&#39;, &#39;row1&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;禁用指定表-删除表或修改表设置前需要先禁用该表&#34;&gt;禁用指定表（删除表或修改表设置前需要先禁用该表）&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;disable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;恢复指定表&#34;&gt;恢复指定表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;enable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;删除表&#34;&gt;删除表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;drop &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装opentsdb&#34;&gt;安装OpenTSDB&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://debugo.com/opentsdb/&#34;&gt;http://debugo.com/opentsdb/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&#34;&gt;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;直接从 github 上下载 OpenTSDB 的 &lt;a href=&#34;https://github.com/OpenTSDB/opentsdb&#34;&gt;release&lt;/a&gt; 版本的 RPM 包。安装 &lt;code&gt;yum localinstall opentsdb-2.2.0.noarch.rpm&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置完成后，我们通过下面命令在 HBase 中建立 opentsdb 所需的表。默认情况下 opentsdb 建立的 HBase 表启用了 lzo 压缩。需要开启 Hadoop 中的 lzo 压缩支持， 这里我们直接在下面脚本中把 COMPRESSION 的支持关闭。修改 &lt;code&gt;/usr/share/opentsdb/tools/create_table.sh&lt;/code&gt;，设置 &lt;code&gt;COMPRESSION=NONE&lt;/code&gt;，并且在文件开始处设置 HBase 所在目录， &lt;code&gt;HBASE_HOME=/home/xxx/hbase-1.1.3&lt;/code&gt;。之后执行该脚本，在 HBase 中创建相应的表。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;修改 OpenTSDB 的配置文件，&lt;code&gt;/etc/opentsdb/opentsdb.conf&lt;/code&gt;，例如绑定的端口号等。&lt;strong&gt;这里需要注意的是 tsd.core.auto_create_metrics 从 false 改为 true。这样上传数据时会自动创建 metric，否则会提示 Unknown metric 的错误。也可以设置为 false，但是使用 &lt;code&gt;tsdb mkmetric proc.loadavg.1m&lt;/code&gt; 来手动添加 metric。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;启动 OpenTSDB，&lt;code&gt;service opentsdb start&lt;/code&gt; 或者 &lt;code&gt;nohup tsdb tsd &amp;amp;&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过浏览器访问 &lt;a href=&#34;http://x.x.x.x:4242&#34;&gt;http://x.x.x.x:4242&lt;/a&gt; 查看是否安装成功。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;http-api&#34;&gt;HTTP API&lt;/h3&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;/api/put&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据 url 参数的不同，可以选择是否获取详细的信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;/api/put?summary&lt;/strong&gt;        // 返回失败和成功的个数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;/api/put?details&lt;/strong&gt;        // 返回详细信息&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;errors&amp;quot;: [],
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过POST方式插入数据，JSON格式，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;metric&amp;quot;:&amp;quot;self.test&amp;quot;, 
    &amp;quot;timestamp&amp;quot;:1456123787, 
    &amp;quot;value&amp;quot;:20, 
    &amp;quot;tags&amp;quot;:{
        &amp;quot;host&amp;quot;:&amp;quot;web1&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查询数据&#34;&gt;查询数据&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;/api/query&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可以选择 Get 或者 Post 两种方式，推荐使用 Post 方式，JSON 格式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1456123705,
    &amp;quot;end&amp;quot;: 1456124985,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web2&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;start 和 end 为指定的查询时间段。&lt;/p&gt;

&lt;p&gt;queries 为一个数组，可以指定多个查询。&lt;/p&gt;

&lt;p&gt;metric 和 tags 是用于过滤的查询条件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;返回字符串也为json格式&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {},
        &amp;quot;aggregateTags&amp;quot;: [
            &amp;quot;host&amp;quot;
        ],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123785&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 10
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        },
        &amp;quot;aggregateTags&amp;quot;: [],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123784&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 15
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;聚合&#34;&gt;聚合&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;aggregator&lt;/strong&gt; 是用于对查询结果进行聚合，将同一 unix 时间戳内的数据进行聚合计算后返回结果，例如如果 tags 不填，1456123705 有两条数据，一条 &lt;code&gt;host=web1&lt;/code&gt;，另外一条 &lt;code&gt;host=web2&lt;/code&gt;，值都为10，那么返回的该时间点的值为 sum 后的 20。&lt;/p&gt;

&lt;h4 id=&#34;条件过滤&#34;&gt;条件过滤&lt;/h4&gt;

&lt;p&gt;可以针对 tag 进行一些条件的过滤，返回 tag 中 host 的值以 web 开头的数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;filters&amp;quot;: [
            {
                &amp;quot;type&amp;quot;: &amp;quot;wildcard&amp;quot;,
                &amp;quot;tagk&amp;quot;: &amp;quot;host&amp;quot;,
                &amp;quot;filter&amp;quot;: &amp;quot;web*&amp;quot;
            }
        ]
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;downsample&#34;&gt;downsample&lt;/h4&gt;

&lt;p&gt;简单来说就是对指定时间段内的数据进行聚合后返回，例如需要返回每分钟的平均值数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;downsample&amp;quot;: &amp;quot;1m-avg&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>如何使golang项目可以在任意目录下编译</title>
          <link>http://blog.fatedier.com/2016/02/25/how-to-compile-go-project-in-any-directory</link>
          <pubDate>Thu, 25 Feb 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/02/25/how-to-compile-go-project-in-any-directory</guid>
          <description>

&lt;p&gt;通常我们将golang项目直接放在 $GOPATH/src 目录下，所有 import 的包的路径也是相对于 GOPATH 的。我在开发 frp（一个可以用于穿透内网的反向代理工具）的时候就遇到一个比较小但是挺棘手的问题，需要使这个项目可以在任意目录里被编译，方便其他成员不需要做额外的操作就可以一同开发，这里分享一下解决的方法。&lt;/p&gt;

&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/fatedier/frp&#34;&gt;frp&lt;/a&gt; 是我业余时间写的一个用于穿透内网的反向代理工具，可以将防火墙内或内网环境的机器对外暴露指定的服务，例如22端口提供ssh服务或者80端口提供一个临时的web测试环境。&lt;/p&gt;

&lt;p&gt;一开始项目是直接放在 &lt;code&gt;$GOPATH/src&lt;/code&gt; 目录下的，第三方包的引用是 &lt;code&gt;import github.com/xxx/xxx&lt;/code&gt;，内部包的引用 &lt;code&gt;import frp/xxx&lt;/code&gt;，这样编译时内部包的查找路径实际上就是 &lt;code&gt;$GOPATH/src/frp/xxx&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;后来由于使用了 &lt;a href=&#34;https://travis-ci.org/&#34;&gt;travis-ci&lt;/a&gt; 做持续集成，travis-ci 中是直接使用 &lt;code&gt;go get github.com/fatedier/frp&lt;/code&gt; 下载代码，然后编译运行。这样问题就来了，通过 go get 下载的源码在本地的路径是 &lt;code&gt;$GOPATH/src/github.com/fatedier/frp&lt;/code&gt;，内部包就找不到了，导致编译失败。&lt;/p&gt;

&lt;h3 id=&#34;使用类似第三方包的引用方式&#34;&gt;使用类似第三方包的引用方式&lt;/h3&gt;

&lt;p&gt;解决这个问题最直接的方法就是将内部包的引用方式修改成 &lt;code&gt;import github.com/fatedier/frp/xxx&lt;/code&gt;，在 travis-ci 中编译的时候就可以通过了，同时需要注意把自己本地的项目路径也更换成&lt;code&gt;$GOPATH/src/github.com/fatedier/frp&lt;/code&gt;，很多开源项目都是用的这种方式引用内部包。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：不推荐使用 ./ ../ 等相对路径来引用内部包，这样管理和定位问题其实都不是很方便。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之后由于需要其他人共同开发，fork了我的项目之后，他们也使用 go get 下载他们fork后的项目源码，这样 &lt;code&gt;fatedier&lt;/code&gt; 就替换成了他们自己的用户名，但是代码中 import 的包名并没有改变，会导致他们无法编译通过。当然，他们可以将项目再放到正确的目录，但是多了一部操作总归不方便。&lt;/p&gt;

&lt;h3 id=&#34;比较tricky的做法-修改gopath&#34;&gt;比较tricky的做法，修改GOPATH&lt;/h3&gt;

&lt;p&gt;其实问题的关键就在于 &lt;code&gt;GOPATH&lt;/code&gt; 这个环境变量，这个变量决定了查找包的绝对路径。我们在项目根目录下建立 &lt;code&gt;src/frp&lt;/code&gt; 这样的目录结构，之后将原来的源代码放到这个目录下，然后内部包的应用方式还是改成 &lt;code&gt;import frp/xxx&lt;/code&gt; 这种简洁的格式。&lt;/p&gt;

&lt;p&gt;编译的时候，把项目根目录加到 &lt;code&gt;GOPATH&lt;/code&gt; 中去，例如 &lt;code&gt;GOPATH=`pwd`:${GOPATH}&lt;/code&gt;，这样就会在自己的目录里查找内部包。&lt;/p&gt;

&lt;p&gt;可以看到，通过这样的方式不管把你把项目放到哪一个目录下，都可以编译成功，当然，为了便于管理，推荐还是放在 &lt;code&gt;$GOPATH/src&lt;/code&gt; 目录下，同时使用 &lt;a href=&#34;https://github.com/tools/godep&#34;&gt;godep&lt;/a&gt; 来管理第三方包。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Go中如何优雅地关闭net.Listener</title>
          <link>http://blog.fatedier.com/2016/02/19/how-to-shutdown-go-net-dot-listeners-gracefully</link>
          <pubDate>Fri, 19 Feb 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/02/19/how-to-shutdown-go-net-dot-listeners-gracefully</guid>
          <description>&lt;p&gt;在开发一个 Go 语言写的服务器项目的时候，遇到一个很有意思的问题，这个程序会根据客户端的请求动态的监听本地的一个端口，并且与客户端交互结束后需要释放这个端口。Go 的标准库提供了常用的接口，开发网络服务非常方便，网上随便就可以找到很多样例代码。&lt;/p&gt;

&lt;p&gt;但是我在释放这个监听端口的时候遇到了一些问题，我发现很难优雅地去关闭这个 &lt;strong&gt;net.Listener&lt;/strong&gt;。在网上查阅了一下资料，基本上都是程序结束时资源被系统自动回收，没发现有需要主动释放的。这个需求确实不多，不过想一下在写测试用例的时候或许可能会用到，我们先创建一个 &lt;strong&gt;net.Listener&lt;/strong&gt; 监听一个端口，&lt;strong&gt;client&lt;/strong&gt; 发送请求进行测试，通过后关闭这个 &lt;strong&gt;net.Listener&lt;/strong&gt;，再创建另外一个 &lt;strong&gt;net.Listener&lt;/strong&gt; 用于测试其他用例。&lt;/p&gt;

&lt;p&gt;初步思考了一下有两个办法来关闭 &lt;strong&gt;net.Listener&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;设置一个结束标志，为 &lt;strong&gt;net.Listener&lt;/strong&gt; 的 &lt;code&gt;accept&lt;/code&gt; 设置超时，&lt;strong&gt;net.Listener&lt;/strong&gt; 提供了一个 &lt;code&gt;SetDeadline(t time.Time)&lt;/code&gt; 接口，需要关闭时将标志置为 &lt;strong&gt;true&lt;/strong&gt;，每次超时后检查一下结束标志，如果为 &lt;strong&gt;true&lt;/strong&gt; 则退出。&lt;/li&gt;
&lt;li&gt;在另外一个协程中 &lt;strong&gt;close net.Listener&lt;/strong&gt;，检查 &lt;code&gt;accept&lt;/code&gt; 返回的 &lt;strong&gt;error&lt;/strong&gt; 信息，如果是被 &lt;strong&gt;close&lt;/strong&gt; 的话就退出，其他情况就继续。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第一个方法很显然不够优雅，在大并发量连接请求时对效率有很大影响，而且退出机制是延迟的，不能及时退出。&lt;/p&gt;

&lt;p&gt;第二个方法的问题就在于如果 &lt;strong&gt;close net.Listener&lt;/strong&gt;，&lt;code&gt;accept&lt;/code&gt; 函数返回的 &lt;strong&gt;error&lt;/strong&gt; 信息只能拿到错误的字符串信息，如果是被 &lt;strong&gt;close&lt;/strong&gt; 的话返回的信息是：&lt;code&gt;use of closed network connection&lt;/code&gt;，这个时候退出监听，如果是其他错误，则继续监听。想法是好的，然而并不能用错误信息的字符串来判断是哪一种类型的错误，有可能以后的版本中错误信息字符串变更也说不定，最好不要在代码中写死。这个 &lt;strong&gt;error&lt;/strong&gt; 其实是有类型的，在标准库中是 &lt;code&gt;errClosing&lt;/code&gt;，开头小写，说明只能在包内部使用，我们没有办法使用这个类型来判断具体是哪一种错误。个人觉得这方面可能还没有 &lt;strong&gt;c语言&lt;/strong&gt; 中通过 &lt;strong&gt;errno&lt;/strong&gt; 的值来判断是哪一种类型的错误来的方便。&lt;/p&gt;

&lt;p&gt;既然不能通过 &lt;strong&gt;error&lt;/strong&gt; 的字符串信息判断是哪一种错误，那么我们只能用类似第一个方法中使用的标志来判断了，先将结束标志置为 &lt;strong&gt;true&lt;/strong&gt;，之后 &lt;strong&gt;close net.Listener&lt;/strong&gt;，&lt;code&gt;accept&lt;/code&gt; 函数返回 &lt;code&gt;error != nil&lt;/code&gt; 时，检查结束标志，如果为 &lt;strong&gt;true&lt;/strong&gt; 就退出，这样相比较第一个方法退出时就没有延迟了，参考代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;net&amp;quot;
    &amp;quot;time&amp;quot;
)

var (
    ln        net.Listener
    closeFlag bool = false
)

func startServer() (err error) {
    ln, err = net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;:12345&amp;quot;)
    if err != nil {
        return err
    }
    defer ln.Close()

    for {
        conn, err := ln.Accept()
        if err != nil {
            fmt.Printf(&amp;quot;accept error: %v\n&amp;quot;, err)
            if closeFlag {
                break
            } else {
                continue
            }
        } else {
            conn.Close()
        }
    }
    return nil
}

func main() {
    go startServer()
    time.Sleep(1 * time.Second)
    closeFlag = true
    ln.Close()
    time.Sleep(1 * time.Second)
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>使用godep管理golang项目的第三方包</title>
          <link>http://blog.fatedier.com/2016/01/15/use-godep-to-manage-third-party-packages-of-golang-projects</link>
          <pubDate>Fri, 15 Jan 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/01/15/use-godep-to-manage-third-party-packages-of-golang-projects</guid>
          <description>

&lt;p&gt;go语言项目的第三方包资源现在十分丰富，使用起来也非常方便，直接在代码中 import 之后再使用 go get 命令下载到本地即可。但是在合作开发一个golang项目时，经常会遇到每个人在各自的机器上使用 go get 下载的第三方包版本不一致的情况（因为 go get 会下载指定包的最新版本），很有可能会遇到版本不兼容的情况。&lt;/p&gt;

&lt;p&gt;目前 go 自身的包管理体系比较薄弱，go 1.5 以后开始使用 vendor 机制来管理，但是依然缺乏对第三方包的版本的管理。&lt;/p&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;确保已经有go语言的环境并且设置好了 GOPATH 环境变量。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;go get -u github.com/tools/godep&lt;/code&gt; 下载 godep 包并自动安装。&lt;/li&gt;
&lt;li&gt;godep 可执行程序会放在 $GOPATH/bin 目录下。所以想直接用 godep 执行命令的话需要将该路径加入到全局的环境变量 PATH 中，可以将&lt;code&gt;export PATH=&amp;quot;$PATH:$GOPATH/bin&amp;quot;&lt;/code&gt;加入到系统启动脚本中。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;使用&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;进入go项目的根目录，需要该项目已经可以使用 go build 正常编译。&lt;/p&gt;

&lt;h4 id=&#34;godep-save&#34;&gt;godep save&lt;/h4&gt;

&lt;p&gt;执行 &lt;code&gt;godep save&lt;/code&gt; 或者 &lt;code&gt;godep save ./...&lt;/code&gt;，后者会递归地查找所有引用的第三方包。&lt;/p&gt;

&lt;p&gt;如果加上 -r 参数，则会替换原来代码中的第三包的路径为 godep 在该项目下copy过后的路径，例如 &lt;code&gt;C/Godeps/_workspace/src/D&lt;/code&gt;， 这样一来，以后直接执行 &lt;code&gt;go build&lt;/code&gt; 等就可以了，不需要使用 &lt;code&gt;godep go build&lt;/code&gt;。&lt;strong&gt;（这个特性在最新版本中已经被移除了）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个命令做了以下几件事：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查找项目中所用到的所有的第三方包&lt;/li&gt;
&lt;li&gt;在项目目录下创建 &lt;code&gt;Godeps&lt;/code&gt; 目录，&lt;code&gt;Godeps/Godeps.json&lt;/code&gt; 是依赖文件，包括了go的版本，用到的第三包的引入路径，版本号等信息，json文件需要一并加入到版本控制里。&lt;/li&gt;
&lt;li&gt;所有依赖的第三包的代码会被拷贝到 &lt;code&gt;Godeps/_workspace/src&lt;/code&gt; 下，并且移除了 &lt;code&gt;.git&lt;/code&gt; 这样的版本控制信息。&lt;code&gt;Godeps/_workspace&lt;/code&gt; 里的内容如果加到版本控制里，别人下载代码后可以直接编译，不需要另外再下依赖包，但是项目大小会变大。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;godep-restore&#34;&gt;godep restore&lt;/h4&gt;

&lt;p&gt;这个命令是根据 &lt;code&gt;Godeps/Godeps.json&lt;/code&gt; 文件把项目的依赖包下载到 &lt;code&gt;$GOPATH&lt;/code&gt; 目录下，需要注意这个命令是会修改 &lt;code&gt;$GOPATH&lt;/code&gt; 下依赖包的状态的，所以最好还是将 &lt;code&gt;Godeps/_workspace&lt;/code&gt; 里的内容直接加到自己项目的版本控制里。&lt;/p&gt;

&lt;h4 id=&#34;其他命令&#34;&gt;其他命令&lt;/h4&gt;

&lt;p&gt;其他的 go 命令基本上都可以通过 godep 执行，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;godep go build
godep go install
godep go fmt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;godep 封装的 go 命令其实就是将 Godeps/_workspace 加入到 GOPATH 中，这样编译的时候就会去 Godeps/_workspace 中寻找第三方包。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>终端利器 Tmux</title>
          <link>http://blog.fatedier.com/2015/12/18/terminal-multiplexer-tmux</link>
          <pubDate>Fri, 18 Dec 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/12/18/terminal-multiplexer-tmux</guid>
          <description>

&lt;p&gt;开发过程中通过ssh到服务器是很常见的，工作中基本上90%的时间在和终端打交道，如果没有一个称手的工具，将会在不停打开新的 tab 页，窗口切换中耗费大量的时间。Tmux 是终端复用器的意思，和 screen 类似，但是高度可定制，通过 tmux 可以方便地管理大量的 ssh 连接，并且灵活地在不同窗口，不同面板之间切换。&lt;/p&gt;

&lt;h3 id=&#34;界面&#34;&gt;界面&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-12-18-terminal-multiplexer-tmux-tmux-overview.png&#34; alt=&#34;tmux&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我用了自己的配置文件，对界面做过一些优化，左下角是 &lt;strong&gt;session&lt;/strong&gt; 名称，中间是各个 &lt;strong&gt;window&lt;/strong&gt; 的名称，可以理解为一般 IDE 中的 Tab 页，右下角显示时间，这个窗口中打开了3个 &lt;strong&gt;pane&lt;/strong&gt;，通过快捷键，我就可以在不同的 &lt;strong&gt;session&lt;/strong&gt;, &lt;strong&gt;window&lt;/strong&gt;, &lt;strong&gt;pane&lt;/strong&gt; 之间来回切换，基本上脱离了鼠标的使用。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;session： 可以用于区分不同的项目，为每个项目建立一个 session。&lt;/li&gt;
&lt;li&gt;window： 对应于其他 IDE 的 Tab 标签页，一个 window 占据一个显示屏幕，一个 session 可以有多个 window。&lt;/li&gt;
&lt;li&gt;pane： 在一个 window 中可以有多个 pane，便于大屏幕显示屏将屏幕切分成多块。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;

&lt;p&gt;Centos下直接通过 &lt;code&gt;yum install -y tmux&lt;/code&gt; 来安装，其他系统也一样可以使用相应的包管理工具安装。&lt;/p&gt;

&lt;h3 id=&#34;常用命令&#34;&gt;常用命令&lt;/h3&gt;

&lt;h4 id=&#34;快捷键前缀&#34;&gt;快捷键前缀&lt;/h4&gt;

&lt;p&gt;为了避免按键冲突，使用 tmux 的快捷键都需要加上一个&lt;strong&gt;前缀按键&lt;/strong&gt;，默认是 &lt;strong&gt;Ctrl-b&lt;/strong&gt; 的组合，可以通过配置修改为自定义的按键。&lt;/p&gt;

&lt;p&gt;例如要退出 tmux 的快捷键是前缀键 + d，那么就需要按 Ctrl-b + d：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;按下组合键 Ctrl-b&lt;/li&gt;
&lt;li&gt;放开组合键 Ctrl-b&lt;/li&gt;
&lt;li&gt;按下 s 键&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我自己将 Ctrl-b 改成了 Ctrl-x ，感觉这样操作顺手一些。&lt;/p&gt;

&lt;h4 id=&#34;基本操作&#34;&gt;基本操作&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;创建一个叫做 &amp;ldquo;test&amp;rdquo; 的 session，并且进入 tmux 界面&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tmux new -s test&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看开启了哪些 session&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tmux ls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;进入 session &amp;ldquo;test&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tmux attach -t test&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;退出 tmux 环境&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + d  // 退出后 session 并不会被关闭，之后通过 attach 进入仍然会看到原来的界面&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;切换 session&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + s，之后按序号切换，或者通过方向键选择后按 Enter 键切换&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;切换 window&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Ctrl-b + &amp;lt;窗口号&amp;gt;
Ctrl-b + n  // 切换到下一个窗口
Ctrl-b + p  // 切换到上一个窗口
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;切换 pane&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这个我在配置文件中修改过，修改成了 vim 的使用习惯，具体配置见下节
Ctrl-b + h  // 左
Ctrl-b + j  // 下
Ctrl-b + k  // 上
Ctrl-b + l  // 右
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;关闭 pane&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + x  // 焦点在要关闭的 pane 内&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关闭 window&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ctrl-b + &amp;amp; // 焦点在要关闭的 window 内&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分割 window 成多个 pane&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这个为了记忆方便也修改了原有的配置
Ctrl-b + _  // 竖直分割
Ctrl-b + |  // 水平分割
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;重新加载配置文件&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这个被我映射到了 r 键，修改完配置文件后不用关闭所有 session 重新打开，直接重新加载即可
Ctrl-b + r
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;小技巧&#34;&gt;小技巧&lt;/h3&gt;

&lt;h4 id=&#34;复制模式&#34;&gt;复制模式&lt;/h4&gt;

&lt;p&gt;如果要在不同 &lt;strong&gt;window&lt;/strong&gt; 或者 &lt;strong&gt;pane&lt;/strong&gt; 之间复制内容，又想实现全键盘的操作，就需要借助于 tmux 的复制功能。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ctrl-b + [&lt;/strong&gt; 进入复制模式&lt;/li&gt;
&lt;li&gt;移动光标到要复制的地方，这里我配置成了 vim 的操作方式&lt;/li&gt;
&lt;li&gt;按下&lt;strong&gt;空格&lt;/strong&gt;开始复制&lt;/li&gt;
&lt;li&gt;再移动到结束的地方，按下 &lt;strong&gt;Enter&lt;/strong&gt; 键退出&lt;/li&gt;
&lt;li&gt;在需要粘贴的地方按下 &lt;strong&gt;Ctrl-b + ]&lt;/strong&gt; 粘贴&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;多-pane-批量操作&#34;&gt;多 pane 批量操作&lt;/h4&gt;

&lt;p&gt;有时候同时登录了多台机器，需要执行一样的命令来进行批量操作，借助于 tmux 同样可以实现。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;:setw synchronize-panes&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个是设置批量操作的开关，如果原来功能是关闭的，则打开，反之亦然，可以将其映射到一个快捷键方便操作。开启这个功能后，在当前 window 任意一个 pane 输入的命令，都会同时作用于该 window 中的其他 pane。&lt;/p&gt;

&lt;h3 id=&#34;配置文件&#34;&gt;配置文件&lt;/h3&gt;

&lt;p&gt;配置文件需要自己在 $HOME 目录下创建，命名为 .tmux.conf，具体内容如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Use something easier to type as the prefix.
set -g prefix C-x
unbind C-b
bind C-x send-prefix

# 窗口计数从1开始，方便切换
set -g base-index 1
setw -g pane-base-index 1

# 启用和关闭status bar
bind S set status on
bind D set status off 

# 消息背景色
set -g message-bg white

set -g mode-keys vi

# 关闭自动重命名窗口
setw -g allow-rename off 
setw -g automatic-rename off 

# bind a reload key
bind r source-file ~/.tmux.conf \; display-message &amp;quot;Config reloaded...&amp;quot;

# I personally rebind the keys so &amp;quot;|&amp;quot; splits the current window vertically, and &amp;quot;-&amp;quot; splits it horizontally. Not the easiest things to type, though easy to remember.
bind | split-window -h
bind _ split-window -v

# fixes the delay problem
set -sg escape-time 0

# 面板切换
bind-key k select-pane -U
bind-key j select-pane -D
bind-key h select-pane -L
bind-key l select-pane -R

# 面板大小调整
bind -r ^k resizep -U 10  
bind -r ^j resizep -D 10
bind -r ^h resizep -L 10
bind -r ^l resizep -R 10

# 状态栏
# 颜色
set -g status-bg black
set -g status-fg white

# 对齐方式
set-option -g status-justify centre

# 左下角
set-option -g status-left &#39;#[bg=black,fg=green][#[fg=cyan]#S#[fg=green]]&#39;
set-option -g status-left-length 20

# 窗口列表
set-window-option -g window-status-format &#39;#[dim]#I:#[default]#W#[fg=grey,dim]&#39;
set-window-option -g window-status-current-format &#39;#[fg=cyan,bold]#I#[fg=blue]:#[fg=cyan]#W#[fg=dim]&#39;

# 右下角
set -g status-right &#39;#[fg=green][#[fg=cyan]%H:%M#[fg=green]]&#39;

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配套工具&#34;&gt;配套工具&lt;/h3&gt;

&lt;h4 id=&#34;tmuxinator&#34;&gt;tmuxinator&lt;/h4&gt;

&lt;p&gt;使用 tmux 可以让我们不管在什么时候，什么地点登录服务器都能得到同样的工作界面，不用因为担心网络暂时中断而需要重新打开一大堆的 tab 页。&lt;/p&gt;

&lt;p&gt;但是如果有的时候服务器重启了，那么所有的 session 就都没了，必须重新打开，可以想象一下我开发时有4-5个 session，每个 session 中有多个 window，然后每个 winodw 中通常又有2-3个 pane，要重新一个个建立开发环境是一件多么痛苦的事。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tmuxinator/tmuxinator&#34;&gt;tmuxinator&lt;/a&gt; 可以稍微缓解一下这个问题，但是不彻底。tmuxinator 可以用于管理 tmux 的 session 和 window 布局等，便于在机器重启后能够快速恢复自己的工作环境。&lt;/p&gt;

&lt;h5 id=&#34;安装-1&#34;&gt;安装&lt;/h5&gt;

&lt;p&gt;先安装 gem， &lt;code&gt;yum install -y rubygems&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于天朝特殊的网络环境，gem的第三方包可能安装不了，可以替换成阿里提供的镜像源。&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gem sources --add [https://ruby.taobao.org/](https://ruby.taobao.org/) --remove [https://rubygems.org/](https://rubygems.org/)
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;使用&#34;&gt;使用&lt;/h5&gt;

&lt;p&gt;创建一个 tmuxinator 的 project： &lt;code&gt;tmuxinator new [project]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后编写项目的配置文件，以后重新打开这个项目所显示的界面就是根据这个配置文件来生成。具体用法可以参考项目文档： &lt;a href=&#34;https://github.com/tmuxinator/tmuxinator。&#34;&gt;https://github.com/tmuxinator/tmuxinator。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当服务器重启了以后，执行 &lt;code&gt;tmuxinator start [project]&lt;/code&gt;，tmuxinator 就会自动根据配置文件创建一个指定布局的 tmux session。&lt;/p&gt;

&lt;h5 id=&#34;缺点&#34;&gt;缺点&lt;/h5&gt;

&lt;p&gt;布局是预先在配置文件中指定好的，你在使用 tmux 过程中修改了的布局是不会记录下来的。&lt;/p&gt;

&lt;h4 id=&#34;tmux-resurrect&#34;&gt;Tmux Resurrect&lt;/h4&gt;

&lt;p&gt;Tmux Resurrect 用于保存当前的session环境到磁盘上，用于以后恢复。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于这个插件需要 tmux 1.9 及以上的版本，而 centos7 的 yum 源里现在是1.8的版本，我的开发环境全是自动构建，不方便升级，所以暂时还没有尝试。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于 Tmux Resurrect 使用的相关文档： &lt;a href=&#34;http://www.linuxidc.com/Linux/2015-07/120304.htm&#34;&gt;http://www.linuxidc.com/Linux/2015-07/120304.htm&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>gem 源被屏蔽的解决方法</title>
          <link>http://blog.fatedier.com/2015/12/06/the-solution-when-gem-source-is-shielded</link>
          <pubDate>Sun, 06 Dec 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/12/06/the-solution-when-gem-source-is-shielded</guid>
          <description>&lt;p&gt;由于国内的网络环境比较特殊，使用 gem install 安装 ruby 包的时候，往往不能成功，我们可以手动替换成阿里提供的镜像源来进行下载。&lt;/p&gt;

&lt;p&gt;官方原先的源地址是 &lt;a href=&#34;https://rubygems.org/&#34;&gt;https://rubygems.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以使用 &lt;code&gt;gem sources&lt;/code&gt; 命令来查看源地址。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;*** CURRENT SOURCES ***

https://rubygems.org/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过 &lt;code&gt;gem sources --add https://ruby.taobao.org/ --remove https://rubygems.org/&lt;/code&gt; 替换成阿里的源。&lt;/p&gt;

&lt;p&gt;再次查看源地址列表。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;*** CURRENT SOURCES ***

https://ruby.taobao.org/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后就可以使用 &lt;code&gt;gem install xxx -V&lt;/code&gt; 安装第三方包或应用并且显示详细过程。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>给shell的输出加上颜色</title>
          <link>http://blog.fatedier.com/2015/11/24/give-your-shell-some-color</link>
          <pubDate>Tue, 24 Nov 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/11/24/give-your-shell-some-color</guid>
          <description>

&lt;p&gt;在写一些脚本的时候输出信息太多，对一些重要信息加上颜色提示会更加友好。&lt;/p&gt;

&lt;h3 id=&#34;前景色-文本颜色&#34;&gt;前景色(文本颜色)&lt;/h3&gt;

&lt;p&gt;例如要将 &lt;code&gt;hello&lt;/code&gt; 在控制台上输出为红色，执行如下的命令&lt;/p&gt;

&lt;p&gt;&lt;code&gt;echo -e &amp;quot;\033[31mhello\033[0m&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\033[31m&lt;/code&gt; 表示将字符的显示颜色改为红色&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\033[0m&lt;/code&gt; 表示将字符的显示颜色改为正常值&lt;/p&gt;

&lt;p&gt;可以看到 &lt;code&gt;\033[&lt;/code&gt; 以及最后的 &lt;code&gt;m&lt;/code&gt; 都是一样的，就是中间的数字有区别，这个数字就代表了要显示的颜色，含义如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;30        黑色 
31        红色 
32        绿色 
33        淡红色 
34        蓝色 
35        紫色 
36        淡蓝色 
37        灰色 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;背景色&#34;&gt;背景色&lt;/h3&gt;

&lt;p&gt;背景色和前景色设置的方法一样，只是使用的数字不同&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;40        黑色 
41        红色 
42        绿色 
43        淡红色 
44        蓝色 
45        紫色 
46        淡蓝色 
47        灰色 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果需要同时设置前景色和背景色，例如输出文本颜色为红色，背景色为绿色的字符串，需要以分号分隔两个数字，示例如下&lt;/p&gt;

&lt;p&gt;&lt;code&gt;echo -e &amp;quot;\033[31;42mhello\033[0m&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;简化&#34;&gt;简化&lt;/h3&gt;

&lt;p&gt;从上面的示例可以看到这样写起来很麻烦，可以简单的将重复的内容定义为一个变量&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lc=&#39;\033[&#39;
rc=&#39;\033[0m&#39;
cred=&#39;31m&#39;        # red
cgreen=&#39;32m&#39;      # green

echo -e &amp;quot;${lc}${cred}hello${rc}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>codis 2.x版本环境搭建与测试</title>
          <link>http://blog.fatedier.com/2015/10/07/installation-and-testing-of-codis-version-two</link>
          <pubDate>Wed, 07 Oct 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/10/07/installation-and-testing-of-codis-version-two</guid>
          <description>

&lt;p&gt;Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别（有一些命令不支持），上层应用可以像使用单机的 Redis 一样，Codis 底层会处理请求的转发。Codis 支持不停机进行数据迁移, 对于前面的客户端来说是透明的, 可以简单的认为后面连接的是一个内存无限大的 Redis 服务。&lt;/p&gt;

&lt;h3 id=&#34;安装并启动-zookeeper&#34;&gt;安装并启动 zookeeper&lt;/h3&gt;

&lt;p&gt;codis 2.x 版本重度依赖于 zookeeper。&lt;/p&gt;

&lt;p&gt;从官网下载 &lt;a href=&#34;http://zookeeper.apache.org/releases.html&#34;&gt;zookeeper&lt;/a&gt;，解压安装。&lt;/p&gt;

&lt;p&gt;使用默认配置启动 zookeeper &lt;code&gt;sh ./bin/zkServer.sh start&lt;/code&gt;，监听地址为 &lt;code&gt;2181&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;下载安装-codis&#34;&gt;下载安装 codis&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;go get -d github.com/CodisLabs/codis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;进入源码根目录 &lt;code&gt;cd $GOPATH/src/github.com/CodisLabs/codis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;执行安装脚本 &lt;code&gt;./bootstrap.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：这里第一步和第三步（会下载第三方库到本地）需要从 github copy 数据，鉴于网络环境的问题，时间会比较长。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之后生成的可执行文件都在 &lt;code&gt;codis/bin&lt;/code&gt; 文件夹下。&lt;/p&gt;

&lt;h3 id=&#34;部署-codis-server&#34;&gt;部署 codis-server&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;codis-server&lt;/strong&gt; 基于 &lt;strong&gt;redis 2.8.21&lt;/strong&gt; 稍微进行了一些修改以支持原子性的迁移数据，具体用法和 redis 一致。&lt;/p&gt;

&lt;p&gt;将 &lt;code&gt;bin&lt;/code&gt; 文件夹下的 codis-server 拷贝到集群中每个节点，和 redis-server 的启动命令一样，指定配置文件，启动。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这里要注意 redis.conf 配置中需要设置 maxmemory，不然无法自动按照负载均衡的方式分配 slot（可以手动分配），推荐单台机器部署多个 redis 实例。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-server ./redis_conf/redis_6400.conf&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;启动-dashboard&#34;&gt;启动 dashboard&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;dashboard&lt;/strong&gt; 既是 codis 集群的管理中心，又提供了一个人性化的 web 界面，方便查看统计信息以及对集群进行管理操作。&lt;/p&gt;

&lt;p&gt;启动 web 控制面板，注意这里要用到配置文件，不指定的话就是当前目录下的 config.ini，可以用 &lt;code&gt;-c&lt;/code&gt; 参数指定。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nohup ./bin/codis-config -c ./config.ini dashboard --addr=:18087 &amp;amp;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;初始化-slot&#34;&gt;初始化 slot&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot init&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;该命令会在 zookeeper 上创建 slot 相关信息。&lt;/p&gt;

&lt;h3 id=&#34;添加-group&#34;&gt;添加 group&lt;/h3&gt;

&lt;p&gt;每个 &lt;strong&gt;group&lt;/strong&gt; 只能有一个 &lt;strong&gt;master&lt;/strong&gt; 和多个 &lt;strong&gt;slave&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;命令格式： &lt;code&gt;codis-config -c ./config.ini server add &amp;lt;group_id&amp;gt; &amp;lt;redis_addr&amp;gt; &amp;lt;role&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;例如向 group 1 和 group 2 中各加入两个 codis-server 实例，一主一从。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 1 localhost:6379 master&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 1 localhost:6380 slave&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 2 localhost:6381 master&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini server add 2 localhost:6382 slave&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1 代表 group_id，必须为数字，且从 1 开始&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;分配-slot&#34;&gt;分配 slot&lt;/h3&gt;

&lt;h4 id=&#34;手动分配&#34;&gt;手动分配&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;codis-config -c ./config.ini slot range-set &amp;lt;slot_from&amp;gt; &amp;lt;slot_to&amp;gt; &amp;lt;group_id&amp;gt; &amp;lt;status&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;slot&lt;/strong&gt; 默认为 &lt;strong&gt;1024&lt;/strong&gt; 个，范围是 &lt;strong&gt;0 - 1023&lt;/strong&gt;，需要将这 1024 个 slot 分配到集群中不同的 group 中。&lt;/p&gt;

&lt;p&gt;例如将 1024 个 slot 平均分配到&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot range-set 0 511 1 online&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot range-set 512 1023 2 online&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;自动分配&#34;&gt;自动分配&lt;/h4&gt;

&lt;p&gt;在 dashboard 上可以自动分配 slot，会按照负载均衡的方式进行分配，不推荐使用，因为可能会造成大量数据的迁移。&lt;/p&gt;

&lt;p&gt;或者使用命令进行自动分配&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-config -c ./config.ini slot rebalance&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;启动-codis-proxy&#34;&gt;启动 codis-proxy&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-proxy -c ./config.ini -L ./log/proxy.log --cpu=8 --addr=10.10.100.1:19000 --http-addr=10.10.100.1:11000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意：这里 &amp;ndash;addr 和 &amp;ndash;http-addr 不要填 0.0.0.0，要绑定一个具体的 ip，不然 zookeeper 中存的将是hostname，会导致 dashboard 无法连接。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;codis-proxy 是无状态的，可以部署多个，且用 go 编写，可以利用多核，建议 cpu 设置核心数的一半到2/3，19000 即为访问 redis 集群的端口，11000 为获取 proxy 相关状态的端口。&lt;/p&gt;

&lt;p&gt;之后使用 codis-config 将 codis-proxy 加入进来，也就是设置online（后来更新了一个版本，默认启动后即自动注册为online）&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bin/codis-config -c ./config.ini proxy online &amp;lt;proxy_name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;需要注意的是，启动 codis-proxy，会在 zookeeper 中注册一个 node，地址为 /zk/codis/db_test/fence，如果使用 kill -9 强行杀掉进程的话，这个会一直存在，需要手工删除。且 node 名称为 [hostname:port]，所以需要注意这个组合不能重复。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;主从切换&#34;&gt;主从切换&lt;/h3&gt;

&lt;p&gt;官方建议是手工操作，避免数据不一致的问题，但是没有自动容灾的话可用性太差。&lt;/p&gt;

&lt;p&gt;官方另外提供了一个工具，&lt;strong&gt;codis-ha&lt;/strong&gt;，这是一个通过 codis 开放的 api 实现自动切换主从的工具。该工具会在检测到 master 挂掉的时候将其下线并选择其中一个 slave 提升为 master 继续提供服务。&lt;/p&gt;

&lt;p&gt;这个工具不是很好用，如果 codis-ha 连接 dashboard 失败之后进程就会自动退出，需要手动重启或者使用 supervisor 拉起来。另外，当有机器被提升为 master 之后，其他 slave 的状态不会改变，还是从原 master 同步数据。原来的 master 重启之后处于 offline 状态，也需要手动加入 group 指定为 slave。也就是说有master 挂掉后，其余机器的状态需要手动修改。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./bin/codis-ha --codis-config=10.10.100.3:18087 --productName=common&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;10.10.100.14:18088&lt;/code&gt; 为 dashboard 所在机器的 ip 和端口。&lt;/p&gt;

&lt;h3 id=&#34;旧数据的迁移&#34;&gt;旧数据的迁移&lt;/h3&gt;

&lt;p&gt;官方提供了一个 &lt;strong&gt;redis-port&lt;/strong&gt; 工具可以将旧 redis 中的数据实时迁移到 codis 集群中，之后需要修改各服务配置文件，重启服务，指向 codis 集群即可。&lt;/p&gt;

&lt;h3 id=&#34;性能测试&#34;&gt;性能测试&lt;/h3&gt;

&lt;p&gt;测试环境： 24核 2.1GHz，4个redis实例&lt;/p&gt;

&lt;h4 id=&#34;不启用-pipeline&#34;&gt;不启用 pipeline&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;SET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;MSET&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;redis单机&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58997.05&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58651.02&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;33557.05&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis1核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;42973.79&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;33003.30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12295.58&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis4核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;44208.66&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;39936.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;21743.86&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;39478.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;23052.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;24679.17&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis12核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;28943.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;24224.81&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;21376.66&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核2proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62085.65&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;68964.40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;48298.74&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;pipeline-100&#34;&gt;pipeline = 100&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;SET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;GET&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;MSET&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;redis单机&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;259067.36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;340136.06&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;40387.72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis1核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;158982.52&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;166112.95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15199.88&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis4核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;491159.12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;403551.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;40157.42&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;518134.72&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;537634.38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58156.44&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis12核1proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;520833.34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;500000.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;53418.80&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;codis8核2proxy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;529812.81&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;607041.47&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62872.28&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;通过测试可以看出，使用 codis 会在性能上比原来直接使用 redis 会有所下降，但是优势就在于可以通过横向扩展（加机器）的方式去提高 redis 的存储容量以及并发量。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Redis集群调研</title>
          <link>http://blog.fatedier.com/2015/09/15/redis-cluster-survey</link>
          <pubDate>Tue, 15 Sep 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/09/15/redis-cluster-survey</guid>
          <description>

&lt;p&gt;Redis作为一个使用场景很高的NoSQL数据库，支持了较为丰富的数据类型，相比于其他关系型数据库在性能方面优势明显。互联网公司通常更加倾向于将一些热点数据放入Redis中来承载高吞吐量的访问。&lt;/p&gt;

&lt;p&gt;单机Redis在普通的服务器上通常ops上限在5w左右，开启pipeline的情况下在20-30w左右。对于大多数中小公司来说，通常单机的Redis已经足够，最多根据不同业务分散到多台Redis。&lt;/p&gt;

&lt;h3 id=&#34;为什么需要集群&#34;&gt;为什么需要集群&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Redis单线程特性，多请求顺序执行，单个耗时的操作会阻塞后续的操作&lt;/li&gt;
&lt;li&gt;单机内存有限&lt;/li&gt;
&lt;li&gt;某些特殊业务，带宽压力较大&lt;/li&gt;
&lt;li&gt;单点问题，缺乏高可用性&lt;/li&gt;
&lt;li&gt;不能动态扩容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Redis集群的目标就是为了实现高可用性，避免性能瓶颈，可动态扩容，易于做监控告警。&lt;/p&gt;

&lt;h3 id=&#34;三种主流的集群解决方案&#34;&gt;三种主流的集群解决方案&lt;/h3&gt;

&lt;h4 id=&#34;客户端静态分片&#34;&gt;客户端静态分片&lt;/h4&gt;

&lt;p&gt;通常需要 smart-client 支持，在业务程序端根据预先设置的路由规则进行分片，从而实现对多个redis实例的分布式访问。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-jedis.png&#34; alt=&#34;jedis&#34; /&gt;&lt;/p&gt;

&lt;p&gt;鉴于redis本身的高性能，并且有一些设计良好的第三方库，例如java开发者可以使用jedis，所以很多小公司使用此方案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt; 相比于使用代理，减少了一层网络传输的消耗，效率较高。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt; 当redis实例需要扩容或切换的情况下，需要修改业务端的程序，较为麻烦。并且需  要维护各个语言的客户端版本，如果要升级客户端成本也会比较高。出现故障时难以及时定位问题。（有些smart-client借助于zookeeper维护客户端访问redis实例的一致性）&lt;/p&gt;

&lt;h4 id=&#34;proxy分片&#34;&gt;Proxy分片&lt;/h4&gt;

&lt;p&gt;通过统一的代理程序访问多个redis实例，比如业内曾广泛使用的 twemproxy 以及 豌豆荚开源的 codis。（twemproxy是twitter开源的一个redis和memcache代理服务器，只用于作为简单的代理中间件，目前twitter内部已经不再使用）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt; 业务程序端只需要使用普通的api去访问代理程序即可。各种组件分离，以后升级较为容易。也避免了客户端需要维持和每个redis实例的长连接导致连接数过多。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt; 增加了一层中间件，增加了网络和数据处理的消耗，性能下降。&lt;/p&gt;

&lt;h4 id=&#34;official-redis-cluster&#34;&gt;Official Redis Cluster&lt;/h4&gt;

&lt;p&gt;Redis3.0之后的版本开始正式支持 redis cluster，核心目标是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;性能：&lt;/strong&gt;Redis作者比较看重性能，增加集群不能对性能有较大影响，所以Redis采用了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;水平扩展：&lt;/strong&gt;官方文档中称目标是能线性扩展到1000结点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可用性：&lt;/strong&gt;集群具有了以前Sentinel的监控和自动Failover能力。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;基于twemproxy的redis集群环境&#34;&gt;基于twemproxy的redis集群环境&lt;/h3&gt;

&lt;h4 id=&#34;整体架构图&#34;&gt;整体架构图&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-twemproxy-architecture.png&#34; alt=&#34;twemproxy_architecture&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;twemproxy的特点&#34;&gt;twemproxy的特点&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;支持失败的节点自动摘除（仅作为缓存时）&lt;/li&gt;
&lt;li&gt;所有的key通过一致性哈希算法分布到集群中所有的redis实例中&lt;/li&gt;
&lt;li&gt;代理与每个redis实例维持长连接，减少客户端和redis实例的连接数&lt;/li&gt;
&lt;li&gt;代理是无状态的，可以任意部署多套，避免单点问题&lt;/li&gt;
&lt;li&gt;默认启用pipeline，连接复用，提高效率，性能损失在 10% - 20%&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;集群组件&#34;&gt;集群组件&lt;/h4&gt;

&lt;p&gt;由于twemproxy本身只是简单的代理，所以需要依赖于一些其他的程序组件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redis Sentinel：&lt;/strong&gt; 管理主从备份，用于主从切换，当主服务器挂掉后，自动将从服务器提升为主服务器&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redis-Twemproxy Agent：&lt;/strong&gt; nodejs写的一个监控程序，用于监听 redis-sentinel 的 master 切换事件，并且及时更新twemproxy的配置文件后将其重新启动&lt;/p&gt;

&lt;h4 id=&#34;why-not-twemproxy&#34;&gt;Why not Twemproxy&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;虽然使用 c 开发，性能损失较小，但同样是单线程。所以基本上twemproxy的数量需要和后端redis实例一样甚至更多才能充分发挥多实例的并发能力，造成运维困难。&lt;/li&gt;
&lt;li&gt;twemproxy更改配置文件需要重新启动，比较坑，需要修改代码使其支持动态加载。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无法动态扩容&lt;/strong&gt;，如果需要实现这个功能，要么自己写迁移脚本，手动迁移，比较繁琐，还会影响到当前服务的正常运行。或者二次开发，增加对zookeeper的依赖，将redis节点信息以及hash域相关的数据存储在zookeeper上，然后增加动态迁移数据的模块，可以在不影响现有服务运行的情况下完成增删实例。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;redis-cluster&#34;&gt;Redis Cluster&lt;/h3&gt;

&lt;h4 id=&#34;数据分布-预分片&#34;&gt;数据分布：预分片&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-redis-cluster-pre-sharding.png&#34; alt=&#34;redis-cluster-pre-sharding&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;预先分配好 16384 个slot&lt;/li&gt;
&lt;li&gt;slot 和 server 的映射关系存储每一个 server 的路由表中&lt;/li&gt;
&lt;li&gt;根据 CRC16(key) mod 16384 的值，决定将一个key放到哪一个slot中&lt;/li&gt;
&lt;li&gt;数据迁移时就是调整 slot 的分布&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;架构-去中心化&#34;&gt;架构：去中心化&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-redis-cluster-architecture.png&#34; alt=&#34;redis-cluster-architecture&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无中心结构，每个节点都保存数据和整个集群的状态。&lt;/li&gt;
&lt;li&gt;采用 gossip 协议传播信息以及发现新节点（最终一致性）。

&lt;ul&gt;
&lt;li&gt;每个节点都和其他所有节点连接，并保持活跃。&lt;/li&gt;
&lt;li&gt;PING/PONG：心跳，附加上自己以及一些其他节点数据，每个节点每秒随机PING几个节点。会选择那些超过cluster-node-timeout一半的时间还未PING过或未收到PONG的节点。&lt;/li&gt;
&lt;li&gt;UPDATE消息：计数戳，如果收到server的计数为3，自己的为4，则发UPDATE更新对方路由表，反之更新自己的路由表，最终集群路由状态会和计数戳最大的实例一样。&lt;/li&gt;
&lt;li&gt;如果 cluster-node-timeout 设置较小，或者节点较多，数据传输量将比较可观。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Broadcast：有状态变动时先broadcast，后PING； 发布/订阅。&lt;/li&gt;
&lt;li&gt;Redis node 不作为client请求的代理（不转发请求），client根据node返回的错误信息重定向请求?（需要 smart-client 支持），所以client连接集群中任意一个节点都可以。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;可用性-master-slave&#34;&gt;可用性：Master-Slave&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;每个Redis Node可以有一个或者多个Slave，当Master挂掉时，选举一个Slave形成新的Master。&lt;/li&gt;
&lt;li&gt;Master Slave 之间异步复制（可能会丢数据）。&lt;/li&gt;
&lt;li&gt;采用 gossip 协议探测其他节点存活状态，超过 cluster-node-timeout，标记为 PFAIL，PING中附加此数据。当 Node A发现半数以上master将失效节点标记为PFAIL，将其标记为FAIL，broadcast FAIL。&lt;/li&gt;
&lt;li&gt;各 slave 等待一个随机时间后 发起选举，向其他 master broadcast，半数以上同意则赢得选举否则发起下一次选举&lt;/li&gt;
&lt;li&gt;当 slave 成为 master，先broadcast，后持续PING，最终集群实例都获知此消息&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;存在的问题&#34;&gt;存在的问题&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Gossip协议通信开销&lt;/li&gt;
&lt;li&gt;严重依赖于smart-client的成熟度

&lt;ul&gt;
&lt;li&gt;如果smart-client支持缓存slot路由，需要额外占用内存空间，为了效率需要建立和所有 redis server 的长连接（每一个使用该库的程序都需要建立这么多连接）。&lt;/li&gt;
&lt;li&gt;如果不支持缓存路由信息，会先访问任意一台 redis server，之后重定向到新的节点。&lt;/li&gt;
&lt;li&gt;需要更新当前所有的client。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;官方只提供了一个ruby程序 redis-trib 完成集群的所有操作，缺乏监控管理工具，很难清楚目前集群的状态&lt;/li&gt;
&lt;li&gt;数据迁移以Key为单位，速度较慢&lt;/li&gt;
&lt;li&gt;某些操作不支持，MultiOp和Pipeline都被限定在命令中的所有Key必须都在同一Slot内&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;codis&#34;&gt;Codis&lt;/h3&gt;

&lt;h4 id=&#34;what-is-codis&#34;&gt;What is Codis ？&lt;/h4&gt;

&lt;p&gt;Go语言开发的分布式 Redis 解决方案，对于上层的应用来说，访问 codis 和原生的 redis server 没有明显区别（不支持发布订阅等某些命令，支持 pipeline）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-09-15-redis-cluster-survey-codis-architecture.png&#34; alt=&#34;codis-architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Codis由四部分组成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Codis Proxy (codis-proxy)&lt;/li&gt;
&lt;li&gt;Codis Dashboard (codis-config)&lt;/li&gt;
&lt;li&gt;Codis Redis (codis-server)&lt;/li&gt;
&lt;li&gt;ZooKeeper/Etcd&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;codis-proxy 是客户端连接的 Redis 代理服务, codis-proxy 本身实现了 Redis 协议, 表现得和一个原生的 Redis 没什么区别 (就像 Twemproxy), 对于一个业务来说, 可以部署多个 codis-proxy, codis-proxy 本身是无状态的。&lt;/p&gt;

&lt;p&gt;codis-config 是 Codis 的管理工具, 支持包括, 添加/删除 Redis 节点, 添加/删除 Proxy 节点, 发起数据迁移等操作. codis-config 本身还自带了一个 http server, 会启动一个 dashboard, 用户可以直接在浏览器上观察 Codis 集群的运行状态。&lt;/p&gt;

&lt;p&gt;codis-server 是 Codis 项目维护的一个 Redis 分支, 基于 2.8.21 开发, 加入了 slot 的支持和原子的数据迁移指令. Codis 上层的 codis-proxy 和 codis-config 只能和这个版本的 Redis 交互才能正常运行。&lt;/p&gt;

&lt;p&gt;Codis 依赖 ZooKeeper 来存放数据路由表和 codis-proxy 节点的元信息, codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。&lt;/p&gt;

&lt;p&gt;Codis 支持按照 Namespace 区分不同的产品, 拥有不同的 product name 的产品, 各项配置都不会冲突。&lt;/p&gt;

&lt;h4 id=&#34;整体设计&#34;&gt;整体设计&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;预分片，1024 slot， key =&amp;gt; crc32(key)%1024&lt;/li&gt;
&lt;li&gt;proxy无状态，便于负载均衡，启动时在 Zookeeper 上注册一个临时节点，方便做 HA&lt;/li&gt;
&lt;li&gt;Redis 只作为存储引擎&lt;/li&gt;
&lt;li&gt;Go语言开发，可以充分利用多核，不必像 twemproxy 一样部署很多套&lt;/li&gt;
&lt;li&gt;性能损失，在不开启pipeline的情况下会损失大概40%，通过加实例线性扩展&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>如何修改进程的名称</title>
          <link>http://blog.fatedier.com/2015/08/24/how-to-modify-process-name</link>
          <pubDate>Mon, 24 Aug 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/08/24/how-to-modify-process-name</guid>
          <description>

&lt;p&gt;在开发 php 扩展的过程中，希望能创建一个独立的子进程做一些额外的处理工作，并且为子进程修改一个有意义的名称，发现还是有一些难度的。&lt;/p&gt;

&lt;h3 id=&#34;效果预览&#34;&gt;效果预览&lt;/h3&gt;

&lt;p&gt;要实现的效果就像 nginx 启动后通过 ps 查到的名称一样，这个名称就是自定义的，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-08-24-how-to-modify-process-name-nginx-process-name.png&#34; alt=&#34;nginx-process-name&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;方法一&#34;&gt;方法一&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;prctl(PR_SET_NAME, name);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个函数可以将当前进程的名称修改为 &lt;code&gt;name&lt;/code&gt; 的内容。&lt;/p&gt;

&lt;p&gt;我测试了一下，发现只有使用 &lt;code&gt;ps -L&lt;/code&gt; 才能看到，达不到想要的效果。&lt;/p&gt;

&lt;h3 id=&#34;方法二&#34;&gt;方法二&lt;/h3&gt;

&lt;p&gt;参考了 &lt;strong&gt;nginx&lt;/strong&gt; 中的源码，主要是通过修改 &lt;strong&gt;argv[0]&lt;/strong&gt; 的值来实现的，但是需要注意将后面跟着的 &lt;strong&gt;environ&lt;/strong&gt; 环境表中的信息移到其他地方，避免被覆盖。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void set_proctitle(char** argv, const char* new_name)
{
    int size = 0;
    int i;
    // 申请新的空间存放 environ 中内容
    for (i = 0; environ[i]; i++) {
        size += strlen(environ[i]) + 1;
    }
    char* p = (char*)malloc(size);
    char* last_argv = argv[0];
    for (i = 0; argv[i]; i++) {
        if (last_argv == argv[i]) {
            last_argv = argv[i] + strlen(argv[i]) + 1;
        }
    }  
    for (i = 0; environ[i]; i++) {
        if (last_argv == environ[i]) {
            size = strlen(environ[i]) + 1;
            last_argv = environ[i] + size;  
   
            memcpy(p, environ[i], size);
            environ[i] = (char*)p;
            p += size;
        }  
    }
    last_argv--;
    // 修改 argv[0]，argv剩余的空间全部填0
    strncpy(argv[0], new_name, last_argv - argv[0]);
    p = argv[0] + strlen(argv[0]) + 1;
    if (last_argv - p &amp;gt; 0) {
        memset(p, 0, last_argv - p);
    }  
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;稍微解释一下，每一个 c 程序都有个 main 函数，作为程序启动入口函数。main 函数的原型是 &lt;code&gt;int main(int argc , char *argv[])&lt;/code&gt;，其中 &lt;strong&gt;argc&lt;/strong&gt; 表示命令行参数的个数，&lt;strong&gt;argv&lt;/strong&gt; 是一个指针数组，保存所有命令行字符串。Linux进程名称是通过命令行参数 &lt;strong&gt;argv[0]&lt;/strong&gt; 来表示的。&lt;/p&gt;

&lt;p&gt;而进程执行时的环境变量信息的存储地址就是紧接着 &lt;strong&gt;argv&lt;/strong&gt; 之后，通过 &lt;code&gt;char **environ&lt;/code&gt; 变量来获取，类似于下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-08-24-how-to-modify-process-name-argv-info.png&#34; alt=&#34;argv-info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于我们需要修改 &lt;strong&gt;argv[0]&lt;/strong&gt; 的值，有可能新的字符串的长度超过原来 &lt;strong&gt;argv&lt;/strong&gt; 中所有字符串长度的总和，又因为 &lt;strong&gt;environ&lt;/strong&gt; 在内存空间上是紧跟着 &lt;strong&gt;argv&lt;/strong&gt; 的，我们如果直接修改 &lt;strong&gt;argv[0]&lt;/strong&gt; 的值，有可能会覆盖掉 &lt;strong&gt;environ&lt;/strong&gt; 的内存空间，所以需要先将 &lt;strong&gt;environ&lt;/strong&gt; 的内容 copy 到一块新的内存空间，之后再将 &lt;strong&gt;environ&lt;/strong&gt; 指针指向新的空间。&lt;/p&gt;

&lt;h3 id=&#34;php-扩展中遇到的困难&#34;&gt;php 扩展中遇到的困难&lt;/h3&gt;

&lt;p&gt;在修改 php 扩展中 fork 的子进程名称时遇到了问题，由于 php 扩展是注入的方式，提供的动态库，无法获取到从 &lt;strong&gt;main&lt;/strong&gt; 函数传入过来的 &lt;strong&gt;argv&lt;/strong&gt; 参数的地址。&lt;/p&gt;

&lt;p&gt;经过测试，发现 &lt;strong&gt;environ&lt;/strong&gt; 是一个全局变量，可以获取到它的地址，而 &lt;strong&gt;argv&lt;/strong&gt; 中内容可以用另外一种方式取得，通过查看 &lt;code&gt;/proc/10000/cmdline&lt;/code&gt; 中的值（10000是该进程的进程号），可以获取命令行启动参数的字符串（也就是 &lt;strong&gt;argv&lt;/strong&gt; 中的内容，如果 &lt;strong&gt;argv&lt;/strong&gt; 没有被其他代码修改过的话），所以用 &lt;strong&gt;environ&lt;/strong&gt; 的地址减去 &lt;strong&gt;cmdline&lt;/strong&gt; 中字符串的长度就可以得到 &lt;strong&gt;argv[0]&lt;/strong&gt; 的地址。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：需要注意的是 cmdline 不是一个普通文件，不能用 stat 或者 ftell 等函数来获取长度，必须用 read 等读取文件的函数去读取。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;参考代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void set_proctitle_unsafe(const char* new_name)
{
    // 获取该进程的启动参数字符串
    int pid = getpid();
    char file_name[100];
    snprintf(file_name, sizeof(file_name), &amp;quot;/proc/%d/cmdline&amp;quot;, pid);

    int fd = open(file_name, O_RDONLY);
    if (fd &amp;lt; 0)
        return;

    char tempCmd[513];
    long cmd_length = read(fd, tempCmd, sizeof(tempCmd));
    close(fd);

    // 获取 argv[0] 的地址
    char *argv = environ[0];
    argv = argv - cmd_length;

    int size = 0;
    int i;
    // 申请新的空间存放 environ 中内容
    for (i = 0; environ[i]; i++) {
        size += strlen(environ[i]) + 1;
    }
    char* p = (char*)malloc(size);

    char* last_argv = argv;
    last_argv = argv + cmd_length;

    for (i = 0; environ[i]; i++) {
        if (last_argv == environ[i]) {
            size = strlen(environ[i]) + 1;
            last_argv = environ[i] + size;

            memcpy(p, environ[i], size);
            environ[i] = (char*)p;
            p += size;
        }
    }
    last_argv--;

    // 修改 argv[0] 的内容
    strncpy(argv, new_name, last_argv - argv);
    p = (argv) + strlen(argv) + 1;
    if (last_argv - p &amp;gt; 0) {
        memset(p, 0, last_argv - p);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个函数是不安全的，需要小心使用，因为不能确定 &lt;strong&gt;environ&lt;/strong&gt; 的地址是否已经被其他人修改过了，比如在 php 扩展中，有可能已经被其他程序用同样的方法修改过，这样就会造成获取到的 &lt;strong&gt;argv[0]&lt;/strong&gt; 的地址是未知的，执行的程序可能就会出现内存错误。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>go语言中使用smtp发送邮件及smtp协议的相关问题</title>
          <link>http://blog.fatedier.com/2015/08/20/use-smtp-to-sendmail-in-go-and-some-problems-with-smtp</link>
          <pubDate>Thu, 20 Aug 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/08/20/use-smtp-to-sendmail-in-go-and-some-problems-with-smtp</guid>
          <description>

&lt;p&gt;go 的标准库中有一个 smtp 包提供了一个可以非常方便的使用 smtp 协议发送邮件的函数，通常情况下使用起来简单方便，不过我在使用中却意外遇到了一个会导致邮件发送出错的情况。&lt;/p&gt;

&lt;h3 id=&#34;smtp-协议发送邮件&#34;&gt;smtp 协议发送邮件&lt;/h3&gt;

&lt;h4 id=&#34;sendmail-函数&#34;&gt;sendmail 函数&lt;/h4&gt;

&lt;p&gt;go 标准库的 net/smtp 包提供了一个 SendMail 函数用于发送邮件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func SendMail(addr string, a Auth, from string, to []string, msg []byte) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;SendMail&lt;/strong&gt;： 连接到 &lt;strong&gt;addr&lt;/strong&gt; 指定的服务器；如果支持会开启 &lt;strong&gt;TLS&lt;/strong&gt;；如果支持会使用 &lt;strong&gt;a(Auth)&lt;/strong&gt; 认证身份；然后以 &lt;strong&gt;from&lt;/strong&gt; 为邮件源地址发送邮件 &lt;strong&gt;msg&lt;/strong&gt; 到目标地址 &lt;strong&gt;to&lt;/strong&gt;。（可以是多个目标地址：群发）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;addr&lt;/strong&gt;： 邮件服务器的地址。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a&lt;/strong&gt;： 身份认证接口，可以由 &lt;code&gt;func PlainAuth(identity, username, password, host string) Auth&lt;/code&gt; 函数创建。&lt;/p&gt;

&lt;h4 id=&#34;简单发送邮件示例&#34;&gt;简单发送邮件示例&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;net/smtp&amp;quot;
    &amp;quot;strings&amp;quot;
)

func main() {
    auth := smtp.PlainAuth(&amp;quot;&amp;quot;, &amp;quot;username@qq.com&amp;quot;, &amp;quot;passwd&amp;quot;, &amp;quot;smtp.qq.com&amp;quot;)
    to := []string{&amp;quot;to-user@qq.com&amp;quot;}
    nickname := &amp;quot;test&amp;quot;
    user := &amp;quot;username@qq.com&amp;quot;
    subject := &amp;quot;test mail&amp;quot;
    content_type := &amp;quot;Content-Type: text/plain; charset=UTF-8&amp;quot;
    body := &amp;quot;This is the email body.&amp;quot;
    msg := []byte(&amp;quot;To: &amp;quot; + strings.Join(to, &amp;quot;,&amp;quot;) + &amp;quot;\r\nFrom: &amp;quot; + nickname +
        &amp;quot;&amp;lt;&amp;quot; + user + &amp;quot;&amp;gt;\r\nSubject: &amp;quot; + subject + &amp;quot;\r\n&amp;quot; + content_type + &amp;quot;\r\n\r\n&amp;quot; + body)
    err := smtp.SendMail(&amp;quot;smtp.qq.com:25&amp;quot;, auth, user, to, msg)
    if err != nil {
        fmt.Printf(&amp;quot;send mail error: %v&amp;quot;, err)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;autu&lt;/strong&gt;： 这里采用简单的明文用户名和密码的认证方式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;nickname&lt;/strong&gt;： 发送方的昵称。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;subject&lt;/strong&gt;： 邮件主题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;content_type&lt;/strong&gt;： 可以有两种方式，一种 text/plain，纯字符串，不做转义。一种 text/html，会展示成 html 页面。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;body&lt;/strong&gt;： 邮件正文内容。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;msg&lt;/strong&gt;： msg 的内容需要遵循 smtp 协议的格式，参考上例。&lt;/p&gt;

&lt;h3 id=&#34;特定邮件服务器出错&#34;&gt;特定邮件服务器出错&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;certificate signed by unknown authority
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在通过公司内部自己搭建的邮件服务器发送邮件时报了上述错误，看上去是因为认证不通过的问题，检查了一下用户名和密码没有问题。&lt;/p&gt;

&lt;p&gt;我通过抓包以及手动 telnet 执行了一遍 smtp 的过程，发送问题出现在是否加密和身份验证上。&lt;/p&gt;

&lt;h4 id=&#34;smtp-协议&#34;&gt;SMTP 协议&lt;/h4&gt;

&lt;p&gt;smtp 协议开始时客户端主动向邮件服务器发送 &lt;code&gt;EHLO&lt;/code&gt;，服务器会返回支持的所有命令，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;250-PIPELINING
250-SIZE 10240000
250-VRFY
250-ETRN
250-STARTTLS
250-AUTH PLAIN LOGIN
250-AUTH=PLAIN LOGIN
250-ENHANCEDSTATUSCODES
250-8BITMIME
250 DSN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果有 &lt;strong&gt;STARTTLS&lt;/strong&gt;，说明支持加密传输，golang 的标准库中会进行判断然后决定是否选择使用 &lt;strong&gt;STARTTLS&lt;/strong&gt; 加密传输。&lt;/p&gt;

&lt;p&gt;如果没有 &lt;strong&gt;AUTH=PLAIN LOGIN&lt;/strong&gt;，说明不支持 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式。&lt;/p&gt;

&lt;p&gt;一共有3种验证方式，可以参考这篇 blog： &lt;a href=&#34;http://blog.csdn.net/mhfh611/article/details/9470599&#34;&gt;http://blog.csdn.net/mhfh611/article/details/9470599&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;starttls-引起的错误&#34;&gt;STARTTLS 引起的错误&lt;/h4&gt;

&lt;p&gt;公司内部的邮件服务器返回了 &lt;strong&gt;STARTTLS&lt;/strong&gt;，但是实际上却不支持加密传输的认证方式，所以就导致了身份认证失败。&lt;/p&gt;

&lt;p&gt;大部分国内的邮件服务器都支持 &lt;strong&gt;LOGIN&lt;/strong&gt; 和 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式，所以我们可以在代码中直接采用 &lt;strong&gt;PLAIN&lt;/strong&gt; 的方式，不过安全性就降低了。&lt;/p&gt;

&lt;p&gt;想要强制使用 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式也不是这么容易的，因为涉及到修改 &lt;strong&gt;net/smtp&lt;/strong&gt; 的 &lt;code&gt;SendMail&lt;/code&gt; 函数，当然标准库我们修改不了，所以只能重新实现一个 &lt;code&gt;SendMail&lt;/code&gt; 函数。&lt;/p&gt;

&lt;p&gt;标准库中 &lt;code&gt;SendMail&lt;/code&gt; 函数代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func SendMail(addr string, a Auth, from string, to []string, msg []byte) error {
    c, err := Dial(addr)
    if err != nil {
        return err
    }
    defer c.Close()
    if err = c.hello(); err != nil {
        return err
    }
    if ok, _ := c.Extension(&amp;quot;STARTTLS&amp;quot;); ok {
        config := &amp;amp;tls.Config{ServerName: c.serverName}
        if testHookStartTLS != nil {
            testHookStartTLS(config)
        }
        if err = c.StartTLS(config); err != nil {
            return err
        }
    }
    if a != nil &amp;amp;&amp;amp; c.ext != nil {
        if _, ok := c.ext[&amp;quot;AUTH&amp;quot;]; ok {
            if err = c.Auth(a); err != nil {
                return err
            }
        }
    }
    if err = c.Mail(from); err != nil {
        return err
    }
    for _, addr := range to {
        if err = c.Rcpt(addr); err != nil {
            return err
        }
    }
    w, err := c.Data()
    if err != nil {
        return err
    }
    _, err = w.Write(msg)
    if err != nil {
        return err
    }
    err = w.Close()
    if err != nil {
        return err
    }
    return c.Quit()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重点就在于下面这一段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;if ok, _ := c.Extension(&amp;quot;STARTTLS&amp;quot;); ok {
    config := &amp;amp;tls.Config{ServerName: c.serverName}
    if testHookStartTLS != nil {
        testHookStartTLS(config)
    }
    if err = c.StartTLS(config); err != nil {
        return err
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;逻辑上就是检查服务器端对于 &lt;strong&gt;EHLO&lt;/strong&gt; 命令返回的所支持的命令中是否有 &lt;strong&gt;STARTTLS&lt;/strong&gt;，如果有，则采用加密传输的方式。我们自己实现的函数中直接把这部分去掉。&lt;/p&gt;

&lt;p&gt;我们仿照 &lt;code&gt;SendMail&lt;/code&gt; 函数实现一个 &lt;code&gt;NewSendMail&lt;/code&gt; 函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func NewSendMail(addr string, a smtp.Auth, from string, to []string, msg []byte) error {
    c, err := smtp.Dial(addr)
    if err != nil {
        return err 
    }   
    defer c.Close()
    if err = c.Hello(&amp;quot;localhost&amp;quot;); err != nil {
        return err 
    }   
    err = c.Auth(a)
    if err != nil {
        return err 
    }   

    if err = c.Mail(from); err != nil {
        fmt.Printf(&amp;quot;mail\n&amp;quot;)
        return err 
    }   
    for _, addr := range to {
        if err = c.Rcpt(addr); err != nil {
            return err 
        }   
    }
    w, err := c.Data()
    if err != nil {
        return err
    }
    _, err = w.Write(msg)
    if err != nil {
        return err
    }
    err = w.Close()
    if err != nil {
        return err
    }
    return c.Quit()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个函数发送邮件，则身份认证时不会采用加密的方式，而是直接使用 &lt;strong&gt;PLAIN&lt;/strong&gt; 方式。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>关于vim的一些小技巧</title>
          <link>http://blog.fatedier.com/2015/07/30/some-skills-about-vim</link>
          <pubDate>Thu, 30 Jul 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/07/30/some-skills-about-vim</guid>
          <description>

&lt;p&gt;记录一下关于 vim 中一些使用频率也许并不高的小技巧。&lt;/p&gt;

&lt;h3 id=&#34;插入与删除&#34;&gt;插入与删除&lt;/h3&gt;

&lt;h4 id=&#34;插入&#34;&gt;插入&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;A&lt;/code&gt; 在行末插入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;I&lt;/code&gt; 在行首插入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;O&lt;/code&gt; 在上一行插入&lt;/p&gt;

&lt;h4 id=&#34;替换字符&#34;&gt;替换字符&lt;/h4&gt;

&lt;p&gt;普通模式下，先按下 &lt;code&gt;r&lt;/code&gt; 再按下其他按键，就是使用新的字符替换旧字符。&lt;/p&gt;

&lt;h4 id=&#34;删除&#34;&gt;删除&lt;/h4&gt;

&lt;p&gt;普通模式下，&lt;code&gt;ct;&lt;/code&gt; 依次按下三个按键，&lt;code&gt;c&lt;/code&gt; 表示删除这部分内容后直接进行插入模式，&lt;code&gt;t;&lt;/code&gt; 表示从当前位置到这一行中下一个出现 &lt;code&gt;;&lt;/code&gt; 号之前的位置，合在一起就是删除这之间的内容。 &lt;code&gt;c&lt;/code&gt; 换成 &lt;code&gt;d&lt;/code&gt; 的话就是删除当前位置到这一行中下一个出现 &lt;code&gt;;&lt;/code&gt; 之前的内容，但是不进入插入模式。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;di&amp;quot;&lt;/code&gt; 将当前行第一次出现两个 &lt;code&gt;&amp;quot;&lt;/code&gt; 之间的内容全部清空并且进入插入模式。&lt;/p&gt;

&lt;h3 id=&#34;移动&#34;&gt;移动&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;f;&lt;/code&gt; 表示移动到这一行中下一个 &lt;code&gt;;&lt;/code&gt; 号的位置。&lt;/p&gt;

&lt;h3 id=&#34;vimgrep&#34;&gt;vimgrep&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;vimgrep /匹配模式/[g][j]&lt;/code&gt; 要搜索的文件/范围&lt;/p&gt;

&lt;p&gt;&lt;code&gt;g&lt;/code&gt; 表示是否把每一行的多个匹配结果都加入&lt;/p&gt;

&lt;p&gt;&lt;code&gt;j&lt;/code&gt; 表示是否搜索完后定位到第一个匹配位置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vimgrep /pattern/ %           // 在当前打开文件中查找
vimgrep /pattern/ *           // 在当前目录下查找所有
vimgrep /pattern/ **          // 在当前目录及子目录下查找所有
vimgrep /pattern/ *.c         // 查找当前目录下所有.c文件
vimgrep /pattern/ **/*        // 只查找子目录
cn                            // 查找下一个
cp                            // 查找上一个
copen                         // 打开quickfix
cw                            // 打开quickfix
cclose                        // 关闭qucikfix
help vimgrep                  // 查看vimgrep帮助
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;从vim正文复制单词到vim命令行&#34;&gt;从vim正文复制单词到vim命令行&lt;/h3&gt;

&lt;p&gt;例如使用 &lt;code&gt;vimgrep&lt;/code&gt; 搜索时，光标先移动到要复制的单词的起始位置，之后切到命令模式， 先按 &lt;code&gt;ctrl + r&lt;/code&gt; ，之后再按 &lt;code&gt;ctrl + w&lt;/code&gt; 即可。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MongoDB常用命令</title>
          <link>http://blog.fatedier.com/2015/06/05/common-commands-of-mongodb</link>
          <pubDate>Fri, 05 Jun 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/06/05/common-commands-of-mongodb</guid>
          <description>

&lt;p&gt;MongoDB 是一个基于分布式文件存储的数据库，由C++编写，介于关系数据库和非关系数据库之间的产品，所以在很多业务上可以取代 mysql，提供更高的性能以及更好的扩展性。虽然 MongoDB 不支持 sql 语法，但是从常用的操作命令上来说和 sql 的用法相类似。&lt;/p&gt;

&lt;h4 id=&#34;查询有哪些数据库&#34;&gt;查询有哪些数据库&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;show dbs&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;切换数据库&#34;&gt;切换数据库&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;use &amp;lt;db_name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果数据库不存在，则创建数据库，否则切换到指定数据库。但是只有在数据库中插入数据，才会在查询数据库列表时显示。&lt;/p&gt;

&lt;h4 id=&#34;查询当前数据库的所有集合&#34;&gt;查询当前数据库的所有集合&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.getCollectionNames()&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查看指定集合的状态信息&#34;&gt;查看指定集合的状态信息&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.&amp;lt;collection_name&amp;gt;.stats()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;ns&amp;quot; : &amp;quot;&amp;lt;db_name&amp;gt;.&amp;lt;collection_name&amp;gt;&amp;quot;,
    &amp;quot;count&amp;quot; : 1,
    &amp;quot;size&amp;quot; : 4080,
    &amp;quot;avgObjSize&amp;quot; : 4080,
    &amp;quot;numExtents&amp;quot; : 1,
    &amp;quot;storageSize&amp;quot; : 8192,
    &amp;quot;lastExtentSize&amp;quot; : 8192,
    &amp;quot;paddingFactor&amp;quot; : 1,
    &amp;quot;paddingFactorNote&amp;quot; : &amp;quot;paddingFactor is unused and unmaintained in 3.0. It remains hard coded to 1.0 for compatibility only.&amp;quot;,
    &amp;quot;userFlags&amp;quot; : 1,
    &amp;quot;capped&amp;quot; : false,
    &amp;quot;nindexes&amp;quot; : 1,
    &amp;quot;totalIndexSize&amp;quot; : 8176,
    &amp;quot;indexSizes&amp;quot; : {
        &amp;quot;_id_&amp;quot; : 8176
    },
    &amp;quot;ok&amp;quot; : 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看当前数据库中的所有的索引&#34;&gt;查看当前数据库中的所有的索引&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.system.indexes.find()&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;查看指定集合中的索引&#34;&gt;查看指定集合中的索引&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.col.getIndexes()&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;创建指定集合中的索引&#34;&gt;创建指定集合中的索引&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.col.ensureIndex({&amp;quot;name&amp;quot;: 1, &amp;quot;age&amp;quot;: -1})&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;根据 name 和 age 进行索引，1表示升序，-1表示降序。&lt;/p&gt;

&lt;h4 id=&#34;查看集合中的文档&#34;&gt;查看集合中的文档&lt;/h4&gt;

&lt;h5 id=&#34;查询所有文档&#34;&gt;查询所有文档&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;以易读的方式显示文档内容&#34;&gt;以易读的方式显示文档内容&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find().pretty()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查询前10个文档&#34;&gt;查询前10个文档&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find().limit(10)&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查询结果排序展示&#34;&gt;查询结果排序展示&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.col.find().sort({&#39;clock&#39;:-1})&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查询结果按照 clock 排序展示，1 为升序，-1 为降序。&lt;/p&gt;

&lt;h5 id=&#34;where-条件&#34;&gt;where 条件&lt;/h5&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;操作&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;范例&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;RDBMS中的类似语句&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:&amp;ldquo;value&amp;rdquo;}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key = &amp;lsquo;value&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;小于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$lt:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;lt; 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;小于等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$lte:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;lt;= 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;大于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$gt:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;gt; 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;大于或等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$gte:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key &amp;gt;= 50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;不等于&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;db.col.find({&amp;ldquo;key&amp;rdquo;:{$ne:50}}).pretty()&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;where key != 50&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&#34;and-条件&#34;&gt;and 条件&lt;/h5&gt;

&lt;p&gt;find() 方法可以传入多个键，每个键以逗号隔开。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;db.col.find({key1:value1, key2:value2}).pretty()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;or-条件&#34;&gt;or 条件&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;db.col.find(
    {
        $or: [
            {key1: value1}, {key2:value2}
        ]
    }
).pretty()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如 &lt;code&gt;db.col.find({$or:[{&amp;quot;key1&amp;quot;:&amp;quot;value1&amp;quot;}, {&amp;quot;key2&amp;quot;: &amp;quot;value2&amp;quot;}]}).pretty()&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;更新操作&#34;&gt;更新操作&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;db.collection.update( query, update, upsert, multi )&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;query&lt;/strong&gt;： update 的查询条件，类似 sql update 操作的 where 子句。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;update&lt;/strong&gt;： update 的对象和一些更新的操作符（如$set, $inc&amp;hellip;）等，也可以理解为 sql update 操作的 set 子句。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;upsert&lt;/strong&gt;： 可选，这个参数的意思是，如果不存在 update 的记录，是否插入新的记录，true 为插入，默认是 false，不插入。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;multi&lt;/strong&gt;： 可选，默认为 false，只更新找到的第一条记录，如果这个参数为 true，就把按条件查出来多条记录全部更新。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;db.agent_conf.update({hostid:137}, {$set: {upload:{interval:10}}}, true)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;将 agent_conf 集合中 hostid = 137 的记录将 upload.interval 的值修改为 3，如果不存在就插入，只修改匹配的第一条。&lt;/p&gt;

&lt;h4 id=&#34;删除操作&#34;&gt;删除操作&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;db.col.remove({id:1})&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;remove 的过滤条件同 find。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>python中使用pycurl库上传文件</title>
          <link>http://blog.fatedier.com/2015/05/08/upload-file-in-python-using-pycurl</link>
          <pubDate>Fri, 08 May 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/05/08/upload-file-in-python-using-pycurl</guid>
          <description>

&lt;p&gt;在对外提供各种语言SDK的时候经常会遇到需要上传文件的问题，例如在python中我们可以借助pycurl库实现这个功能。&lt;/p&gt;

&lt;h3 id=&#34;项目地址&#34;&gt;项目地址&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/pycurl/pycurl&#34;&gt;https://github.com/pycurl/pycurl&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;示例代码&#34;&gt;示例代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pycurl
import StringIO

# 用于执行http请求的通用函数
# post_data: post参数字符串
# upload_file: dict类型，需要有file_path(指定要上传的文件路径)和file_name(指定上传后的文件名)
def do_http_request(method, url, post_data=&#39;&#39;, upload_file=None): 
    ch = pycurl.Curl() 
    buf = StringIO.StringIO() 
    ch.setopt(ch.URL, url) 
    ch.setopt(ch.CUSTOMREQUEST, method) 
    if upload_file != None: 
        ch.setopt(ch.HTTPPOST, [(&#39;file&#39;, (ch.FORM_FILE, upload_file[&#39;file_path&#39;], \ 
            ch.FORM_FILENAME, upload_file[&#39;file_name&#39;]))]) 
    else: 
        if method == self.METHOD_POST: 
            ch.setopt(ch.POSTFIELDS,  urlencode(post_data)) 

    ch.setopt(ch.TIMEOUT, 30) 
    ch.setopt(ch.WRITEFUNCTION, buf.write)
    ch.perform() 
    content = buf.getvalue()
    buf.close()
    ch.close()
    return content
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码是一个用pycurl库写的调用http请求的通用函数，如果upload_file不为None，则表示需要上传文件，upload_file是一个dict类型，需要有两个key，file_path(指定要上传的文件路径)和file_name(指定上传后的文件名)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ch.FORM_FILE&lt;/strong&gt;：指定要上传文件的路径&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ch.FORM_FILENAME&lt;/strong&gt;：指定要上传文件的文件名&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>在C&#43;&#43;中利用反射和简单工厂模式实现业务模块解耦</title>
          <link>http://blog.fatedier.com/2015/03/04/decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp</link>
          <pubDate>Wed, 04 Mar 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/03/04/decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp</guid>
          <description>

&lt;p&gt;在设计一个系统框架的时候往往需要划分各个模块、组件，抽象出公共的部分，尽量避免耦合，以利于以后的扩展和复用。在这方面，JAVA的很多特性在利用各种设计模式的时候会非常容易，而在C++中就需要自己去一步步实现。&lt;/p&gt;

&lt;h3 id=&#34;业务说明&#34;&gt;业务说明&lt;/h3&gt;

&lt;p&gt;为了便于说明，举一个简单的例子。假设现在有一个项目需要建立一个和银行交互的平台，目前只接入工商银行，后续接入其他银行，每个银行的业务都有差异，报文格式可能也不一致。&lt;/p&gt;

&lt;p&gt;这里只列举几个简要的流程，仅包括拼报文，发送报文，接收报文，解析报文，其余整体架构以及后续处理等内容省略。&lt;/p&gt;

&lt;h3 id=&#34;初步设计&#34;&gt;初步设计&lt;/h3&gt;

&lt;p&gt;创建一个银行交互类 BankOpt，包括四个函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int setMsg();       // 拼报文
int sendMsg();      // 发送报文
int getMsg();       // 接收报文
int parseMsg();     // 解析报文
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在每个函数中通过if-else来判断具体是哪一个银行，之后进行相应的处理。&lt;/p&gt;

&lt;p&gt;这种设计在刚开发的时候非常方便，代码量少，但是如果后续需要接入另外一个银行时就需要改动 &lt;strong&gt;BankOpt&lt;/strong&gt; 类，不符合设计模式中的开放-封闭原则。而且单个函数中将来可能会有大量的 &lt;strong&gt;if-else&lt;/strong&gt;，使代码可读性下降。&lt;/p&gt;

&lt;h3 id=&#34;简单工厂模式&#34;&gt;简单工厂模式&lt;/h3&gt;

&lt;p&gt;通过简单工厂模式，我们可以创建一个专门的工厂类用于实例化一个合适的银行交互类，只需要这个银行交互类具有共同的接口即可。&lt;/p&gt;

&lt;p&gt;首先，为了实现更好的复用，把各个银行交互类中相同的部分抽象出来，形成一个银行交互基类，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;class BaseBank
{
public:
    virtual int setMsg() = 0;
    virtual int sendMsg() = 0;
    virtual int getMsg() = 0;
    virtual int parseMsg() = 0;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里仅仅声明了四个纯虚函数，具体的业务逻辑在子类中实现。&lt;/p&gt;

&lt;p&gt;创建两个银行交互子类GSBank（工商银行）和RMBank（人民银行），继承BaseBank，实现四个虚函数。&lt;/p&gt;

&lt;h4 id=&#34;创建一个工厂类&#34;&gt;创建一个工厂类&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;class BankFactory
{
public:
    BaseBank* createBank(const string&amp;amp; bank_name) {
    if (bank_name == &amp;quot;SBank&amp;quot;) 
        return new GSBank();
    else if (bank_name == &amp;quot;MBank&amp;quot;)
        return new RMBank();
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;工厂类中有一个 &lt;strong&gt;createBank&lt;/strong&gt; 函数，用于根据银行编码创建相应的实例并返回其基类指针，这样我们只需要通过基类指针调用相关函数即可。&lt;/p&gt;

&lt;h4 id=&#34;在主流程中调用&#34;&gt;在主流程中调用&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;BankFactory bf;
BaseBank* t = (BaseBank*)bf.createBank(bank_name);
if (t == NULL) {
    cout &amp;lt;&amp;lt; &amp;quot;银行编码错误！&amp;quot; &amp;lt;&amp;lt; endl;
    return 2;
}
t-&amp;gt;setMsg();
t-&amp;gt;sendMsg();
t-&amp;gt;getMsg();
t-&amp;gt;parseMsg();
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;优缺点&#34;&gt;优缺点&lt;/h4&gt;

&lt;p&gt;利用简单工厂模式，当我们后续接入另外的银行时，只需要添加具体的银行交互类，实现业务函数，然后在工厂类的 &lt;strong&gt;createBank&lt;/strong&gt; 函数中添加一个 &lt;strong&gt;else if&lt;/strong&gt; 子句。相对于原来的设计已经改进很多了，但是仍然需要修改原来的工厂类的代码，没有彻底实现解耦。&lt;/p&gt;

&lt;h3 id=&#34;反射&#34;&gt;反射&lt;/h3&gt;

&lt;p&gt;反射在java的一些框架中使用的比较多，而且用起来非常方便。C++本身并不支持，但是我们可以模拟一些简单的特性。&lt;/p&gt;

&lt;p&gt;我们需要一种能够根据字符串动态获取对应的银行交互类的实例的方法。这样在工厂类的 &lt;strong&gt;createBank&lt;/strong&gt; 方法中就可以根据字符串直接获取对应银行交互类的实例，而不需要再每次通过新增 &lt;strong&gt;else if&lt;/strong&gt; 子句来新增一个银行接口。&lt;/p&gt;

&lt;p&gt;也就是说，利用反射和简单工厂模式，下次当我们需要新增一个银行接口的时候只需要新增一个银行交互类即可，不需要修改原来的任何代码，实现了业务上的解耦。&lt;/p&gt;

&lt;h4 id=&#34;如何在c-中实现反射&#34;&gt;如何在C++中实现反射&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;需要一个全局的map用于存储类的信息以及创建实例的函数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;需要反射的类需要提供一个用于创建自身实例的函数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;利用类的静态变量在程序启动的时候会进行初始化来在全局map中将类名及创建实例的函数存入map中&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;相关代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef void* (*register_func)();

class Class
{
public:
static void* newInstance(const string&amp;amp; class_name) {
    map&amp;lt;string, register_func&amp;gt;::iterator it = m_register.find(class_name);
    if (it == m_register.end())
        return NULL;
    else
        return it-&amp;gt;second();
}
static void registerClass(const string&amp;amp; class_name, register_func func) {
    m_register[class_name] = func;
}

private:
    /* key is class name and value is function to create instance of class */
    static map&amp;lt;string, register_func&amp;gt; m_register;
};


class Register
{
public:
    Register(const string&amp;amp; class_name, register_func func) {
        Class::registerClass(class_name, func);
    }
};

#define REGISTER_CLASS(class_name) \
    class class_name##Register { \
    public: \
        static void* newInstance() { \
            return new class_name; \
        } \
    private: \
        static const Register reg; \
    };\
const Register class_name##Register::reg(#class_name,class_name##Register::newInstance);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还需要修改工厂类的 &lt;strong&gt;createBank&lt;/strong&gt; 函数，利用Class的 &lt;strong&gt;newInstance&lt;/strong&gt; 函数来创建实例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;BaseBank* createBank(const string&amp;amp; bank_name) {
    return (BaseBank*)Class::newInstance(bank_name);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Class类中的 &lt;strong&gt;m_register&lt;/strong&gt; 变量是 &lt;strong&gt;static&lt;/strong&gt; 类型的map，相当于全局变量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;newInstance&lt;/strong&gt; 函数，传入类名，查找map，调用回调函数，返回一个对应类的实例。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;registerClass&lt;/strong&gt; 函数传入类名和用于创建实例的回调函数并将信息存入全局的map中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Register&lt;/strong&gt; 类只有一个构造函数，会调用Class的 &lt;strong&gt;registerClass&lt;/strong&gt; 函数完成注册。&lt;/p&gt;

&lt;p&gt;利用宏定义，在每一个需要反射的类后面额外增加一个类，其中有一个 &lt;strong&gt;Register&lt;/strong&gt; 类型的 &lt;strong&gt;static const&lt;/strong&gt; 变量，这样在程序启动的时候就会完成初始化调用 &lt;strong&gt;Register&lt;/strong&gt; 类的构造函数，完成注册。&lt;/p&gt;

&lt;p&gt;之后只需要在需要反射的类，例如在工商银行交互类 GSBank 后面加上一条宏定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;REGISTER_CLASS(GSBank)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以通过工厂类传入 &amp;ldquo;GSBank&amp;rdquo; 字符串获得工商银行交互类的实例。&lt;/p&gt;

&lt;h3 id=&#34;测试&#34;&gt;测试&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-03-04-decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp-gsbank.jpg&#34; alt=&#34;GSBANK&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2015/2015-03-04-decoupling-by-using-reflect-and-simple-factory-pattern-in-cpp-rmbank.jpg&#34; alt=&#34;RMBANK&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过传入不同的银行编码，会实例化不同的银行交互类，并且执行其对应的函数。&lt;/p&gt;

&lt;p&gt;如果需要增加新的银行接口，例如农业银行，只需要新增一个 &lt;strong&gt;NYBank&lt;/strong&gt; 类，实现具体的业务逻辑，不需要改动原来的任何代码，传入 &lt;strong&gt;NYBank&lt;/strong&gt; 字符串，就会执行农业银行相关的处理流程。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>epoll使用说明</title>
          <link>http://blog.fatedier.com/2015/01/25/introduction-of-using-epoll</link>
          <pubDate>Sun, 25 Jan 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2015/01/25/introduction-of-using-epoll</guid>
          <description>

&lt;p&gt;在《UNIX网络编程》一书中介绍了如何使用select/poll来实现I/O多路复用，简而言之就是通过内核的一种机制，监视多个文件描述符，一旦某个文件描述符处于就绪状态，就通知用户程序进行相应的读写操作，这样用户程序就不用阻塞在每一个文件描述符上。&lt;/p&gt;

&lt;p&gt;epoll相对于select/poll来说有很大优势：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;不再需要每次把fd集合从用户态拷贝到内核态。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;不再需要在每次就绪时遍历fd集合中的所有fd来检查哪些fd处于就绪状态，epoll只返回就绪的fd集合。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;select一般只支持1024个文件描述符，而epoll没有类似的限制。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;epoll相关函数&#34;&gt;epoll相关函数&lt;/h3&gt;

&lt;p&gt;使用epoll只需要记住3个系统调用函数。&lt;/p&gt;

&lt;h4 id=&#34;int-epoll-create-int-size&#34;&gt;int epoll_create(int size)&lt;/h4&gt;

&lt;p&gt;创建一个epoll实例，从2.68的Linux内核开始，size参数不再生效，内核会动态分配所需的数据结构。失败返回-1，成功则该函数会返回一个文件描述符，并占用一个fd值，所以在使用完之后要记得close该文件描述符。&lt;/p&gt;

&lt;h4 id=&#34;int-epoll-ctl-int-epfd-int-op-int-fd-struct-epoll-event-event&#34;&gt;int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)&lt;/h4&gt;

&lt;p&gt;用于对epoll实例执行不同的操作的函数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;epfd&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用epoll_create()返回的文件描述符&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;op&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用三个宏表示不同的操作&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;EPOLL_CTL_ADD：注册新的fd到epfd中；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;EPOLL_CTL_MOD：修改已经注册的fd的监听事件；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;EPOLL_CTL_DEL：从epfd中删除指定fd；&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;fd&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;要监听的文件描述符&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;event&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;event 是与指定fd关联的epoll_event结构，包含了监听事件，附加数据&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;struct epoll_event&lt;/strong&gt; 的结构如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef union epoll_data {
    void        *ptr;
    int          fd;
    __uint32_t   u32;
    __uint64_t   u64;
}epoll_data_t;
 
struct epoll_event {
    __uint32_t  events;      /* Epoll events */
    epoll_data_t data;       /* User data variable */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;这里需要特别注意的是epoll_data_t是一个union结构，fd和ptr指针只能使用一个，通常我们使用void *ptr存储需要附加的用户数据结构，然后在用户数据结构中存储int型的fd，这样在epoll_wait调用后就仍然能获得该注册事件对应的文件描述符。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;events可以是如下值的集合&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）
EPOLLOUT：表示对应的文件描述符可以写
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）
EPOLLERR：表示对应的文件描述符发生错误
EPOLLHUP：表示对应的文件描述符被挂断
EPOLLET： 将EPOLL设为边缘触发(EdgeTriggered)模式，这是相对于水平触发(Level Triggered)来说的
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;int-epoll-wait-int-epfd-struct-epoll-event-events-int-maxevents-int-timeout&#34;&gt;int epoll_wait(int epfd, struct epoll_event * events, int maxevents,int timeout)&lt;/h4&gt;

&lt;p&gt;该函数等待epoll实例中的fd集合有就绪事件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;epfd：使用epoll_create()返回的文件描述符
events：指向处于就绪状态的事件集合
maxevents：最多maxevents数量的事件集合会被返回
timeout：超时时间，单位为毫秒；指定为-1没有超时时间，指定为0则立即返回并返回0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果成功，返回已就绪的事件的个数；如果达到超时时间仍然没有就绪事件，返回0；如果出现错误，返回-1并置errno值&lt;/p&gt;

&lt;h3 id=&#34;lt和et两种工作方式&#34;&gt;LT和ET两种工作方式&lt;/h3&gt;

&lt;p&gt;epoll 默认使用LT的工作方式，当指定事件就绪时，内核通知用户进行操作，如果你只处理了部分数据，只要对应的套接字缓冲区中还有剩余数据，下一次内核仍然还会继续通知用户去进行处理，所以使用这种模式来写程序较为简单。&lt;/p&gt;

&lt;p&gt;ET工作方式是一种高速工作方式，只能使用非阻塞socket，它的效率要比LT方式高。当一个新事件就绪时，内核通知用户进行操作，如果这时用户没有处理完缓冲区的数据，缓冲区中剩余的数据就会丢失，用户无法从下一次epoll_wait调用中获取到这个事件。&lt;/p&gt;

&lt;p&gt;举个例子，可以指定事件为 EPOLLIN| EPOLLET 来使用ET工作方式获取指定文件描述符的可读事件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在该事件就绪后，需要不断调用read函数来获取缓冲区数据，直到产生一个EAGAIN错误或者read函数返回的读取到的数据长度小于请求的数据长度时才认为此事件处理完成。write也是一样的处理方式。&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>如何处理僵尸进程</title>
          <link>http://blog.fatedier.com/2014/12/16/how-to-deal-with-zombie-process</link>
          <pubDate>Tue, 16 Dec 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/12/16/how-to-deal-with-zombie-process</guid>
          <description>

&lt;p&gt;在使用c/c++开发过程中经常会用到多进程，需要fork一些子进程，但是如果不注意的话，就有可能导致子进程结束后变成了僵尸进程。从而逐渐耗尽系统资源。&lt;/p&gt;

&lt;h3 id=&#34;什么是僵尸进程&#34;&gt;什么是僵尸进程&lt;/h3&gt;

&lt;p&gt;如果父进程在子进程之前终止，则所有的子进程的父进程都会改变为init进程，我们称这些进程由init进程领养。这时使用ps命令查看后可以看到子进程的父进程ppid已经变为了1。&lt;/p&gt;

&lt;p&gt;而当子进程在父进程之前终止时，&lt;strong&gt;内核为每个终止子进程保存了一定量的信息，所以当终止进程的父进程调用wait或waitpid时&lt;/strong&gt;，可以得到这些信息。这些信息至少包括进程ID、该进程的终止状态、以及该进程使用的CPU时间总量。其他的进程所使用的存储区，打开的文件都会被内核释放。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一个已经终止、但是其父进程尚未对其进行善后处理（获取终止子进程的有关信息，释放它仍占用的资源）的进程被称为僵尸进程。&lt;/strong&gt; ps命令将僵尸进程的状态打印为Z。&lt;/p&gt;

&lt;p&gt;可以设想一下，比如一个web服务器端，假如每次接收到一个连接都创建一个子进程去处理，处理完毕后结束子进程。假如在父进程中没有使用wait或waitpid函数进行善后，这些子进程将全部变为僵尸进程，Linux系统的进程数一般有一个固定限制值，僵尸进程将会逐渐耗尽系统资源。&lt;/p&gt;

&lt;h3 id=&#34;查看僵尸进程的例子&#34;&gt;查看僵尸进程的例子&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
 
int main(int argc, char **argv)
{
    pid_t pid;
    for (int i=0; i&amp;lt;5; i++) {
        if ((pid = fork()) &amp;lt; 0) {
            printf(&amp;quot;fork error,%s\n&amp;quot;, strerror(errno));
            return -1;
        }
        
        /* child */
        if (pid == 0) {
            sleep(1);
            exit(0);
        }
    }  
    /* parent */
    sleep(20);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译完成后，在执行程序的命令后加上 &amp;ldquo;&amp;amp;&amp;rdquo; 符号，表示让当前程序在后台运行。&lt;/p&gt;

&lt;p&gt;之后输入&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ps –e –o pid,ppid,stat,command|grep [程序名]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到如下的结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;2915  1961 S    ./dd
2917  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2918  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2919  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2920  2915 Z    [dd] &amp;lt;defunct&amp;gt;
2921  2915 Z    [dd] &amp;lt;defunct&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到5个子进程都已经是僵尸进程了。&lt;/p&gt;

&lt;h3 id=&#34;sigchld信号和处理僵尸进程&#34;&gt;SIGCHLD信号和处理僵尸进程&lt;/h3&gt;

&lt;p&gt;当子进程终止时，内核就会向它的父进程发送一个SIGCHLD信号，父进程可以选择忽略该信号，&lt;strong&gt;也可以提供一个接收到信号以后的处理函数&lt;/strong&gt;。对于这种信号的系统默认动作是忽略它。&lt;/p&gt;

&lt;p&gt;我们不希望有过多的僵尸进程产生，所以当父进程接收到SIGCHLD信号后就应该调用 wait 或 waitpid 函数对子进程进行善后处理，释放子进程占用的资源。&lt;/p&gt;

&lt;p&gt;下面是一个捕获SIGCHLD信号以后使用wait函数进行处理的简单例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;lt;sys/wait.h&amp;gt;
 
void deal_child(int sig_no)
{
    wait(NULL);
}
 
int main(int argc, char **argv)
{
    signal(SIGCHLD, deal_child);
 
    pid_t pid;
    for (int i=0; i&amp;lt;5; i++) {
        if ((pid = fork()) &amp;lt; 0) {
            printf(&amp;quot;fork error,%s\n&amp;quot;,strerror(errno));
            return -1;
        }  
 
        /* child */
        if (pid == 0) {
            sleep(1);
            exit(0);
        }  
    }  
    /* parent */
    for(int i=0; i&amp;lt;100000; i++) {
        for (int j=0; j&amp;lt;100000; j++) {
            int temp = 0;
        }  
    }  
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样在后台运行后使用ps命令查看进程状态，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;6622  1961 R    ./dd
6627  6622 Z    [dd] &amp;lt;defunct&amp;gt;
6628  6622 Z    [dd] &amp;lt;defunct&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现创建的5个进程，有3个已经被彻底销毁，但是还有2个仍然处于僵尸进程的状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这是因为当5个进程同时终止的时候，内核都会向父进程发送SIGCHLD信号，而父进程此时有可能仍然处于信号处理的deal_child函数中，那么在处理完之前，中间接收到的SIGCHLD信号就会丢失，内核并没有使用队列等方式来存储同一种信号。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;正确地处理僵尸进程的方法&#34;&gt;正确地处理僵尸进程的方法&lt;/h3&gt;

&lt;p&gt;为了解决上面出现的这种问题，我们需要使用waitpid函数。&lt;/p&gt;

&lt;p&gt;函数原型&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;pid_t waitpid(pid_t pid, int *statloc, int options);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;若成功则返回进程ID，如果设置为非阻塞方式，返回0表示子进程状态未改变，出错时返回-1。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;options参数可以设置为WNOHANG常量，表示waitpid不阻塞，如果由pid指定的子进程不是立即可用的，则立即返回0。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;只需要修改一下SIGCHLD信号的处理函数即可:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void deal_child(int sig_no)
{
    for (;;) {
        if (waitpid(-1, NULL, WNOHANG) == 0)
            break;
    }  
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再次执行程序后使用ps命令查看，发现已经不会产生僵尸进程了。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>linux core文件调试</title>
          <link>http://blog.fatedier.com/2014/12/07/debug-with-linux-core-file</link>
          <pubDate>Sun, 07 Dec 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/12/07/debug-with-linux-core-file</guid>
          <description>

&lt;p&gt;在完成公司项目，测试进程的时候，经常会发现日志到了某一段特定的代码的时候就没了，进程直接退出，也没有捕获到任何的异常信息，如果日志打印的较多还可能比较容易发现问题
题，如果日志较少，就很难进行进一步的查错了。但是发现在该目录下生成了一个core文件，可以帮助我们查找程序崩溃的原因。&lt;/p&gt;

&lt;h3 id=&#34;什么是core文件&#34;&gt;什么是core文件&lt;/h3&gt;

&lt;p&gt;在linux系统下，如果进程不能正常运行，就可能会产生core文件。core文件就是当前内存状态的一个映像，同时加上一些调试信息。&lt;/p&gt;

&lt;p&gt;bug和操作系统或硬件的保护机制都会导致程序异常终止，操作系统会kill掉这些进程并产生core文件，比如常见的段错误等。&lt;/p&gt;

&lt;h3 id=&#34;为什么我的linux不会生成core文件&#34;&gt;为什么我的linux不会生成core文件&lt;/h3&gt;

&lt;p&gt;使用 &lt;code&gt;ulimit -a&lt;/code&gt; 命令可以查看当前系统资源的一些限制信息，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-t: cpu time (seconds)              unlimited
-f: file size (blocks)              unlimited
-d: data seg size (kbytes)          unlimited
-s: stack size (kbytes)             8192
-c: core file size (blocks)         0
-m: resident set size (kbytes)      unlimited
-u: processes                       3847
-n: file descriptors                1024
-l: locked-in-memory size (kbytes)  64
-v: address space (kbytes)          unlimited
-x: file locks                      unlimited
-i: pending signals                 3847
-q: bytes in POSIX msg queues       819200
-e: max nice                        0
-r: max rt priority                 0
-N 15:                              unlimited
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的 &lt;strong&gt;-c: core file size&lt;/strong&gt; 如果设置为0的话，当程序崩溃的时候就不会产生core文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ulimit -c unlimited
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;设置core文件大小为无限&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ulimit -c 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;阻止系统生成core文件&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：这条命令只在当前生效，如果希望永久生效，就需要在 .bash_profile 或者类似文件中加上这条命令。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;设置core-dump的核心转储文件目录和命名规则&#34;&gt;设置Core Dump的核心转储文件目录和命名规则&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;/proc/sys/kernel/core_uses_pid&lt;/strong&gt; 可以控制产生的core文件的文件名中是否添加pid作为扩展，如果添加则文件内容为1，否则为0。需要有超级用户的权限才能进行修改。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;/proc/sys/kernel/core_pattern&lt;/strong&gt; 可以设置格式化的 core文件保存位置或文件名，默认的是 &lt;strong&gt;|/usr/libexec/abrt-hook-ccpp %s %c %p %u %g %t e&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;需要修改的话，可以使用这条命令：&lt;code&gt;echo &amp;quot;/corefile/core-%e-%p-%t&amp;quot;&amp;gt; /proc/sys/kernel/core_pattern&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;将会控制所产生的core文件会存放到 /corefile 目录下，产生的文件名为 &lt;strong&gt;core-命令名-pid-时间戳&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下是参数列表：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%p - insert pid into filename 添加pid
%u - insert current uid into filename 添加当前uid
%g - insert current gid into filename 添加当前gid
%s - insert signal that caused the coredump into the filename 添加导致产生core的信号
%t - insert UNIX time that the coredump occurred into filename 添加core文件生成时的unix时间
%h - insert hostname where the coredump happened into filename 添加主机名
%e - insertcoredumping executable name into filename 添加命令名
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用core文件&#34;&gt;使用core文件&lt;/h3&gt;

&lt;p&gt;在linux上可以使用gdb来调试core文件，格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gdb [程序名] [core文件名]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你不知道这个core文件到底是哪个程序生成的，可以使用&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gdb -c[core 文件名] 来查看生成此core文件的程序名。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;显示结果中可以看出程序名，可能像下面这样&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Core wasgenerated by `./test&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后进入gdb调试状态，输入 where 就可以看到程序崩溃时堆栈信息（当前函数之前的所有已调用函数的列表（包括当前函数），我们可以借此找出是程序中的哪个部分导致了程序崩溃。注意：在编译程序的时候要加入选项-g。&lt;/p&gt;

&lt;h3 id=&#34;一个简单的例子&#34;&gt;一个简单的例子&lt;/h3&gt;

&lt;p&gt;编译如下的程序&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
using namespace std;
 
class A
{
public:
    int a;
};
 
void fun()
{
    A*t = new A();
    t-&amp;gt;a = 1;
    cout &amp;lt;&amp;lt; t-&amp;gt;a &amp;lt;&amp;lt; endl;
    delete t;
    delete t;
}
 
int main()
{
    fun();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;1
*** glibc detected *** ./test: double freeor corruption (fasttop): 0x09fd7008 ***
======= Backtrace: =========
/lib/libc.so.6[0x3ebe31]
/usr/lib/libstdc++.so.6(_ZdlPv+0x22)[0x43fc552]
./test[0x8048705]
./test[0x8048712]
/lib/libc.so.6(__libc_start_main+0xe6)[0x391d26]
./test[0x8048611]
======= Memory map: ========
00327000-00328000 r-xp 00000000 00:000          [vdso]
00334000-00351000 r-xp 00000000 08:02926955    /lib/libgcc_s-4.4.7-20120601.so.1
00351000-00352000 rw-p 0001d000 08:02926955    /lib/libgcc_s-4.4.7-20120601.so.1
00355000-00373000 r-xp 00000000 08:02926876     /lib/ld-2.12.so
00373000-00374000 r--p 0001d000 08:02926876     /lib/ld-2.12.so
00374000-00375000 rw-p 0001e000 08:02926876     /lib/ld-2.12.so
0037b000-0050c000 r-xp 00000000 08:02926877     /lib/libc-2.12.so
0050c000-0050e000 r--p 00191000 08:02926877     /lib/libc-2.12.so
0050e000-0050f000 rw-p 00193000 08:02926877     /lib/libc-2.12.so
0050f000-00512000 rw-p 00000000 00:00 0
00543000-0056b000 r-xp 00000000 08:02926889     /lib/libm-2.12.so
0056b000-0056c000 r--p 00027000 08:02926889     /lib/libm-2.12.so
0056c000-0056d000 rw-p 00028000 08:02926889     /lib/libm-2.12.so
0434d000-0442e000 r-xp 00000000 08:02155001     /usr/lib/libstdc++.so.6.0.13
0442e000-04432000 r--p 000e0000 08:02155001     /usr/lib/libstdc++.so.6.0.13
04432000-04434000 rw-p 000e4000 08:02155001     /usr/lib/libstdc++.so.6.0.13
04434000-0443a000 rw-p 00000000 00:00 0
08048000-08049000 r-xp 00000000 08:02419326    /home/wcl/fate/src/app/test/test
08049000-0804a000 rw-p 00000000 08:02419326    /home/wcl/fate/src/app/test/test
09fd7000-09ff8000 rw-p 00000000 00:000          [heap]
b7719000-b771c000 rw-p 00000000 00:00 0
b7727000-b772a000 rw-p 00000000 00:00 0
bfd2a000-bfd3f000 rw-p 00000000 00:000          [stack]
Aborted (core dumped)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为我们对一个已经delete过了的指针再次delete，所以程序down掉了，可以看到在当前目录下已经生成了一个core.4377的文件，4377就是之前程序启动的PID。&lt;/p&gt;

&lt;p&gt;调试core文件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gdb test core.4377
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入gdb调试后，键入where命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(gdb) where
#0 0x00327424 in __kernel_vsyscall ()
#1 0x003a5b11 in raise () from /lib/libc.so.6
#2 0x003a73ea in abort () from /lib/libc.so.6
#3 0x003e59d5 in __libc_message () from /lib/libc.so.6
#4 0x003ebe31 in malloc_printerr () from /lib/libc.so.6
#5 0x043fc552 in operator delete(void*) () from/usr/lib/libstdc++.so.6
#6 0x08048705 in fun() ()
#7 0x08048712 in main ()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以很明显的看出是在main函数中调用fun函数，之后delete指针的时候出错了，后面的函数调用栈就是程序输出错误信息的部分了，和我们的用户代码无关。到这一步，我们就能推断是是fun()这个函数中delete某个指针的时候出现了错误，就可以有的放矢地查找具体的问题了。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>linux shell中的条件判断</title>
          <link>http://blog.fatedier.com/2014/11/24/conditional-judgement-in-linux-shell</link>
          <pubDate>Mon, 24 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/24/conditional-judgement-in-linux-shell</guid>
          <description>

&lt;p&gt;在日常开发中经常需要编写一些简单的部署或者测试统计之类的脚本，直接用shell来编写几条命令就可以实现一些较为复杂的功能，十分方便。不过 linux shell 中的条件判断和其他编程语言略有不同，有一些需要特别注意的地方。&lt;/p&gt;

&lt;h3 id=&#34;退出状态&#34;&gt;退出状态&lt;/h3&gt;

&lt;p&gt;在Linux系统中，每当一条命令执行完成后，系统都会返回一个退出状态，这个状态被存放在$? 这个变量中，是一个整数值，我们可以根据这个值来判断命令运行的结果是否正确。&lt;/p&gt;

&lt;p&gt;通常情况下，退出状态值为0，表示执行成功，不为0的时候表示执行失败。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;POSIX规定的退出状态和退出状态的含义&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;0 （运行成功）&lt;/p&gt;

&lt;p&gt;1-255 （运行失败，脚本命令、系统命令错误或参数传递错误）&lt;/p&gt;

&lt;p&gt;126 （找到了该命令但无法执行）&lt;/p&gt;

&lt;p&gt;127 （未找到要运行的命令）&lt;/p&gt;

&lt;p&gt;128 （命令被系统强行结束）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;测试命令&#34;&gt;测试命令&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test expression
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用test命令进行测试，expression是一个表达式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[ expression ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了提高可读性，可以使用简化的这种格式&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;需要注意的是大括号和表达式之间需要有一个空格，不能省略。这种方式和if、case、while等语句结合，可以作为shell脚本中的判断条件。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;整数比较运算符&#34;&gt;整数比较运算符&lt;/h3&gt;

&lt;p&gt;在shell中对两个数进行比较，不像在C/C++中可以使用 &amp;ldquo;&amp;gt;&amp;rdquo; 之类的运算符，而是使用类似参数选项的格式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-eq  # 如果等于则为真
-ge  # 如果大于或等于则为真
-gt  # 如果大于则为真
-le  # 如果小于或等于则为真
-lt  # 如果小于则为真
-ne  # 如果不等于则为真
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;其中的参数可以这样理解e(equal)，g(greater)，t(than)，l(less)，n(not)，这样方便记忆。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;字符串相关运算符&#34;&gt;字符串相关运算符&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-n string            # 字符串不为空则为真
-z string            # 字符串为空则为真
string1 = string2    # 字符串相等则为真 （或者 == 也可以）
string1 != string2   # 字符串不等则为真
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;这里有一个需要注意的地方，就是使用 -n 这个运算符进行判断的时候需要注意在变量两边加上双引号。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;例如 if [ -n $string ] 应该写成 if [ -n “$string” ] ，不然该表达式总是会返回真，因为当string变量为空的时候就相当于是 if [ -n ]。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;文件操作符&#34;&gt;文件操作符&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-d file # 测试file是否为目录
-e file # 测试file是否存在
-f file # 测试file是否为普通文件
-r file # 测试file是否是进程可读文件
-s file # 测试file的长度是否不为0
-w file # 测试file是否是进程可写文件
-x file # 测试file是否是进程可执行文件
-L file # 测试file是否符号化链接
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;逻辑运算符&#34;&gt;逻辑运算符&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;! expression                # 非
expression1 -a expression2  # 与
expression1 -o expression2  # 或
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多重的嵌套&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ $a == 1 ] &amp;amp;&amp;amp; [ $b == 1 -o $b == 3 ]
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>能否被8整除</title>
          <link>http://blog.fatedier.com/2014/11/13/can-be-divisible-by-eight</link>
          <pubDate>Thu, 13 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/13/can-be-divisible-by-eight</guid>
          <description>

&lt;p&gt;题目：给定一个非负整数，问能否重排它的全部数字，使得重排后的数能被8整除。 输入格式： 多组数据，每组数据是一个非负整数。非负整数的位数不超过10000位。 输出格式 每组数据输出一行,YES或者NO，表示能否重排它的全部数字得到能被8整除的数。注意：重排可以让0开头。&lt;/p&gt;

&lt;h3 id=&#34;思路&#34;&gt;思路&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;考虑到64位整型可以直接取余8求得结果，所以当输入非负整数位数小于20位的时候，可以直接转换成64位整型进行计算。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对于一个非负整数，最后四位相当于是 p*1000 + x*100 + y*10 + z ，可以很显然的看出p*1000必然能被8整除，所以一个非负整数只需要后三位能被8整除，那么这个数就一定能被8整除。所以如果我们能从这个数中任意取出三位，作为最后三位，其值能被8整除，就输出YES，否则NO。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;没必要对可能的10000位做全排列，因为0-9每个数最多只能用3次，我们只需要遍历一遍每一位，将0-9出现的次数记录下来，最多允许记录3次。这样最坏的情况下需要对30个数进行全排列即可，效率会非常高。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;代码&#34;&gt;代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;sys/types.h&amp;gt;

#define MAX 10001

int has_num[10];    //0-9在这个数中出现的次数

bool check()
{
    int deal_num[30];   //0-9每个数最多可以用3次，只需要30的空间
    int n = 0;
    //将所有出现过数依次存放在deal_num数组中
    for (int i=0; i&amp;lt;10; i++) {
        for (int j=0; j&amp;lt;has_num[i]; j++) {
            deal_num[n] = i;
            n++;
        }
    }

    //排列任意三个数组成一个整数，其值能被8整除，返回true，否则false
    for (int i=0; i&amp;lt;n; i++) {
        for (int j=0; j&amp;lt;n; j++) {
            if (j == i)
                continue;
            for (int k=0; k&amp;lt;n; k++) {
                if (k == i || k == j) {
                    continue;
                }
                if ((deal_num[i]*100 + deal_num[j]*10 + deal_num[k]) % 8 == 0)
                    return true;
            }
        }
    }
    return false;
}

int main()
{
    char str_num[MAX];  //用于保存不超过10000位的整数
    int n;
    long long temp = 0; //如果位数小于等于19，直接转换为64位整型

    for (;;) {
        memset(str_num, 0, sizeof(str_num));
        for (int i=0; i&amp;lt;10; i++) {
            has_num[i] = 0;
        }
        if (scanf(&amp;quot;%s&amp;quot;, &amp;amp;str_num) == 1) {
            n = strlen(str_num);
            //转换为64位整型
            if (n &amp;lt;= 19) {
                sscanf(str_num, &amp;quot;%lld&amp;quot;, &amp;amp;temp);
                if ((temp % 8) == 0)
                    printf(&amp;quot;YES\n&amp;quot;);
                else
                    printf(&amp;quot;NO\n&amp;quot;);
                continue;
            }
            
            //将0-9出现的次数保存在has_num数组中，最多3次
            for (int i=0; i&amp;lt;n; i++) {
                if (has_num[(int)str_num[i] - 48] &amp;lt; 3)
                    has_num[(int)str_num[i] - 48]++;
            }
            if (check())
                printf(&amp;quot;YES\n&amp;quot;);
            else
                printf(&amp;quot;NO\n&amp;quot;);
            continue;

        } else {
            break;
        }
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>使用astyle进行代码格式化</title>
          <link>http://blog.fatedier.com/2014/11/10/use-astyle-to-format-code</link>
          <pubDate>Mon, 10 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/10/use-astyle-to-format-code</guid>
          <description>

&lt;p&gt;在参与团队的开发的时候，由于平台和编写代码的工具的不同等等问题，经常会遇到代码格式非常混乱的情况，严重影响了代码的阅读效率。后来发现了一款比较好的工具 &amp;ndash; &amp;ldquo;astyle&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;astyle这个工具可以将现有的代码格式转换为指定的风格，当你将乱七八糟的代码用astyle转换一下之后，就会感觉整个世界都清静了……&lt;/p&gt;

&lt;h3 id=&#34;如何获取&#34;&gt;如何获取&lt;/h3&gt;

&lt;p&gt;astyle是一个开放源码的项目，支持C/C++、C#和java的代码格式化&lt;/p&gt;

&lt;p&gt;SourceForge地址: &lt;a href=&#34;http://sourceforge.net/projects/astyle/&#34;&gt;http://sourceforge.net/projects/astyle/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我的Github拷贝: &lt;a href=&#34;https://github.com/fatedier/fatedier-tools/tree/master/astyle&#34;&gt;https://github.com/fatedier/fatedier-tools/tree/master/astyle&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;编译&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;直接写一个Makefile编译下源码，我的Github的拷贝里有写好的Makefile，直接用gmake命令编译一下就可以用了。&lt;/p&gt;

&lt;h3 id=&#34;示例&#34;&gt;示例&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./astyle --style=ansi test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行之后会提示&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Formatted  xxx/test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;astyle&lt;/strong&gt; 会在当前目录下生成一个备份文件，以 &lt;strong&gt;.orig&lt;/strong&gt; 结尾，例如 &amp;ldquo;test.cpp.orig&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;而 &lt;strong&gt;test.cpp&lt;/strong&gt; 就已经转换为了 &lt;strong&gt;ansi&lt;/strong&gt; 代码风格了。&lt;/p&gt;

&lt;h3 id=&#34;常用选项&#34;&gt;常用选项&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;注：使用 &amp;ndash;help 选项可以查看astyle的帮助文档&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;style风格设置&#34;&gt;style风格设置&lt;/h4&gt;

&lt;p&gt;常用的代码风格主要有三种: &lt;strong&gt;ansi&lt;/strong&gt; 和 &lt;strong&gt;k&amp;amp;r&lt;/strong&gt; 以及 &lt;strong&gt;java&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&amp;ndash;style=allman  OR &amp;ndash;style=ansi OR &amp;ndash;style=bsd OR &amp;ndash;style=break OR -A1&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int Foo()
{
   if (isBar)
    {
       bar();
       return 1;
    }
   else
    {
       return 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;style=kr OR &amp;ndash;style=k&amp;amp;r OR &amp;ndash;style=k/r OR -A3&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int Foo()
{
   if (isBar) {
       bar();
       return 1;
    }else {
       return 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;style=java OR &amp;ndash;style=attach OR -A2&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int Foo() {
   if (isBar) {
       bar();
       return 1;
    }else {
       return 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;tab选项&#34;&gt;Tab选项&lt;/h4&gt;

&lt;p&gt;默认是使用4个空格替换一个tab。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&amp;ndash;indent=spaces=# OR -s#&lt;/p&gt;

&lt;p&gt;指定用几个空格替换一个tab，例如 &amp;ndash;indent=spaces=8 ，指定用8个空格替换一个tab。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;indent=tab OR &amp;ndash;indent=tab=# OR -t OR -t#&lt;/p&gt;

&lt;p&gt;指定缩进使用tab，=#同上，指定一个tab占几个空格，不说明的话默认是4个。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;递归处理&#34;&gt;递归处理&lt;/h4&gt;

&lt;p&gt;&amp;ndash;recursive OR -r OR -R&lt;/p&gt;

&lt;p&gt;可以递归处理所有子目录的文件。&lt;/p&gt;

&lt;h4 id=&#34;排除不处理的文件&#34;&gt;排除不处理的文件&lt;/h4&gt;

&lt;p&gt;&amp;ndash;exclude=####&lt;/p&gt;

&lt;p&gt;指定哪些文件或者文件夹不需要进行处理。&lt;/p&gt;

&lt;h4 id=&#34;指定配置文件&#34;&gt;指定配置文件&lt;/h4&gt;

&lt;p&gt;&amp;ndash;options=####&lt;/p&gt;

&lt;p&gt;可以指定读取某个文件的内容作为参数选项。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Linux下如何进行文件编码格式转换</title>
          <link>http://blog.fatedier.com/2014/11/03/how-to-convert-file-encoding-format-on-linux</link>
          <pubDate>Mon, 03 Nov 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/11/03/how-to-convert-file-encoding-format-on-linux</guid>
          <description>

&lt;p&gt;最近把项目放到github上，但是发现代码中注释的中文部分有些是乱码，检查后发现是因为我的Centos装在虚拟机上，而我是在Windows环境下通过UE来写代码的，而UE默认是使用ASCII编码。为了避免在UE里对一个个文件进行手动修改，希望在Linux上使用命令来批量转换编码格式。&lt;/p&gt;

&lt;p&gt;查了资料后发现可以使用 &lt;strong&gt;iconv&lt;/strong&gt; 命令。&lt;/p&gt;

&lt;p&gt;首先使用 &lt;strong&gt;file&lt;/strong&gt; 命令来检测文件的类型&lt;/p&gt;

&lt;p&gt;例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;file test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ISO-8859 Cprogram text
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;iconv命令的参数说明&#34;&gt;iconv命令的参数说明&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-l  列出所有已知的字符集
-f  原始文本编码
-t  输出文本编码
-o  输出文件名
-s  关闭警告
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;例子&#34;&gt;例子&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iconv -f GB2312 -t UTF-8 test.cpp &amp;gt; test_utf.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为iconv默认输出到标准输出，所以我们需要重定向到一个其他文件。&lt;strong&gt;（这里不能重定向到自身，否则会清空文件内容）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果想要把输出内容直接输出到当前文件，可以这样用：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iconv -f GB2312 -t UTF-8 -o test.cpp test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;附上我自己用的编码转换脚本-iconvfa-sh&#34;&gt;附上我自己用的编码转换脚本 iconvfa.sh&lt;/h3&gt;

&lt;h4 id=&#34;使用说明&#34;&gt;使用说明&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Usage:
    iconvfa.sh [option] [file|dir]
    from GB2312 to UTF-8, the old file will be replaced by the new converted file

Options:
    -R: convert files recursively, the following parameter should be the directory name
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;脚本代码&#34;&gt;脚本代码&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/env bash

function show_help
{
    echo &amp;quot;Usage:&amp;quot;
    echo &amp;quot;  iconvfa.sh [option] [file|dir]&amp;quot;
    echo -e &amp;quot;  from GB2312 to UTF-8, the old file will be replaced by the new converted file\n&amp;quot;
    echo &amp;quot;Options:&amp;quot;
    echo &amp;quot;  -R: convert files recursively, the following parameter should be the directory name&amp;quot;
}

# param 1: directory name
function convert_rescursive()
{
   local dir_path=`echo $1 | sed &#39;s/\(.*\)\/$/\1/g&#39;`
   local dir_names=`ls ${dir_path} -l | awk &#39;/^d/{print $NF}&#39;`
   
   # convert files in this directory
   local file_names=`ls ${dir_path} -l | awk &#39;/^-/{print $NF}&#39;`
   for file in ${file_names}
   do
       iconv -f ${from_code} -t ${to_code} ${dir_path}/${file} &amp;amp;&amp;gt; /dev/null
       if [ $? == 0 ]; then
           iconv -f ${from_code} -t ${to_code} &amp;lt; ${dir_path}/${file} &amp;gt; $@.$$$$
           cp $@.$$$$ ${dir_path}/${file}
           rm -f $@.$$$$
           echo &amp;quot;File ${dir_path}/${file} is formatted.&amp;quot;
       fi
   done

   # if the directory has no other directory, return 0
   if [ &amp;quot;${dir_names}X&amp;quot; == &amp;quot;X&amp;quot; ]; then
       return 0
   fi

   # continue convert files in directories recursively
   for dir in ${dir_names}
   do
       convert_rescursive &amp;quot;${dir_path}/${dir}&amp;quot;
   done 
}

# defines
from_code=&amp;quot;GB2312&amp;quot;
to_code=&amp;quot;UTF-8&amp;quot;

case &amp;quot;$1&amp;quot; in
&amp;quot;-R&amp;quot;)
    ls $2 &amp;amp;&amp;gt; /dev/null
    if [ $? != 0 -o &amp;quot;$2X&amp;quot; == &amp;quot;X&amp;quot; ]; then
        echo &amp;quot;#### error: please check the directory name following the &#39;-R&#39; option!&amp;quot;
        exit 1
    fi
    convert_rescursive $2
    ;;
&amp;quot;&amp;quot;)
    show_help
    ;;
*)
    iconv -f ${from_code} -t ${to_code} $1 &amp;amp;&amp;gt; /dev/null
    if [ $? == 0 ]; then
        iconv -f ${from_code} -t ${to_code} &amp;lt; $1 &amp;gt; $@.$$$$
        cp $@.$$$$ $1
        rm -f $@.$$$$
        echo &amp;quot;File $1 is formatted.&amp;quot;
    else
        echo &amp;quot;Convert wrong!&amp;quot;
    fi
    ;;
esac
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>使用Vim打造自己的IDE</title>
          <link>http://blog.fatedier.com/2014/10/29/use-vim-to-make-my-ide</link>
          <pubDate>Wed, 29 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/29/use-vim-to-make-my-ide</guid>
          <description>

&lt;p&gt;之前一直使用UE的FTP功能编辑Linux虚拟机上的代码文件，之后再切换到Linux上去编译，调试程序，感觉这样比较麻烦，而且UE的功能也不像VS以及Eclipse的IDE那样强大，所以就查阅了一些资料，想要把Linux下最常用的文本编辑工具Vim打造成一个适合自己的IDE，可以直接ssh登陆到远程机器上直接进行开发。&lt;/p&gt;

&lt;p&gt;配置自己的Vim过程中参考了以下的blog和文档：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/fbfsber008/article/details/7055842&#34;&gt;http://blog.csdn.net/fbfsber008/article/details/7055842&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.douban.com/note/257815917/&#34;&gt;http://www.douban.com/note/257815917/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/vim-scripts/vundle&#34;&gt;https://github.com/vim-scripts/vundle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最终的效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2014/2014-10-29-use-vim-to-make-my-ide-overview.jpg&#34; alt=&#34;overview&#34; /&gt;&lt;/p&gt;

&lt;p&gt;现在把整个配置的过程记录下来，方便以后参考。&lt;/p&gt;

&lt;h3 id=&#34;前期准备&#34;&gt;前期准备&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;有一个github帐号&lt;/li&gt;
&lt;li&gt;Linux上安装git版本控制工具，可以使用命令安装，例如 yum install git&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;github是一个好地方，不仅可以浏览很多的开源程序，而且可以把自己正在开发的项目或者有用的文档托管在上面，不管在其他任何的计算机上都可以很容易的获取到。&lt;/p&gt;

&lt;p&gt;比如我的 .vimrc 的配置文件就放在了Github上，有一个版本库是专门用来存放配置文件的。&lt;/p&gt;

&lt;p&gt;地址为：&lt;a href=&#34;https://github.com/fatedier/dot_file&#34;&gt;https://github.com/fatedier/dot_file&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;vim常用配置&#34;&gt;vim常用配置&lt;/h3&gt;

&lt;p&gt;个人的vim配置文件一般是放在用户主目录下的.vimrc文件。&lt;/p&gt;

&lt;p&gt;配置文件中 &lt;code&gt;&amp;quot;&lt;/code&gt; 之后的部分都被当作注释。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;if v:lang =~ &amp;quot;utf8$&amp;quot; || v:lang =~&amp;quot;UTF-8$&amp;quot;
    set fileencodings=ucs-bom,utf-8,latin1
endif
       
set nocompatible            &amp;quot; Use Vim defaults (much better!)
set bs=indent,eol,start     &amp;quot; allow backspacing overeverything in insert mode
set viminfo=&#39;20,\&amp;quot;50        &amp;quot; read/write a .viminfo file, don&#39;t store more
                            &amp;quot; than 50 lines of registers
set history=50              &amp;quot; keep 50 lines of command line history
set ruler                   &amp;quot; show the cursor position all the time
                                    
&amp;quot; -----------个人设置-----------
filetype off

set ts=4          &amp;quot; tab所占空格数
set shiftwidth=4  &amp;quot; 自动缩进所使用的空格数
set expandtab     &amp;quot; 用空格替换tab
set autoindent    &amp;quot; 自动缩进
set smartindent   &amp;quot; C语言缩进
set number        &amp;quot; 显示行号
set ignorecase    &amp;quot; 搜索忽略大小写
set incsearch     &amp;quot; 输入字符串就显示匹配点
set showtabline=2 &amp;quot; 总是显示标签页
                                      
if has(&amp;quot;mouse&amp;quot;)
    set mouse=iv  &amp;quot; 在 insert 和 visual 模式使用鼠标定位
endif
      
&amp;quot; -------------颜色配置-------------
&amp;quot; 补全弹出窗口
hi Pmenu ctermbg=light magenta
&amp;quot; 补全弹出窗口选中条目
hi PmenuSel ctermbg=yellow ctermfg=black
       
&amp;quot; -------------键盘映射-------------
&amp;quot; Ctrl+S 映射为保存
nnoremap &amp;lt;C-S&amp;gt; :w&amp;lt;CR&amp;gt;
inoremap &amp;lt;C-S&amp;gt;&amp;lt;Esc&amp;gt;:w&amp;lt;CR&amp;gt;a
        
&amp;quot; Ctrl+C 复制，Ctrl+V 粘贴
inoremap &amp;lt;C-C&amp;gt; y
inoremap &amp;lt;C-V&amp;gt; &amp;lt;Esc&amp;gt;pa
vnoremap &amp;lt;C-C&amp;gt; y
vnoremap &amp;lt;C-V&amp;gt; p
nnoremap &amp;lt;C-V&amp;gt; p

&amp;quot; F3 查找当前高亮的单词
inoremap &amp;lt;F3&amp;gt;*&amp;lt;Esc&amp;gt;:noh&amp;lt;CR&amp;gt;:match Todo /\k*\%#\k*/&amp;lt;CR&amp;gt;v
vnoremap &amp;lt;F3&amp;gt;*&amp;lt;Esc&amp;gt;:noh&amp;lt;CR&amp;gt;:match Todo /\k*\%#\k*/&amp;lt;CR&amp;gt;v

&amp;quot; Ctrl+\ 取消缩进
inoremap &amp;lt;C-\&amp;gt; &amp;lt;Esc&amp;gt;&amp;lt;&amp;lt;i
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用vundle管理vim插件&#34;&gt;使用vundle管理vim插件&lt;/h3&gt;

&lt;p&gt;很多时候我们的vim都需要安装大量的插件，需要进行各种配置，而且插件路径下面的文件也会变的非常混乱，这个时候使用 &lt;strong&gt;vundle&lt;/strong&gt; 就是一个不错的选择。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vim-scripts/vundle&#34;&gt;vundle&lt;/a&gt; 是可以算是一个用来管理各种vim插件的插件。&lt;/p&gt;

&lt;h4 id=&#34;安装ctags&#34;&gt;安装ctags&lt;/h4&gt;

&lt;p&gt;直接使用命令 yuminstall ctags 进行安装。&lt;/p&gt;

&lt;p&gt;之后在你的项目文件的根目录中执行如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ctags -R
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会发现当前目录下生成了一个名为tags的文件。&lt;/p&gt;

&lt;p&gt;tags文件是由ctags程序产生的一个索引文件，如果你在读程序时看了一个函数调用, 或者一个变量, 或者一个宏等等, 你想知道它们的定义在哪儿，tags文件就起作用了。使用把光标移动到你想查的地方，按下&amp;rdquo;Ctrl + ]&amp;ldquo;，就可以跳转到定义处。&lt;/p&gt;

&lt;p&gt;最后需要在vim配置文件中将tags文件加入到vim中来：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;set tags=~/tags
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注：这里需要填具体的tags文件所在路径。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;先安装vundle这个插件&#34;&gt;先安装vundle这个插件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后其他的插件也都会被放在~/.vim/bundle这个目录下。&lt;/p&gt;

&lt;h4 id=&#34;安装其他需要的插件&#34;&gt;安装其他需要的插件&lt;/h4&gt;

&lt;p&gt;以后当你需要安装其他的vim插件的时候，直接在.vimrc中加上如下部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;filetype off
 
setrtp+=~/.vim/bundle/vundle/
call vundle#rc()
&amp;quot; Bundles
&amp;quot; 显示变量、函数列表等
Bundle&amp;quot;taglist.vim&amp;quot;
&amp;quot; 窗口管理器
Bundle&amp;quot;winmanager&amp;quot;
&amp;quot; 标签工具
Bundle&amp;quot;Visual-Mark&amp;quot;
&amp;quot; 代码补全工具
Bundle&amp;quot;neocomplcache&amp;quot;
  
filetype pluginindent on
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bundle 后面的插件名称用引号引起来，最后在vim中输入:BundleInstall就会完成自动安装，实际上是也是从github上下载各种插件，因为大多数的插件已经备份在了github上的vim-scripts上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;:PluginSearch&lt;/code&gt; 命令可以查看有哪些插件可以直接使用插件名下载的。&lt;/p&gt;

&lt;p&gt;如果你需要的插件在这个里面没有找到，那么在.vimrc配置文件中可以直接用git远程仓库的地址，例如要安装command-t这个插件，可以在配置文件中加上：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;Bundle &amp;quot;git://git.wincent.com/command-t.git&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会直接从这个地址上下载所需插件。&lt;/p&gt;

&lt;h3 id=&#34;其他插件的配置与使用&#34;&gt;其他插件的配置与使用&lt;/h3&gt;

&lt;h4 id=&#34;快速浏览源码-taglist&#34;&gt;快速浏览源码：TagList&lt;/h4&gt;

&lt;p&gt;在Windows平台我经常用来浏览项目源码的工具就是SourceInsight，会在窗口左边列出当前文件中的变量、宏、函数名等等，点击以后就会快速跳转到页面相应的地方，使用taglist就可以在vim中实现相同的效果。&lt;/p&gt;

&lt;p&gt;通过vundle安装完成后，在vim中使用 &lt;code&gt;:Tlist&lt;/code&gt; 命令就可以打开TagList窗口。&lt;/p&gt;

&lt;h4 id=&#34;窗口管理器-winmanager&#34;&gt;窗口管理器：WinManager&lt;/h4&gt;

&lt;p&gt;WinManager可以帮助我们管理在屏幕上显示的多个窗口。&lt;/p&gt;

&lt;p&gt;之后我们需要设置一下在normal模式下可以直接输入wm来打开文件管理窗口以及TagList，.vimrc文件增加如下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;let g:winManagerWindowLayout=&#39;FileExplorer|TagList&#39;
nnoremap wm:WMToggle&amp;lt;cr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注：nnoremap是设置键盘映射。第一个字母n是normal模式，i是insert模式，v是visual模式。加上nore表示不会递归替换命令，比如a映射到b，b映射到c，那么按a不会得到按c的效果。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;高亮标签-visualmark&#34;&gt;高亮标签：VisualMark&lt;/h4&gt;

&lt;p&gt;这个插件的作用就是在浏览代码的时候在指定的行上添加标签，之后可以快速跳转回来，方便快捷。&lt;/p&gt;

&lt;p&gt;安装完成之后直接就可以在vim中使用。&lt;/p&gt;

&lt;p&gt;&amp;ldquo;mm&amp;rdquo; 命令会在当前行添加标签，再次按 &amp;ldquo;mm&amp;rdquo; 会取消标签。&lt;/p&gt;

&lt;p&gt;按下“F2”可以在多个标签之间进行快速跳转。&lt;/p&gt;

&lt;h4 id=&#34;自动补全-neocomplcache&#34;&gt;自动补全：neocomplcache&lt;/h4&gt;

&lt;p&gt;这个补全插件需要tags文件的支持，所以需要安装ctags，并且在项目根目录生成tags文件，之后在.vimrc中加入这个tags文件。&lt;/p&gt;

&lt;p&gt;并且在配置文件中加上如下配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;let g:neocomplcache_enable_at_startup = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这一行是设置是否自动启用补全，为1代表启用。这样就不需要每次都使用Ctrl+P或者Ctrl+N来弹出补全列表。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;let g:neocomplcache_enable_auto_select = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这一行是设置是否启用自动选择，为1代表启用。这个时候弹出补全列表的时候会自动选择第一个，按下Enter键就会使用列表的第一项，否则每一次都需要自己多按一次进行选择。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>vimdiff常用命令</title>
          <link>http://blog.fatedier.com/2014/10/24/vimdiff-common-commands</link>
          <pubDate>Fri, 24 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/24/vimdiff-common-commands</guid>
          <description>

&lt;p&gt;整理了一下在使用vimdiff进行文件合并的时候用到的一些常用的命令，方便以后查询。&lt;/p&gt;

&lt;p&gt;可以有多种方式使用vimdiff，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vimdiff [file1] [file2]

vim -d [file1] [file2]
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;其他的一些的编辑命令与vim相同，这里主要记录一些常用的合并文件需要用到的命令：&lt;/p&gt;

&lt;h4 id=&#34;ctrl-w之后按w&#34;&gt;Ctrl+w之后按w&lt;/h4&gt;

&lt;p&gt;可以切换到另外一个文件&lt;/p&gt;

&lt;h4 id=&#34;c&#34;&gt;[c&lt;/h4&gt;

&lt;p&gt;跳转到上一个差异点&lt;/p&gt;

&lt;h4 id=&#34;c-1&#34;&gt;]c&lt;/h4&gt;

&lt;p&gt;跳转到下一个差一点&lt;/p&gt;

&lt;h4 id=&#34;zo或者i&#34;&gt;zo或者i&lt;/h4&gt;

&lt;p&gt;展开折叠区域，或者使用i进入插入模式也会进行展开&lt;/p&gt;

&lt;h4 id=&#34;zc&#34;&gt;zc&lt;/h4&gt;

&lt;p&gt;重新折叠，可以把使用zo展开折叠的区域恢复原样&lt;/p&gt;

&lt;h4 id=&#34;dp-diff-put的意思&#34;&gt;dp（diff put的意思）&lt;/h4&gt;

&lt;p&gt;把当前文件的差异点内容复制到另一个文件&lt;/p&gt;

&lt;h4 id=&#34;do-diff-obtain的意思&#34;&gt;do（diff obtain的意思）&lt;/h4&gt;

&lt;p&gt;把另一个文件的差异点内容复制到当前文件&lt;/p&gt;

&lt;h4 id=&#34;diffupdate&#34;&gt;:diffupdate&lt;/h4&gt;

&lt;p&gt;有时候修改了文件之后不会立即刷新重新比对，使用该命令可以重新进行文件比较。&lt;/p&gt;

&lt;h4 id=&#34;qa&#34;&gt;qa&lt;/h4&gt;

&lt;p&gt;退出所有打开的文件，但是不保存&lt;/p&gt;

&lt;h4 id=&#34;wqa&#34;&gt;wqa&lt;/h4&gt;

&lt;p&gt;退出并保存所有已打开的文件&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Git常用命令</title>
          <link>http://blog.fatedier.com/2014/10/17/git-usually-command</link>
          <pubDate>Fri, 17 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/17/git-usually-command</guid>
          <description>

&lt;p&gt;在用Git进行项目管理的时候有一些经常会遇到的问题处理起来比较复杂，本文记录了一些常用的命令和操作。&lt;/p&gt;

&lt;h3 id=&#34;修改某一次提交的说明信息&#34;&gt;修改某一次提交的说明信息&lt;/h3&gt;

&lt;p&gt;有时候我们需要修改之前提交的时候的说明信息，没有操作命令可以直接完成，但是使用rebase命令可以实现。&lt;/p&gt;

&lt;p&gt;例如我们要修改倒数第二次的提交的说明信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rebase -i HEAD~3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注意：这里HEAD~后面跟着的是3而不是2，因为这里指的是要修改的提交的父提交。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之后会进入到文本编辑界面，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2014/2014-10-17-git-usually-command-git-reset-commit-message.jpg&#34; alt=&#34;reset-commit-message&#34; /&gt;&lt;/p&gt;

&lt;p&gt;将要修改的提交前面的 &lt;strong&gt;pick&lt;/strong&gt; 改为 &lt;strong&gt;edit&lt;/strong&gt; ，保存后退出。&lt;/p&gt;

&lt;p&gt;这个时候执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit --amend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以修改该次提交的说明了，修改完成后保存并退出。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rebase --continue
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行这条命令后，后续的提交说明将不会改变。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：不要修改已经push到远程仓库的提交！！！会引起版本混乱，使提交历史变的不清晰！&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;查看-删除-重命名远程分支&#34;&gt;查看、删除、重命名远程分支&lt;/h3&gt;

&lt;p&gt;查看所有的分支（包括远程分支）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当一个分支已经被合并到主分支后，我们通常会删除这个分支，如果仅仅 git branch -d 是删除本地分支&lt;/p&gt;

&lt;p&gt;删除远程分支的话可以使用如下命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push origin --delete &amp;lt;branchName&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重命名一个分支不是很常用，可以先删除远程分支，再重命名本地分支，之后将重命名后的本地分支推送到远程仓库&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push --delete origin &amp;lt;branchName&amp;gt;

$ git branch -m &amp;lt;branchName&amp;gt; &amp;lt;newBranchName&amp;gt;

$ git push origin &amp;lt;newBranchName&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;合并多个提交&#34;&gt;合并多个提交&lt;/h3&gt;

&lt;p&gt;比如要合并最后两次的提交，其实和修改某一次提交的说明信息有点类似。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rebase -i HEAD~2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后同样会进入到文本编辑界面，将第二行开头的 &lt;strong&gt;pick&lt;/strong&gt; 改为 &lt;strong&gt;squash&lt;/strong&gt; 或 &lt;strong&gt;s&lt;/strong&gt;，保存后退出。&lt;/p&gt;

&lt;p&gt;这时git会把两次提交合并，并且提示让你输入新的提交信息，保存后退出就成功完成两次提交的合并了。&lt;/p&gt;

&lt;h3 id=&#34;强制回退远程仓库到指定提交&#34;&gt;强制回退远程仓库到指定提交&lt;/h3&gt;

&lt;p&gt;当我们在开发的时候出现一些关键性的错误，并且确认现在已经做的开发工作是无意义的时候，可能需要回退到之前的版本。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git reset --hard &amp;lt;commit_id&amp;gt;

$ git push origin HEAD --force
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外，reset命令还有几个可选参数&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;git reset &amp;ndash;mixed&lt;/strong&gt;：此为默认方式，不带任何参数的git reset，即时这种方式，它回退到某个版本，只保留源码，回退commit和index信息。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;git reset &amp;ndash;soft&lt;/strong&gt;：回退到某个版本，只回退了commit的信息，不会恢复到indexfile一级。如果还要提交，直接commit即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;git reset &amp;ndash;hard&lt;/strong&gt;：彻底回退到某个版本，本地的源码也会变为上一个版本的内容。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;reset-hard之后的恢复&#34;&gt;reset &amp;ndash;hard之后的恢复&lt;/h3&gt;

&lt;p&gt;使用 &lt;code&gt;git reset --hard&lt;/code&gt; 之后，也许才发现这是一次错误的操作，那么我们就想要恢复到之前的版本。&lt;/p&gt;

&lt;p&gt;这个时候用git log是看不到之前的提交历史记录的。&lt;/p&gt;

&lt;p&gt;需要使用 &lt;code&gt;$ git reflog&lt;/code&gt; 找到我们需要恢复的HEAD的ID，然后使用reset命令恢复回去。&lt;/p&gt;

&lt;h3 id=&#34;查看指定版本的某个文件的内容&#34;&gt;查看指定版本的某个文件的内容&lt;/h3&gt;

&lt;p&gt;例如要查看 f4869b0 这次提交的 test.cpp 文件的内容，test.cpp的路径需要使用相对于git目录的路径名，使用如下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git show f4869b0:test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文件的内容会全部显示在界面上，可以使用文件重定向到另外的文件，再进行后续操作。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Git使用备忘</title>
          <link>http://blog.fatedier.com/2014/10/16/git-use-for-remind</link>
          <pubDate>Thu, 16 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/16/git-use-for-remind</guid>
          <description>

&lt;p&gt;Git是一款免费、开源的分布式版本控制系统，由于 GitHub 的存在，我们很方便的用于管理我们平时的开发项目。&lt;/p&gt;

&lt;p&gt;Git的命令较多，虽然大多数都不是很常用，但是还是需要记下来方便日后查看。&lt;/p&gt;

&lt;h3 id=&#34;git的配置&#34;&gt;Git的配置&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;/etc/gitconfig 文件：系统中对所有用户都普遍适用的配置。若使用 git config 时用 &amp;ndash;system 选项，读写的就是这个文件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;~/.gitconfig 文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 &amp;ndash;global 选项，读写的就是这个文件。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当前项目的 Git 目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所.git/config 里的配置会覆盖 /etc/gitconfig 中的同名变量。&lt;/p&gt;

&lt;h4 id=&#34;设置用户信息&#34;&gt;设置用户信息&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git config --globaluser.name  &amp;quot;your-uasername&amp;quot;
$ git config --global user.email example@example.com
$ git config --global core.editor vim
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;设置差异分析工具&#34;&gt;设置差异分析工具&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git config --global merge.tool vimdiff
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;如何获取帮助文档&#34;&gt;如何获取帮助文档&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git help &amp;lt;verb&amp;gt;
$ git &amp;lt;verb&amp;gt; --help
$ man git-&amp;lt;verb&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如 &lt;code&gt;man git-config&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;git基础操作&#34;&gt;Git基础操作&lt;/h3&gt;

&lt;h4 id=&#34;取得git仓库-从现有仓库克隆&#34;&gt;取得Git仓库（从现有仓库克隆）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/schacon/fatest.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会在当前目录下创建一个fatest的目录，其中的.git目录保存所有的版本记录。fatest下是项目的所有文件。&lt;/p&gt;

&lt;p&gt;如果要自定义目录名称，可以在末尾指定，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/schacon/fatest.git fatestnew
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在创建的目录就是fatestnew而不是fatest了，其他的都一样。&lt;/p&gt;

&lt;h4 id=&#34;检查当前项目文件状态&#34;&gt;检查当前项目文件状态&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到有哪些文件是没有加入到版本中的，哪些是修改了还没提交的等等。&lt;/p&gt;

&lt;h4 id=&#34;将新文件加入到版本中&#34;&gt;将新文件加入到版本中&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git add test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注：&lt;code&gt;git add&lt;/code&gt;命令对于不同状态的文件有不同的效果，可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。&lt;/p&gt;

&lt;p&gt;*注意*修改过后的文件处于未暂存状态，提交的时候处于未暂存状态的文件将不会提交，需要使用git add命令更改为暂存状态，之后再提交就会提交到仓库中了。&lt;/p&gt;

&lt;h4 id=&#34;忽略某些文件&#34;&gt;忽略某些文件&lt;/h4&gt;

&lt;p&gt;对于不需要加入到版本中，并且使用git status时不再提示的文件。&lt;/p&gt;

&lt;p&gt;在 .gitignore 文件中进行配置，例如*.exe&lt;/p&gt;

&lt;p&gt;那么所有的以.exe结尾的文件都会被忽略，而不再提醒。&lt;/p&gt;

&lt;p&gt;例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 此为注释，将被 Git 忽略
# 忽略所有 .a 结尾的文件
*.a
# 但 lib.a 除外
!lib.a
# 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO
/TODO
# 忽略 build/ 目录下的所有文件
build/
# 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt
doc/*.txt
# ignore all .txt files in the doc/ directory
doc/**/*.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看已暂存和未暂存的更新文件差异&#34;&gt;查看已暂存和未暂存的更新文件差异&lt;/h4&gt;

&lt;p&gt;未暂存：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git diff
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;已暂存：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git diff --staged
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;提交更新&#34;&gt;提交更新&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后进入vim编辑提交说明，保存即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit --m &amp;quot;comment&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 &lt;em&gt;-m&lt;/em&gt; 命令可以直接在一行命令中写说明。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit -a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 &lt;em&gt;-a&lt;/em&gt; 命令，会把未暂存和已暂存的文件一起提交，不然只会提交已暂存的文件。&lt;/p&gt;

&lt;h4 id=&#34;删除文件和取消跟踪&#34;&gt;删除文件和取消跟踪&lt;/h4&gt;

&lt;p&gt;可以先本地使用rm命令删掉，这时候放在未暂存区域，之后用“git rm文件名”删掉。&lt;/p&gt;

&lt;p&gt;也可以直接使用 &lt;code&gt;git rm 文件名&lt;/code&gt; 删掉。&lt;/p&gt;

&lt;p&gt;另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仅是从跟踪清单中删除。比如一些大型日志文件或者一堆 .a 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 &amp;ndash;cached 选项即可：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git rm --cached readme.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;移动文件&#34;&gt;移动文件&lt;/h4&gt;

&lt;p&gt;例如要把 test.cpp 改为 tt.cpp&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git mv test.cpp tt.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就相当于是&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mv README.txt README
$ git rm README.txt
$ git add README
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看提交历史&#34;&gt;查看提交历史&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;撤销操作&#34;&gt;撤销操作&lt;/h4&gt;

&lt;h5 id=&#34;覆盖上一次的提交&#34;&gt;覆盖上一次的提交&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git commit --amend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会将上次提交和这次提交合并起来，算作一次提交。&lt;/p&gt;

&lt;h5 id=&#34;取消已暂存文件&#34;&gt;取消已暂存文件&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git reset HEAD &amp;lt;file&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个时候文件状态就从已暂存变为未暂存&lt;/p&gt;

&lt;h5 id=&#34;取消对文件的修改-还没有放到暂存区&#34;&gt;取消对文件的修改（还没有放到暂存区）&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout -- &amp;lt;file&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;运程仓库的使用&#34;&gt;运程仓库的使用&lt;/h4&gt;

&lt;h5 id=&#34;查看当前的远程库&#34;&gt;查看当前的远程库&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会列出每个远程库的简短的名字，默认使用origin表示原始仓库&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会额外列出远程库对应的克隆地址&lt;/p&gt;

&lt;h5 id=&#34;添加远程仓库&#34;&gt;添加远程仓库&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote add [shortname] [url]
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;从远程仓库抓取数据&#34;&gt;从远程仓库抓取数据&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git fetch [remote-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;抓取数据，但并不合并到当前分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git pull
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自动抓取数据，并自动合并到当前分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -r
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看所有远程分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout -b test origin/test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;获取远程分支到本地新的分支上，并切换到新分支&lt;/p&gt;

&lt;h5 id=&#34;推送数据到远程仓库&#34;&gt;推送数据到远程仓库&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push [remote-name] [branch-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;推送操作会默认使用origin和master名字&lt;/p&gt;

&lt;h5 id=&#34;查看远程仓库信息&#34;&gt;查看远程仓库信息&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote show [remote-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除了对应的克隆地址外，它还给出了许多额外的信息。它友善地告诉你如果是在 master 分支，就可以用 git pull 命令抓取数据合并到本地。另外还列出了所有处于跟踪状态中的远端分支。&lt;/p&gt;

&lt;h5 id=&#34;远程仓库的删除&#34;&gt;远程仓库的删除&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git remote rm [remote-name]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;标签的使用&#34;&gt;标签的使用&lt;/h4&gt;

&lt;h5 id=&#34;显示已有的标签&#34;&gt;显示已有的标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;新建标签&#34;&gt;新建标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag v1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新建一个简单的标签&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag -a v1.0 -m &#39;my version 1.0&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-m 指定了对应标签的说明&lt;/p&gt;

&lt;h5 id=&#34;后期加注标签&#34;&gt;后期加注标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log --pretty=oneline --abbrev-commit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先显示提交历史&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git tag -a v1.1 9fceb02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;补加标签&lt;/p&gt;

&lt;h5 id=&#34;推送标签&#34;&gt;推送标签&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push origin [tagname]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;设置命令别名&#34;&gt;设置命令别名&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git config --global alias.co checkout
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;git分支&#34;&gt;Git分支&lt;/h3&gt;

&lt;h4 id=&#34;新建分支&#34;&gt;新建分支&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会在当前commit对象上新建一个分支指针&lt;/p&gt;

&lt;p&gt;&lt;em&gt;注：HEAD这个特别的指针是指向正在工作中的本地分支的指针&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;切换分支&#34;&gt;切换分支&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;切换到testing分支上&lt;/p&gt;

&lt;h4 id=&#34;分支的合并&#34;&gt;分支的合并&lt;/h4&gt;

&lt;p&gt;在master分支上，执行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git merge testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将tesing分支合并回master&lt;/p&gt;

&lt;h4 id=&#34;使用合并工具-可以自己设置-例如设置成vimdiff&#34;&gt;使用合并工具（可以自己设置，例如设置成vimdiff）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git mergetool
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;分支的管理&#34;&gt;分支的管理&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch --merged
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看哪些分支已经被并入当前分支，通常这些都可以删除了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -d testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;删除一个分支&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git branch -D testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果该分支尚没有合并，可以使用-D选项强制删除。&lt;/p&gt;

&lt;h4 id=&#34;推送本地分支&#34;&gt;推送本地分支&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git push origin testing
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;分支的衍合&#34;&gt;分支的衍合&lt;/h4&gt;

&lt;p&gt;例如现在有两个分支，一个master，一个testing&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git checkout testing
$ git rebase master
$ git checkout master
$ git merge testing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常在贡献自己的代码之前先衍合，再提交，会让历史提交记录更清晰。&lt;/p&gt;

&lt;h3 id=&#34;git调试&#34;&gt;Git调试&lt;/h3&gt;

&lt;h4 id=&#34;文件标注&#34;&gt;文件标注&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git blame -L 12,22 test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看test.cpp文件对每一行进行修改的最近一次提交。&lt;/p&gt;

&lt;h4 id=&#34;查看文件的历史提交&#34;&gt;查看文件的历史提交&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log --pretty=oneline test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看test.cpp文件的历史提交记录&lt;/p&gt;

&lt;h4 id=&#34;查看文件的历史版本&#34;&gt;查看文件的历史版本&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git show [commit] [file]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如：&lt;code&gt;$ git show 7da7c23 test.cpp&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看7da7c23这次提交的test.cpp文件。&lt;/p&gt;

&lt;h4 id=&#34;查看历史提交的详细文件变化&#34;&gt;查看历史提交的详细文件变化&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git log -p -2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这条命令可以看到最近两次提交的文件变化情况，删除的部分会以 &amp;ldquo;-&amp;rdquo; 开头，新增的部分会以 &amp;ldquo;+&amp;rdquo; 开头，方便查看。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>学习Git的常用网站</title>
          <link>http://blog.fatedier.com/2014/10/16/learn-git-website</link>
          <pubDate>Thu, 16 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/16/learn-git-website</guid>
          <description>

&lt;p&gt;学习Git的使用的过程中参考了很多的网站，主要是两个地方讲的比较清楚，例子也很丰富，特别记录一下。&lt;/p&gt;

&lt;h4 id=&#34;git官方文档&#34;&gt;Git官方文档&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://git-scm.com/book/zh/&#34;&gt;http://git-scm.com/book/zh/&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;廖雪峰git教程&#34;&gt;廖雪峰Git教程&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000&#34;&gt;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>主机使用代理上网，虚拟机Linux的shell如何连外网</title>
          <link>http://blog.fatedier.com/2014/10/14/how-virtual-machine-connect-internet-while-host-getonline-with-agent</link>
          <pubDate>Tue, 14 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/10/14/how-virtual-machine-connect-internet-while-host-getonline-with-agent</guid>
          <description>&lt;p&gt;在公司电脑上网都需要使用代理，虚拟机里面装的Linux系统需要使用yum命令来安装软件，所以需要在shell界面能连上外网才行。&lt;/p&gt;

&lt;p&gt;因为公司限制了每个人只能用一个IP，所以虚拟机中的Linux系统使用NAT方式和主机相连。主机是Win7操作系统，会发现网络里面多了VMnet8这个网络。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2014/2014-10-14-how-virtual-machine-connect-internet-while-host-getonline-with-agent-vmware-net.jpg&#34; alt=&#34;vmware-net&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在VMware界面，点击“编辑”，“虚拟网络编辑器”&lt;/p&gt;

&lt;p&gt;可以看到子网地址分配的是192.168.131.0&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;一般来说这时我们的主机会自动分配一个IP类似192.168.131.1这样的，子网掩码为255.255.255.0，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2014/2014-10-14-how-virtual-machine-connect-internet-while-host-getonline-with-agent-host-net.jpg&#34; alt=&#34;host-net&#34; /&gt;&lt;/p&gt;

&lt;p&gt;现在进入虚拟机的Linux进行设置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2014/2014-10-14-how-virtual-machine-connect-internet-while-host-getonline-with-agent-network-configuration.jpg&#34; alt=&#34;network-configuration&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意IP需要设置成192.168.131.x的形势，网关是192.168.131.2。&lt;/p&gt;

&lt;p&gt;之后使用 &lt;code&gt;service network restart&lt;/code&gt; 命令重启网络服务。&lt;/p&gt;

&lt;p&gt;然后可以用 &lt;code&gt;ifconfig&lt;/code&gt; 命令检查配置是否正确。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;最后，修改自己目录下的配置文件，使用“cd”命令进入自己的根目录。&lt;/p&gt;

&lt;p&gt;比如我的是.bash_profile&lt;/p&gt;

&lt;p&gt;添加代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export http_proxy=&amp;quot;http://proxy_addr:port&amp;quot;
export https_proxy=&amp;quot;http://proxy_addr:port&amp;quot;
export ftp_proxy=&amp;quot;http://proxy_addr:port&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;proxy_addr&lt;/strong&gt; 就是代理的IP地址&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;port&lt;/strong&gt; 是代理的款口号&lt;/p&gt;

&lt;p&gt;如果代理需要用户名和密码的话，这样设置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export http_proxy=&amp;quot;http://username:password@proxy_addr:port&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在就可以使用yum命令安装需要的软件了。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>C/C&#43;&#43;获取精确到微秒级的系统时间</title>
          <link>http://blog.fatedier.com/2014/09/30/get-systime-accurate-to-microseconds-in-c-or-cpp</link>
          <pubDate>Tue, 30 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/30/get-systime-accurate-to-microseconds-in-c-or-cpp</guid>
          <description>

&lt;p&gt;最近要为自己的项目开发一个日志模块，需要获取精确到微秒级的系统时间，查阅了一些资料，发现在C/C++里面可以通过 gettimeofday(struct timeval * tv,struct timezone * tz) 和 localtime(const time_t * timep) 这两个函数的配合使用来得到我想要的结果。&lt;/p&gt;

&lt;p&gt;先贴一下这两个函数的说明&lt;/p&gt;

&lt;h4 id=&#34;gettimeofday&#34;&gt;gettimeofday&lt;/h4&gt;

&lt;p&gt;头文件：&lt;strong&gt;#include &lt;sys/time.h&gt;   #include &lt;unistd.h&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数定义：&lt;strong&gt;int gettimeofday (struct timeval * tv, struct timezone * tz);&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数说明：gettimeofday()会把目前的时间有tv 所指的结构返回，当地时区的信息则放到tz 所指的结构中。时间是从公元 1970 年1 月1 日的UTC 时间从0 时0 分0 秒算起到现在所经过的时间。&lt;/p&gt;

&lt;p&gt;timeval 结构定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct timeval
{
    long tv_sec;     // 秒
    long tv_usec;    // 微秒
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;timezone 结构定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct timezone
{
    int tz_minuteswest;  // 和格林威治时间差了多少分钟
    int tz_dsttime;      // 日光节约时间的状态
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;localtime&#34;&gt;localtime&lt;/h4&gt;

&lt;p&gt;头文件：&lt;strong&gt;#include &lt;time.h&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数定义：&lt;strong&gt;struct tm *localtime (const time_t *timep);&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;函数说明：localtime()将参数timep 所指的time_t 结构中的信息转换成真实世界所使用的时间日期表示方法，然后将结果由结构tm 返回。&lt;/p&gt;

&lt;p&gt;结构tm 的定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int tm_sec;   // 代表目前秒数, 正常范围为0-59, 但允许至61 秒
int tm_min;   // 代表目前分数, 范围0-59
int tm_hour;  // 从午夜算起的时数, 范围为0-23
int tm_mday;  // 目前月份的日数, 范围1-31
int tm_mon;   // 代表目前月份, 从一月算起, 范围从0-11
int tm_year;  // 从1900 年算起至今的年数
int tm_wday;  // 一星期的日数, 从星期一算起, 范围为0-6
int tm_yday;  // 从今年1 月1 日算起至今的天数, 范围为0-365
int tm_isdst; // 日光节约时间的旗标
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用localtime函数的时候需要注意计算年份的时候需要加上1900，计算月份的时候需要加1。&lt;/p&gt;

&lt;h3 id=&#34;使用说明&#34;&gt;使用说明&lt;/h3&gt;

&lt;p&gt;我们先调用gettimeofday函数获取到从公元 1970年1 月1 日的UTC 时间从0 时0 分0 秒算起到现在所经过的秒数加上微秒数，然后将秒数作为参数再调用localtime函数，转换为本地时区的当前时间即可，之后可以使用localtime函数返回的tm结构体对象来获取具体的年月日时分秒等数据。&lt;/p&gt;

&lt;h3 id=&#34;示例代码&#34;&gt;示例代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;time.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
using namespace std;
 
string fa_getSysTime()
{
    struct timeval tv;
    gettimeofday(&amp;amp;tv,NULL);
    struct tm* pTime;
    pTime = localtime(&amp;amp;tv.tv_sec);
    
    charsTemp[30] = {0};
    snprintf(sTemp, sizeof(sTemp), &amp;quot;%04d%02d%02d%02d%02d%02d%03d%03d&amp;quot;, pTime-&amp;gt;tm_year+1900, \
    pTime-&amp;gt;tm_mon+1, pTime-&amp;gt;tm_mday, pTime-&amp;gt;tm_hour, pTime-&amp;gt;tm_min, pTime-&amp;gt;tm_sec, \
    tv.tv_usec/1000,tv.tv_usec%1000);
    return (string)sTemp;
}
 
int main()
{
    cout&amp;lt;&amp;lt; &amp;quot;当前时间：&amp;quot; &amp;lt;&amp;lt; fa_getSysTime() &amp;lt;&amp;lt; endl;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;输出为&#34;&gt;输出为&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;当前时间：20140930110457794678
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>size() == 0和empty()的比较</title>
          <link>http://blog.fatedier.com/2014/09/26/function-size-equal-zero-compare-with-empty</link>
          <pubDate>Fri, 26 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/26/function-size-equal-zero-compare-with-empty</guid>
          <description>

&lt;p&gt;最近开发公司项目的时候发现大量用到了STL模板库，而且很多地方都需要判断一个容器是否为空，看到了两种写法，分别使用了容器的 size() 函数和 empty()函数。&lt;/p&gt;

&lt;p&gt;我觉得很好奇，这两种写法有什么区别呢？在网上查阅了一些资料，发现说empty()效率更高的占大多数。又查看了SGI STL的帮助文档，里面有一句话：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you are testing whether a container is empty, you should always write c.empty()instead of c.size() == 0. The two expressions are equivalent, but the formermay be much faster.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;大致上的意思就是在检测容器是否为空的时候，推荐用empty()代替使用size() == 0，两者的含义是相等的，但是前者可能会更快一些。&lt;/p&gt;

&lt;p&gt;之后又在stackoverflow上看到有人提了一个类似的问题，并且贴出了STL的实现源码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;bool empty()const
    {return(size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这就让我更诧异了，这样的话empty()会比size() == 0更高效吗？&lt;/p&gt;

&lt;p&gt;实践是检验真理的唯一标准，那么我们就亲自来测试一下吧。&lt;/p&gt;

&lt;p&gt;为了公平起见，也为了测试方便，我分别在两个平台上进行测试，分别是Aix5.3以及Centos6.5。&lt;/p&gt;

&lt;p&gt;由于容器的内部实现的不同，我们测试三种比较典型也用的较多的容器：vector、list以及map。&lt;/p&gt;

&lt;p&gt;测试的代码如下，因为代码基本上差别不大，这里只贴一下测试vector的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;vector&amp;gt;
using namespace std;

class A
{
public:
    int a;
};

int main()
{
    cout &amp;lt;&amp;lt; &amp;quot;vector:&amp;quot; &amp;lt;&amp;lt; endl;

    long number = 20000000;
    vector&amp;lt;A&amp;gt; tmpList;
    A temp;
    temp.a = 1;

    struct timeval tv_begin, tv_end;

    //初始化tmpList中元素个数为：number
    tmpList.resize(number);

    //对size() == 0计时
    int flag = 0;
    gettimeofday(&amp;amp;tv_begin, NULL);
    for(long i=0; i&amp;lt;number*5; i++)
    {
        if(tmpList.size() == 0)
        {
        }
    }
    gettimeofday(&amp;amp;tv_end, NULL);
    cout &amp;lt;&amp;lt; &amp;quot;size() msec: &amp;quot; &amp;lt;&amp;lt; (tv_end.tv_sec - tv_begin.tv_sec)*1000 + (tv_end.tv_usec - tv_begin.tv_usec)/1000 &amp;lt;&amp;lt; endl;

    //对empty()计时
    gettimeofday(&amp;amp;tv_begin, NULL);
    for(long i=0; i&amp;lt;number*5; i++)
    {
        if(tmpList.empty())
        {
        }
    }
    gettimeofday(&amp;amp;tv_end, NULL);
    cout &amp;lt;&amp;lt; &amp;quot;empty() msec: &amp;quot; &amp;lt;&amp;lt; (tv_end.tv_sec - tv_begin.tv_sec)*1000 + (tv_end.tv_usec - tv_begin.tv_usec)/1000 &amp;lt;&amp;lt; endl;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里用到了gettimeofday这个函数用来计时，在需要计时的地方分别调用两次该函数之后得到的时间相减即可获得该代码段执行的时间。&lt;/p&gt;

&lt;p&gt;timeval结构体有两个变量分别是tv_sec和tv_usec分别是精确到秒和微秒级别。&lt;/p&gt;

&lt;p&gt;因为这两个函数本身耗时太短，不方便测算时间，所以采取重复调用再计时的方法。&lt;/p&gt;

&lt;h3 id=&#34;vector&#34;&gt;vector&lt;/h3&gt;

&lt;h4 id=&#34;aix&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec:2736
empty() msec:4820

第2次输出：
vector:
size() msec:2762
empty() msec:4877
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;centos&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 298
empty() msec:1541

第2次输出：
vector:
size() msec: 283
empty() msec:1530
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;list&#34;&gt;list&lt;/h3&gt;

&lt;h4 id=&#34;aix-1&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 13
empty() msec: 22

第2次输出：
vector:
size() msec: 13
empty() msec: 22
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;centos-1&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 241696
empty() msec: 1

第2次输出：
vector:
size() msec: 242109
empty() msec: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;map&#34;&gt;map&lt;/h3&gt;

&lt;h4 id=&#34;aix-2&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 1337
empty() msec: 1733

第2次输出：
vector:
size() msec: 1339
empty() msec: 1733
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;centos-2&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-code&#34;&gt;第1次输出：
vector:
size() msec: 291
empty() msec: 267

第2次输出：
vector:
size() msec: 290
empty() msec: 304
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出，并非在所有情况下empty()的效率都是优于size()的。具体的效率还和所使用的平台相关，准确的说是和STL源码的实现方式有关。&lt;/p&gt;

&lt;p&gt;下面我们就一起来看一下两个系统中STL源码部分是如何实现size()和empty()的。&lt;/p&gt;

&lt;h3 id=&#34;vector源码&#34;&gt;vector源码&lt;/h3&gt;

&lt;h4 id=&#34;aix-3&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    {return (_Size); }
 
bool empty() const
    {return (size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出Aix上vector的empty()函数实际上是调用了size()函数进行判断，size()函数返回的是表示当前容器数量的一个变量，所以，显然，size() == 0的效率是要高于empty()的，因为少了函数调用部分的耗时。&lt;/p&gt;

&lt;h4 id=&#34;centos-3&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    { return size_type(this-&amp;gt;_M_impl._M_finish -this-&amp;gt;_M_impl._M_start); }
 
bool empty() const
    { return begin() == end(); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里size()是尾指针减去头指针得到的，而empty()是比较头指针和尾指针是否相等。在empty()里多了函数调用以及临时变量赋值等操作。&lt;/p&gt;

&lt;h3 id=&#34;list源码&#34;&gt;list源码&lt;/h3&gt;

&lt;h4 id=&#34;aix-4&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    {return (_Size); }
 
bool empty() const
    {return (size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Aix上对于在list中的处理方式依然和vector一样，维护了一个_Size变量，empty()多了一层函数调用，效率较低。&lt;/p&gt;

&lt;h4 id=&#34;centos-4&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    { return std::distance(begin(), end()); }
 
bool empty() const
    { return this-&amp;gt;_M_impl._M_node._M_next ==&amp;amp;this-&amp;gt;_M_impl._M_node; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;size()函数调用了distance函数用遍历的方法取得两个指针间的元素个数，然后返回。而empty()函数则是判断头指针的下一个节点是否是自己本身，只需要进行一次判断。所以，当list容器元素个数较多的时候，这里的empty()效率远大于size() == 0。&lt;/p&gt;

&lt;h3 id=&#34;map源码&#34;&gt;map源码&lt;/h3&gt;

&lt;h4 id=&#34;aix-5&#34;&gt;Aix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;size_type size() const
    {return (_Size); }
 
bool empty() const
    {return (size() == 0); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不出意外，可以看出Aix上依然维护了一个_Size变量，在判断的时候都是用这个变量来判断，但是empty()多了一层函数调用，所以效率上会稍微低一些。&lt;/p&gt;

&lt;h4 id=&#34;centos-5&#34;&gt;Centos&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;bool empty() const
    { return _M_impl._M_node_count == 0; }
 
size_type size() const
    { return _M_impl._M_node_count; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的map用到了红黑树，就不详细解释了，有兴趣的同学可以自己查阅相关资料。代码中empty()和size()用到的都是保存红黑树的节点数的变量，可以看出empty()和size() == 0两者其实是等价的。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;并不是所有的时候用empty()的效率都比size() == 0要高。&lt;/p&gt;

&lt;p&gt;例如在Aix上，由于所有的容器都维护了一个保存元素个数的值，调用size()的时候直接返回，而调用empty()的时候还是要去调用size()函数，所以会多一次函数调用的开销。在Aix上，显然使用size() == 0替代empty()将会使程序效率更高。&lt;/p&gt;

&lt;p&gt;而在Centos上，由于STL源码的实现方式不同，需要考虑到使用的容器，不同的容器调用size()和empty()的开销也不同，但是，相对来说，使用empty()的效率更加平均，例如在使用list容器的时候，如果数据量较大，size()的开销太大，而empty()则不会出现这种极端情况。&lt;/p&gt;

&lt;p&gt;如果考虑到平台迁移等等将来可能出现的状况，显然，empty()比size() == 0更加合适，可以确保你的程序不会出现太大的性能问题。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>从简单实例开始，学会写Makefile（二）</title>
          <link>http://blog.fatedier.com/2014/09/24/learn-to-write-makefile-02</link>
          <pubDate>Wed, 24 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/24/learn-to-write-makefile-02</guid>
          <description>

&lt;p&gt;如果文件间存在着相互之间的引用关系该怎么办？如果把.h文件和.cpp文件放在了不同的目录下该怎么办？如果我想生成静态库，然后在其他地方引用静态库该怎么办？如果我想将程序迁移到Unix平台下，使用不同的编译器，难道要依次修改所有的Makefile？&lt;/p&gt;

&lt;h3 id=&#34;d文件-解决文件间的相互引用&#34;&gt;.d文件，解决文件间的相互引用&lt;/h3&gt;

&lt;h4 id=&#34;自动生成依赖关系&#34;&gt;自动生成依赖关系&lt;/h4&gt;

&lt;p&gt;在前文的项目基础上，考虑一下这种情况：如果我们在w1.h文件里包含了头文件w2.h以及w3.h并且用到其中定义的函数。&lt;/p&gt;

&lt;p&gt;第一次编译没有遇到问题，但是如果后续的开发过程中修改了w2.h或者w3.h文件中的内容，再执行gmake命令的时候，就遇到问题了——w1.cpp文件不会被重新编译了！&lt;/p&gt;

&lt;p&gt;显然，我们需要将生成目标文件w1.o的规则的依赖项加上w2.h和w3.h。可是如果手动的去检查每一个文件的引用关系，然后修改Makefile文件，这样做的效率就太低了。&lt;/p&gt;

&lt;p&gt;万幸的是，编译器可以帮助我们自动生成依赖关系，只需要在编译命令中加上“-M”选项，就可以让编译器自动寻找源文件中包含的头文件，并生成一个依赖关系，例如，你可以在shell界面下敲下如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++-MM w1.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，其输出为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;w1.o:w1.cpp w2.h w3.h。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里需要特别注意的是，我们使用“-MM”而不是“-M”，因为我们使用的是GUN的C/C++编译器，使用“-M”参数会将标准库的头文件也一并包含进来，但这并不是我们想要的，而使用“-MM”则不会。&lt;/p&gt;

&lt;p&gt;现在的问题是，如何利用这个命令去写好我们的Makefile呢？&lt;/p&gt;

&lt;p&gt;GUN组织建议把每一个源文件自动生成的依赖关系放到一个.d文件中，让每一个.cpp文件都对应一个.d文件，例如之前的w1.cpp，我们可以生成一个w1.d文件，内容为自动生成的依赖关系 w1.o:w1.cpp w2.h w3.h，然后在Makefile中包含所有的.d文件，我们只需要写出.cpp文件和.d文件的依赖关系，让make自动更新或生成.d文件即可。&lt;/p&gt;

&lt;h4 id=&#34;生成-d文件&#34;&gt;生成.d文件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dep/%.d:%.cpp
    @if test ! -d &amp;quot;dep&amp;quot;; then\
        mkdir -p dep;\
    fi; \
    set -e; rm -f $@;
    g++ -MM $&amp;lt; &amp;gt; $@.$$$$; \
    sed &#39;s/$*\.o[ :]*/obj\/$*\.o dep\/$*\.d: /g&#39; &amp;lt; $@.$$$$ &amp;gt; $@; \
    rm -f $@.$$$$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Makefile中加上如上的代码，就可以生成我们所需要的.d文件了。&lt;/p&gt;

&lt;p&gt;又是一堆莫名其妙的符号，我们还是来逐句进行分析。&lt;/p&gt;

&lt;h5 id=&#34;dep-d-cpp&#34;&gt;dep/%.d: %.cpp&lt;/h5&gt;

&lt;p&gt;使所有的.d文件依赖于对应的.cpp文件，也就是说只要.cpp更新了，我们就重新生成对应的.d文件。这里和.o文件类似的，我们也创建一个dep目录用来存放所有的.d文件，既能保持项目文件的整洁和统一，也方便管理。&lt;/p&gt;

&lt;h5 id=&#34;if-test-d-dep-then&#34;&gt;@if test ! -d &amp;ldquo;dep&amp;rdquo;; then&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;@if test ! -d &amp;quot;dep&amp;quot;; then\
    mkdir -p dep;\
fi; \
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;检查当前目录下是否存在dep目录，如果不存在，就使用mkdir命令创建dep目录。&lt;/p&gt;

&lt;h5 id=&#34;set-e-rm-f&#34;&gt;set -e; rm -f $@;&lt;/h5&gt;

&lt;p&gt;set–e 的作用是如果命令执行出错就直接退出。$@的含义之前已经说过，这里rm –f $@的意思就是删除所有的目标文件。&lt;/p&gt;

&lt;h5 id=&#34;g-mm&#34;&gt;g++ -MM $&amp;lt; &amp;gt; $@.$$$$; &lt;/h5&gt;

&lt;p&gt;$&amp;lt; 的含义是第一个依赖项的名称，&amp;gt; 是重定向符号，将输出结果重定向到指定文件中。$@.$$$$ 就是这个文件的文件名，其中“$$$$”表示一个随机的编号，例如如果有目标文件是w1.d，那么“$@.$$$$”一个可能的结果就是w1.d.12345。那么，这句话的含义就是将g++ -MM w1.cpp的输出结果重定向到w1.d.12345这个文件中。&lt;/p&gt;

&lt;h5 id=&#34;sed-s-o-obj-o-dep-d-g&#34;&gt;sed &amp;rsquo;s/$&lt;em&gt;.o[ :]&lt;/em&gt;/obj\/$&lt;em&gt;.o dep\/$&lt;/em&gt;.d : /g&amp;rsquo; &amp;lt; $@.$$$$ &amp;gt; $@;&lt;/h5&gt;

&lt;p&gt;这里使用了sed这个工具对文本进行替换处理，单引号中的规则是’s/old/new/g’，s表示替换，末尾的g代表全局的意思，对文本中所有符合要求的字符串进行替换，sed会将符合old模式的字符串替换为new，具体的使用方法可以查阅一下sed这个工具的帮助文档。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;$@$$$$，将这个文件的内容作为sed工具的输入。

&amp;gt;$@，将sed处理后的内容重定向输出到这个文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过这一步的处理后，就把自动生成的依赖关系：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;w1.o:w1.cpp w2.h w3.h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;转成：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;w1.o w1.d:w1.cpp w2.h w3.h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样，我们的.d文件也会自动更新啦。&lt;/p&gt;

&lt;h5 id=&#34;rm-f&#34;&gt;rm -f $@.$$$$&lt;/h5&gt;

&lt;p&gt;删除掉这个临时文件。&lt;/p&gt;

&lt;h4 id=&#34;使用include包含其他文件&#34;&gt;使用include包含其他文件&lt;/h4&gt;

&lt;p&gt;在Makefile中我们也可以像在C++文件中那样包含其他文件。&lt;/p&gt;

&lt;p&gt;现在在我们的Makefile中加上这样一句：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;include w1.d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用这个语句就可以将之前我们生成的.d文件中的内容包含到当前的Makefile中。&lt;/p&gt;

&lt;p&gt;当然，也可以用这个命令来包含其他的Makefile文件。具体的用法后面再进行介绍。&lt;/p&gt;

&lt;p&gt;我们希望把所有的.d文件都包含在当前的Makefile中。&lt;/p&gt;

&lt;p&gt;先定义一个变量，存放所有的.d文件名：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DEPS = $(addsuffix .d,$(addprefix dep/,$(BASE)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后使用include$(DEPS) 包含所有的.d文件。&lt;/p&gt;

&lt;h3 id=&#34;i-引用其他目录下的-h文件&#34;&gt;-I，引用其他目录下的.h文件&lt;/h3&gt;

&lt;p&gt;考虑这种情况：现在有两个目录，一个inc目录用来存放.h文件，一个src目录，用来存放.cpp文件。怎么让编译器找到引用的.h文件在哪个目录下呢？&lt;/p&gt;

&lt;p&gt;我们可以使用“-I”选项。  格式为“-I目录名”，这样在编译的时候，编译器就会依次到我们指定的目录中寻找.h文件。&lt;/p&gt;

&lt;p&gt;同样，先定义一个变量，存放所有头文件的目录名：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;INCLUDEDIR = -I../inc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后将&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;g++ -c -o $@ $&amp;lt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样的编译命令中写成&lt;/p&gt;

&lt;p&gt;g++ -c -o $@ $(INCLUDEDIR) $&amp;lt;&lt;/p&gt;

&lt;p&gt;OK，再来尝试用gmake命令编译一下吧，已经可以成功编译了。&lt;/p&gt;

&lt;p&gt;如果需要包含多个目录下的.h文件，可以重复使用-I选项，中间需要用空格隔开。&lt;/p&gt;

&lt;h3 id=&#34;使用静态库&#34;&gt;使用静态库&lt;/h3&gt;

&lt;h4 id=&#34;修改生成静态库的makefile&#34;&gt;修改生成静态库的Makefile&lt;/h4&gt;

&lt;p&gt;有的时候我们不需要生成一个可执行的程序，而是生成一个静态库文件，之后在其他的地方引用这个静态库文件。&lt;/p&gt;

&lt;p&gt;假设我们的项目目录结构是这样的，src是项目根目录，src下面有common和app以及lib两个目录，common和app下面都有inc和src两个目录。common存放公共库的源文件，app存放程序源文件，lib存放生成的静态库。&lt;/p&gt;

&lt;p&gt;修改我们在common目录下的Makefile文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;top_srcdir = ../..
#生成静态库后所存放的位置
libdir = $(top_srcdir)/lib
#静态库文件名
LIBNAME = libfa_common.a
#路径+静态库文件名
TARGET = $(libdir)/$(LIBNAME)

$(TARGET): $(OBJS)
    -rm -f $@
    ar cr $(TARGET) $(OBJS)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;top_srcdir是项目根目录的路径，使用相对路径，方便我们在后面引用其他目录。&lt;/li&gt;
&lt;li&gt;libdir是生成的静态库所存放的路径。&lt;/li&gt;
&lt;li&gt;LIBNAME是静态库名称，注意，静态库的命名必须以“lib”开头，以“.a”结尾。&lt;/li&gt;
&lt;li&gt;TARGET是目标文件名称，包含路径。&lt;/li&gt;
&lt;li&gt;在生成静态库文件的规则中，使用ar这个命令。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;修改引用静态库的makefile&#34;&gt;修改引用静态库的Makefile&lt;/h4&gt;

&lt;p&gt;在app/src目录下的源文件中，编译的时候需要引用libfa_common.a这个静态库，这就需要我们再修改app目录下的Makefile文件。&lt;/p&gt;

&lt;p&gt;这里使用了两个新的参数，“-l”和“-L”。&lt;/p&gt;

&lt;p&gt;“-l”参数指定要引用的库的名称。例如我们要引用libfa_common.a这个静态库，那么需要在编译命令里加上“-lfa_common”，可以看出，-l后面的库名称需要去除前面的“lib”和后面的“.a”。&lt;/p&gt;

&lt;p&gt;“-L”参数指定了要引用的库的目录，用法和之前的“-I”一样。这里需要注意的是，我们需要修改一下VPATH这个变量，指明要引用的静态库的目录。类似这样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;VPATH:= -L $(top_srcdir)/lib
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;完整的makefile&#34;&gt;完整的Makefile&lt;/h3&gt;

&lt;p&gt;其实在每一个目录下的Makefile中有很多部分是重复的，我们可以考虑将重复的部分提取出来，单独放在一个公共的Makefile中，然后在其他Makefile中用include包含这个公共的Makefile即可。&lt;/p&gt;

&lt;p&gt;我写了三套Makefile，分别是Makefile（app）、Makefile（lib）、Make.rules。&lt;/p&gt;

&lt;p&gt;其中，Make.rules是公共部分，Makefile（app）是用来生成可执行程序的，Makefile（lib）是用来生成静态库的，为了以后迁移方便，考虑到Linux和Unix平台的差异，以及各个编译器之间的差异，可以将各种命令也定义成变量，之后使用宏定义进行条件编译。&lt;/p&gt;

&lt;p&gt;贴一下完整的Makefile代码。&lt;/p&gt;

&lt;h4 id=&#34;make-rules&#34;&gt;Make.rules&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#公用Make规则配置

#设置编译器类型
CXX := g++
CC := gcc

#设置编译.d文件相关内容
DEPFLAGS := -MM
DEPFILE = $@.$$$$

#设置所有静态库文件所在位置，会根据每个Makefile文件的top_srcdir设置相对位置
LIBDIR := $(top_srcdir)/lib

#设置编译程序时需要在哪些目录查找静态库文件
LDFLAGS := -L.\
           -L$(top_srcdir)/lib

#设置VPATH，在检查依赖关系时，如果查找-lxxxx时，在哪些目录查找静态库文件
VPATH := $(LIBDIR)

#设置编译程序时查找头文件的目录位置
INCLUDEDIR := -I.\
              -I../inc\

#声明要生成的目标文件，具体规则在具体的Makefile中定义
$(TARGET):

#生成.o文件所依赖的.cpp和.c文件
obj/%.o:%.cpp
@if test ! -d &amp;quot;obj&amp;quot;; then\
    mkdir-p obj;\
fi;
$(CXX)-c -o $@ $(INCLUDEDIR) $&amp;lt;

obj/%.o:%.c
    @iftest ! -d &amp;quot;obj&amp;quot;; then\
            mkdir-p obj;\
    fi;
    $(CC)-c -o $@ $(INCLUDEDIR) $&amp;lt;

#生成.d文件,存放.cpp文件的所有依赖规则
dep/%.d: %.cpp
    @iftest ! -d &amp;quot;dep&amp;quot;; then\
            mkdir-p dep;\
    fi;\
    set-e; rm -f $@;
    $(CXX)$(DEPFLAGS) $(INCLUDEDIR) $&amp;lt; &amp;gt;$(DEPFILE); \
    sed&#39;s/$*\.o[ :]*/obj\/$*\.o dep\/$*\.d : /g&#39; &amp;lt; $@.$$$$ &amp;gt; $@;\
    rm-f $@.$$$$

#生成.d文件,存放.c文件的所有依赖规则
dep/%.d: %.c
    @iftest ! -d &amp;quot;dep&amp;quot;; then\
            mkdir-p dep;\
    fi;\
    set-e; rm -f $@;
    $(CC)$(DEPFLAGS) $(INCLUDEDIR) $&amp;lt; &amp;gt; $(DEPFILE); \
    sed&#39;s/$*\.o[ :]*/obj\/$*\.o dep\/$*\.d : /g&#39; &amp;lt; $@.$$$$ &amp;gt; $@; \
    rm-f $@.$$$$

include $(DEPS)

#检测是否有文件被修改，只要有就全部编译
all: $(SRCS) $(TARGETS)

#清除编译文件
.PHONY:clean
clean:
    -rm-f $(TARGET)
    -rm-f obj/*.o
    -rm-f dep/*.d
    -rm-f core
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;makefile-lib&#34;&gt;Makefile（lib）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#需要生成静态库的Makefile

#程序根目录
top_srcdir         =../../..

#生成静态库后所存放的位置
libdir = $(top_srcdir)/lib
#静态库文件名
LIBNAME          =libfa_common.a
#路径+静态库文件名
TARGET           =$(libdir)/$(LIBNAME)

CPP_FILES = $(shell ls *.cpp)
C_FILES = $(-shell ls *.c)
SRCS = $(CPP_FILES) $(C_FILES)
BASE = $(basename $(SRCS))
OBJS = $(addsuffix .o, $(addprefixobj/,$(BASE)))
DEPS = $(addsuffix .d, $(addprefixdep/,$(BASE)))

#包含公共Make规则
include$(top_srcdir)/makeinclude/Make.rules

#设置头文件及库文件的位置
INCLUDEDIR := $(INCLUDEDIR)

$(TARGET): $(OBJS)
    -rm-f $@
    ar cr $(TARGET) $(OBJS)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;makefile-app&#34;&gt;Makefile（app）&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#需要生成可执行程序的Makefile

#程序根目录
top_srcdir         =../../..

#目标程序名
TARGET = test

CPP_FILES = $(shell ls *.cpp)
C_FILES = $(-shell ls *.c)
SRCS = $(CPP_FILES) $(C_FILES)
BASE = $(basename $(SRCS))
OBJS = $(addsuffix .o, $(addprefixobj/,$(BASE)))
DEPS = $(addsuffix .d, $(addprefixdep/,$(BASE)))

#包含公共Make规则
include $(top_srcdir)/makeinclude/Make.rules

#额外需要包含的头文件的目录位置
INCLUDEDIR := $(INCLUDEDIR)\
              -I$(top_srcdir)/src/common/inc\

#所有要包含的静态库的名称
LIBS := -lfa_common

#设置目标程序依赖的.o文件
$(TARGET):$(OBJS) $(LIBS)
    -rm-f $@
    $(CXX)-o $(TARGET) $(INCLUDEDIR) $(LDFLAGS) $(OBJS) $(LIBS)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    
      
        <item>
          <title>从简单实例开始，学会写Makefile（一）</title>
          <link>http://blog.fatedier.com/2014/09/08/learn-to-write-makefile-01</link>
          <pubDate>Mon, 08 Sep 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2014/09/08/learn-to-write-makefile-01</guid>
          <description>

&lt;p&gt;作为一个刚刚从大学毕业的新人，进公司不久就遇到了一个不大不小的门槛——看不懂Makefile！而Makefile所干的事却关系到程序的编译和链接，一个好的Makefile文件可以极大地提升编译项目文件的效率，免去手动编译的烦恼。&lt;/p&gt;

&lt;p&gt;不会写Makefile虽然还不至于影响到项目进度，从别的地方拷贝一份过来稍加修改就可以用了，但是，对于咱们“程序猿”来说这实在是一件让人感觉很不爽的事。于是，百度，谷歌（PS：吐槽一下，不XX的话Google已经完全不能用了，Bing的效果都要比百度好一些），各种看资料，看大牛的博客，或许是本人比较笨，也或许是网上的资料不太适合咱们这种新人，缺乏生动的实例讲解，所以决定自己动手研究一下，并把过程分享给大家，希望新人们看完这篇文章后就能够自己动手，为自己的项目编写合适的Makefile啦。&lt;/p&gt;

&lt;h3 id=&#34;为什么要写makefile&#34;&gt;为什么要写Makefile&lt;/h3&gt;

&lt;p&gt;首先要确定我们的目标，Makefile是用来干嘛的？&lt;/p&gt;

&lt;p&gt;曾经很长时间我都是在从事Windows环境下的开发，所以根本不知道Makefile是个什么东西。因为早已经习惯了使用VS、Eclipse等等优秀的IDE做开发，只要点一个按钮，程序就可以运行啦。但是进入公司以后，从事的是Unix环境下的开发工作，没有了IDE，要怎么才能让我写的代码编译后运行呢？&lt;/p&gt;

&lt;p&gt;在这里，Makefile的作用就体现出来了，简单的四个字—— “自动编译”。一旦整个项目的Makefile都写好了以后，只需要一个简单的make命令，就可以实现自动编译了。当然，准确的说，是make这个命令工具帮助我们实现了我们想要做的事，而Makefile就相当于是一个规则文件，make程序会按照Makefile所指定的规则，去判断哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译。&lt;/p&gt;

&lt;p&gt;俗话说，懒人创造了整个世界，程序员就是在不断偷懒的过程中获得进步，使用Makefile最根本的目的就是简化我们的工作。&lt;/p&gt;

&lt;p&gt;下面我们就从头开始，一步一步的去学习如何写好一个Makefile文件吧！&lt;/p&gt;

&lt;h3 id=&#34;从单个文件开始&#34;&gt;从单个文件开始&lt;/h3&gt;

&lt;h4 id=&#34;1-单个文件的编译&#34;&gt;1、单个文件的编译&lt;/h4&gt;

&lt;p&gt;为了便于大家学习，这篇文章是以常见的Linux平台为基础的，系统为Centos6.5，使用GNU make工具进行编译，项目文件为C++格式。这里假定看到这篇文章的都是已经对C++程序的编译等基础知识和相关命令有了一定的了解的，鉴于篇幅限制，如果还有不清楚的就请自行查阅相关资料啦。&lt;/p&gt;

&lt;p&gt;假设我们在src目录下有一个test.cpp文件，我们是如何编译它的呢？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++ -o test test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在shell界面执行这句命令，当前目录下会生成一个名为test的可执行程序，使用./test就可以执行该程序，看到输出结果。&lt;/p&gt;

&lt;p&gt;现在我们尝试使用编写Makefile的方式来实现这一编译过程。 首先在当前目录下新建文件并命名为“Makefile”，这样编译的时候直接使用gmake命令即可，默认使用“Makefile”文件进行编译，也可以是其他名字，那样的话需要使用“gmake -f 文件名”的格式来指定Makefile文件。&lt;/p&gt;

&lt;p&gt;Makefile文件内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test:test.cpp
    g++-o test test.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在shell界面下执行gmake命令，敲下回车，OK。&lt;/p&gt;

&lt;p&gt;可以发现，g++ -o test test.cpp 这条命令已经被自动执行了，生成了名为test的程序。&lt;/p&gt;

&lt;h4 id=&#34;2-makefile的描述规则&#34;&gt;2、Makefile的描述规则&lt;/h4&gt;

&lt;p&gt;至此，我们已经完成了一个最简单的Makefile文件，向我们的最终目标迈出了一大步！&lt;/p&gt;

&lt;p&gt;有的人会问，传说中的自动化编译呢？难道每一个文件都要自己去写文件名和命令？&lt;/p&gt;

&lt;p&gt;不用急，我们先来分析一下这个Makefile文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;TARGET... :PREREQUISITES...
    COMMAND
    ...
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是最简单的Makefile文件的描述规则，可以说，这也是Makefile中最精华的部分，其他部分都是围绕着这个最基本的描述规则的。先来解释一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TARGET：规则生成的目标文件，通常是需要生成的程序名（例如前面出现的程序名test）或者过程文件（类似.o文件）。&lt;/li&gt;
&lt;li&gt;PREREQUISITES：规则的依赖项，比如前面的Makefile文件中我们生成test程序所依赖的就是test.cpp。&lt;/li&gt;
&lt;li&gt;COMMAND：规则所需执行的命令行，通常是编译命令。这里需要注意的是每一行命令都需要以[TAB]字符开头。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;再来看我们之前写过的Makefile文件，这个规则，用通俗的自然语言翻译过来就是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果目标test文件不存在，根据规则创建它。&lt;/li&gt;
&lt;li&gt;目标test文件存在，并且test文件的依赖项中存在任何一个比目标文件更新（比如修改了一个函数，文件被更新了），根据规则重新生成它。&lt;/li&gt;
&lt;li&gt;目标test文件存在，并且它比所有的依赖项都更新，那么什么都不做。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当我们第一次执行gmake命令时，test文件还不存在，所以就会执行g++-o test test.cpp这条命令创建test文件。&lt;/p&gt;

&lt;p&gt;而当我们再一次执行gmake时，会提示文件已经是最新的，什么都不做。&lt;/p&gt;

&lt;p&gt;这时候，如果修改了test.cpp命令，再次执行gmake命令。&lt;/p&gt;

&lt;p&gt;由于依赖项比目标文件更新，g++ -o test test.cpp这条命令就又会被再一次执行。&lt;/p&gt;

&lt;p&gt;现在，我们已经学会如何写一个简单的Makefile文件了，每次修改过源文件以后，只要执行gmake命令就可以得到我们想要生成的程序，而不需要一遍遍地重复敲g++ -o test test.cpp这个命令。&lt;/p&gt;

&lt;h3 id=&#34;多个文件的编译&#34;&gt;多个文件的编译&lt;/h3&gt;

&lt;h4 id=&#34;1-使用命令行编译多个文件&#34;&gt;1、使用命令行编译多个文件&lt;/h4&gt;

&lt;p&gt;一个项目不可能只有一个文件，学会了单个文件的编译，自然而然就要考虑如何去编译多个文件呢？&lt;/p&gt;

&lt;p&gt;同样，假设当前目录下有如下7个文件，test.cpp、w1.h、w1.cpp、w2.h、w2.cpp、w3.h、w3.cpp。其中test.cpp包含main函数，并且引用了w1.h、w2.h以及w3.h。我们需要生成的程序名为test。&lt;/p&gt;

&lt;p&gt;在shell界面下，为了正确编译我们的项目，我们需要敲下如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++ -c -o w1.ow1.cpp
g++ -c -o w2.o w2.cpp
g++ -c -o w3.o w3.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时当前目录下会生成w1.o、w2.o、w3.o三个.o文件。这里需要注意的是，“-c”命令是只编译，不链接，通常生成.o文件的时候使用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;g++ -o testtest.cpp w1.o w2.o w3.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行完这条命令后，编译成功，得到了我们想要的test文件。&lt;/p&gt;

&lt;h4 id=&#34;2-使用makefile编译多个文件&#34;&gt;2、使用Makefile编译多个文件&lt;/h4&gt;

&lt;p&gt;既然单个文件的Makefile会写了，相信多个文件举一反三也不是问题了。&lt;/p&gt;

&lt;p&gt;Makefile具体内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test:test.cppw1.o w2.o w3.o
    g++ -o test test.cpp w1.o w2.o w3.o
w1.o:w1.cpp
    g++ -c -o w1.o w1.cpp
w2.o:w2.cpp
    g++ -c -o w2.o w2.cpp
w3.o:w3.cpp
    g++ -c -o w3.o w3.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里需要注意的是，我们写的第一个规则的目标，将会成为“终极目标”，也就是我们最终希望生成的程序，这里是“test”文件。根据我们的“终极目标”，make会进行自动推导，例如“终极目标”依赖于的.o文件，make就会寻找生成这些.o文件的规则，然后执行相应的命令去生成这些文件，这样一层一层递归地进行下去，直到最终生成了“终极目标”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2014/2014-09-08-learn-to-write-makefile-01-gmake-target.jpg&#34; alt=&#34;gmake-target&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，虽然生成test文件的规则写在最前面，但是由于依赖于w1.o、w2.o、w3.o，make会先执行生成w1.o、w2.o、w3.o所需的命令，然后才会执行g++ -o test test.cpp w1.o w2.o w3.o 来生成test文件。&lt;/p&gt;

&lt;h4 id=&#34;3-使用伪目标来清除过程文件&#34;&gt;3、使用伪目标来清除过程文件&lt;/h4&gt;

&lt;p&gt;我们现在已经可以自动编译多个文件的项目了，但是当我们需要全部重新编译的时候，难道还要手动地一个一个去删除那些生成的.o文件吗？&lt;/p&gt;

&lt;p&gt;既然已经使用了Makefile，我们的目标就是实现自动化编译，那么这些清除过程文件这点小事必须得能够用一个命令搞定啦。&lt;/p&gt;

&lt;p&gt;我们只需要在Makefile文件的最后加上如下几行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;clean:
    -rm–f test *.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK，轻松搞定，然后在shell界面下执行gmakeclean。仔细看看，是不是所有的.o文件和最后生成的程序文件已经被清除了？&lt;/p&gt;

&lt;p&gt;这里说明一下，rm是Linux下删除文件或目录的命令，前面加上“-”符号意思是忽略执行rm产生的错误。“-f”参数是指强制删除，忽略不存在的文件。&lt;/p&gt;

&lt;p&gt;这样的目标叫做“伪目标”，通过“gmake 目标名”来指定这个目标，然后执行这个目标规则下的命令。&lt;/p&gt;

&lt;h3 id=&#34;使用变量简化makefile&#34;&gt;使用变量简化Makefile&lt;/h3&gt;

&lt;p&gt;作为一个“懒惰”的程序员，现在问题又来了。如果按照上面的写法，在文件数量和名称不变的情况的下确实是没有问题，但是如果我们新增一个文件的话，岂不是又要去修改Makefile了，一个项目多的可能有成百上千的文件，这样管理起来得有多麻烦呀！&lt;/p&gt;

&lt;p&gt;还记得我们在Linux下如果要查看当前目录下所有的cpp文件的时候，使用的命令吗？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls *.cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个命令，我们就可以将所有的cpp文件名称显示在界面上。而在Makefile中我们同样可以使用类似的规则来做简化，进一步减少后续开发过程中对Makefile文件的修改。&lt;/p&gt;

&lt;p&gt;修改后的Makefile文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;TARGET = test

CPP_FILES = $(shell ls *.cpp)
BASE = $(basename $(CPP_FILES))
OBJS = $(addsuffix .o, $(addprefix obj/,$(BASE)))
 
$(TARGET):$(OBJS)
    -rm -f $@
    g++ -o $(TARGET)$(OBJS)
 
obj/%.o:%.cpp
    @if test ! -d&amp;quot;obj&amp;quot;; then\
    mkdir -pobj;\
    fi;
    g++ -c -o $@ $&amp;lt;
 
clean:
    -rm -f test
    -rm -f obj/*.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是不是瞬间有种摸不着头脑的感觉？别急，这是因为我们用到了一些新的语法和命令，其实，本质上和我们之前所写的Makefile文件是一个意思，下面我们就逐条来进行分析。&lt;/p&gt;

&lt;h5 id=&#34;target-test&#34;&gt;TARGET = test&lt;/h5&gt;

&lt;p&gt;定义一个变量，保存目标文件名，这里我们需要生成的程序名就叫test。&lt;/p&gt;

&lt;h5 id=&#34;cpp-files-shell-ls-cpp&#34;&gt;CPP_FILES = $(shell ls *.cpp)&lt;/h5&gt;

&lt;p&gt;定义一个变量，内容为所有的以.cpp为后缀的文件的文件名，以空格隔开。&lt;/p&gt;

&lt;p&gt;这里&amp;amp;(shell 命令)的格式，说明这里将会用shell命令执行后输出的内容进行替换，就和在命令行下输入ls *.cpp得到的结果一样。&lt;/p&gt;

&lt;h5 id=&#34;base-basename-cpp-files&#34;&gt;BASE = $(basename $(CPP_FILES))&lt;/h5&gt;

&lt;p&gt;定义一个变量，内容为所有的以.cpp为后缀的文件的文件名去除掉后缀部分。&lt;/p&gt;

&lt;p&gt;$(CPP_FILES)是引用CPP_FIFES这个变量的内容，相信学过如何写shell命令的同学肯定不会陌生。basename 是一个函数，其作用就是去除掉文件名的后缀部分，例如“test.cpp”，经过这一步后就变成了“test”。&lt;/p&gt;

&lt;h5 id=&#34;objs-addsuffix-o-addprefix-obj-base&#34;&gt;OBJS = $(addsuffix .o, $(addprefix obj/,$(BASE)))&lt;/h5&gt;

&lt;p&gt;定义一个变量，内容为所有的以.cpp为后缀的文件去除调后缀部分后加上“.o”。&lt;/p&gt;

&lt;p&gt;和basename一样，addsuffix和addprefix同样也是调用函数。addprefix的作用是给每个文件名加上前缀，这里是加上“obj/”，而addsuffix的作用是给每个文件名加上后缀，这里是在文件名后加上“.o”。例如“test”，经过变换后变成了“obj/test.o”。&lt;/p&gt;

&lt;p&gt;为什么要在文件名前加上“obj/”？&lt;/p&gt;

&lt;p&gt;这个不是必须的，只是我自己觉得将所有的.o文件放在一个obj目录下统一管理会让目录结构显得更加清晰，包括以后的.d文件会统一放在dep目录下一样。当然，你也可以选择不这样做，而是全部放在当前目录下。&lt;/p&gt;

&lt;h5 id=&#34;target-objs&#34;&gt;$(TARGET):$(OBJS)&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$(TARGET):$(OBJS)
    -rm -f $@
    g++ -o $(TARGET) $(OBJS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个描述规则和我们之前写过的很像，只不过，使用了变量进行替换。其中需要注意的是$@这个奇怪的符号，它的含义是这个规则的目标文件的名称，在这里就相当于是$(TARGET)。&lt;/p&gt;

&lt;p&gt;把这里的变量替换成我们之前项目中的实际值，就相当于：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test:test.ow1.o w2.o w3.o
    -rm-f test
    g++ -o test test.o w1.o w2.o w3.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果按照这种写法，当我们新增了一个w4.cpp文件的时候，就需要对Makefile进行修改，而如果我们使用了变量进行替换，那么我们就什么都不用做，直接再执行一遍gmake命令即可。&lt;/p&gt;

&lt;h5 id=&#34;obj-o-cpp&#34;&gt;obj/%.o:%.cpp&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;obj/%.o:%.cpp
    @if test ! -d&amp;quot;obj&amp;quot;; then\
        mkdir -p obj;\
    fi;
    g++ -c -o $@ $&amp;lt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是依次生成所有cpp文件所对应的.o文件的规则。&lt;/p&gt;

&lt;p&gt;%.o和%.c表示以.o和.c结尾的文件名。因为我们准备把所有的.o文件放在obj目录下，所以这里在“%.o”前面加上前缀“obj/”。&lt;/p&gt;

&lt;p&gt;下面命令行的前三行，具体的作用是检查当前目录下是否有名为“obj”的目录，如果没有，则使用mkdir命令创建这个目录。如果不了解的同学不如先去看一下shell编程的相关知识吧。&lt;/p&gt;

&lt;p&gt;最后一句中的$@前面已经解释过了，是代表规则的目标文件名称，而$&amp;lt;与之对应的，则是代表规则的依赖项中第一个依赖文件的名称。&lt;/p&gt;

&lt;p&gt;例如obj/test.o:test.cpp&lt;/p&gt;

&lt;p&gt;那么$@的值为“test.o”，$&amp;lt;的值为“test.cpp”&lt;/p&gt;

&lt;h5 id=&#34;clean&#34;&gt;clean:&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;clean:
    -rm -f test
    -rm -f obj/*.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个就没什么好说的啦，这里只是修改了一下.o文件的路径。&lt;/p&gt;

&lt;p&gt;到这里，相信你对如何使用Makefile来编译一个小的项目已经颇有些眉目了吧。使用这个Makefile文件，不管你往这个目录下加多少文件，轻轻松松一个gmake命令搞定，不需要再因为加了一个新的文件而去修改Makefile了。&lt;/p&gt;

&lt;p&gt;但是，你难道没有觉得仍然存在着很多问题吗？&lt;/p&gt;

&lt;p&gt;如果文件间存在着相互之间的引用关系该怎么办？&lt;/p&gt;

&lt;p&gt;如果把.h文件和.cpp文件放在了不同的目录下该怎么办？&lt;/p&gt;

&lt;p&gt;如果我想生成静态库，然后在其他地方引用静态库该怎么办？&lt;/p&gt;

&lt;p&gt;如果我想将程序迁移到Unix平台下，使用不同的编译器，难道要依次修改所有的Makefile？&lt;/p&gt;

&lt;p&gt;大家可以先尝试着自己解决以上的问题，在之后的篇幅中我们会就以上几点继续通过举例的方式来加以解决。&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
