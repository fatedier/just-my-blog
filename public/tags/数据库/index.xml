<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fatedier blog </title>
    <link>http://blog.fatedier.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2016</rights>
    <updated>2016-07-05 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>时间序列数据库调研之InfluxDB</title>
          <link>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb</link>
          <pubDate>Tue, 05 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/05/research-of-time-series-database-influxdb</guid>
          <description>

&lt;p&gt;基于 Go 语言开发，社区非常活跃，项目更新速度很快，日新月异，关注度高。&lt;/p&gt;

&lt;h3 id=&#34;测试版本:441ef2dfb3e97650c90da967029aaee7&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;1.0.0_beta2-1&lt;/p&gt;

&lt;h3 id=&#34;安装部署:441ef2dfb3e97650c90da967029aaee7&#34;&gt;安装部署&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo yum localinstall influxdb-1.0.0_beta2.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;配置文件路径为 &lt;code&gt;/etc/influxdb/influxdb.conf&lt;/code&gt;，修改后启动服务&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo service influxdb start&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;特点:441ef2dfb3e97650c90da967029aaee7&#34;&gt;特点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可以设置metric的保存时间。&lt;/li&gt;
&lt;li&gt;支持通过条件过滤以及正则表达式删除数据。&lt;/li&gt;
&lt;li&gt;支持类似 sql 的语法。&lt;/li&gt;
&lt;li&gt;可以设置数据在集群中的副本数。&lt;/li&gt;
&lt;li&gt;支持定期采样数据，写入另外的measurement，方便分粒度存储数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;概念:441ef2dfb3e97650c90da967029aaee7&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式-line-protocol:441ef2dfb3e97650c90da967029aaee7&#34;&gt;数据格式 Line Protocol&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;measurement[,tag_key1=tag_value1...] field_key=field_value[,field_key2=field_value2] [timestamp]

cpu_load,host_id=1 value=0.1 1434055562000000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比于 JSON 格式，无需序列化，更加高效。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;measurement: metric name，例如 cpu_load。&lt;/li&gt;
&lt;li&gt;field-key, field-value: 通常用来存储数据，类似 opentsdb 中的 value=0.6，但是支持各种类型，数据存储时不会进行索引，每条数据必须拥有一个 field-key，如果使用 field-key 进行过滤，需要遍历一遍所有数据。&lt;/li&gt;
&lt;li&gt;tags-key, tags-value: 和 field-key 类似，但是会进行索引，方便查询时用于过滤条件。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;series:441ef2dfb3e97650c90da967029aaee7&#34;&gt;Series&lt;/h4&gt;

&lt;p&gt;measurement, tag set, retention policy 相同的数据集合算做一个 series。&lt;/p&gt;

&lt;p&gt;假设 cpu_load 有两个 tags，host_id 和 name，host_id 的数量为 100，name 的数量为 200，则 series 基数为 100 * 200 = 20000。&lt;/p&gt;

&lt;h4 id=&#34;数据存储:441ef2dfb3e97650c90da967029aaee7&#34;&gt;数据存储&lt;/h4&gt;

&lt;p&gt;measurements, tag keys, field keys，tag values 全局存一份。&lt;/p&gt;

&lt;p&gt;field values 和 timestamps 每条数据存一份。&lt;/p&gt;

&lt;h4 id=&#34;retention-policy:441ef2dfb3e97650c90da967029aaee7&#34;&gt;Retention Policy&lt;/h4&gt;

&lt;p&gt;保留策略包括设置数据保存的时间以及在集群中的副本个数。&lt;/p&gt;

&lt;p&gt;默认的 RP 为 &lt;strong&gt;default&lt;/strong&gt;，保存时间不限制，副本个数为 1，默认 RP 是可以修改的，并且我们可以创建新的 RP。&lt;/p&gt;

&lt;h4 id=&#34;continuous-query:441ef2dfb3e97650c90da967029aaee7&#34;&gt;Continuous Query&lt;/h4&gt;

&lt;p&gt;CQ 是预先配置好的一些查询命令，&lt;strong&gt;SELECT&lt;/strong&gt; 语句必须包含 &lt;strong&gt;GROUP BY time()&lt;/strong&gt;，influxdb 会定期自动执行这些命令并将查询结果写入指定的另外的 measurement 中。&lt;/p&gt;

&lt;p&gt;利用这个特性并结合 RP 我们可以方便地保存不同粒度的数据，根据数据粒度的不同设置不同的保存时间，这样不仅节约了存储空间，而且加速了时间间隔较长的数据查询效率，避免查询时再进行聚合计算。&lt;/p&gt;

&lt;h4 id=&#34;shard:441ef2dfb3e97650c90da967029aaee7&#34;&gt;Shard&lt;/h4&gt;

&lt;p&gt;Shard 这个概念并不对普通用户开放，实际上是 InfluxDB 将连续一段时间内的数据作为一个 shard 存储，根据数据保存策略来决定，通常是保存1天或者7天的数据。例如如果保存策略 RP 是无限制的话，shard 将会保存7天的数据。这样方便之后的删除操作，直接关闭下层对应的一个数据库即可。&lt;/p&gt;

&lt;h3 id=&#34;存储引擎:441ef2dfb3e97650c90da967029aaee7&#34;&gt;存储引擎&lt;/h3&gt;

&lt;p&gt;从 LevelDB（LSM Tree），到 BoltDB（mmap B+树），现在是自己实现的 TSM Tree 的算法，类似 LSM Tree，针对 InfluxDB 的使用做了特殊优化。&lt;/p&gt;

&lt;h4 id=&#34;leveldb:441ef2dfb3e97650c90da967029aaee7&#34;&gt;LevelDB&lt;/h4&gt;

&lt;p&gt;LevelDB 底层使用了 LSM Tree 作为数据结构，用于存储大量的 key 值有序的 K-V 数据，鉴于时序数据的特点，只要将时间戳放入 key 中，就可以非常快速的遍历指定时间范围内的数据。LSM Tree 将大量随机写变成顺序写，所以拥有很高的写吞吐量，并且 LevelDB 内置了压缩功能。&lt;/p&gt;

&lt;p&gt;数据操作被先顺序写入 WAL 日志中，成功之后写入内存中的 MemTable，当 MemTable 中的数据量达到一定阀值后，会转换为 Immutable MemTable，只读，之后写入 SSTable。SSTable 是磁盘上只读的用于存储有序键值对的文件，并且会持续进行合并，生成新的 SSTable。在 LevelDB 中是分了不同层级的 SSTable 用于存储数据。&lt;/p&gt;

&lt;p&gt;LevelDB 不支持热备份，它的变种 RocksDB 和 HyperLevelDB 实现了这个功能。&lt;/p&gt;

&lt;p&gt;最严重的问题是由于 InfluxDB 通过 shard 来组织数据，每一个 shard 对应的就是一个 LevelDB 数据库，而由于 LevelDB 的底层存储是大量 SSTable 文件，所以当用户需要存储长时间的数据，例如几个月或者一年的时候，会产生大量的 shard，从而消耗大量文件描述符，将系统资源耗尽。&lt;/p&gt;

&lt;h4 id=&#34;boltdb:441ef2dfb3e97650c90da967029aaee7&#34;&gt;BoltDB&lt;/h4&gt;

&lt;p&gt;之后 InfluxDB 采用了 BoltDB 作为数据存储引擎。BoltDB 是基于 LMDB 使用 Go 语言开发的数据库。同 LevelDB 类似的是，都可以用于存储 key 有序的 K-V 数据。&lt;/p&gt;

&lt;p&gt;虽然采用 BoltDB 的写效率有所下降，但是考虑到用于生产环境需要更高的稳定性，BoltDB 是一个合适的选择，而且 BoltDB 使用纯 Go 编写，更易于跨平台编译部署。&lt;/p&gt;

&lt;p&gt;最重要的是 BoltDB 的一个数据库存储只使用一个单独的文件。Bolt 还解决了热备的问题，很容易将一个 shard 从一台机器转移到另外一台。&lt;/p&gt;

&lt;p&gt;但是当数据库容量达到数GB级别时，同时往大量 series 中写入数据，相当于是大量随机写，会造成 IOPS 上升。&lt;/p&gt;

&lt;h4 id=&#34;tsm-tree:441ef2dfb3e97650c90da967029aaee7&#34;&gt;TSM Tree&lt;/h4&gt;

&lt;p&gt;TSM Tree 是 InfluxDB 根据实际需求在 LSM Tree 的基础上稍作修改优化而来。&lt;/p&gt;

&lt;h5 id=&#34;wal:441ef2dfb3e97650c90da967029aaee7&#34;&gt;WAL&lt;/h5&gt;

&lt;p&gt;每一个 shard 对应底层的一个数据库。每一个数据库有自己的 WAL 文件，压缩后的元数据文件，索引文件。&lt;/p&gt;

&lt;p&gt;WAL 文件名类似 &lt;code&gt;_000001.wal&lt;/code&gt;，数字递增，每达到 2MB 时，会关闭此文件并创建新的文件，有一个写锁用于处理多协程并发写入的问题。&lt;/p&gt;

&lt;p&gt;可以指定将 WAL 从内存刷新到磁盘上的时间，例如30s，这样会提高写入性能，同时有可能会丢失这30s内的数据。&lt;/p&gt;

&lt;p&gt;每一个 WAL 中的条目遵循 TLV 的格式，1字节用于表示类型（points，new fields，new series，delete），4字节表示 block 的长度，后面则是具体压缩后的 block 内容。WAL 文件中得内容在内存中会进行缓存，并且不会压缩，每一个 point 的 key 为 measurement, tagset 以及 unique field，每一个 field 按照自己的时间顺序排列。&lt;/p&gt;

&lt;p&gt;查询操作将会去 WAL 以及索引中查询，WAL 在内存中缓存有一个读写锁进行控制。删除操作会将缓存中的key删除，同时在 WAL 文件中进行记录并且在内存的索引中进行删除标记。&lt;/p&gt;

&lt;h5 id=&#34;data-files-sstables:441ef2dfb3e97650c90da967029aaee7&#34;&gt;Data Files(SSTables)&lt;/h5&gt;

&lt;p&gt;这部分 InfluxDB 自己定义了特定的数据结构，将时间戳编码到了 DataFiles 中，进行了相对于时间序列数据的优化。&lt;/p&gt;

&lt;h3 id=&#34;api:441ef2dfb3e97650c90da967029aaee7&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;通过 HTTP 访问 influxdb。&lt;/p&gt;

&lt;p&gt;语法上是一种类似于 SQL 的命令，官方称为 InfluxQL。&lt;/p&gt;

&lt;h4 id=&#34;创建数据库:441ef2dfb3e97650c90da967029aaee7&#34;&gt;创建数据库&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -POST http://localhost:8086/query --data-urlencode &amp;quot;q=CREATE DATABASE mydb&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;插入数据:441ef2dfb3e97650c90da967029aaee7&#34;&gt;插入数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;cpu_load_short 是 measurement，host 和 region 是 tags-key，value 是 field-key。&lt;/p&gt;

&lt;p&gt;多条数据时，用换行区分每条数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -i -XPOST &#39;http://localhost:8086/write?db=mydb&#39; --data-binary &#39;cpu_load_short,host=server02 value=0.67
cpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257
cpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;读取数据:441ef2dfb3e97650c90da967029aaee7&#34;&gt;读取数据&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -GET &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时查询多条数据时，以分号分隔&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -G &#39;http://localhost:8086/query&#39; --data-urlencode &amp;quot;db=mydb&amp;quot; --data-urlencode &amp;quot;epoch=s&amp;quot; --data-urlencode &amp;quot;q=SELECT value FROM cpu_load_short WHERE region=&#39;us-west&#39;;SELECT count(value) FROM cpu_load_short WHERE region=&#39;us-west&#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 &lt;code&gt;--data-urlencode &amp;quot;epoch=s&amp;quot;&lt;/code&gt; 会使返回的时间戳为 unix 时间戳格式。&lt;/p&gt;

&lt;h4 id=&#34;创建-rp:441ef2dfb3e97650c90da967029aaee7&#34;&gt;创建 RP&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE RETENTION POLICY two_hours ON food_data DURATION 2h REPLICATION 1 DEFAULT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里将 &lt;strong&gt;two_hours&lt;/strong&gt; 设置成了默认保存策略，存入 food_data 中的数据如果没有明确指定 RP 将会默认采用此策略，数据保存时间为 2 小时，副本数为 1。&lt;/p&gt;

&lt;h4 id=&#34;创建-cq:441ef2dfb3e97650c90da967029aaee7&#34;&gt;创建 CQ&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CREATE CONTINUOUS QUERY cq_5m ON food_data BEGIN SELECT mean(website) AS mean_website,mean(phone) AS mean_phone INTO food_data.&amp;quot;default&amp;quot;.downsampled_orders FROM orders GROUP BY time(5m) END
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里创建了一个 CQ，每个5分钟将 two_hours.orders 中的数据计算5分钟的平均值后存入 default.downsampled_orders 中，default 这个 RP 中的数据是永久保存的。&lt;/p&gt;

&lt;h4 id=&#34;where:441ef2dfb3e97650c90da967029aaee7&#34;&gt;WHERE&lt;/h4&gt;

&lt;p&gt;查询时指定查询的限制条件，例如查询最近1小时内 host_id=1 的机器的 cpu 数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT value FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;group-by:441ef2dfb3e97650c90da967029aaee7&#34;&gt;GROUP BY&lt;/h4&gt;

&lt;p&gt;类似于 SQL 中的语法，可以对细粒度数据进行聚合计算，例如查询最近1小时内 host_id=1 的机器的 cpu 的数据，并且采样为每5分钟的平均值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SELECT mean(value) FROM cpu_load WHERE time &amp;gt; now() - 1h and host_id = 1 GROUP BY time(5m)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;官方推荐硬件配置:441ef2dfb3e97650c90da967029aaee7&#34;&gt;官方推荐硬件配置&lt;/h3&gt;

&lt;h4 id=&#34;单节点:441ef2dfb3e97650c90da967029aaee7&#34;&gt;单节点&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Load&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Writes per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Queries per second&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Unique series&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Low&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Moderate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;lt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;High&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 1 million&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Probably infeasible&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 500 thousand&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 100&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 10 million&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;Low: CPU 2-4, RAM 2-4GB, IOPS 500&lt;/li&gt;
&lt;li&gt;Moderate: CPU 4-6, RAM 8-32GB, IOPS 500-1000&lt;/li&gt;
&lt;li&gt;High: CPU CPU 8+, RAM 32GB+, IOPS 1000+&lt;/li&gt;
&lt;li&gt;Probably infeasible: 可能单机无法支持，需要集群环境&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;集群:441ef2dfb3e97650c90da967029aaee7&#34;&gt;集群&lt;/h4&gt;

&lt;p&gt;InfluxDB 从 0.12 版本开始将不再开源其 cluster 源码，而是被用做提供商业服务。&lt;/p&gt;

&lt;p&gt;如果考虑到以后的扩展，需要自己在前端做代理分片或者类似的开发工作。&lt;/p&gt;

&lt;p&gt;已知七牛是采用了 InfluxDB 作为时间序列数据的存储，自研了调度器以及高可用模块，具有横向扩展的能力。&lt;/p&gt;

&lt;h3 id=&#34;总结:441ef2dfb3e97650c90da967029aaee7&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;目前最火热的时间序列数据库项目，社区开发活跃，迭代更新较快，存储引擎经常变化，网上的一些资料都比较过时，例如最新的 TSM 存储引擎只能看到官方的文档简介，还没有详细的原理说明的文章。&lt;/p&gt;

&lt;p&gt;就单机来说，在磁盘占用、cpu使用率、读写速度方面都让人眼前一亮。如果数据量级不是非常大的情况下，单节点的 InfluxDB 就可以承载数十万每秒的写入，是一个比较合适的选择。&lt;/p&gt;

&lt;p&gt;另一方面，从 0.12 版本开始不再开源其集群代码（虽然之前的集群部分就比较烂），如果考虑到之后进行扩展的话，需要进行二次开发。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>时间序列数据库调研之OpenTSDB</title>
          <link>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb</link>
          <pubDate>Mon, 04 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb</guid>
          <description>

&lt;p&gt;Java 项目，基于 HBase（2.3版本貌似开始支持 Google BigTable 和 Cassandra） 的一个时间序列数据库，被广泛应用于监控系统中。很多大公司都在使用，社区较为活跃。&lt;/p&gt;

&lt;h3 id=&#34;测试版本:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;hbase-1.1.5&lt;/p&gt;

&lt;p&gt;opentsdb-2.2.0&lt;/p&gt;

&lt;h3 id=&#34;单机部署:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;单机部署&lt;/h3&gt;

&lt;p&gt;单机部署可以参考我之前的一篇文章，集群部署比较复杂，这里仅使用单机进行测试。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/&#34;&gt;OpenTSDB部署与使用&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;数据格式&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;metric: 一个可测量的单位的标称。&lt;/li&gt;
&lt;li&gt;tags: 对 metric 的具体描述。&lt;/li&gt;
&lt;li&gt;timestamp: 时间戳。&lt;/li&gt;
&lt;li&gt;value: metric 的实际测量值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;uid:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;UID&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，每一个 metric、tagk 或者 tagv 在创建的时候被分配一个唯一标识叫做 UID。在后续的实际存储中，实际上存储的是 UID，而不是它们原本的字符串，UID 占 3个字节（也可以修改源码改为4字节），这样可以节省存储空间。&lt;/p&gt;

&lt;h4 id=&#34;tsuid:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;TSUID&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;metric_UID&amp;gt;&amp;lt;timestamp&amp;gt;&amp;lt;tagk1_UID&amp;gt;&amp;lt;tagv1_UID&amp;gt;[...&amp;lt;tagkN_UID&amp;gt;&amp;lt;tagvN_UID&amp;gt;]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;写入 HBase 时的 row key 格式，其中的 metric、tagk 和 tagv 都被转换成了 UID。&lt;/p&gt;

&lt;h4 id=&#34;data-table-schema:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;Data Table Schema&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-data-table-schema.png&#34; alt=&#34;data-table-schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RowKey&lt;/strong&gt; 就是上述的 TSUID，除了时间戳占 4 byte，其余 UID 占 3 byte。&lt;/p&gt;

&lt;p&gt;时间戳的部分只保留到了小时粒度，具体相对于小时的偏移量被存储在了 &lt;strong&gt;列族 t&lt;/strong&gt; 中。这样就减小了 HBase 中的存储行数。也就是说对于同一个小时的 metric + tags 相同的数据都会存放在一个 row 下面，这样的设计提高了 row 的检索速度。&lt;/p&gt;

&lt;p&gt;这样的 RowKey 设计使得 metric + tags 相同的数据都会连续存放，且 metric 相同的数据也会连续存放，底层 HBase 中会放在同一 Region 中，在做 Scan 的时候可以快速读取到大片数据，加速查询的过程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;value&lt;/strong&gt; 使用 8 bytes 存储，既可以存储 long,也可以存储 double。&lt;/p&gt;

&lt;h4 id=&#34;compaction:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;Compaction&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，会将多列合并到一列之中以减少磁盘占用空间，这个过程会在 TSD 写数据或者查询过程中不定期的发生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-compaction.png&#34; alt=&#34;compaction&#34; /&gt;&lt;/p&gt;

&lt;p&gt;例如图中，将列 1890 和 列 1892 合并到了一起。&lt;/p&gt;

&lt;h3 id=&#34;api:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;OpenTSDB 同样提供了一套基于 HTTP 的 API 接口。&lt;/p&gt;

&lt;h4 id=&#34;插入数据:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/put&#34;&gt;http://localhost:4242/api/put&lt;/a&gt;, POST&lt;/p&gt;

&lt;p&gt;内容为 JSON 格式，支持同时插入多条数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 18,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web01&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 9,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web02&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查询数据:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;查询数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/query&#34;&gt;http://localhost:4242/api/query&lt;/a&gt;, POST&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1463452826,
    &amp;quot;end&amp;quot;: 1463453026,
    &amp;quot;globalAnnotations&amp;quot;: true,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;avg&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.disk.usage&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.load&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;start&lt;/strong&gt; 和 &lt;strong&gt;end&lt;/strong&gt; 指定了查询的时间范围。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tags&lt;/strong&gt; 指定了过滤条件，2.2 版本中将不被推荐，取而代之的是 filters 参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;downsample&lt;/strong&gt; 聚合计算，例如上面是对每隔60s的数据计算一次平均值。&lt;/p&gt;

&lt;h3 id=&#34;总结:2bcfdb374ee9d4126e3ae956caebf257&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;OpenTSDB 在存储时间序列数据这一领域拥有很大的优势，被大多数公司所采用，网上的相关文档也比较全面。&lt;/p&gt;

&lt;p&gt;底层存储依托于 HBase，采用特殊设计过的数据存储格式，提供了非常快的查询速度，在此基础之上也更容易横向扩展。&lt;/p&gt;

&lt;p&gt;但是，相对于 InfluxDB 这种即使是新手也可以在两分钟内部署运行完成，OpenTSDB 的部署和运维显然要麻烦很多，由于底层依赖于 HBase，想要大规模运行起来，需要相当专业、细心的运维工作。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>OpenTSDB部署与使用</title>
          <link>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb</link>
          <pubDate>Sat, 12 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb</guid>
          <description>

&lt;p&gt;OpenTSDB 是基于 HBase 存储时间序列数据的一个开源数据库，对于存储监控系统采集的数据来说非常合适，不仅在写入查询上有很高的效率，而且节省存储空间。&lt;/p&gt;

&lt;h3 id=&#34;安装-hbase:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;安装 HBase&lt;/h3&gt;

&lt;p&gt;因为 OpenTSDB 的后端存储使用的是 HBase，所以我们需要先安装 HBase。&lt;/p&gt;

&lt;p&gt;参考文档： &lt;a href=&#34;https://hbase.apache.org/book.html#quickstart&#34;&gt;Quick Start - Standalone HBase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里简单搭建了一个&lt;strong&gt;单机&lt;/strong&gt;的 HBase 环境：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;安装 JDK 环境，centos 上可以直接通过 yum 安装。&lt;/li&gt;
&lt;li&gt;下载 HBase，&lt;a href=&#34;http://apache.fayea.com/hbase/stable&#34;&gt;http://apache.fayea.com/hbase/stable&lt;/a&gt;，这里我们选择下载 stable 的 1.1.3 版本，文件名为 &lt;code&gt;hbase-1.1.3-bin.tar.gz&lt;/code&gt;，解压到任意目录。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-env.sh&lt;/code&gt; ，设置  &lt;code&gt;JAVA_HOME=/usr&lt;/code&gt;，这个是 &lt;code&gt;/bin/java&lt;/code&gt; 所在的目录，通过 &lt;code&gt;which java&lt;/code&gt; 查看。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-site.xml&lt;/code&gt;， 设置 hbase 的数据存储目录以及 zookeeper 的数据存储目录，默认会放到 &lt;code&gt;/tmp&lt;/code&gt; 目录下，这个目录机器重启后会清空，所以需要更改目录。&lt;/li&gt;
&lt;li&gt;执行 &lt;code&gt;bin/start-hbase.sh&lt;/code&gt; 启动 HBase，之后可以通过 &lt;code&gt;jps&lt;/code&gt; 命令来查看 HMaster 进程是否启动成功。 &lt;code&gt;bin/stop-hbase.sh&lt;/code&gt; 用于关闭 HBase。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;conf/hbase-site.xml&lt;/code&gt; 的配置示例如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/testuser/hbase&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/testuser/zookeeper&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过命令行操作-hbase:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;通过命令行操作 HBase&lt;/h3&gt;

&lt;p&gt;这里可以稍微熟悉一下 HBase 的操作，非必须。&lt;/p&gt;

&lt;h5 id=&#34;连接到-hbase:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;连接到 HBase&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;./bin/hbase shell&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;创建一张表:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;创建一张表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;create &#39;test&#39;, &#39;cf&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看表信息:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;查看表信息&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;list &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;向表中插入数据:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;向表中插入数据&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;
put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;
put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看表中所有数据:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;查看表中所有数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;scan &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看指定行的数据:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;查看指定行的数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;get &#39;test&#39;, &#39;row1&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;禁用指定表-删除表或修改表设置前需要先禁用该表:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;禁用指定表（删除表或修改表设置前需要先禁用该表）&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;disable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;恢复指定表:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;恢复指定表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;enable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;删除表:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;删除表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;drop &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装opentsdb:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;安装OpenTSDB&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://debugo.com/opentsdb/&#34;&gt;http://debugo.com/opentsdb/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&#34;&gt;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;直接从 github 上下载 OpenTSDB 的 &lt;a href=&#34;https://github.com/OpenTSDB/opentsdb&#34;&gt;release&lt;/a&gt; 版本的 RPM 包。安装 &lt;code&gt;yum localinstall opentsdb-2.2.0.noarch.rpm&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置完成后，我们通过下面命令在 HBase 中建立 opentsdb 所需的表。默认情况下 opentsdb 建立的 HBase 表启用了 lzo 压缩。需要开启 Hadoop 中的 lzo 压缩支持， 这里我们直接在下面脚本中把 COMPRESSION 的支持关闭。修改 &lt;code&gt;/usr/share/opentsdb/tools/create_table.sh&lt;/code&gt;，设置 &lt;code&gt;COMPRESSION=NONE&lt;/code&gt;，并且在文件开始处设置 HBase 所在目录， &lt;code&gt;HBASE_HOME=/home/xxx/hbase-1.1.3&lt;/code&gt;。之后执行该脚本，在 HBase 中创建相应的表。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;修改 OpenTSDB 的配置文件，&lt;code&gt;/etc/opentsdb/opentsdb.conf&lt;/code&gt;，例如绑定的端口号等。&lt;strong&gt;这里需要注意的是 tsd.core.auto_create_metrics 从 false 改为 true。这样上传数据时会自动创建 metric，否则会提示 Unknown metric 的错误。也可以设置为 false，但是使用 &lt;code&gt;tsdb mkmetric proc.loadavg.1m&lt;/code&gt; 来手动添加 metric。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;启动 OpenTSDB，&lt;code&gt;service opentsdb start&lt;/code&gt; 或者 &lt;code&gt;nohup tsdb tsd &amp;amp;&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过浏览器访问 &lt;a href=&#34;http://x.x.x.x:4242&#34;&gt;http://x.x.x.x:4242&lt;/a&gt; 查看是否安装成功。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;http-api:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;HTTP API&lt;/h3&gt;

&lt;h4 id=&#34;插入数据:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;/api/put&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据 url 参数的不同，可以选择是否获取详细的信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;/api/put?summary&lt;/strong&gt;        // 返回失败和成功的个数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;/api/put?details&lt;/strong&gt;        // 返回详细信息&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;errors&amp;quot;: [],
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过POST方式插入数据，JSON格式，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;metric&amp;quot;:&amp;quot;self.test&amp;quot;, 
    &amp;quot;timestamp&amp;quot;:1456123787, 
    &amp;quot;value&amp;quot;:20, 
    &amp;quot;tags&amp;quot;:{
        &amp;quot;host&amp;quot;:&amp;quot;web1&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查询数据:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;查询数据&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;/api/query&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可以选择 Get 或者 Post 两种方式，推荐使用 Post 方式，JSON 格式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1456123705,
    &amp;quot;end&amp;quot;: 1456124985,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web2&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;start 和 end 为指定的查询时间段。&lt;/p&gt;

&lt;p&gt;queries 为一个数组，可以指定多个查询。&lt;/p&gt;

&lt;p&gt;metric 和 tags 是用于过滤的查询条件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;返回字符串也为json格式&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {},
        &amp;quot;aggregateTags&amp;quot;: [
            &amp;quot;host&amp;quot;
        ],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123785&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 10
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        },
        &amp;quot;aggregateTags&amp;quot;: [],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123784&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 15
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;聚合:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;聚合&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;aggregator&lt;/strong&gt; 是用于对查询结果进行聚合，将同一 unix 时间戳内的数据进行聚合计算后返回结果，例如如果 tags 不填，1456123705 有两条数据，一条 &lt;code&gt;host=web1&lt;/code&gt;，另外一条 &lt;code&gt;host=web2&lt;/code&gt;，值都为10，那么返回的该时间点的值为 sum 后的 20。&lt;/p&gt;

&lt;h4 id=&#34;条件过滤:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;条件过滤&lt;/h4&gt;

&lt;p&gt;可以针对 tag 进行一些条件的过滤，返回 tag 中 host 的值以 web 开头的数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;filters&amp;quot;: [
            {
                &amp;quot;type&amp;quot;: &amp;quot;wildcard&amp;quot;,
                &amp;quot;tagk&amp;quot;: &amp;quot;host&amp;quot;,
                &amp;quot;filter&amp;quot;: &amp;quot;web*&amp;quot;
            }
        ]
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;downsample:f7a0fb8dc4f1344c3cd3f22f8254b5c8&#34;&gt;downsample&lt;/h4&gt;

&lt;p&gt;简单来说就是对指定时间段内的数据进行聚合后返回，例如需要返回每分钟的平均值数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;downsample&amp;quot;: &amp;quot;1m-avg&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
      
    

  </channel>
</rss>
