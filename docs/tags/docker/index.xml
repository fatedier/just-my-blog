<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fatedier blog </title>
    <link>http://blog.fatedier.com/tags/docker/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2017</rights>
    <updated>2017-07-16 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>记一次mesos集群停容器时间过长的问题排查</title>
          <link>http://blog.fatedier.com/2017/07/16/record-problem-resolve-for-docker-stop-slow/</link>
          <pubDate>Sun, 16 Jul 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2017/07/16/record-problem-resolve-for-docker-stop-slow/</guid>
          <description>&lt;p&gt;公司 mesos 集群某个 app 已经有数千的实例数，每次做滚动升级时，由于总资源不足，需要分批操作，每次起一批新版本实例，再停一批旧版本实例。目前停容器的策略是，先从服务发现中摘除需要停掉的节点，等待 60 秒后再停止容器，释放资源，但是实际上每次从发送停止容器的请求到容器资源被实际释放需要长达 6 分钟，导致滚动升级耗时过长。经过排查，最终确认问题出在我们使用 docker 的方式上，这里记录下分析和解决问题的过程。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;集群环境&#34;&gt;集群环境&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;ubuntu 14.04&lt;/li&gt;
&lt;li&gt;mesos 1.0.1&lt;/li&gt;
&lt;li&gt;docker 1.12.1&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;现象&#34;&gt;现象&lt;/h3&gt;

&lt;p&gt;从发送停止容器请求给 mesos 调度器到实际资源被释放，耗时超过 6 分钟。登录机器手动调用 &lt;code&gt;docker stop&lt;/code&gt; 停止容器只需 10 秒。&lt;/p&gt;

&lt;h3 id=&#34;排查问题&#34;&gt;排查问题&lt;/h3&gt;

&lt;p&gt;停止一个容器的请求，经过的步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;client 发送停止容器请求给 scheduler。&lt;/li&gt;
&lt;li&gt;scheduler 和 mesos-master 交互，请求停止对应的 TASK。&lt;/li&gt;
&lt;li&gt;mesos-master 发送请求给对应机器的 mesos-agent 要求停止这个容器。&lt;/li&gt;
&lt;li&gt;mesos-agent 发送 &lt;code&gt;TASK_KILL&lt;/code&gt; 消息给对应的 executor（这里用的是 mesos-docker-executor）。&lt;/li&gt;
&lt;li&gt;mesos-docker-executor 收到 &lt;code&gt;TASK_KILL&lt;/code&gt; 消息，调用 docker stop 停止容器，确认容器被停止后，发送确认消息给 mesos-agent。&lt;/li&gt;
&lt;li&gt;mesos-docker-executor 退出。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中步骤二 scheduler 和 mesos-master 的交互会延迟 60s，是为了让容器平滑的关闭，处理完已经接收到的请求。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;初步推测可能是 mesos-agent 或者 mesos-docker-executor 组件哪里出现了问题。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;检查是否是-mesos-agent-或-executor-的问题&#34;&gt;检查是否是 mesos-agent 或 executor 的问题&lt;/h4&gt;

&lt;p&gt;登录要停止的容器的机器，通过 &lt;code&gt;docker ps&lt;/code&gt; 查看对应容器的 name，这里假设是 &lt;code&gt;mesos-5ff75923-a2fd-4959-bb3b-4b128e43e9eb-S353.d008ad6c-37be-4cc5-ae40-3ba6a7ebca20&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;ps -ef|grep mesos-5ff75923-a2fd-4959-bb3b-4b128e43e9eb-S353.d008ad6c-37be-4cc5-ae40-3ba6a7ebca20&lt;/code&gt; 获取这个容器对应的 mesos-docker-executor 的 pid，这里假设是 &lt;code&gt;24235&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;ss -antp|grep 24235|grep LIS&lt;/code&gt; 查看这个进程目前监听的端口，mesos-agent 会通过这个端口和 mesos-docker-executor 通信，我们需要使用 &lt;strong&gt;tcpdump&lt;/strong&gt; 抓包跟踪这两个组件之间的通信，这里假设端口为 &lt;code&gt;20017&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;抓包命令 &lt;code&gt;tcpdump -i any -ASnn port 20017&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;00:39:22.202763 IP 192.168.76.53.21877 &amp;gt; 192.168.76.53.20017: Flags [P.], seq 3399346312:3399346653, ack 3564212561, win 342, length 341
E..}..@.@.&amp;lt;...L5..L5UuN1.....q.QP..V.+..POST /executor(1)/mesos.internal.KillTaskMessage HTTP/1.1
User-Agent: libprocess/slave(1)@192.168.76.53:5051
Libprocess-From: slave(1)@192.168.76.53:5051
Connection: Keep-Alive
Host:
Transfer-Encoding: chunked

6f
+
)5ff75923-a2fd-4959-bb3b-4b128e43e9eb-0000.@
&amp;gt;image.cb5aeece-697b-11e7-ad61-6c92bf2f06d8.1500136612181605046
0

00:44:22.516118 IP 192.168.76.53.21877 &amp;gt; 192.168.76.53.20017: Flags [P.], seq 3399346994:3399347417, ack 3564212561, win 342, length 423
E.....@.@.&amp;lt;...L5..L5UuN1...2.q.QP..V.}..POST /executor(1)/mesos.internal.StatusUpdateAcknowledgementMessage HTTP/1.1
User-Agent: libprocess/slave(1)@192.168.76.53:5051
Libprocess-From: slave(1)@192.168.76.53:5051
Connection: Keep-Alive
Host:
Transfer-Encoding: chunked

ae

+
)5ff75923-a2fd-4959-bb3b-4b128e43e9eb-S353.+
)5ff75923-a2fd-4959-bb3b-4b128e43e9eb-0000.@
&amp;gt;image.cb5aeece-697b-11e7-ad61-6c92bf2f06d8.1500136612181605046&amp;quot;..!....Hn.&#39;.j&amp;amp;.6.
0


00:44:22.516137 IP 192.168.76.53.20017 &amp;gt; 192.168.76.53.21877: Flags [.], ack 3399347417, win 2523, length 0
E..(..@.@.u...L5..L5N1Uu.q.Q....P.      .....
00:44:23.486916 IP 192.168.76.53.20017 &amp;gt; 192.168.76.53.21877: Flags [F.], seq 3564212561, ack 3399347417, win 2523, length 0
E..(..@.@.u...L5..L5N1Uu.q.Q....P.      .....
00:44:23.487507 IP 192.168.76.53.21877 &amp;gt; 192.168.76.53.20017: Flags [F.], seq 3399347417, ack 3564212562, win 342, length 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看 meso-agent 日志如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-mesos-agent-log.png&#34; alt=&#34;mesos-agent-log&#34; /&gt;&lt;/p&gt;

&lt;p&gt;确认 mesos-agent 在 &lt;strong&gt;00:39:22&lt;/strong&gt; 给 mesos-docker-executor 发送了 kill task 的消息，但是 mesos-docker-executor 在 &lt;strong&gt;00:44:22&lt;/strong&gt; 时才回复消息确认实例被停止了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明问题出在 mesos-docker-executor。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;分析-mesos-docker-executor-源码&#34;&gt;分析 mesos-docker-executor 源码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-mesos-docker-executor.png&#34; alt=&#34;mesos-docker-executor&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出，这里有一个很关键的 &lt;code&gt;gracePeriod&lt;/code&gt; 变量，如果停止任务的请求中有设置 &lt;code&gt;killPolicy&lt;/code&gt; 则此值为 &lt;code&gt;killPolicy&lt;/code&gt; 中的值，否则使用默认值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-executor-shutdown-code.png&#34; alt=&#34;shutdown-code&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这个值在 mesos-agent 启动的时候通过 &lt;code&gt;--executor_shutdown_grace_period&lt;/code&gt; 传进去，实际环境中我们配置的是 5 分钟。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2017/2017-07-16-record-problem-resolve-for-docker-stop-slow-docker-stop-code.png&#34; alt=&#34;docker-stop-code&#34; /&gt;&lt;/p&gt;

&lt;p&gt;mesos-docker-executor 会根据 &lt;code&gt;gracePeriod&lt;/code&gt; 的值调用 &lt;code&gt;docker stop -t&lt;/code&gt; 来停止容器。&lt;/p&gt;

&lt;h4 id=&#34;docker-问题排查&#34;&gt;docker 问题排查&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;docker stop&lt;/code&gt; 停止一个容器会先发送 &lt;strong&gt;SIGTERM&lt;/strong&gt; 信号给容器，如果在 &lt;code&gt;-t&lt;/code&gt; 指定的时间仍然没有结束，则发送 &lt;strong&gt;SIGKILL&lt;/strong&gt; 信号强行杀掉。所以问题就是为什么我们的容器收到 &lt;strong&gt;SIGTERM&lt;/strong&gt; 信号后没有退出。&lt;/p&gt;

&lt;p&gt;使用 &lt;code&gt;docker exec -ti {container_name} bash&lt;/code&gt; 登录容器，查看容器内进程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 00:04 ?        00:00:00 /bin/sh /root/start.sh
root         8     1 99 00:04 ?        01:25:14 /root/dora-image -f /root/doraimage.conf
root      1111     0  2 01:23 ?        00:00:00 bash
root      1216  1111  0 01:23 ?        00:00:00 ps -ef
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;手动向 PID 为 1 的进程发送 SIGTERM 信号，结果无响应，到这一步已经定位到问题所在了。&lt;/p&gt;

&lt;p&gt;通过 Google 搜索后了解到原因。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;如果 pid 为 1 的进程，无法向其子进程传递信号，可能导致容器发送 SIGTERM 信号之后，父进程等待子进程退出。此时，如果父进程不能将信号传递到子进程，则整个容器就将无法正常退出，除非向父进程发送 SIGKILL 信号，使其强行退出。&lt;/p&gt;

&lt;p&gt;考虑如下进程树：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;bash（PID 1）

&lt;ul&gt;
&lt;li&gt;app（PID2）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;bash 进程在接受到 SIGTERM 信号的时候，不会向 app 进程传递这个信号，这会导致 app 进程仍然不会退出。对于传统 Linux 系统（bash 进程 PID 不为 1），在 bash进程退出之后，app进程的父进程会被 init 进程（PID 为 1）接管，成为其父进程。但是在容器环境中，这样的行为会使 app 进程失去父进程，因此 bash 进程不会退出。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;解决方案&#34;&gt;解决方案&lt;/h3&gt;

&lt;p&gt;最后找到了一个解决 init 问题的项目 &lt;a href=&#34;https://github.com/krallin/tini&#34;&gt;tini&lt;/a&gt;。而对于我们遇到的问题，目前想到的解决方案有三个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;docker 1.13 及以后的版本已经解决了 init 问题，就是内置了 &lt;strong&gt;tini&lt;/strong&gt;，使 &lt;strong&gt;tini&lt;/strong&gt; 作为 PID  为 1 的进程启动。&lt;/li&gt;
&lt;li&gt;升级 docker 版本难度较大，既然明确了新版本 docker 是如何解决问题的，我们就直接使用 &lt;strong&gt;tini&lt;/strong&gt; 作为 init 进程即可。&lt;/li&gt;
&lt;li&gt;修改 mesos-agent 的启动参数，将 &lt;code&gt;executor_shutdown_grace_period&lt;/code&gt; 设置的短一些，但是这样会影响到其他正常的容器。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;经过考虑，采用方案二较为简单和稳妥。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;对于 mesos 和 docker 的使用姿势还不熟悉，并且这两个项目的生态系统也并不成熟，导致在实际使用的过程中容易遇到各种各样的问题。通过日志，抓包，源码分析等手段相结合，就能够快速地定位到问题，再通过搜索引擎和官方文档资料等来解决问题。如果是一些社区当前还没有解决的问题，可能需要自己修改源码来 fix。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>kubernetes 初探及部署实践</title>
          <link>http://blog.fatedier.com/2016/06/24/demystifying-kubernetes-and-deployment/</link>
          <pubDate>Fri, 24 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/06/24/demystifying-kubernetes-and-deployment/</guid>
          <description>&lt;p&gt;Kubernetes 是 Google 开源的容器集群管理系统，作为 Go 语言开发的热门项目之一，它提供了应用部署、维护、 扩展机制等功能，利用 Kubernetes 能够方便地管理跨机器运行的容器化应用，目前主要是针对 Docker 的管理。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;主要概念&#34;&gt;主要概念&lt;/h3&gt;

&lt;h4 id=&#34;pod&#34;&gt;Pod&lt;/h4&gt;

&lt;p&gt;在 Kubernetes 中是最基本的调度单元，可以包含多个相关的容器，属于同一个 pod 的容器会被运行在同一个机器上，看作一个统一的管理单元。例如我们的一个应用由 nginx、web网站、数据库三部分组成，每一部分都运行在一个单独的容器中，那么我们可以将这三个容器创建成一个 pod。&lt;/p&gt;

&lt;h4 id=&#34;service&#34;&gt;Service&lt;/h4&gt;

&lt;p&gt;Service 是 pod 的路由代理抽象，主要是为了解决 pod 的服务发现问题。因为当有机器出现故障导致容器异常退出时，这个 pod 可能就会被 kubernetes 分配到另外一个正常且资源足够的机器上，此时 IP 地址以及端口都有可能发生变化，所以我们并不能通过 host 的真实 IP 地址和端口来访问。Service 的引入正是为了解决这样的问题，通过 service 这层代理我们就可以访问到 pod 中的容器，目前的版本是通过 iptables 来实现的。&lt;/p&gt;

&lt;h4 id=&#34;replicationcontroller&#34;&gt;ReplicationController&lt;/h4&gt;

&lt;p&gt;ReplicationController 的概念比较简单，从名字就可以看出是用于管理 pod 的多副本运行的。它用于确保 kubernetes 集群中指定的 pod 始终会有指定数量的副本在运行。如果检测到有容器异常退出，replicationController 会立即重新启动新的容器，并且通过 replicationController 我们还可以动态地调整 pod 的副本数量。&lt;/p&gt;

&lt;h4 id=&#34;label&#34;&gt;Label&lt;/h4&gt;

&lt;p&gt;Label 是用于将上述几个概念关联起来的一些 k-v 值。例如我们创建了一个 pod 并且设置了 label 为 &lt;code&gt;app=nginx&lt;/code&gt;，同样在创建 service 和 replicationController 时也设置相同的 label，这样通过 label 的 selector 机制就可以将创建好的 service 和 replicationController 作用在之前创建的 pod 上。&lt;/p&gt;

&lt;h3 id=&#34;主要组件&#34;&gt;主要组件&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-06-24-demystifying-kubernetes-and-deployment-k8s-overview.png&#34; alt=&#34;k8s-overview&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes 集群中主要存在两种类型的节点，分别是 master 节点，以及 minion 节点。&lt;/p&gt;

&lt;p&gt;Minion 节点是实际运行 Docker 容器的节点，负责和节点上运行的 Docker 进行交互，并且提供了代理功能。&lt;/p&gt;

&lt;p&gt;Master 节点负责对外提供一系列管理集群的 API 接口，并且通过和 Minion 节点交互来实现对集群的操作管理。&lt;/p&gt;

&lt;h4 id=&#34;apiserver&#34;&gt;apiserver&lt;/h4&gt;

&lt;p&gt;用户和 kubernetes 集群交互的入口，封装了核心对象的增删改查操作，提供了 RESTFul 风格的 API 接口，通过 etcd 来实现持久化并维护对象的一致性。&lt;/p&gt;

&lt;h4 id=&#34;scheduler&#34;&gt;scheduler&lt;/h4&gt;

&lt;p&gt;负责集群资源的调度和管理，例如当有 pod 异常退出需要重新分配机器时，scheduler 通过一定的调度算法从而找到最合适的节点。&lt;/p&gt;

&lt;h4 id=&#34;controller-manager&#34;&gt;controller-manager&lt;/h4&gt;

&lt;p&gt;主要是用于保证 replicationController 定义的复制数量和实际运行的 pod 数量一致，另外还保证了从 service 到 pod 的映射关系总是最新的。&lt;/p&gt;

&lt;h4 id=&#34;kubelet&#34;&gt;kubelet&lt;/h4&gt;

&lt;p&gt;运行在 minion 节点，负责和节点上的 Docker 交互，例如启停容器，监控运行状态等。&lt;/p&gt;

&lt;h4 id=&#34;proxy&#34;&gt;proxy&lt;/h4&gt;

&lt;p&gt;运行在 minion 节点，负责为 pod 提供代理功能，会定期从 etcd 获取 service 信息，并根据 service 信息通过修改 iptables 来实现流量转发（最初的版本是直接通过程序提供转发功能，效率较低。），将流量转发到要访问的 pod 所在的节点上去。&lt;/p&gt;

&lt;h3 id=&#34;部署实践&#34;&gt;部署实践&lt;/h3&gt;

&lt;p&gt;Kubernetes 的部署十分简单，先从 Github 上下载编译好的二进制文件（我自己尝试编译耗时太久，遂作罢），这里强调简单的原因是因为每个组件并不需要配置文件，而是直接通过启动参数来设置。相比于很多 Java 项目一系列的环境设置，组件搭建，k8s 还是比较友好的。下面主要说一下各个组件常用的启动参数的设置。&lt;/p&gt;

&lt;h4 id=&#34;etcd&#34;&gt;etcd&lt;/h4&gt;

&lt;p&gt;安装并启动 etcd 集群，这里以一台作为示例，比较简单，不具体说明，假设访问地址为 &lt;code&gt;192.168.2.129:2379&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;flannel&#34;&gt;flannel&lt;/h4&gt;

&lt;p&gt;Flannel 是 CoreOS 团队针对 Kubernetes 设计的一个覆盖网络（Overlay Network）工具，需要另外下载部署。我们知道当我们启动 Docker 后会有一个用于和容器进行交互的 IP 地址，如果不去管理的话可能这个 IP 地址在各个机器上是一样的，并且仅限于在本机上进行通信，无法访问到其他机器上的 Docker 容器。&lt;/p&gt;

&lt;p&gt;Flannel 的目的就是为集群中的所有节点重新规划 IP 地址的使用规则，从而使得不同节点上的容器能够获得同属一个内网且不重复的 IP 地址，并让属于不同节点上的容器能够直接通过内网 IP 通信。&lt;/p&gt;

&lt;p&gt;具体实现原理可以参考： &lt;a href=&#34;http://www.open-open.com/news/view/1aa473a&#34;&gt;http://www.open-open.com/news/view/1aa473a&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&#34;安装-flannel&#34;&gt;安装 flannel&lt;/h5&gt;

&lt;p&gt;在 etcd 中创建 flannel 需要用到的键，假设我们 Minion 中 flannel 所使用的子网范围为&lt;code&gt;172.17.1.0~172.17.254.0&lt;/code&gt;（每一个Minion节点都有一个独立的flannel子网）。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;etcdctl mk /coreos.com/network/config &#39;{&amp;quot;Network&amp;quot;:&amp;quot;172.17.0.0/16&amp;quot;, &amp;quot;SubnetMin&amp;quot;: &amp;quot;172.17.1.0&amp;quot;, &amp;quot;SubnetMax&amp;quot;: &amp;quot;172.17.254.0&amp;quot;}&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;启动参数&#34;&gt;启动参数&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;flanneld -etcd-endpoints=http://192.168.2.129:2379 -etcd-prefix=/coreos.com/network --log_dir=./ --logtostderr=false&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-etcd-endpoints: etcd 集群的地址
-etcd-prefix: etcd 中存储 flannel 信息的前缀
--log_dir: 设置日志文件存储目录
--logtostderr: 设置错误信息是否存储到标准输出中
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;修改-docker0-网卡的-ip-地址&#34;&gt;修改 docker0 网卡的 IP 地址&lt;/h5&gt;

&lt;p&gt;默认情况下启动 docker 后会有一个 docker0 的虚拟网卡，每一台机器的 docker0 网卡对应的 ip 地址都是相同的。&lt;/p&gt;

&lt;p&gt;修改启动 docker 的参数，centos7 下可以修改 &lt;code&gt;/usr/lib/systemd/system/docker.service&lt;/code&gt; 文件。&lt;/p&gt;

&lt;p&gt;增加 &lt;code&gt;EnvironmentFile=-/run/flannel/subnet.env&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ExecStart&lt;/code&gt; 增加两个参数 &lt;code&gt;--bip=${FLANNEL_SUBNET}  --mtu=${FLANNEL_MTU}&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;FLANNEL_SUBNET&lt;/code&gt; 和 &lt;code&gt;FLANNEL_MTU&lt;/code&gt; 这两个变量就是从 &lt;code&gt;/run/flannel/subnet.env&lt;/code&gt; 文件中读取，记录了 flannel 在这台机器上被分配到的一个网段。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;systemctl daemon-reload&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;systemctl start docker.service&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后通过 &lt;code&gt;ifconfig&lt;/code&gt; 可以看到 docker0 的网卡 ip 已经变成了 flannel 的网段。&lt;/p&gt;

&lt;h4 id=&#34;kube-apiserver&#34;&gt;kube-apiserver&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-apiserver --logtostderr=false --log-dir=./ --v=0 --etcd-servers=http://192.168.2.129:2379 --address=0.0.0.0 --port=8080 --kubelet-port=10250 --allow-privileged=true --service-cluster-ip-range=10.254.0.0/16&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-scheduler&#34;&gt;kube-scheduler&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-scheduler --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-controller-manager&#34;&gt;kube-controller-manager&lt;/h4&gt;

&lt;p&gt;部署在 Master 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-controller-manager --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kubelet-1&#34;&gt;kubelet &lt;/h4&gt;

&lt;p&gt;部署在 Minion 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubelet --logtostderr=false --log-dir=./ --v=0 --api-servers=http://192.168.2.129:8080 --address=0.0.0.0 --port=10250 --allow-privileged=true&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kube-proxy&#34;&gt;kube-proxy&lt;/h4&gt;

&lt;p&gt;部署在 Minion 节点上。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kube-proxy --logtostderr=false --log-dir=./ --v=0 --master=http://192.168.2.129:8080&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;遇到的问题&#34;&gt;遇到的问题&lt;/h3&gt;

&lt;p&gt;通过上面的步骤，k8s 集群就差不多搭建成功了，但是仍然遇到了一些问题，有的甚至目前还没有找到解决方案，直接导致了我丧失了将 k8s 用于实际开发环境的动力。&lt;/p&gt;

&lt;h4 id=&#34;pause-镜像&#34;&gt;pause 镜像&lt;/h4&gt;

&lt;p&gt;在每个 Minion 节点上的 Docker 需要安装  gcr.io/google_containers/pause 镜像，这个镜像是在 kubernetes 集群启动用户配置的容器时需要用到。&lt;/p&gt;

&lt;p&gt;本来启动容器后会直接从 google 官方源下载，因为墙的原因，在国内无法下载成功，这里可以先从 dockerhub 上下载，&lt;code&gt;sudo docker pull kubernetes/pause&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;之后再打上 tag，&lt;code&gt;sudo docker tag kubernetes/pause gcr.io/google_containers/pause:2.0&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;我装的 &lt;code&gt;kubernetes 1.2.3&lt;/code&gt; 版本对应的 tag 是 &lt;code&gt;pause:2.0&lt;/code&gt;，如果不知道版本，可以尝试运行一个 pod ，之后通过查看错误信息得到。&lt;/p&gt;

&lt;p&gt;后来查看文档发现也可以通过在 kubelet 的启动参数中设置这个镜像的地址，不过还没有测试过。&lt;/p&gt;

&lt;h4 id=&#34;搭建私有-docker-镜像仓库&#34;&gt;搭建私有 docker 镜像仓库&lt;/h4&gt;

&lt;p&gt;为了便于使用，最好自己搭建内网环境的私有镜像仓库，因为 k8s 中每一台机器上的 docker 都需要 pull 镜像到本地，如果从外网环境拉镜像的话效率较低，而且以后更新镜像等操作将变的非常不方便。&lt;/p&gt;

&lt;p&gt;具体的步骤可以参考我之前的一篇文章， &lt;a href=&#34;http://blog.fatedier.com/2016/05/16/install-private-docker-registry/&#34;&gt;『搭建私有docker仓库』&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;service-访问问题&#34;&gt;service 访问问题&lt;/h4&gt;

&lt;p&gt;测试时可以在一台机器上的容器内部通过 service 提供的内网 IP 地址访问到运行在另外一台机器上的容器。但是必须是在容器内部才行，如果直接在这个机器上通过 telnet 或者 curl 访问，则无法正确地根据这个内网 IP 转发到对应节点的容器中。&lt;/p&gt;

&lt;p&gt;因为是通过 iptables 来进行转发，我查看了 iptables 的规则，并没有发现问题，后来通过抓包发现这个包的目的 IP 地址被替换成功了，但是源地址并没有被正确替换，导致对方节点无法正确回复。这个问题我还没有发现具体的原因，目前不能在容器外部通过 service 提供的 IP 地址来访问容器，导致很多应用没有了实际部署的意义，后面有时间还是要研究下。&lt;/p&gt;

&lt;h4 id=&#34;文件存储&#34;&gt;文件存储&lt;/h4&gt;

&lt;p&gt;由于 pod 可能会被在任意一台机器上重新启动，所以并不能简单的像运行单机 Docker 那样将容器内部的目录映射到宿主机的指定目录上，否则将会丢失文件。所以通常我们需要使用类似 NFS、ceph、glusterFS 这样的分布式存储系统来为 k8s 集群提供后端的统一存储。这样一来，无疑就增加了部署的难度，比如要搭建一个靠谱的 ceph 集群，无疑是需要有比较靠谱的运维团队的。&lt;/p&gt;

&lt;h3 id=&#34;测试-nginx-容器&#34;&gt;测试 nginx 容器&lt;/h3&gt;

&lt;h4 id=&#34;创建并启动-replicationcontroller&#34;&gt;创建并启动 replicationController&lt;/h4&gt;

&lt;p&gt;创建配置文件 &lt;code&gt;nginx-rc.yaml&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1 
kind: ReplicationController 
metadata: 
  name: nginx-controller 
spec: 
  replicas: 2 
  selector: 
    name: nginx 
  template: 
    metadata: 
      labels: 
        name: nginx 
    spec: 
      containers: 
        - name: nginx
          image: nginx
          ports: 
            - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里定义了一个 nginx pod 的复制器，复制份数为2。&lt;/p&gt;

&lt;p&gt;执行下面的操作创建nginx pod复制器：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 create -f nginx-rc.yaml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看创建 pod 的状态：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 get pods&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;创建并启动-service&#34;&gt;创建并启动 service&lt;/h4&gt;

&lt;p&gt;Service 的 type 有 ClusterIP 和 NodePort 之分，缺省是 ClusterIP，这种类型的 Service 只能在集群内部访问，而 NodePort 可以在集群外部访问，但是它的原理就是在所有节点上都绑定这个端口，之后将所有的流量转发到正确的节点上。&lt;/p&gt;

&lt;p&gt;创建配置文件 &lt;code&gt;nginx-service-clusterip.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1 
kind: Service 
metadata: 
  name: nginx-service-clusterip 
spec: 
  ports: 
    - port: 8001 
      targetPort: 80 
      protocol: TCP 
  selector: 
    name: nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行下面的命令创建 service：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 create -f ./nginx-service-clusterip.yaml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看 service 提供的 IP 地址和端口：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl -s http://192.168.2.129:8080 get service&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后就可以通过 curl 来验证是否能够成功访问到之前部署的 nginx 容器，由于启用了 service，会自动帮我们进行负载均衡，流量会被分发到后端的多个 pod 中。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>搭建私有docker仓库</title>
          <link>http://blog.fatedier.com/2016/05/16/install-private-docker-registry/</link>
          <pubDate>Mon, 16 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/05/16/install-private-docker-registry/</guid>
          <description>&lt;p&gt;docker 使用起来确实非常方便，易于部署，但是在国内如果要从 DockerHub 上下载镜像实在是一件非常吃力的事，而且公司内部环境使用或者搭建类似 kubernetes 集群的话就需要搭建一个私有的 docker 镜像仓库，方便在集群上快速部署 docker 服务。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;registry-镜像下载&#34;&gt;registry 镜像下载&lt;/h3&gt;

&lt;p&gt;直接下载官方提供的 docker 镜像&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker pull registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里有一点需要注意的比较坑的是官方的 &lt;code&gt;latest&lt;/code&gt; 的镜像指向的是 &lt;code&gt;0.9.1&lt;/code&gt; 版本，使用 python 开发的，已经被废弃了，新版本采用 go 开发，效率和安全方面都提升很多，所以需要手动指定最新的版本。&lt;/p&gt;

&lt;h3 id=&#34;启动-registry-容器&#34;&gt;启动 registry 容器&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker run -d --name registry -p 5000:5000 -v /opt/registry:/var/lib/registry registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;由于需要做目录映射，如果你的机器上开启了 &lt;strong&gt;SELINUX&lt;/strong&gt;，则使用如下命令：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker run -d --name registry -p 5000:5000 -v /opt/registry:/var/lib/registry:Z registry:2.4&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;否则在 docker 容器中可能没有操作此目录的权限，也可以临时关闭 &lt;strong&gt;SELINUX&lt;/strong&gt;，执行 &lt;code&gt;setenforce 0&lt;/code&gt;，永久关闭的话需要修改配置文件 &lt;code&gt;/etc/selinux/config&lt;/code&gt;，将 &lt;code&gt;SELINUX=enforcing&lt;/code&gt; 改为&lt;code&gt;SELINUX=disabled&lt;/code&gt;，并且重启系统。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-p 5000:5000&lt;/strong&gt;： 对外暴露 5000 端口用于提供服务&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-v  /opt/registry:/var/lib/registry&lt;/strong&gt;： 将宿主机的 &lt;code&gt;/opt/registry&lt;/code&gt; 目录映射到容器内的 &lt;code&gt;/var/lib/registry&lt;/code&gt;，这个目录用来存储 docker 的镜像文件，为了持久化存储，不然容器关闭后这些镜像文件会丢失。&lt;/p&gt;

&lt;p&gt;这里根据 registry 镜像的不同版本，存储镜像文件的目录可能并不是 &lt;code&gt;/var/lib/registry&lt;/code&gt;，&lt;code&gt;2.4&lt;/code&gt; 版本是 &lt;code&gt;/var/lib/registry&lt;/code&gt;，如果是其他版本可以查看具体的 Dockerfile 来确认。&lt;/p&gt;

&lt;h3 id=&#34;上传下载镜像&#34;&gt;上传下载镜像&lt;/h3&gt;

&lt;p&gt;由于 docker 的安全策略限制，如果要从私有的仓库上传下载镜像需要修改 docker 的启动参数，把我们自己搭建的 registry 的 ip 地址或者域名添加进来。&lt;/p&gt;

&lt;p&gt;centos7 上的配置文件位置为 &lt;code&gt;/etc/sysconfig/docker&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;设置 &lt;code&gt;INSECURE_REGISTRY=&#39;--insecure-registry 192.168.2.129:5000&#39;&lt;/code&gt;，重启 docker 服务，以后要和这个 registry 交互的机器都需要执行上述步骤。&lt;/p&gt;

&lt;p&gt;另外一个方法就是自己签一组证书，把 &lt;code&gt;ca.crt&lt;/code&gt; 拷贝到 &lt;code&gt;/etc/docker/certs.d/192.168.2.199:5000/ca.crt&lt;/code&gt; 就可以了，这样就不需要重启 docker 服务，这个方法目前还没试过，之后可以尝试一下。&lt;/p&gt;

&lt;h4 id=&#34;上传镜像&#34;&gt;上传镜像&lt;/h4&gt;

&lt;p&gt;给要上传的镜像打上 tag，修改前缀为我们的 registry 的 ip 和 port&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker tag centos 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker push 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;可以看到上传的镜像已经被存储在 /opt/registry 上了&lt;/p&gt;

&lt;h4 id=&#34;下载镜像&#34;&gt;下载镜像&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;docker pull 192.168.2.129:5000/centos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;直接从内网环境下载镜像的速度相当快。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;Registry 的 API 也更新到了 V2 版本，可以通过 HTTP API 对私有仓库进行一些管理操作。具体的说明可以参考 github 上的项目文档 &lt;a href=&#34;https://github.com/docker/distribution。&#34;&gt;https://github.com/docker/distribution。&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>利用docker搭建gitlab及持续集成模块</title>
          <link>http://blog.fatedier.com/2016/04/05/install-gitlab-supporting-ci-with-docker/</link>
          <pubDate>Tue, 05 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/04/05/install-gitlab-supporting-ci-with-docker/</guid>
          <description>&lt;p&gt;版本控制的重要性应该是毋庸置疑了，git 作为现在最流行的版本控制工具，各种规模的公司都在用。通常开源项目都会放在 github 上，基础功能是免费的，私有项目收费。对于一个小团队来说，gitlab 就是另外一个替代品，可以用来搭建自己私有的git服务器。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;为什么需要版本控制和持续继承&#34;&gt;为什么需要版本控制和持续继承？&lt;/h3&gt;

&lt;p&gt;经常听到很多程序员说自己没有时间写测试用例，但其实很多人的时间都花在了手动测试，修复bug，调试程序上。如果写好测试用例，每次提交代码后都自动进行编译，然后将测试用例全部跑一遍，如果测试失败能够获取到足够的反馈信息，这样避免了重复构建测试环境，手动运行测试用例等低效率的工作，而这就是持续集成的好处。&lt;/p&gt;

&lt;h3 id=&#34;准备工作&#34;&gt;准备工作&lt;/h3&gt;

&lt;h4 id=&#34;docker-环境&#34;&gt;docker 环境&lt;/h4&gt;

&lt;p&gt;安装 &lt;code&gt;docker&lt;/code&gt; 环境，&lt;code&gt;centos&lt;/code&gt; 的话可以使用 &lt;code&gt;sudo yum install -y docker&lt;/code&gt; 直接安装&lt;/p&gt;

&lt;p&gt;之后启动 &lt;code&gt;docker&lt;/code&gt;，&lt;code&gt;sudo service docker start&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;docker-镜像加速&#34;&gt;docker 镜像加速&lt;/h4&gt;

&lt;p&gt;由于国内的网络环境过于恶劣，多次尝试从 &lt;a href=&#34;https://gitlab.com/&#34;&gt;gitlab&lt;/a&gt; 官网下载源码安装包未果，之后发现  gitlab 还提供 docker 镜像，这样不仅部署方便，利用国内一些云服务商提供的镜像加速功能，可以加速 docker 镜像的下载。&lt;/p&gt;

&lt;p&gt;推荐 daocloud 的镜像加速服务，&lt;a href=&#34;https://dashboard.daocloud.io/mirror&#34;&gt;https://dashboard.daocloud.io/mirror&lt;/a&gt;，安装之后，使用 &lt;code&gt;dao pull&lt;/code&gt; 替代 &lt;code&gt;docker pull&lt;/code&gt; 即可。&lt;/p&gt;

&lt;h4 id=&#34;下载相关docker镜像&#34;&gt;下载相关docker镜像&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;gitlab/gitlab-ce:latest （gitlab 的 docker镜像）&lt;/li&gt;
&lt;li&gt;gitlab/gitlab-runner:latest （用于持续集成，构建测试环境）&lt;/li&gt;
&lt;li&gt;golang:1.5 （golang基础环境，用于编译代码，运行测试用例）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;启动-gitlab&#34;&gt;启动 gitlab&lt;/h3&gt;

&lt;p&gt;具体的官方说明文档：&lt;a href=&#34;http://doc.gitlab.com/omnibus/docker/README.html&#34;&gt;http://doc.gitlab.com/omnibus/docker/README.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;启动 &lt;code&gt;gitlab&lt;/code&gt; 就是启动相应的 &lt;code&gt;docker&lt;/code&gt; 镜像，设置好相关配置参数，命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --detach \
    --hostname x.x.x.x \
    --publish 7000:443 --publish 80:80 --publish 7002:22 \
    --name gitlab \
    --restart always \
    --volume /srv/gitlab/config:/etc/gitlab \
    --volume /srv/gitlab/logs:/var/log/gitlab \
    --volume /srv/gitlab/data:/var/opt/gitlab \
    gitlab/gitlab-ce:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你的机器开启了 &lt;code&gt;SELINUX&lt;/code&gt;，需要使用如下的命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --detach \
    --hostname x.x.x.x \
    --publish 7000:443 --publish 80:80 --publish 7002:22 \
    --name gitlab \
    --restart always \
    --volume /srv/gitlab/config:/etc/gitlab:Z \
    --volume /srv/gitlab/logs:/var/log/gitlab:Z \
    --volume /srv/gitlab/data:/var/opt/gitlab:Z \
    gitlab/gitlab-ce:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;hostname&lt;/code&gt; 可以是gitlab服务器的ip，也可以是绑定的域名，80端口需要映射到宿主机的80端口，因为之后 &lt;code&gt;github-ci-runner&lt;/code&gt; 会从这个端口下载测试源码。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/srv/gitlab&lt;/code&gt; 是用于持久化 docker 容器中产生的数据，例如 &lt;strong&gt;redis&lt;/strong&gt;，&lt;strong&gt;postgresql&lt;/strong&gt; 等等，gitlab 的docker 镜像中已经内置了这些服务。&lt;/p&gt;

&lt;p&gt;启动成功后，可以通过浏览器访问80端口来使用 gitlab 了，可能是由于我的测试服务器配置较低，等待约2分钟后才能访问。&lt;/p&gt;

&lt;p&gt;初始帐号和密码为 &lt;code&gt;root&lt;/code&gt;  &lt;code&gt;5iveL!fe&lt;/code&gt;，第一次登录成功后需要修改密码。&lt;/p&gt;

&lt;p&gt;gitlab 的具体使用文档比较多，这里就不详细介绍了。&lt;/p&gt;

&lt;h3 id=&#34;创建测试项目&#34;&gt;创建测试项目&lt;/h3&gt;

&lt;p&gt;简单创建一个 &lt;code&gt;test&lt;/code&gt; 项目，先不要提交到 gitlab 仓库。&lt;/p&gt;

&lt;p&gt;包含一个 &lt;code&gt;a.go&lt;/code&gt; 文件，文件内容如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import fmt 

func main() {
    fmt.Printf(&amp;quot;aaa\n&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;可以看到 import 包名没有加双引号，显然编译时就会出错。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;添加-gitlab-ci-yml-文件&#34;&gt;添加 .gitlab-ci.yml 文件&lt;/h4&gt;

&lt;p&gt;配置文件详细内容请参考 &lt;a href=&#34;http://doc.gitlab.com/ce/ci/yaml/README.html&#34;&gt;http://doc.gitlab.com/ce/ci/yaml/README.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里简单写一下，仅仅用于测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;image: golang:1.5

job1:
    script:
        - go build a.go
        - ./a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;image&lt;/code&gt; 表示使用 &lt;code&gt;golang:1.5&lt;/code&gt; 的 docker 镜像来部署编译和测试代码，我们之前已经下好了。&lt;/p&gt;

&lt;p&gt;测试命令有两条，&lt;code&gt;go build a.go&lt;/code&gt; 编译源码， &lt;code&gt;./a&lt;/code&gt; 执行编译后的程序。&lt;/p&gt;

&lt;h3 id=&#34;获取-runner-registration-token&#34;&gt;获取 Runner registration token&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-registration-token.png&#34; alt=&#34;registration-token&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;gitlab&lt;/code&gt; 的管理员配置界面，左边有一个 &lt;code&gt;Runners&lt;/code&gt;，点进去之后可以看到有一个 &lt;code&gt;Registration token&lt;/code&gt;，这个是用于之后创建的 &lt;code&gt;runner&lt;/code&gt; 服务与 &lt;code&gt;gitlab&lt;/code&gt; 通信的时候认证使用。&lt;/p&gt;

&lt;p&gt;例如图中的 &lt;code&gt;Registration token&lt;/code&gt; 为 &lt;code&gt;XKZmVj9t8j4xj1e5k34N&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;启动-runner&#34;&gt;启动 Runner&lt;/h3&gt;

&lt;p&gt;Runner 官方详细说明文档： &lt;a href=&#34;https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/install/docker.md&#34;&gt;https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/install/docker.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Runner&lt;/code&gt;其实就是用于编译和管理测试环境的服务，当 &lt;code&gt;gitlab&lt;/code&gt; 上的项目有 &lt;code&gt;commit&lt;/code&gt; 或 &lt;code&gt;merge&lt;/code&gt; 的时候，&lt;code&gt;Runner&lt;/code&gt; 可以 hook 到相关信息，然后从 &lt;code&gt;gitlab&lt;/code&gt; 上拉取代码，利用 &lt;code&gt;docker&lt;/code&gt; 创建一个新的测试环境，之后执行 &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; 文件中预先配置好的命令。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --name gitlab-runner --restart always \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v /srv/gitlab-runner/config:/etc/gitlab-runner \
      gitlab/gitlab-runner:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你的机器开启了 SELINUX，需要使用如下的命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --name gitlab-runner --restart always \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v /srv/gitlab-runner/config:/etc/gitlab-runner:Z \
      gitlab/gitlab-runner:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;关联-gitlab&#34;&gt;关联 gitlab&lt;/h4&gt;

&lt;p&gt;启动成功后的 &lt;code&gt;Runner&lt;/code&gt; 需要在 &lt;code&gt;gitlab&lt;/code&gt; 上注册，通过在 &lt;code&gt;Runner&lt;/code&gt; 上执行注册命令，会调用 &lt;code&gt;gitlab&lt;/code&gt; 的相关接口注册。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -it gitlab-runner gitlab-runner register

Please enter the gitlab-ci coordinator URL (e.g. [https://gitlab.com/ci](https://gitlab.com/ci) )
[https://gitlab.com/ci](https://gitlab.com/ci)（这里的gitlab.com替换成之前启动gitlab时填写的 hostname）

Please enter the gitlab-ci token for this runner
xxx（填写获取到的 runner registration token）

Please enter the gitlab-ci description for this runner
my
INFO[0034] fcf5c619 Registering runner... succeeded

Please enter the executor: shell, docker, docker-ssh, ssh?
docker

Please enter the Docker image (eg. ruby:2.1):
golang:1.5
INFO[0037] Runner registered successfully. Feel free to start it, but if it&#39;s
running already the config should be automatically reloaded!
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试&#34;&gt;测试&lt;/h3&gt;

&lt;p&gt;利用 &lt;code&gt;docker&lt;/code&gt; 来搭建这套环境还是非常简单的。&lt;/p&gt;

&lt;p&gt;接着提交我们之前创建的两个文件，&lt;code&gt;a.go&lt;/code&gt; 和 &lt;code&gt;.gitlab-ci.yml&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;访问 &lt;code&gt;gitlab&lt;/code&gt; 查看 &lt;code&gt;build&lt;/code&gt; 的结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-commit.png&#34; alt=&#34;test-commit&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到提交记录右边有一个红叉，表示测试未通过，点击红叉，可以看到测试的摘要信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-info.png&#34; alt=&#34;test-info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;继续点 红色的 &lt;code&gt;failed&lt;/code&gt; 按钮就可以看到详细的测试信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-deatil.png&#34; alt=&#34;test-deatil&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从 &lt;code&gt;Runner&lt;/code&gt; 测试过程的输出信息可以看出来，&lt;code&gt;Runner&lt;/code&gt; 先 &lt;code&gt;pull&lt;/code&gt; 我们指定的 &lt;code&gt;docker&lt;/code&gt; 镜像，这里是 &lt;code&gt;golang:1.5&lt;/code&gt;，之后 &lt;code&gt;git clone&lt;/code&gt; 代码到测试环境，然后开始执行测试命令，在执行 &lt;code&gt;go build a.go&lt;/code&gt; 的时候出现了错误，并且显示了错误信息。&lt;/p&gt;

&lt;p&gt;将错误的代码修改后再次提交&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;fmt&amp;quot;
)

func main() {
    fmt.Printf(&amp;quot;aaa\n&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到能够通过测试了，执行程序后的输出 &lt;code&gt;aaa&lt;/code&gt; 也能够看到。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-commit-all.png&#34; alt=&#34;test-commit-all&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-04-05-install-gitlab-supporting-ci-with-docker-test-succ-detail.png&#34; alt=&#34;test-succ-detail&#34; /&gt;&lt;/p&gt;</description>
        </item>
      
    

  </channel>
</rss>
