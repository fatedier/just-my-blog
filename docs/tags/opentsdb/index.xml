<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fatedier blog </title>
    <link>http://blog.fatedier.com/tags/opentsdb/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2017</rights>
    <updated>2016-07-04 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>时间序列数据库调研之OpenTSDB</title>
          <link>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb/</link>
          <pubDate>Mon, 04 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/07/04/research-of-time-series-database-opentsdb/</guid>
          <description>&lt;p&gt;Java 项目，基于 HBase（2.3版本貌似开始支持 Google BigTable 和 Cassandra） 的一个时间序列数据库，被广泛应用于监控系统中。很多大公司都在使用，社区较为活跃。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;测试版本&#34;&gt;测试版本&lt;/h3&gt;

&lt;p&gt;hbase-1.1.5&lt;/p&gt;

&lt;p&gt;opentsdb-2.2.0&lt;/p&gt;

&lt;h3 id=&#34;单机部署&#34;&gt;单机部署&lt;/h3&gt;

&lt;p&gt;单机部署可以参考我之前的一篇文章，集群部署比较复杂，这里仅使用单机进行测试。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/&#34;&gt;OpenTSDB部署与使用&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;

&lt;h4 id=&#34;数据格式&#34;&gt;数据格式&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;metric: 一个可测量的单位的标称。&lt;/li&gt;
&lt;li&gt;tags: 对 metric 的具体描述。&lt;/li&gt;
&lt;li&gt;timestamp: 时间戳。&lt;/li&gt;
&lt;li&gt;value: metric 的实际测量值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;uid&#34;&gt;UID&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，每一个 metric、tagk 或者 tagv 在创建的时候被分配一个唯一标识叫做 UID。在后续的实际存储中，实际上存储的是 UID，而不是它们原本的字符串，UID 占 3个字节（也可以修改源码改为4字节），这样可以节省存储空间。&lt;/p&gt;

&lt;h4 id=&#34;tsuid&#34;&gt;TSUID&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;metric_UID&amp;gt;&amp;lt;timestamp&amp;gt;&amp;lt;tagk1_UID&amp;gt;&amp;lt;tagv1_UID&amp;gt;[...&amp;lt;tagkN_UID&amp;gt;&amp;lt;tagvN_UID&amp;gt;]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;写入 HBase 时的 row key 格式，其中的 metric、tagk 和 tagv 都被转换成了 UID。&lt;/p&gt;

&lt;h4 id=&#34;data-table-schema&#34;&gt;Data Table Schema&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-data-table-schema.png&#34; alt=&#34;data-table-schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RowKey&lt;/strong&gt; 就是上述的 TSUID，除了时间戳占 4 byte，其余 UID 占 3 byte。&lt;/p&gt;

&lt;p&gt;时间戳的部分只保留到了小时粒度，具体相对于小时的偏移量被存储在了 &lt;strong&gt;列族 t&lt;/strong&gt; 中。这样就减小了 HBase 中的存储行数。也就是说对于同一个小时的 metric + tags 相同的数据都会存放在一个 row 下面，这样的设计提高了 row 的检索速度。&lt;/p&gt;

&lt;p&gt;这样的 RowKey 设计使得 metric + tags 相同的数据都会连续存放，且 metric 相同的数据也会连续存放，底层 HBase 中会放在同一 Region 中，在做 Scan 的时候可以快速读取到大片数据，加速查询的过程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;value&lt;/strong&gt; 使用 8 bytes 存储，既可以存储 long,也可以存储 double。&lt;/p&gt;

&lt;h4 id=&#34;compaction&#34;&gt;Compaction&lt;/h4&gt;

&lt;p&gt;在 OpenTSDB 中，会将多列合并到一列之中以减少磁盘占用空间，这个过程会在 TSD 写数据或者查询过程中不定期的发生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7xs9f1.com1.z0.glb.clouddn.com/pic/2016/2016-07-04-research-of-time-series-database-opentsdb-compaction.png&#34; alt=&#34;compaction&#34; /&gt;&lt;/p&gt;

&lt;p&gt;例如图中，将列 1890 和 列 1892 合并到了一起。&lt;/p&gt;

&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;

&lt;p&gt;OpenTSDB 同样提供了一套基于 HTTP 的 API 接口。&lt;/p&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/put&#34;&gt;http://localhost:4242/api/put&lt;/a&gt;, POST&lt;/p&gt;

&lt;p&gt;内容为 JSON 格式，支持同时插入多条数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 18,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web01&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.nice&amp;quot;,
        &amp;quot;timestamp&amp;quot;: 1346846400,
        &amp;quot;value&amp;quot;: 9,
        &amp;quot;tags&amp;quot;: {
           &amp;quot;host&amp;quot;: &amp;quot;web02&amp;quot;,
           &amp;quot;dc&amp;quot;: &amp;quot;lga&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查询数据&#34;&gt;查询数据&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:4242/api/query&#34;&gt;http://localhost:4242/api/query&lt;/a&gt;, POST&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1463452826,
    &amp;quot;end&amp;quot;: 1463453026,
    &amp;quot;globalAnnotations&amp;quot;: true,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;avg&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.disk.usage&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;sys.cpu.load&amp;quot;,
            &amp;quot;downsample&amp;quot;: &amp;quot;60s-avg&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host_id&amp;quot;: &amp;quot;123&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;start&lt;/strong&gt; 和 &lt;strong&gt;end&lt;/strong&gt; 指定了查询的时间范围。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tags&lt;/strong&gt; 指定了过滤条件，2.2 版本中将不被推荐，取而代之的是 filters 参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;downsample&lt;/strong&gt; 聚合计算，例如上面是对每隔60s的数据计算一次平均值。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;OpenTSDB 在存储时间序列数据这一领域拥有很大的优势，被大多数公司所采用，网上的相关文档也比较全面。&lt;/p&gt;

&lt;p&gt;底层存储依托于 HBase，采用特殊设计过的数据存储格式，提供了非常快的查询速度，在此基础之上也更容易横向扩展。&lt;/p&gt;

&lt;p&gt;但是，相对于 InfluxDB 这种即使是新手也可以在两分钟内部署运行完成，OpenTSDB 的部署和运维显然要麻烦很多，由于底层依赖于 HBase，想要大规模运行起来，需要相当专业、细心的运维工作。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>OpenTSDB部署与使用</title>
          <link>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/</link>
          <pubDate>Sat, 12 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://blog.fatedier.com/2016/03/12/install-and-use-opentsdb/</guid>
          <description>&lt;p&gt;OpenTSDB 是基于 HBase 存储时间序列数据的一个开源数据库，对于存储监控系统采集的数据来说非常合适，不仅在写入查询上有很高的效率，而且节省存储空间。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装-hbase&#34;&gt;安装 HBase&lt;/h3&gt;

&lt;p&gt;因为 OpenTSDB 的后端存储使用的是 HBase，所以我们需要先安装 HBase。&lt;/p&gt;

&lt;p&gt;参考文档： &lt;a href=&#34;https://hbase.apache.org/book.html#quickstart&#34;&gt;Quick Start - Standalone HBase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里简单搭建了一个&lt;strong&gt;单机&lt;/strong&gt;的 HBase 环境：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;安装 JDK 环境，centos 上可以直接通过 yum 安装。&lt;/li&gt;
&lt;li&gt;下载 HBase，&lt;a href=&#34;http://apache.fayea.com/hbase/stable&#34;&gt;http://apache.fayea.com/hbase/stable&lt;/a&gt;，这里我们选择下载 stable 的 1.1.3 版本，文件名为 &lt;code&gt;hbase-1.1.3-bin.tar.gz&lt;/code&gt;，解压到任意目录。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-env.sh&lt;/code&gt; ，设置  &lt;code&gt;JAVA_HOME=/usr&lt;/code&gt;，这个是 &lt;code&gt;/bin/java&lt;/code&gt; 所在的目录，通过 &lt;code&gt;which java&lt;/code&gt; 查看。&lt;/li&gt;
&lt;li&gt;修改 &lt;code&gt;conf/hbase-site.xml&lt;/code&gt;， 设置 hbase 的数据存储目录以及 zookeeper 的数据存储目录，默认会放到 &lt;code&gt;/tmp&lt;/code&gt; 目录下，这个目录机器重启后会清空，所以需要更改目录。&lt;/li&gt;
&lt;li&gt;执行 &lt;code&gt;bin/start-hbase.sh&lt;/code&gt; 启动 HBase，之后可以通过 &lt;code&gt;jps&lt;/code&gt; 命令来查看 HMaster 进程是否启动成功。 &lt;code&gt;bin/stop-hbase.sh&lt;/code&gt; 用于关闭 HBase。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;conf/hbase-site.xml&lt;/code&gt; 的配置示例如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/testuser/hbase&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/testuser/zookeeper&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过命令行操作-hbase&#34;&gt;通过命令行操作 HBase&lt;/h3&gt;

&lt;p&gt;这里可以稍微熟悉一下 HBase 的操作，非必须。&lt;/p&gt;

&lt;h5 id=&#34;连接到-hbase&#34;&gt;连接到 HBase&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;./bin/hbase shell&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;创建一张表&#34;&gt;创建一张表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;create &#39;test&#39;, &#39;cf&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看表信息&#34;&gt;查看表信息&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;list &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;向表中插入数据&#34;&gt;向表中插入数据&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;
put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;
put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;查看表中所有数据&#34;&gt;查看表中所有数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;scan &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;查看指定行的数据&#34;&gt;查看指定行的数据&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;get &#39;test&#39;, &#39;row1&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;禁用指定表-删除表或修改表设置前需要先禁用该表&#34;&gt;禁用指定表（删除表或修改表设置前需要先禁用该表）&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;disable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;恢复指定表&#34;&gt;恢复指定表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;enable &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&#34;删除表&#34;&gt;删除表&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;drop &#39;test&#39;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装opentsdb&#34;&gt;安装OpenTSDB&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://debugo.com/opentsdb/&#34;&gt;http://debugo.com/opentsdb/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&#34;&gt;http://opentsdb.net/docs/build/html/installation.html#runtime-requirements&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;直接从 github 上下载 OpenTSDB 的 &lt;a href=&#34;https://github.com/OpenTSDB/opentsdb&#34;&gt;release&lt;/a&gt; 版本的 RPM 包。安装 &lt;code&gt;yum localinstall opentsdb-2.2.0.noarch.rpm&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置完成后，我们通过下面命令在 HBase 中建立 opentsdb 所需的表。默认情况下 opentsdb 建立的 HBase 表启用了 lzo 压缩。需要开启 Hadoop 中的 lzo 压缩支持， 这里我们直接在下面脚本中把 COMPRESSION 的支持关闭。修改 &lt;code&gt;/usr/share/opentsdb/tools/create_table.sh&lt;/code&gt;，设置 &lt;code&gt;COMPRESSION=NONE&lt;/code&gt;，并且在文件开始处设置 HBase 所在目录， &lt;code&gt;HBASE_HOME=/home/xxx/hbase-1.1.3&lt;/code&gt;。之后执行该脚本，在 HBase 中创建相应的表。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;修改 OpenTSDB 的配置文件，&lt;code&gt;/etc/opentsdb/opentsdb.conf&lt;/code&gt;，例如绑定的端口号等。&lt;strong&gt;这里需要注意的是 tsd.core.auto_create_metrics 从 false 改为 true。这样上传数据时会自动创建 metric，否则会提示 Unknown metric 的错误。也可以设置为 false，但是使用 &lt;code&gt;tsdb mkmetric proc.loadavg.1m&lt;/code&gt; 来手动添加 metric。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;启动 OpenTSDB，&lt;code&gt;service opentsdb start&lt;/code&gt; 或者 &lt;code&gt;nohup tsdb tsd &amp;amp;&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过浏览器访问 &lt;a href=&#34;http://x.x.x.x:4242&#34;&gt;http://x.x.x.x:4242&lt;/a&gt; 查看是否安装成功。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;http-api&#34;&gt;HTTP API&lt;/h3&gt;

&lt;h4 id=&#34;插入数据&#34;&gt;插入数据&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;/api/put&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据 url 参数的不同，可以选择是否获取详细的信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;/api/put?summary&lt;/strong&gt;        // 返回失败和成功的个数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;/api/put?details&lt;/strong&gt;        // 返回详细信息&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;errors&amp;quot;: [],
    &amp;quot;failed&amp;quot;: 0,
    &amp;quot;success&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过POST方式插入数据，JSON格式，例如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;metric&amp;quot;:&amp;quot;self.test&amp;quot;, 
    &amp;quot;timestamp&amp;quot;:1456123787, 
    &amp;quot;value&amp;quot;:20, 
    &amp;quot;tags&amp;quot;:{
        &amp;quot;host&amp;quot;:&amp;quot;web1&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查询数据&#34;&gt;查询数据&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;/api/query&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可以选择 Get 或者 Post 两种方式，推荐使用 Post 方式，JSON 格式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;start&amp;quot;: 1456123705,
    &amp;quot;end&amp;quot;: 1456124985,
    &amp;quot;queries&amp;quot;: [
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
            }
        },
        {
            &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
            &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
            &amp;quot;tags&amp;quot;: {
                &amp;quot;host&amp;quot;: &amp;quot;web2&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;start 和 end 为指定的查询时间段。&lt;/p&gt;

&lt;p&gt;queries 为一个数组，可以指定多个查询。&lt;/p&gt;

&lt;p&gt;metric 和 tags 是用于过滤的查询条件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;返回字符串也为json格式&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {},
        &amp;quot;aggregateTags&amp;quot;: [
            &amp;quot;host&amp;quot;
        ],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123785&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 10
        }
    },
    {
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        },
        &amp;quot;aggregateTags&amp;quot;: [],
        &amp;quot;dps&amp;quot;: {
            &amp;quot;1456123784&amp;quot;: 10,
            &amp;quot;1456123786&amp;quot;: 15
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;聚合&#34;&gt;聚合&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;aggregator&lt;/strong&gt; 是用于对查询结果进行聚合，将同一 unix 时间戳内的数据进行聚合计算后返回结果，例如如果 tags 不填，1456123705 有两条数据，一条 &lt;code&gt;host=web1&lt;/code&gt;，另外一条 &lt;code&gt;host=web2&lt;/code&gt;，值都为10，那么返回的该时间点的值为 sum 后的 20。&lt;/p&gt;

&lt;h4 id=&#34;条件过滤&#34;&gt;条件过滤&lt;/h4&gt;

&lt;p&gt;可以针对 tag 进行一些条件的过滤，返回 tag 中 host 的值以 web 开头的数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;filters&amp;quot;: [
            {
                &amp;quot;type&amp;quot;: &amp;quot;wildcard&amp;quot;,
                &amp;quot;tagk&amp;quot;: &amp;quot;host&amp;quot;,
                &amp;quot;filter&amp;quot;: &amp;quot;web*&amp;quot;
            }
        ]
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;downsample&#34;&gt;downsample&lt;/h4&gt;

&lt;p&gt;简单来说就是对指定时间段内的数据进行聚合后返回，例如需要返回每分钟的平均值数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;queries&amp;quot;: [
    {
        &amp;quot;aggregator&amp;quot;: &amp;quot;sum&amp;quot;,
        &amp;quot;metric&amp;quot;: &amp;quot;self.test&amp;quot;,
        &amp;quot;downsample&amp;quot;: &amp;quot;1m-avg&amp;quot;,
        &amp;quot;tags&amp;quot;: {
            &amp;quot;host&amp;quot;: &amp;quot;web1&amp;quot;
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    

  </channel>
</rss>
